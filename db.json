{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/0.png","path":"img/0.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/head.png","path":"img/head.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/1.png","path":"img/hexo/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/2.png","path":"img/hexo/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/3.png","path":"img/hexo/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/5.png","path":"img/hexo/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/4.png","path":"img/hexo/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/6.png","path":"img/hexo/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/7.png","path":"img/hexo/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/8.png","path":"img/hexo/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/1.png","path":"img/datastruct/2_linearlist/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/2.png","path":"img/datastruct/2_linearlist/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/3.png","path":"img/datastruct/2_linearlist/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/4.png","path":"img/datastruct/2_linearlist/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/5.png","path":"img/datastruct/2_linearlist/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/1.png","path":"img/datastruct/1_extract/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/2.png","path":"img/datastruct/1_extract/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/3.png","path":"img/datastruct/1_extract/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/5.png","path":"img/datastruct/1_extract/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/4.png","path":"img/datastruct/1_extract/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/8.png","path":"img/datastruct/1_extract/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/6.png","path":"img/datastruct/1_extract/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/7.png","path":"img/datastruct/1_extract/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/1_extract/9.png","path":"img/datastruct/1_extract/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/1.png","path":"img/datastruct/4_string/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/11.png","path":"img/datastruct/4_string/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/2.png","path":"img/datastruct/4_string/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/22.png","path":"img/datastruct/4_string/22.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/3.png","path":"img/datastruct/4_string/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/33.png","path":"img/datastruct/4_string/33.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/4.png","path":"img/datastruct/4_string/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/6.png","path":"img/datastruct/4_string/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/7.png","path":"img/datastruct/4_string/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/5.png","path":"img/datastruct/4_string/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/8.png","path":"img/datastruct/4_string/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/4_string/9.png","path":"img/datastruct/4_string/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/website/1.png","path":"img/experience/website/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/website/3.png","path":"img/experience/website/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/website/2.png","path":"img/experience/website/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/commend/4.png","path":"img/linux/commend/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/commend/5.png","path":"img/linux/commend/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/commend/6.png","path":"img/linux/commend/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/commend/7.png","path":"img/linux/commend/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/config/1.png","path":"img/hexo/config/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/hexo/config/2.png","path":"img/hexo/config/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/install/1.png","path":"img/linux/install/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/install/2.png","path":"img/linux/install/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/install/3.png","path":"img/linux/install/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/user/8.png","path":"img/linux/user/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png","path":"img/datastruct/2_linearlist/doublelinklist/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png","path":"img/datastruct/2_linearlist/doublelinklist/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png","path":"img/datastruct/2_linearlist/doublelinklist/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png","path":"img/datastruct/2_linearlist/doublelinklist/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png","path":"img/datastruct/2_linearlist/doublelinklist/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png","path":"img/datastruct/2_linearlist/linklist/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png","path":"img/datastruct/2_linearlist/linklist/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png","path":"img/datastruct/2_linearlist/linklist/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png","path":"img/datastruct/2_linearlist/linklist/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png","path":"img/datastruct/2_linearlist/linklist/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png","path":"img/datastruct/2_linearlist/linklist/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/1.png","path":"img/datastruct/3_stack/exam/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/3.png","path":"img/datastruct/3_stack/exam/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/2.png","path":"img/datastruct/3_stack/exam/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/5.png","path":"img/datastruct/3_stack/exam/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/4.png","path":"img/datastruct/3_stack/exam/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/6.png","path":"img/datastruct/3_stack/exam/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/1.png","path":"img/datastruct/3_stack/matrix/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/2.png","path":"img/datastruct/3_stack/matrix/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/3.png","path":"img/datastruct/3_stack/matrix/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/4.png","path":"img/datastruct/3_stack/matrix/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/5.png","path":"img/datastruct/3_stack/matrix/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/6.png","path":"img/datastruct/3_stack/matrix/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/7.png","path":"img/datastruct/3_stack/matrix/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/8.png","path":"img/datastruct/3_stack/matrix/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/9.png","path":"img/datastruct/3_stack/matrix/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/1.png","path":"img/datastruct/3_stack/queue/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/2.png","path":"img/datastruct/3_stack/queue/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/3.png","path":"img/datastruct/3_stack/queue/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/4.png","path":"img/datastruct/3_stack/queue/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/5.png","path":"img/datastruct/3_stack/queue/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/1.png","path":"img/datastruct/3_stack/stack/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/1.png","path":"img/datastruct/5_tree/bintree/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/2.png","path":"img/datastruct/3_stack/stack/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/3.png","path":"img/datastruct/3_stack/stack/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/4.png","path":"img/datastruct/3_stack/stack/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/10.png","path":"img/datastruct/5_tree/bintree/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/11.png","path":"img/datastruct/5_tree/bintree/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/13.png","path":"img/datastruct/5_tree/bintree/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/12.png","path":"img/datastruct/5_tree/bintree/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/14.png","path":"img/datastruct/5_tree/bintree/14.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/15.png","path":"img/datastruct/5_tree/bintree/15.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/17.png","path":"img/datastruct/5_tree/bintree/17.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/16.png","path":"img/datastruct/5_tree/bintree/16.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/18.png","path":"img/datastruct/5_tree/bintree/18.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/19.png","path":"img/datastruct/5_tree/bintree/19.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/21.png","path":"img/datastruct/5_tree/bintree/21.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/2.png","path":"img/datastruct/5_tree/bintree/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/22.png","path":"img/datastruct/5_tree/bintree/22.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/20.png","path":"img/datastruct/5_tree/bintree/20.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/3.png","path":"img/datastruct/5_tree/bintree/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/4.png","path":"img/datastruct/5_tree/bintree/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/5.png","path":"img/datastruct/5_tree/bintree/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/6.png","path":"img/datastruct/5_tree/bintree/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/7.png","path":"img/datastruct/5_tree/bintree/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/8.png","path":"img/datastruct/5_tree/bintree/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/9.png","path":"img/datastruct/5_tree/bintree/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/1.png","path":"img/datastruct/5_tree/set/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/2.png","path":"img/datastruct/5_tree/set/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/3.png","path":"img/datastruct/5_tree/set/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png","path":"img/datastruct/5_tree/hafmantree/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/4.png","path":"img/datastruct/5_tree/set/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/5.png","path":"img/datastruct/5_tree/set/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png","path":"img/datastruct/5_tree/hafmantree/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png","path":"img/datastruct/5_tree/hafmantree/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png","path":"img/datastruct/5_tree/hafmantree/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/1.png","path":"img/datastruct/5_tree/tree/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/2.png","path":"img/datastruct/5_tree/tree/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/3.png","path":"img/datastruct/5_tree/tree/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/2.png","path":"img/datastruct/5_tree/treesave/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/1.png","path":"img/datastruct/5_tree/treesave/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/4.png","path":"img/datastruct/5_tree/treesave/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/3.png","path":"img/datastruct/5_tree/treesave/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/5.png","path":"img/datastruct/5_tree/treesave/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/6.png","path":"img/datastruct/5_tree/treesave/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/7.png","path":"img/datastruct/5_tree/treesave/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/8.png","path":"img/datastruct/5_tree/treesave/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/1.png","path":"img/datastruct/6_graph/DAG/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/11.png","path":"img/datastruct/6_graph/DAG/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/12.png","path":"img/datastruct/6_graph/DAG/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/10.png","path":"img/datastruct/6_graph/DAG/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/13.png","path":"img/datastruct/6_graph/DAG/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/2.png","path":"img/datastruct/6_graph/DAG/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/3.png","path":"img/datastruct/6_graph/DAG/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/4.png","path":"img/datastruct/6_graph/DAG/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/6.png","path":"img/datastruct/6_graph/DAG/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/5.png","path":"img/datastruct/6_graph/DAG/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/7.png","path":"img/datastruct/6_graph/DAG/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/8.png","path":"img/datastruct/6_graph/DAG/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/9.png","path":"img/datastruct/6_graph/DAG/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/1.png","path":"img/datastruct/6_graph/generatetree/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/10.png","path":"img/datastruct/6_graph/generatetree/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/3.png","path":"img/datastruct/6_graph/generatetree/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/2.png","path":"img/datastruct/6_graph/generatetree/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/4.png","path":"img/datastruct/6_graph/generatetree/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/5.png","path":"img/datastruct/6_graph/generatetree/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/6.png","path":"img/datastruct/6_graph/generatetree/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/7.png","path":"img/datastruct/6_graph/generatetree/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/8.png","path":"img/datastruct/6_graph/generatetree/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/9.png","path":"img/datastruct/6_graph/generatetree/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/1.png","path":"img/datastruct/6_graph/graph/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/10.png","path":"img/datastruct/6_graph/graph/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/11.png","path":"img/datastruct/6_graph/graph/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/12.png","path":"img/datastruct/6_graph/graph/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/13.png","path":"img/datastruct/6_graph/graph/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/14.png","path":"img/datastruct/6_graph/graph/14.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/15.png","path":"img/datastruct/6_graph/graph/15.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/16.png","path":"img/datastruct/6_graph/graph/16.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/17.png","path":"img/datastruct/6_graph/graph/17.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/18.png","path":"img/datastruct/6_graph/graph/18.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/19.png","path":"img/datastruct/6_graph/graph/19.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/2.png","path":"img/datastruct/6_graph/graph/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/20.png","path":"img/datastruct/6_graph/graph/20.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/22.png","path":"img/datastruct/6_graph/graph/22.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/21.png","path":"img/datastruct/6_graph/graph/21.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/23.png","path":"img/datastruct/6_graph/graph/23.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/24.png","path":"img/datastruct/6_graph/graph/24.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/25.png","path":"img/datastruct/6_graph/graph/25.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/26.png","path":"img/datastruct/6_graph/graph/26.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/3.png","path":"img/datastruct/6_graph/graph/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/4.png","path":"img/datastruct/6_graph/graph/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/5.png","path":"img/datastruct/6_graph/graph/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/6.png","path":"img/datastruct/6_graph/graph/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/7.png","path":"img/datastruct/6_graph/graph/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/8.png","path":"img/datastruct/6_graph/graph/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/9.png","path":"img/datastruct/6_graph/graph/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/1.png","path":"img/datastruct/7_search/AVL/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/2.png","path":"img/datastruct/7_search/AVL/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/3.png","path":"img/datastruct/7_search/AVL/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/4.png","path":"img/datastruct/7_search/AVL/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/5.png","path":"img/datastruct/7_search/AVL/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/6.png","path":"img/datastruct/7_search/AVL/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/7.png","path":"img/datastruct/7_search/AVL/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png","path":"img/datastruct/6_graph/shortestpath/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png","path":"img/datastruct/6_graph/shortestpath/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png","path":"img/datastruct/6_graph/shortestpath/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png","path":"img/datastruct/6_graph/shortestpath/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png","path":"img/datastruct/6_graph/shortestpath/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png","path":"img/datastruct/6_graph/shortestpath/14.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png","path":"img/datastruct/6_graph/shortestpath/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png","path":"img/datastruct/6_graph/shortestpath/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png","path":"img/datastruct/6_graph/shortestpath/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png","path":"img/datastruct/6_graph/shortestpath/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png","path":"img/datastruct/6_graph/shortestpath/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png","path":"img/datastruct/6_graph/shortestpath/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/B/1.png","path":"img/datastruct/7_search/B/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png","path":"img/datastruct/6_graph/shortestpath/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png","path":"img/datastruct/6_graph/shortestpath/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/1.png","path":"img/datastruct/7_search/BST/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/2.png","path":"img/datastruct/7_search/BST/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/3.png","path":"img/datastruct/7_search/BST/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/4.png","path":"img/datastruct/7_search/BST/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/身份证2.jpg","path":"img/datastruct/7_search/BST/身份证2.jpg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/身份证1.jpg","path":"img/datastruct/7_search/BST/身份证1.jpg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/1.png","path":"img/datastruct/7_search/search/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/3.png","path":"img/datastruct/7_search/search/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/2.png","path":"img/datastruct/7_search/search/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/4.png","path":"img/datastruct/7_search/search/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/5.png","path":"img/datastruct/7_search/search/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/6.png","path":"img/datastruct/7_search/search/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/red/2.png","path":"img/datastruct/7_search/red/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/7.png","path":"img/datastruct/7_search/search/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/search/8.png","path":"img/datastruct/7_search/search/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/red/1.png","path":"img/datastruct/7_search/red/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/red/3.png","path":"img/datastruct/7_search/red/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/red/5.png","path":"img/datastruct/7_search/red/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/datastruct/7_search/red/4.png","path":"img/datastruct/7_search/red/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/1.png","path":"img/experience/pycharm/link_server/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/10.png","path":"img/experience/pycharm/link_server/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/11.png","path":"img/experience/pycharm/link_server/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/2.png","path":"img/experience/pycharm/link_server/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/3.png","path":"img/experience/pycharm/link_server/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/5.png","path":"img/experience/pycharm/link_server/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/4.png","path":"img/experience/pycharm/link_server/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/6.png","path":"img/experience/pycharm/link_server/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/7.png","path":"img/experience/pycharm/link_server/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/8.png","path":"img/experience/pycharm/link_server/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/9.png","path":"img/experience/pycharm/link_server/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/1.png","path":"img/experience/app/lrc_to_smi/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/3.png","path":"img/experience/app/lrc_to_smi/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/2.png","path":"img/experience/app/lrc_to_smi/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/vscode/relative_path/1.png","path":"img/experience/vscode/relative_path/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/4.png","path":"img/experience/app/lrc_to_smi/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/5.png","path":"img/experience/app/lrc_to_smi/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/vscode/relative_path/2.png","path":"img/experience/vscode/relative_path/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/1.png","path":"img/deeplearning/paper/SR/CDM/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/2.png","path":"img/deeplearning/paper/SR/CDM/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/3.png","path":"img/deeplearning/paper/SR/CDM/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/11.png","path":"img/deeplearning/paper/SR/HAT/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/1.png","path":"img/deeplearning/paper/SR/HAT/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/2.png","path":"img/deeplearning/paper/SR/HAT/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/3.png","path":"img/deeplearning/paper/SR/HAT/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/4.png","path":"img/deeplearning/paper/SR/HAT/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/5.png","path":"img/deeplearning/paper/SR/HAT/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/6.png","path":"img/deeplearning/paper/SR/HAT/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/7.png","path":"img/deeplearning/paper/SR/HAT/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/8.png","path":"img/deeplearning/paper/SR/HAT/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/9.png","path":"img/deeplearning/paper/SR/HAT/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/1.png","path":"img/deeplearning/paper/SR/SRDiff/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/2.png","path":"img/deeplearning/paper/SR/SRDiff/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/3.png","path":"img/deeplearning/paper/SR/SRDiff/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/10.png","path":"img/deeplearning/paper/SR/SwinIR/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png","path":"img/deeplearning/paper/SR/SwinIR/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/11.png","path":"img/deeplearning/paper/SR/SwinIR/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/12.png","path":"img/deeplearning/paper/SR/SwinIR/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/13.png","path":"img/deeplearning/paper/SR/SwinIR/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/2.png","path":"img/deeplearning/paper/SR/SwinIR/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/3.png","path":"img/deeplearning/paper/SR/SwinIR/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/5.png","path":"img/deeplearning/paper/SR/SwinIR/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/4.png","path":"img/deeplearning/paper/SR/SwinIR/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/6.png","path":"img/deeplearning/paper/SR/SwinIR/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/8.png","path":"img/deeplearning/paper/SR/SwinIR/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/7.png","path":"img/deeplearning/paper/SR/SwinIR/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/9.png","path":"img/deeplearning/paper/SR/SwinIR/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_1_1.svg","path":"img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_1_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_3_1.svg","path":"img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_3_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg","path":"img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png","path":"img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png","path":"img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg","path":"img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1img/1.png","path":"img/deeplearning/code/pytorch/3_mlp/1img/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png","path":"img/deeplearning/code/pytorch/3_mlp/4img/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png","path":"img/deeplearning/code/pytorch/3_mlp/6img/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/1.png","path":"img/java/produce_practice/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/10.png","path":"img/java/produce_practice/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/11.png","path":"img/java/produce_practice/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/12.png","path":"img/java/produce_practice/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/13.png","path":"img/java/produce_practice/13.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/14.png","path":"img/java/produce_practice/14.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/15.png","path":"img/java/produce_practice/15.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/16.png","path":"img/java/produce_practice/16.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/17.png","path":"img/java/produce_practice/17.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/18.png","path":"img/java/produce_practice/18.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/20.png","path":"img/java/produce_practice/20.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/19.png","path":"img/java/produce_practice/19.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/23.png","path":"img/java/produce_practice/23.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/21.png","path":"img/java/produce_practice/21.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/3.png","path":"img/java/produce_practice/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/35.png","path":"img/java/produce_practice/35.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4.png","path":"img/java/produce_practice/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/5.png","path":"img/java/produce_practice/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/7.png","path":"img/java/produce_practice/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/6.png","path":"img/java/produce_practice/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/8.png","path":"img/java/produce_practice/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/9.png","path":"img/java/produce_practice/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/1.png","path":"img/linux/usage/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/10.png","path":"img/linux/usage/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/3.png","path":"img/linux/usage/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/4.png","path":"img/linux/usage/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/2.png","path":"img/linux/usage/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/5.png","path":"img/linux/usage/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/6.png","path":"img/linux/usage/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/7.png","path":"img/linux/usage/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/8.png","path":"img/linux/usage/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linux/usage/9.png","path":"img/linux/usage/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/1.png","path":"img/experience/app/word/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/1.png","path":"img/java/produce_practice/2/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/2.png","path":"img/java/produce_practice/2/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/10.png","path":"img/java/produce_practice/2/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/3.png","path":"img/java/produce_practice/2/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/4.png","path":"img/java/produce_practice/2/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/5.png","path":"img/java/produce_practice/2/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/6.png","path":"img/java/produce_practice/2/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/7.png","path":"img/java/produce_practice/2/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/8.png","path":"img/java/produce_practice/2/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/2/9.png","path":"img/java/produce_practice/2/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/3/1.png","path":"img/java/produce_practice/3/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/3/2.png","path":"img/java/produce_practice/3/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/3/3.png","path":"img/java/produce_practice/3/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/1.png","path":"img/java/produce_practice/4/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/2.png","path":"img/java/produce_practice/4/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/5.png","path":"img/java/produce_practice/4/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/3.png","path":"img/java/produce_practice/4/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/4.png","path":"img/java/produce_practice/4/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/7.png","path":"img/java/produce_practice/4/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/6.png","path":"img/java/produce_practice/4/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/4/8.png","path":"img/java/produce_practice/4/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/5/1.png","path":"img/java/produce_practice/5/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/5/2.png","path":"img/java/produce_practice/5/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/5/3.png","path":"img/java/produce_practice/5/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/10.png","path":"img/java/produce_practice/0/10.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/1.png","path":"img/java/produce_practice/0/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/11.png","path":"img/java/produce_practice/0/11.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/12.png","path":"img/java/produce_practice/0/12.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/2.png","path":"img/java/produce_practice/0/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/4.png","path":"img/java/produce_practice/0/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/5.png","path":"img/java/produce_practice/0/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/7.png","path":"img/java/produce_practice/0/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/6.png","path":"img/java/produce_practice/0/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/8.png","path":"img/java/produce_practice/0/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/0/9.png","path":"img/java/produce_practice/0/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/1.png","path":"img/experience/keyboard/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/3.png","path":"img/experience/keyboard/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/2.png","path":"img/experience/keyboard/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/4.png","path":"img/experience/keyboard/4.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/5.png","path":"img/experience/keyboard/5.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/7.png","path":"img/experience/keyboard/7.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/6.png","path":"img/experience/keyboard/6.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/8.png","path":"img/experience/keyboard/8.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/keyboard/9.png","path":"img/experience/keyboard/9.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/windows/ssh/2.png","path":"img/experience/windows/ssh/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/windows/ssh/1.png","path":"img/experience/windows/ssh/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/windows/ssh/3.png","path":"img/experience/windows/ssh/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/6/0.png","path":"img/java/produce_practice/6/0.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/6/1.png","path":"img/java/produce_practice/6/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/6/2.png","path":"img/java/produce_practice/6/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/java/produce_practice/6/3.png","path":"img/java/produce_practice/6/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/windows/powershell/1.png","path":"img/experience/windows/powershell/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/windows/powershell/2.png","path":"img/experience/windows/powershell/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/mouse/1.png","path":"img/experience/app/mouse/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/mouse/2.png","path":"img/experience/app/mouse/2.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/mouse/3.png","path":"img/experience/app/mouse/3.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/7/1.png","path":"img/deeplearning/code/pytorch/3_mlp/7/1.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/to_pdf/1.png","path":"img/experience/app/word/to_pdf/1.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/to_pdf/2.png","path":"img/experience/app/word/to_pdf/2.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/0.png","path":"img/experience/app/word/page/0.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/1.png","path":"img/experience/app/word/page/1.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/2.png","path":"img/experience/app/word/page/2.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/3.png","path":"img/experience/app/word/page/3.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/4.png","path":"img/experience/app/word/page/4.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/5.png","path":"img/experience/app/word/page/5.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/experience/app/word/page/6.png","path":"img/experience/app/word/page/6.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/2.png","path":"img/deeplearning/code/pytorch/2_linear_neural_network/4img/2.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/3.png","path":"img/deeplearning/code/pytorch/2_linear_neural_network/4img/3.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg","path":"img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg","path":"img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/_drafts/1_DDPM.md","hash":"7671adbb402c865080617b04082d61c62320c72b","modified":1698118711023},{"_id":"source/_drafts/progress1.md","hash":"c51366bc76ec2d0499a9c5ef02c18724cb53460a","modified":1677147418035},{"_id":"source/_drafts/yilia配置.md","hash":"652c0eaa09d219c5ba9cd082b86c3cf5eb632811","modified":1708574709517},{"_id":"source/categories/index.md","hash":"736c605a6585b78360deb7eaea3451f3e4b4eeac","modified":1690344261211},{"_id":"source/tags/index.md","hash":"a9b6dfbb10c311720b9d8e66804f219f91f2bd19","modified":1698055450779},{"_id":"source/_posts/linux/Linux_2.用户和权限.md","hash":"d39f88945bfc625aefd54d786812a6b2cb130460","modified":1709347612786},{"_id":"source/_posts/hexo/hexo搭建.md","hash":"55349b8e1cb1de2f13bbbb07f088064af5769f32","modified":1706182457268},{"_id":"source/_posts/linux/Linux_1.基础命令.md","hash":"d438178ca6e6695de63483ed108503ac0917123c","modified":1709349153280},{"_id":"source/_posts/linux/Linux_0安装.md","hash":"87c6ad8b50edf4efeaaf5d0916c205539a8a27ee","modified":1709347458204},{"_id":"source/_posts/hexo/latex.md","hash":"f5ea9c1b3c693904ce7541f2f623e35f63d7632b","modified":1708861361152},{"_id":"source/_posts/hexo/hello-world.md","hash":"795449ef0e6e4d87eb446e60d1e6857383499e1f","modified":1698054930261},{"_id":"source/_posts/hexo/sourcecode.md","hash":"9b82f5c12ca64f79ba1f25ad18bfca7af76dde72","modified":1710156422043},{"_id":"source/_posts/wechartapp/weixin.md","hash":"157f8b711b8fce6b443086f5a9784d5783100afc","modified":1705552596694},{"_id":"source/_posts/experience/pycharm/link_server.md","hash":"c175d38a524b054a0cb6bf2f950332099c9744e2","modified":1709810324296},{"_id":"source/_posts/experience/app/lrc_to_smi.md","hash":"0a4d033a946fcde5bb54ac9dc0eb8eb6108d4790","modified":1709810352644},{"_id":"source/_posts/datastruct/1_extract/1_基础.md","hash":"01d0ac070c51a281402c20ae1d8c3454260985fa","modified":1698062355750},{"_id":"source/_posts/datastruct/3_stack/1_stack.md","hash":"c5bac3f9b0df15b30b34a5eaa912c1f6066c2317","modified":1698067215453},{"_id":"source/_posts/datastruct/3_stack/4_matrix.md","hash":"801bbb8d81c49ffbe6cfe9e56c1cd636fb687fd6","modified":1698062953828},{"_id":"source/_posts/experience/vscode/vscode.md","hash":"1013f0aff285ff74b8728bc77e8b695e1fcffcc6","modified":1709810312314},{"_id":"source/_posts/datastruct/3_stack/2_queue.md","hash":"c5e8e2879013a17a3c36d453b8e50b97d3fba922","modified":1698062900396},{"_id":"source/_posts/datastruct/2_linearlist/1_linearlist.md","hash":"d7bd03e466cf991023eb7845dfe26b0e4b0500db","modified":1698062554209},{"_id":"source/_posts/datastruct/3_stack/3_exam.md","hash":"09d1f7e08b9e0736d823003453848e9ebd61362e","modified":1698062918400},{"_id":"source/_posts/datastruct/2_linearlist/2_linklist.md","hash":"2cd1a0ab4f4e81f63cc7cf9a3ae20aa1f8b5d32e","modified":1698062568746},{"_id":"source/_posts/datastruct/4_string/1_string.md","hash":"192e8c0c9fb2abf12f6129446e3f5d9872bd7623","modified":1698063339435},{"_id":"source/_posts/datastruct/5_tree/2_bintree.md","hash":"f080a883557453884928b4fed627e43a581276a7","modified":1698063380694},{"_id":"source/_posts/datastruct/2_linearlist/3_doublelinklist.md","hash":"eb1f564dcacdc514d76434c6b6841babd720c319","modified":1698062620512},{"_id":"source/_posts/datastruct/5_tree/1_tree.md","hash":"09e75c758b997fa656e0bec274410e5f9345e4ff","modified":1698063355713},{"_id":"source/_posts/algorithm/1_base/1_base.md","hash":"ef8baf80a47af49838cf57dd0fb57b1cfe327d26","modified":1698062281517},{"_id":"source/_posts/datastruct/5_tree/4_Hafmantree.md","hash":"56c2c29ee3d30867eb2534a0f2176fd9a1d8904d","modified":1698063679991},{"_id":"source/_posts/experience/website/kaggle.md","hash":"61491e9c8d158eebfe176f57aa8a8409af01c5d9","modified":1709810308689},{"_id":"source/_posts/datastruct/7_search/1_search.md","hash":"a217f11a8e1b8e16c5941a6b58ecdefc86346bd9","modified":1698065418625},{"_id":"source/_posts/datastruct/5_tree/3_treesave.md","hash":"b3c8097e12215a278d82a08f9bbddfdb225b4bc2","modified":1698063608035},{"_id":"source/_posts/datastruct/5_tree/5_set.md","hash":"96744e1e200311a3c4d5e0e21682916aeb9d3982","modified":1698063800125},{"_id":"source/_posts/datastruct/7_search/2_BST.md","hash":"05269080838cf628f5ca643c6746aaf57f1161fc","modified":1698065629690},{"_id":"source/_posts/datastruct/7_search/3_AVL.md","hash":"79e876850fa8f40afba8adad82d24f9d2fef7cfa","modified":1698066122520},{"_id":"source/_posts/datastruct/7_search/4_redblacktree.md","hash":"95d5f24714c50bfd1f802fc1d39d4b0e5af42b36","modified":1698066147149},{"_id":"source/_posts/datastruct/6_graph/3_shortestpath.md","hash":"ead39c8afafeaf71678b4bb5bd408f50d7e639ad","modified":1698064227797},{"_id":"source/_posts/datastruct/6_graph/1_graph.md","hash":"8d4c50d24df9889a112b4a2bfd938c49c76b4b6f","modified":1698064007885},{"_id":"source/_posts/datastruct/6_graph/2_generatetree.md","hash":"0145a02d79dabab66ccf45bd6e7bb7af5af70d20","modified":1698064235357},{"_id":"source/_posts/datastruct/7_search/5_Btree.md","hash":"57c298d1ceafaa1070406dc97c2c8005c5bb7848","modified":1698066328937},{"_id":"source/_posts/deeplearning/paper/SR/CDM.md","hash":"3cd0fd968738243ef330a7670480b29c88cbfeec","modified":1706628964579},{"_id":"source/_posts/datastruct/6_graph/4_DAG.md","hash":"555bfaac97a76d0724658f8abc7f1b65ff0fd8cd","modified":1698064476586},{"_id":"source/_posts/deeplearning/paper/SR/Resshift.md","hash":"619af24a5769247cb5379c11e920a0031d071464","modified":1706628970587},{"_id":"source/_posts/deeplearning/paper/SR/HAT.md","hash":"5475e08292bd4659feca64e0d8a5fe9e684d7cf2","modified":1706267723399},{"_id":"source/_posts/deeplearning/paper/SR/SRDiff.md","hash":"ea222f8466f4cccd9278252f314f227de07baee7","modified":1706628975672},{"_id":"source/_posts/deeplearning/paper/SR/SwinIR.md","hash":"303b0c8ae5c9a728afb0e2c81290a381f848f416","modified":1706625438986},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/1_dataoperation.ipynb","hash":"bb373a219e2cfc2b687582755287595ef6efd7a1","modified":1706932114825},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/2_preprocessing.ipynb","hash":"0bbede0144ce9acf3125e00bf8c3338be5258a67","modified":1706932104906},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/1_dataoperation.md","hash":"4e1c7e8d3ebe4afc4da66510a74734ab4d145887","modified":1706932109053},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/2_preprocessing.md","hash":"4015dff7a32d34953b466d2e65277952d4308b37","modified":1706932100134},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/3_linearalgebra.ipynb","hash":"56232c401adefbc3e6526c1b648caa573e8de927","modified":1706932095692},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/3_linearalgebra.md","hash":"a07a80e7ebcc1145822d0490e4da364e5d5ffdf2","modified":1706932090090},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/4_calculus.ipynb","hash":"63df9bcecc172c1c938f7faeb20d8e4668ceda9c","modified":1706932084925},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/4_calculus.md","hash":"56662d60bc7900770f04996502e3c34fcac2ed3d","modified":1707143003801},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/5_autodifferential.md","hash":"d943430344d5ba95990f29a97c884657e01f036f","modified":1706932071611},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/5_autodifferential.ipynb","hash":"3589abb9c1faf3c21cf3b024e945309dd249bbe6","modified":1706932076942},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/6_probability.md","hash":"5890143b8b325b3990a6c4f6a1994004b75d4a95","modified":1707143118539},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/7_api.ipynb","hash":"f1a147e2ec3dde83dc8dab75846b5833084685ab","modified":1710753926238},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/7_api.md","hash":"cb96cd74df82e898c0800720b938b27caa6fe687","modified":1710753917306},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression.ipynb","hash":"2439a449d4ce1e3142d618603e2d74956635bd8f","modified":1706947639975},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize.md","hash":"1898dd51270d0aee3bb3b6b5268cb9c826b122aa","modified":1707143293472},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression.md","hash":"0bb39b0999e7518f4a738706238868497d7e99bb","modified":1707143259955},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/3_linear_regression_simplerealize.ipynb","hash":"5a41a585841c1f860e313751bdc1436ba4300453","modified":1706960945487},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/3_linear_regression_simplerealize.md","hash":"3038911b7f5141d72fa5a432d12e387f19fa8def","modified":1706960993844},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/4_softmax_regression.md","hash":"00fdaeb9d9a53a9b286fb6f2d9bfb0e3e4951442","modified":1707143401422},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/4_softmax_regression.ipynb","hash":"aec0f7e96960e97ab25cd811d5f87c8fc3037735","modified":1713446370186},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset.md","hash":"401e7f5f488d04784dd414a9bd27a00fdd282b01","modified":1707143440285},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize.md","hash":"abbfe62cbdde8a38e5777ecbcb0695c15a7fe44d","modified":1708854594685},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple.md","hash":"a25ea3ee1c1d4ac90ef9b29e5d2ba6b1abb15c1f","modified":1707143508993},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1690258400287},{"_id":"themes/yilia/source-src/css/article.scss","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1690363683164},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1_mlp.md","hash":"bcb1fa44ef7966a9547ac06968b04f35ef288c0c","modified":1710932696049},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/2_mlp_realize.md","hash":"3f654e020d5e0df04632027e28a6b48c8e1fcd09","modified":1710932787272},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple.ipynb","hash":"d6e6d599997509211881e6403670caa1af845789","modified":1707061205909},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple.ipynb","hash":"6dcefd8cbf049090719bea560566a9a3bdd9e2e2","modified":1707128701957},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple.md","hash":"6d416388f887fcaef11cd1f54485d34515d88e34","modified":1710932840484},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4_overfitting.md","hash":"ffe58dbc51f383b3124b3b5f93f50b446ce444e3","modified":1710933037936},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay.md","hash":"9f21cfacef3ac5415c9b74800177ac53cdc33174","modified":1710933136715},{"_id":"source/_posts/deeplearning/code/pytorch/data/house_tiny.csv","hash":"b32168bc42e12b5594eb2b0a8cae6f77c459a72e","modified":1703739275650},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/6_deopout.md","hash":"8e1bca3499bcdbcef94533dc979825eff6decc50","modified":1710933194981},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/7_backward.ipynb","hash":"521538b8926208eff6f451be09cbf7bf26336a62","modified":1710564667904},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/.ipynb_checkpoints/2_preprocessing-checkpoint.ipynb","hash":"9bc3b4afb0145f5795387830e5376960d315e439","modified":1703740534185},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/.ipynb_checkpoints/4_calculus-checkpoint.ipynb","hash":"96341d722267f34e7425aaf6e549607172121990","modified":1706775885763},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/.ipynb_checkpoints/7_api-checkpoint.ipynb","hash":"3b7ddc391949f132f2d6f1bbdd9b413ee3ff9ca8","modified":1706931418606},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_3_1.svg","hash":"4388b61bde02e3677bad2d58f1cc537f2ce40879","modified":1706791900029},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_1_1.svg","hash":"2268e578363aa8e3ea0d9fc6f9048b5476965606","modified":1706791900006},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg","hash":"117d33ae7e24490dd351cb3dda9f01697604a260","modified":1706947544080},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg","hash":"b40bd446671c91e8423328496f591d47f9b855fe","modified":1707126900118},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg","hash":"916e9f81fd64d864e8928b2d075bbf51b853735f","modified":1707126900117},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg","hash":"0aeb69df6b54fa10fc0bba6dd6b8f74bc906c713","modified":1707126900119},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg","hash":"286de42a50f439d72b9a4431c26633c68c9e5244","modified":1707049500016},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg","hash":"0b967ebe55c0efd5a10943f13da50b17012b8d9b","modified":1707049500017},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg","hash":"2cdad356448f53f436b46f6a1dfb3301d9edeca1","modified":1707127769954},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg","hash":"893bf7bd6b1facaafeaa59f0a74e1ec9efbcb4d9","modified":1707129399808},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg","hash":"15de8b4f4bdc9f439bd6567de0e4a4a511710dd1","modified":1707127769955},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg","hash":"e7326b636020ee834dedefa365a0bc50df191fcf","modified":1707061270220},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg","hash":"aeac8a3e0b2759086aaaa1c870717c441ead05c6","modified":1707214733201},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg","hash":"ef90ef3ede804f998cc308e825b05d226570b0ca","modified":1707214733202},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg","hash":"c4a09daa3725c074825db20b1ae97145f33cbb24","modified":1707214733200},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg","hash":"430b01e4581ecbbdfa0b2bf4990c15efdcab7603","modified":1707296564136},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4img/1.png","hash":"acef488b314a0eafa2b537f365d5fc373e271623","modified":1707139509508},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg","hash":"0cb1e259525ec525d6356f7f8c112a6e9f91977e","modified":1707296564139},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg","hash":"28bfe489d1ba3253bd9a1369f8ecf0deb413a211","modified":1707296564137},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg","hash":"90fa91d6679990bbb69a51ae6fba74606e031747","modified":1707314614179},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg","hash":"06c12519eeda924c77fc54eb45521bc677fb69ca","modified":1707314614177},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg","hash":"53c269365154a5776b6af1b449e163d41f59fa77","modified":1707296564139},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/t10k-labels-idx1-ubyte","hash":"958122e8b4b97fd4e71eca2d08ef754ed77c3ad9","modified":1707047905356},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz","hash":"9caad14e1aff9adac77d3744963212d36af15bee","modified":1707047905345},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/train-labels-idx1-ubyte","hash":"4bccf37222e01638381eaa326bf730337a597267","modified":1707047896468},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz","hash":"09814cfef5a041118ceace42f8dae995319d331a","modified":1707047896466},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset.ipynb","hash":"1cdaa5c0f0f5b8d8a374e67cefb0ee782e238775","modified":1707022646415},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize.ipynb","hash":"4929f3e79db17454fb476a911d9cbc7142759dc7","modified":1707049463722},{"_id":"themes/yilia/.babelrc","hash":"db600d40e93e6d8023737a65d58d3be7370e5e30","modified":1690258400255},{"_id":"themes/yilia/.eslintignore","hash":"ed9d8911ca08c3dd5072c48dd0be4d06f8897730","modified":1690258400271},{"_id":"themes/yilia/.editorconfig","hash":"daaa8757fac18f8735fadd0a37a42c06f421ca14","modified":1690258400255},{"_id":"themes/yilia/.gitattributes","hash":"758cfbecfa7919e99abddf3297f37cde7e3d8d4e","modified":1690258400271},{"_id":"themes/yilia/.eslintrc.js","hash":"303d25adf02ad65720e537a16a4a137d14bb755f","modified":1690258400271},{"_id":"themes/yilia/.gitignore","hash":"d5fc575329853ff620b50fc62ad4b18fa09a308a","modified":1690258400271},{"_id":"themes/yilia/_config.yml","hash":"ba7d701c3b0ae07b725d5a7070e40a517f8b1814","modified":1708846442559},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1690258400271},{"_id":"themes/yilia/webpack.config.js","hash":"da7657347109ddb4ab8602b219778117254677fe","modified":1690258400333},{"_id":"themes/yilia/package.json","hash":"ee6aa61f1cb89fd549e3e087c0232207a9c9ee30","modified":1690258400287},{"_id":"themes/yilia/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1690258400271},{"_id":"themes/yilia/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1690258400271},{"_id":"themes/yilia/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1690258400271},{"_id":"themes/yilia/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1690258400271},{"_id":"themes/yilia/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1690258400271},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1690258400271},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1690258400271},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1690258400287},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1690258400287},{"_id":"themes/yilia/layout/categories.ejs","hash":"9041a223a9965188cd5c1a893b3e9e2f1cf67223","modified":1697888836478},{"_id":"themes/yilia/layout/index.ejs","hash":"ec498c6c0606acde997ce195dad97b267418d980","modified":1690258400287},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1690258400287},{"_id":"themes/yilia/layout/layout.ejs","hash":"b471ab706d48e0be3f783eab1c94bf5878ef5a94","modified":1690258400287},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1690258400287},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1690258400287},{"_id":"themes/yilia/source/slider.e37972.js","hash":"ce5eac88301fe4f2fce0fb6203adfd58eb8313ac","modified":1690258400333},{"_id":"themes/yilia/source-src/script.ejs","hash":"28abac2426761d7e715b38aadd86ce6549c8ae77","modified":1690258400318},{"_id":"themes/yilia/source-src/css.ejs","hash":"cf7eab48d626433120d1ef9697f719a359817018","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"c70f367f54064a441e574c913f5e0ea121d0f899","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"edc0154b30a4127acda10297bec6aacf754b4ac4","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"155327c23607f69989b58845f24d842a54e504b8","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a4eacc2bc1278095a0ef99f904b0634c78f980eb","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"751e5deab5365348be5243688b419c82d337ab9a","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"8dea8f5f93a60185439b330b0f1d1649a6ab4bd0","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"871f81cacd5d41cb2eb001cd56254217a857dc2f","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"b69855e07b65117769adc515cb64b803932068c9","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"11550a418921d330e6553be0569a94ab5a217967","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"12ca7d8dba56bc767b9309dda9526dcbaffc1614","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"fb1b8457b9eb15b55da1bf7b133e12c375dd26f8","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"ccec1fc70f021cb50ac85b524e7949878ab93a18","modified":1690258400271},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"0ffcb251b79e8a920c9b4cb6bb7a96a808816165","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"cc1c39903aed0a0601d104238d2bbd13ad2a36f3","modified":1690258400287},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1690258400333},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1690258400333},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1690258400333},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1690258400318},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1690258400318},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1690258400333},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1690258400333},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1690258400333},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"29ba600e98ed55f7af4ade8038272c84cba21188","modified":1690258400287},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1690258400333},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"d6a7dd88404b383b5b94e4c7ec675a410c41f3cc","modified":1690258400287},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"f7388f5c11370ef462f7cb913d8f72edf24ecaf9","modified":1690258400287},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"1577a2336b3ad122f49f60dff2bc1a97d4e7b18b","modified":1690258400287},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"ce227b6f5a9af194fd5d455200630f32c05e151f","modified":1690258400287},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"8f82fe898ba1c1bd00c24a7d8270feddc7eba3bc","modified":1690258400302},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"07244c188f58ecfb90bb7c047b8cde977f1dc4b4","modified":1690258400302},{"_id":"themes/yilia/source-src/css/category.scss","hash":"5accf5b4cb4de54317f5a45b28ae84a4cc21d3ef","modified":1690362971612},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"b85f344f2c66d43d7094746e0a9ccb21d0534201","modified":1690258400302},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7ca837a4cc34db1c35f01baec85eb10ccc64ea86","modified":1690258400302},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"96d7eb1d42c06fdcccb8ef969f6ecd30c3194903","modified":1690258400302},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"40e5aa5056dc0b3b9f51c5b387370b612e265d4e","modified":1690258400302},{"_id":"themes/yilia/source-src/css/global.scss","hash":"db5e94a4f3e2768d85da58f5fcb4b211928a0de0","modified":1690355445904},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"f53ea8270752b5919ec5d79224d22af91f2eda12","modified":1690258400302},{"_id":"themes/yilia/source-src/css/left.scss","hash":"80dac621e43581a254d0152d5df901e4d0b01c09","modified":1690258400302},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"19f10fd2f0c3377aa4b165b3c2291ecf86dd9351","modified":1690258400302},{"_id":"themes/yilia/source-src/css/page.scss","hash":"244c4d75c375978ff9edb74acc68825e63c6b235","modified":1690258400318},{"_id":"themes/yilia/source-src/css/main.scss","hash":"dfb309c9801595a3c3978b5edb821eff85d9649c","modified":1690363018427},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"d995dcd483a250fe61b426158afb61bf8923a927","modified":1690258400302},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"a557a9ed244c82b8b71e9da9de3339d92783499f","modified":1690258400318},{"_id":"themes/yilia/source-src/css/social.scss","hash":"a10a038a1dac8953cb4ffc7e04272eff9fac54e4","modified":1690258400318},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"2495f7e4e3b055735c531f944b5f40a118a351ec","modified":1690258400318},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"399744e98e7c67939ed9b23c2670d8baad044eda","modified":1690258400318},{"_id":"themes/yilia/source-src/css/share.scss","hash":"9d6f6884f40c191882e56a1e1e1192400944a515","modified":1690258400318},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"915c93edd67c5326695cc7dc84b14c5f154dbcc8","modified":1690258400318},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"b81cedbe31accca82e597801186911a7b5e6841c","modified":1690258400318},{"_id":"themes/yilia/source-src/js/Q.js","hash":"e56d9710afa79b31ca6b9fbd845f6d1895f5214b","modified":1690258400318},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"2924fb6f77c4a9973cd928c2c7db0acb848ed483","modified":1690258400318},{"_id":"themes/yilia/source-src/js/anm.js","hash":"d18f6276a352b871390a4112d479b9e58b8cdbbe","modified":1690258400318},{"_id":"themes/yilia/source-src/js/fix.js","hash":"67b8819abb886c9d066fb3b0624ca15e06f63fe0","modified":1690258400318},{"_id":"themes/yilia/source-src/js/main.js","hash":"fe98bf90ce61658fe16ae057f8b6a512a845af3b","modified":1690258400318},{"_id":"themes/yilia/source-src/js/aside.js","hash":"5e4c3c3d61f1e1ce2f09688d3aff25fadc851fff","modified":1690258400318},{"_id":"themes/yilia/source-src/js/browser.js","hash":"4dc04845cf27f350922b63f1813a9c82e6e33b05","modified":1690258400318},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"461c08ffcbc724d74ec7e0ff38e171eefe0f89fd","modified":1690258400318},{"_id":"themes/yilia/source-src/js/report.js","hash":"57680f9a23bd0a1eaafd64ae08cc33e20627ab15","modified":1690258400318},{"_id":"themes/yilia/source-src/js/share.js","hash":"d4ccff8266c37363b3904226f5d035b7db882c61","modified":1690258400318},{"_id":"themes/yilia/source-src/js/slider.js","hash":"0beaa112657ad57c723d9e773d5b79de60c1dd74","modified":1690258400318},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"e777cbf959b11c4dfda649c562799899b90ab4a3","modified":1690258400287},{"_id":"themes/yilia/source-src/js/util.js","hash":"3bcdeb95072b85600874424e6929e3e22cfddaa0","modified":1690258400318},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"c699cf3c89409ec8f044258e0715a470861b5d5d","modified":1690258400318},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"086c8a88fd3bcae7ec13258df58e25d6354af2fa","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"aae96de18d48cd3b9b7bf6fed0100e15b53cca97","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"25655016773aa5d0774c56115ae1736a9fc9ea1f","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"b6a97043f9ec37e571aacacfedcda1d4d75e3c7c","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"345b262e3c3b75c0cd9a93d9ecabcf06e33e54ff","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2c4e4ca36c9bb4318506c38aca7127f1f44d827f","modified":1690258400287},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"fb022502c741b4a26bad6b2ad37245c10ede3f1a","modified":1690258400287},{"_id":"themes/yilia/source/img/hexo/1.png","hash":"eb5d590c866b115b711b6b18e688d0fb750b0fbc","modified":1661746009070},{"_id":"themes/yilia/source/img/hexo/2.png","hash":"1a2488cab647b2d9ee0645f8b1404f20d8f6391b","modified":1661746807535},{"_id":"themes/yilia/source/img/hexo/3.png","hash":"1c144b98e4d21f31d06466142a48efaf2a94d5e2","modified":1661780828596},{"_id":"themes/yilia/source/img/hexo/4.png","hash":"1386eb7152ca993db6bb1b73ec224640ed73ace1","modified":1661781049168},{"_id":"themes/yilia/source/img/hexo/6.png","hash":"e48c5ecbd482f3d30befe212e0bdbb7edfc8e1ce","modified":1661821525083},{"_id":"themes/yilia/source/img/hexo/7.png","hash":"e6b833a8a600ccde88c4204782cc3e8004e0edb2","modified":1661821616108},{"_id":"themes/yilia/source/img/hexo/8.png","hash":"2caad5ef038d9170ea58f0a0026bc8306280ec37","modified":1661821801772},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"262ffcd88775080b7f511db37f58d2bcb1b2bfc7","modified":1690258400302},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"1834c3ed8560716e63bb3a50be94cac87fbbeaf3","modified":1690258400302},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"91db061c9c17628291a005e5bd4936cf9d35a6c4","modified":1690258400302},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"398a49913b4a47d928103562b1ce94520be4026a","modified":1690258400302},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"6e75bdaa46de83094ba0873099c6e7d656a22453","modified":1690258400302},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1690258400302},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1690258400302},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1690258400302},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1690258400302},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1690258400302},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1690258400302},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1690258400302},{"_id":"themes/yilia/source/img/datastruct/1_extract/2.png","hash":"6d1421cc038218e94daff7ef39c7d3ac9d2e881c","modified":1690680047457},{"_id":"themes/yilia/source/img/datastruct/1_extract/3.png","hash":"571cded10b5c4269a889e56dab07bc689818e102","modified":1690680342728},{"_id":"themes/yilia/source/img/datastruct/1_extract/4.png","hash":"743e8d48e403ebd444289b1668ec6512099c9bb5","modified":1690681296164},{"_id":"themes/yilia/source/img/experience/website/3.png","hash":"aa0520b3b2ccc24d5cb1bdd6f0470f39156e50d6","modified":1708773092431},{"_id":"themes/yilia/source/img/hexo/config/2.png","hash":"368052a20c17d974130d81cad86bf9eefbe696e6","modified":1706626651446},{"_id":"themes/yilia/source/img/linux/install/1.png","hash":"f5e18416748c8cc86938da9ae1f1ff42e91e08bd","modified":1672553166188},{"_id":"themes/yilia/source/img/linux/install/2.png","hash":"23d49dab591d627c6673fb2a75fd5d2eb9d2fed3","modified":1672553372958},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png","hash":"8f35efb483252f734fcce32a59701f95ae08ca08","modified":1691217646864},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/10.png","hash":"39b9fd6684a084dab653c885553bdfb48e616d96","modified":1702802732650},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/11.png","hash":"b6ebbcce0e705315d2b9d49cfe47a5b0c7d738ef","modified":1702803286275},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/2.png","hash":"155e96cd73c2a354ba31581c3ae7990c35f1e77f","modified":1702801057457},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/5.png","hash":"528b88149b3eab3ef15c7cd04f18cf14463a9f8e","modified":1702801274883},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/3.png","hash":"d5c06088084abdd3d3f791266baf3e490353fa8e","modified":1702801133568},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/4.png","hash":"c2347bb419ce0b59e6a10bf13e67aabb6f1d6000","modified":1702801183526},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/7.png","hash":"8998704ce34bfa8d04b681a1b979c2ec712511df","modified":1702802255878},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/1.png","hash":"3e6bf1d0664a78945a62cb8efe7291c559bdd95f","modified":1702357564761},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/8.png","hash":"faedba9e3148fa893311cd9ddf820ae269dcc09a","modified":1702802406352},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/9.png","hash":"d38b41763eab121538504eba96a933f860d3fca0","modified":1702802438755},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/2.png","hash":"29999d449f335d959a928b47ee573094d6407e6f","modified":1702358201820},{"_id":"themes/yilia/source/img/experience/vscode/relative_path/1.png","hash":"5bf68e898eaedce375a846d2766c9d3c5f2c21c6","modified":1661864089789},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/4.png","hash":"2739ef20646d80910f98405f596227832d73dca7","modified":1702358320554},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/2.png","hash":"7e63a4151dc6c4e94cf281abe73dcdd544fe67e1","modified":1706269099314},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/3.png","hash":"8557ef65ec097d18405fe25075ce508a569cdf3c","modified":1706094402890},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/4.png","hash":"bd2061a683d43542f298d3b6c369a7a73e940802","modified":1706094657110},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/6.png","hash":"f626d8e52052327ea89c2ef3f164331a2c5813e6","modified":1706094865295},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_1_1.svg","hash":"2268e578363aa8e3ea0d9fc6f9048b5476965606","modified":1706791900006},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_3_1.svg","hash":"4388b61bde02e3677bad2d58f1cc537f2ce40879","modified":1706791900029},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg","hash":"117d33ae7e24490dd351cb3dda9f01697604a260","modified":1706947544080},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg","hash":"286de42a50f439d72b9a4431c26633c68c9e5244","modified":1707049500016},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg","hash":"0b967ebe55c0efd5a10943f13da50b17012b8d9b","modified":1707049500017},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg","hash":"e7326b636020ee834dedefa365a0bc50df191fcf","modified":1707061270220},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg","hash":"916e9f81fd64d864e8928b2d075bbf51b853735f","modified":1707126900117},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg","hash":"0aeb69df6b54fa10fc0bba6dd6b8f74bc906c713","modified":1707126900119},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg","hash":"b40bd446671c91e8423328496f591d47f9b855fe","modified":1707126900118},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg","hash":"15de8b4f4bdc9f439bd6567de0e4a4a511710dd1","modified":1707127769955},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg","hash":"893bf7bd6b1facaafeaa59f0a74e1ec9efbcb4d9","modified":1707129399808},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg","hash":"2cdad356448f53f436b46f6a1dfb3301d9edeca1","modified":1707127769954},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png","hash":"acef488b314a0eafa2b537f365d5fc373e271623","modified":1707139509508},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg","hash":"ef90ef3ede804f998cc308e825b05d226570b0ca","modified":1707214733202},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg","hash":"c4a09daa3725c074825db20b1ae97145f33cbb24","modified":1707214733200},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg","hash":"430b01e4581ecbbdfa0b2bf4990c15efdcab7603","modified":1707296564136},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg","hash":"28bfe489d1ba3253bd9a1369f8ecf0deb413a211","modified":1707296564137},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg","hash":"aeac8a3e0b2759086aaaa1c870717c441ead05c6","modified":1707214733201},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg","hash":"0cb1e259525ec525d6356f7f8c112a6e9f91977e","modified":1707296564139},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg","hash":"53c269365154a5776b6af1b449e163d41f59fa77","modified":1707296564139},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg","hash":"90fa91d6679990bbb69a51ae6fba74606e031747","modified":1707314614179},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg","hash":"06c12519eeda924c77fc54eb45521bc677fb69ca","modified":1707314614177},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1_mlp.ipynb","hash":"c48577fce4928bd1f49fafbf7635c7effa285ee1","modified":1707126390022},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/2_mlp_realize.ipynb","hash":"1fb2191c7f964298f4ab796729f81f4f9cbc4ed0","modified":1707127726588},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/6_deopout.ipynb","hash":"0dead9fa8e99abc5d56be582398a9f251ea2b9b7","modified":1707314639209},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg","hash":"4fb11c7574654e616736bb655a7365c62e42810c","modified":1706930246524},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png","hash":"29edd99abc43a64b80c27ae3404d354bbaf2e1aa","modified":1706947212470},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg","hash":"7745038901e6c501386a5bc1d7afda51874a0a9f","modified":1706952737930},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png","hash":"a65d5f49e5bb5f2cdc688e75966e4f8d23530336","modified":1706962050655},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg","hash":"a84269a32f13a9403e16b3b83416bbe856798469","modified":1707022695907},{"_id":"source/_posts/deeplearning/code/pytorch/1_prepare/6_probability.ipynb","hash":"d53aca7515fc6e0ae1d1af15775fbef5d9ee676e","modified":1706932067833},{"_id":"source/_posts/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize.ipynb","hash":"745be9a0a846966f3b23ee44a94b9f9b321d2b26","modified":1706953000878},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"061e9c742c59a6cd017b9437f1a4879aa36cc101","modified":1708574416275},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"1801ef448909ea23c0a48e9d63b80d0cfd5534ce","modified":1690258400333},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"283ae27ea37ac3e0e45b2e05c2482a4c594b9c25","modified":1690258400333},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"e98ec0b3b56f14d1d79af99ceb42727719a584f3","modified":1690258400287},{"_id":"themes/yilia/source/img/0.png","hash":"18cd3f368afc326152fddaf38353d0a3a5b88cce","modified":1661821028108},{"_id":"themes/yilia/source/img/hexo/5.png","hash":"795caa1da3dd3b5194ca066cc4a3dc684ae5c4a7","modified":1661783564220},{"_id":"themes/yilia/source/img/linux/commend/4.png","hash":"312407c7570bf5d0226a98c51f1e400f9e426418","modified":1672894004665},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png","hash":"cd2d22e47a4ccf7d698aa886967d484994fe68c7","modified":1691217715248},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/1.png","hash":"18f61385a1aa2a42b57ed9fd4eb058988038bc79","modified":1702800985856},{"_id":"themes/yilia/source/img/experience/pycharm/link_server/6.png","hash":"8e2eb0e6a096b258aa6d87f122a6901cadc81c22","modified":1702801338326},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/3.png","hash":"a1fce07f832cae4b3b251dde1c87376f4386ad2c","modified":1702358281362},{"_id":"themes/yilia/source/img/experience/app/lrc_to_smi/5.png","hash":"fe826175ce8041af3cd87afada1a66204a489e4e","modified":1702358837390},{"_id":"themes/yilia/source/img/experience/vscode/relative_path/2.png","hash":"6845b7d833c89764ce7e87a437079bc76022ad43","modified":1661864909823},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/3.png","hash":"12aefac57158ded661913fee37c1348baeb1fb5f","modified":1706339037074},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/2.png","hash":"c62663719646ff08f57958e388c64cadf00bec40","modified":1705998220007},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg","hash":"4fb11c7574654e616736bb655a7365c62e42810c","modified":1706930246524},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg","hash":"7745038901e6c501386a5bc1d7afda51874a0a9f","modified":1706952737930},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png","hash":"a65d5f49e5bb5f2cdc688e75966e4f8d23530336","modified":1706962050655},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png","hash":"29edd99abc43a64b80c27ae3404d354bbaf2e1aa","modified":1706947212470},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg","hash":"a84269a32f13a9403e16b3b83416bbe856798469","modified":1707022695907},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/4_overfitting.ipynb","hash":"dc91427d34b41d9b830f272f7e01887acc79aafe","modified":1707214561788},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay.ipynb","hash":"603b2a6d0d3fd5e3524487f17a80317e230f016b","modified":1707296452212},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/1img/1.png","hash":"32187b3f3d27abf58d84102ec722a3bdfc1aaa95","modified":1707062625616},{"_id":"themes/yilia/source/img/experience/website/1.png","hash":"e3f3761e0a8d13765d07c62356c8cb531085832f","modified":1708746521632},{"_id":"themes/yilia/source/img/hexo/config/1.png","hash":"57c220f0666493e9aa46e655dd3e4c8d8769526f","modified":1706626629440},{"_id":"themes/yilia/source/img/linux/install/3.png","hash":"aff317a4f01469d43aea727220d5f35dda5ad82f","modified":1672554935824},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png","hash":"1be61897417af386bdaab09257f60b624fa4b7a7","modified":1691384095099},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/1.png","hash":"8859dd1b37ba832fcf39bea466172166a4872ca1","modified":1706331071359},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/3.png","hash":"ad4657eb56551df2f18233832075681a371be953","modified":1705998561333},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/5.png","hash":"05264fcc3adc2b358081b88c0f8cbb3a3ac7bce9","modified":1705999852098},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/1img/1.png","hash":"32187b3f3d27abf58d84102ec722a3bdfc1aaa95","modified":1707062625616},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/6img/1.png","hash":"9e19fa51e5bb17e6afa8a8fc5ff26081074e890d","modified":1707310830587},{"_id":"themes/yilia/source/img/head.png","hash":"c695336ba203c92400d8801be883217f516ccfa9","modified":1689933128876},{"_id":"themes/yilia/source/img/datastruct/4_string/22.png","hash":"69fc98bbd8b19f77b749ff2aac2fc1d84da041fc","modified":1691550343135},{"_id":"themes/yilia/source/img/datastruct/4_string/6.png","hash":"02c58cbb86448ab130e8de56a8ed30190a270441","modified":1691502055706},{"_id":"themes/yilia/source/img/datastruct/4_string/7.png","hash":"5045a59070a4dc3abf0b75adc7ea361e417a9ac6","modified":1691503180357},{"_id":"themes/yilia/source/img/experience/website/2.png","hash":"386f3140232edd163a74963d3f1fb71b631c7ccc","modified":1708748005485},{"_id":"themes/yilia/source/img/linux/commend/7.png","hash":"b5334dff05fddfb776b67cfa62e1bde08ad5a7d1","modified":1672894983674},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/5.png","hash":"53bae744eb1d75032b76b2a34393b483c507d45d","modified":1691590471263},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/身份证1.jpg","hash":"f4ad46fab9a1874986ccd963cb4f4d8a8602554c","modified":1691897167185},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/1.png","hash":"d0284a0aa9cfc0bb236b9b2d21da006c12aeba82","modified":1706268247587},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/11.png","hash":"d1c328c62f3a3894356be5017e148cf82228ccb3","modified":1706096480418},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/CDM/3.png","hash":"f1489a76081146c43436f33662b8fb24dd93705b","modified":1706330569143},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/2.png","hash":"4949684eeb63cf7260e919617454a2d551b3f64d","modified":1706094334407},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/6.png","hash":"13827355692c474261b3db2cd451e6704ac78953","modified":1706000581563},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/7.png","hash":"e6e1d6e4486b4a67ccf1de20a0c3fcd7e12fc168","modified":1706008471089},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png","hash":"9e19fa51e5bb17e6afa8a8fc5ff26081074e890d","modified":1707310830587},{"_id":"themes/yilia/source/img/datastruct/4_string/11.png","hash":"16f3b25aabe8fabac62e4dee790ebd76f9f5cd7b","modified":1691505320863},{"_id":"themes/yilia/source/img/datastruct/4_string/33.png","hash":"51078f091563b3fc4126d3a1ff3e46adb6dbf1dd","modified":1691551707442},{"_id":"themes/yilia/source/img/datastruct/4_string/9.png","hash":"89fb11a7191f94bd33c84aad1f97b63e15def4e5","modified":1691505233957},{"_id":"themes/yilia/source/img/linux/commend/5.png","hash":"9877ec4411499460626515956172ac17c0461194","modified":1672894495658},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png","hash":"37e2c7e31f6b34a0c678c3241da2028ea694b61a","modified":1691304383828},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png","hash":"c3b59117bc61e06960711487d2c9faae1d8490af","modified":1691228570021},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/4.png","hash":"ccf102d7ac6a969e1bdcd81001538a5e14bc0685","modified":1691420162004},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/2.png","hash":"cfd647157788822a1ee87152474331d6b72983c1","modified":1691556786300},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/3.png","hash":"bb65dc7f7d243290cdfc39e6ad91d29a44a5a978","modified":1691556831286},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/1.png","hash":"f518bf1aa4309d3129066c1f7a4de9d0126bfc64","modified":1691759834419},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/身份证2.jpg","hash":"c7248cff105487f06b45d89d6b51e972489f667a","modified":1691897146994},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/4.png","hash":"d5be991310455fd4f492c541ef0b327914c7c15b","modified":1705999226659},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/4.png","hash":"b0f7022db8b8bdf2dfd25b3be51b483c35c86632","modified":1690708324052},{"_id":"themes/yilia/source/img/datastruct/1_extract/1.png","hash":"f62dbc992f719d4edde6745400129010f2df805f","modified":1690602999185},{"_id":"themes/yilia/source/img/datastruct/1_extract/5.png","hash":"f8bc031e79eea55114892711cede3ef873029495","modified":1690684253517},{"_id":"themes/yilia/source/img/datastruct/1_extract/6.png","hash":"58eecabd401a7bb5dab4706e4a65b0ad3ab55d3e","modified":1690688739273},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/7.png","hash":"303a2e13032a6ab2b2e45c50c1e3666232dc39ef","modified":1691498549869},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/1.png","hash":"c188269b5cbcbb8fbc67391b7be94cfea7ca8ecb","modified":1691420396781},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/6.png","hash":"dc6fafa3d3c1dac6a0df6a46537738fb955991bc","modified":1691564823431},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/7.png","hash":"a4960ce0bb113834995b83f1e72a5f1d59b5b580","modified":1691564859427},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/1.png","hash":"f1791e355115d078e7858dcb207f8e87bbd736d6","modified":1691591913410},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/2.png","hash":"33126a20ebac6b4dd33fda2b1337f0132e432f28","modified":1691592072637},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/2.png","hash":"c36f61b2f331b4794bb7affb5653a3c70b6bf7eb","modified":1691556321740},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/2.png","hash":"3a0427868ede3bc4fbd980e1eb44d1ddcf8ba662","modified":1691759872116},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/3.png","hash":"273b817773cfca2cefedf37e00beffce3aac979d","modified":1691746400702},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/2.png","hash":"7e507b8326c93a6720e559066f42886e7a8255e9","modified":1691746322625},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/4.png","hash":"42244dfc16a8545eb1d6f29cbefa1d7b10b8908f","modified":1693034802616},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/8.png","hash":"090cb62b2d7077ec1bddd563b06245be0a144a7e","modified":1706096218818},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png","hash":"103d09498654fe7acde2c2bd20371fe75cba9456","modified":1705995313277},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/11.png","hash":"5f5dd2e2cdc0161d68f514f5f6fa92a17097cc15","modified":1706008853684},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/2.png","hash":"8c9d5f586b67d8973d280205ad376279861d9fa3","modified":1690705661628},{"_id":"themes/yilia/source/img/datastruct/1_extract/8.png","hash":"f46809238bf064e700e57d6e341b568072b9c1ef","modified":1690688916784},{"_id":"themes/yilia/source/img/datastruct/4_string/8.png","hash":"c6fff07a1454c9886d48afe21a3b2dcf4190090e","modified":1691503712680},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png","hash":"400a7006ed7e701ecf338868d027fa9d4fc09aa4","modified":1691311294470},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/1.png","hash":"0355d11dc2d67894016a00819bb2f9fa048e3456","modified":1691467561263},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/9.png","hash":"483683c7cd2491fcaab026f2501fb097a99e5af2","modified":1691498712107},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/3.png","hash":"7389121d9a2981d2f7a913f27ceb495c9b3e3f85","modified":1691465700780},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/1.png","hash":"320bb1490c7237abc6cfa31f75d80a2ff667d10e","modified":1691412904112},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/5.png","hash":"1d3549ac63517ed5a5fdb36c60ec68570530c6ee","modified":1691466497758},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/1.png","hash":"f2ab94acf03f8427536230e7e4492f6286a8863b","modified":1691556489183},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/3.png","hash":"bbfeff2baa2a09d1cfde6efd8ced65950969d451","modified":1691419743434},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/5.png","hash":"0ef37d1a33ac8f7adfc64f2df93ddc46db02a255","modified":1691760417873},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/4.png","hash":"4bd74ef02a7ce777be6d6be132b809eadd333795","modified":1691746532552},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/10.png","hash":"f8f49b35a8464be6d441c4d1c9d89eacd46c99d0","modified":1691743303424},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/17.png","hash":"96a3732857d13b320d44a5d2bba58b24e63eb2c3","modified":1691743889302},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/21.png","hash":"96cd917e4e00ec460d56bf1497a6ecf875ac2412","modified":1691744568147},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/5.png","hash":"2ac3fdffca3ece0b482b346dc80124c9b1a9b293","modified":1693034837983},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png","hash":"f198322bd8b57e7f7730ad78a1502b72d34af28b","modified":1691756652403},{"_id":"themes/yilia/source/img/datastruct/7_search/search/1.png","hash":"abcd55aa8269afb2ec7d383f5bc03379182b18e3","modified":1691764394502},{"_id":"themes/yilia/source/img/datastruct/7_search/search/8.png","hash":"b86ec6b6a477e655a484cb62d2a8372e71bbf398","modified":1691764991881},{"_id":"themes/yilia/source/img/datastruct/7_search/red/1.png","hash":"24ed2aaf9c398cf0bd548949cc530a82f26bbe3b","modified":1693036044722},{"_id":"themes/yilia/source/img/datastruct/7_search/red/5.png","hash":"91fa356e862977aedcd8380883ebba68ce55ff51","modified":1693039095844},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/1.png","hash":"f3127e2c823a2115d3eee9c9186e66775f7c8c56","modified":1690689329458},{"_id":"themes/yilia/source/img/datastruct/1_extract/7.png","hash":"719ea9a0ff7bdeb47bb6068bacaf8799080544bd","modified":1690688753401},{"_id":"themes/yilia/source/img/datastruct/1_extract/9.png","hash":"352ebd7320c0daf59164cc606c54748d4461364c","modified":1690688988499},{"_id":"themes/yilia/source/img/datastruct/4_string/3.png","hash":"0263d9a7b8552db5293da17683a78fc6b18add52","modified":1691499407217},{"_id":"themes/yilia/source/img/datastruct/4_string/5.png","hash":"48c8a60a2eade60271df902361219dc60182b147","modified":1691499684778},{"_id":"themes/yilia/source/img/linux/commend/6.png","hash":"1ad966f50410b760b5c4da236b00fa3c87d6e794","modified":1672894794061},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png","hash":"93d909b592f79bb93cb05e461f1cfe5b19975588","modified":1691217017748},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/3.png","hash":"d4697e7aa4faf3faaec31795d056369aee9a0747","modified":1691477782460},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/8.png","hash":"a14b20161150d5ec27c26a8769d2fbc63882cc02","modified":1691498617510},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/11.png","hash":"d6da827299c4424e820f13b641b8cf1d7dcc8647","modified":1691573880053},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/14.png","hash":"e09f44ccfd173d7e22a664ba1da0496578fe71fa","modified":1691573669468},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/16.png","hash":"ea7d466a5c4df3dab2b7d5fd1db34983ad20bcc9","modified":1691573739880},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/21.png","hash":"01cce10b1c97bfe85564457670c02523f9e22bbf","modified":1691586981364},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/4.png","hash":"a1a7f2f52dea3bb78b7e610b99cd46c8eb638324","modified":1691561708831},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/9.png","hash":"617b5e71fbb4b6cbde53988e84b7db14227521aa","modified":1691565503866},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png","hash":"4b489a3880d5c72496e6bb3e9a0fb1867c72a61e","modified":1691591243003},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/3.png","hash":"5c23b6d576d9ab930ff7bed0ef93f7286fece156","modified":1691556359280},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/8.png","hash":"fa5bb9c206f9d820b4829b82a815acfe9535f698","modified":1691590739780},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/11.png","hash":"2c57ffd92b97d2c5cb9cd6e86d45ba7a7c3ef152","modified":1691763100420},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/13.png","hash":"f82c00b83d4707743244ced4344eb173088f6537","modified":1691763299482},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/10.png","hash":"367b5db4a5df4056bc852b4d15d90569f16d47ad","modified":1691762989848},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/12.png","hash":"2c57ffd92b97d2c5cb9cd6e86d45ba7a7c3ef152","modified":1691763259051},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/7.png","hash":"1640ed8edab3a2235f8d1890dd911df427202d5b","modified":1691760901602},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/9.png","hash":"1c087e833e9d95f77fdfc1c5393872f67b161620","modified":1691762393639},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/10.png","hash":"8f1df1e8b36321baa8454a6e408fc3132f3a0b49","modified":1691746859035},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/5.png","hash":"c31e028791baa33832977eba8885d7c2fa495f5a","modified":1691746557384},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/8.png","hash":"ad9e53a5806f86ec4f2e076279d81ba1faf82b80","modified":1691746765810},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/9.png","hash":"9af35488623060bb152e66796eed3d11de500b69","modified":1691746775997},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/11.png","hash":"3b8f079b47feb4ead637c8e8799668081da3b3c7","modified":1691743725482},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/12.png","hash":"f5f8a7f60d80bdea3901f24d757d71f354b21076","modified":1691743739055},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/14.png","hash":"ad20949a8476a1eab20b23a627f5d1c2c5245b72","modified":1691743791966},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/13.png","hash":"1a0b6b8999306d37bb4e5e021dcd2860fb91003a","modified":1691743782462},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/16.png","hash":"8accfd8baed48f5129fd22bc026b3baeea3f53dc","modified":1691743869442},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/19.png","hash":"3b6cc333c977fabc8759d19010d40eadfec4e126","modified":1691744359775},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png","hash":"4f739f585dcd7d2fadc90c2ec487d810e50b12b5","modified":1691747129640},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png","hash":"8af073f178b71de473f6779005b693b6fe931e35","modified":1691757741065},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png","hash":"ccabac77b9f87025d39cb178c736ab08be966a53","modified":1691757014920},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png","hash":"6cdb024dea1b8f80280a985b970deb30f92229dc","modified":1691757054076},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/2.png","hash":"11152e9108147bf5ddaf92da0a6ae3b40310f0f3","modified":1691765426369},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/4.png","hash":"4ce88adb5b069d4d0f3e019c8baaff3daf93577d","modified":1691765563689},{"_id":"themes/yilia/source/img/datastruct/7_search/search/2.png","hash":"ee0dcdd98d36ebf968203e086842f82983833393","modified":1691764532822},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/1.png","hash":"9645f93ecfba9f5b9206fde1c0aa73917896f582","modified":1706093510193},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/5.png","hash":"a743c446dfcf9b937205f58dc028f41d070e48b5","modified":1706094671973},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/3.png","hash":"5a8a80187065f83608b3d27cf134ca2b1345ea50","modified":1690708244606},{"_id":"themes/yilia/source/img/datastruct/4_string/2.png","hash":"fc16f97df3cd583499ebfdc08a17a59d584f5dbe","modified":1691499178548},{"_id":"themes/yilia/source/img/linux/user/8.png","hash":"0b8417b51075ac859bcf37582f6ca9cdc6d1ed9e","modified":1672921178317},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png","hash":"2fd148d973e964c5a66a6677e08c8d40bb4086a7","modified":1691412524458},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png","hash":"e9347e1f225c5cbb9c549e8dfb9f5bec9b0aeb0c","modified":1691222122560},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/4.png","hash":"a3e580c7a52b96615056d54e0901e927210ec6bd","modified":1691482513563},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/1.png","hash":"4232903681e5acd2874ed02adbb613f650cbd3a4","modified":1691485812683},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/2.png","hash":"e5f12710a7ee824a071f4b667c21c6adcacf57f8","modified":1691487476795},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/4.png","hash":"52cfb649fee62c2d0248b8a19634016a6e7dfeb0","modified":1691487901540},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/2.png","hash":"372e33824e44870739b0b2dd31473891d8be39d5","modified":1691421821662},{"_id":"themes/yilia/source/img/datastruct/3_stack/queue/4.png","hash":"ccc7388fe9d234b85dfaf0f13df2011fdd448cc9","modified":1691466312459},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/13.png","hash":"5c51b87683faf0b42ff105b4b509847ce28f033c","modified":1691573506131},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/12.png","hash":"7b9ec3a8aeea46a650d5f324f6bcd450d7c6f1ce","modified":1691573450339},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/15.png","hash":"642ac58ff76d07fdb5f34aa690c5d9198947b50b","modified":1691573704026},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/19.png","hash":"4850932f1aa82436d5d483bf8c65762911e63d5d","modified":1691575204498},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/20.png","hash":"e3ccd07772d3937fe059f7030cb5637d07272705","modified":1691575240008},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/5.png","hash":"5606a7bf100e9f72e25622c5364701c62e995057","modified":1691561772170},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/3.png","hash":"2656e0c353bab48a03f657aff960e69d4ccf488e","modified":1691592192803},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png","hash":"c93b19d02e8eecbcd748e4e7d0b212fdb258e3d2","modified":1691591181645},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/4.png","hash":"60b7cd6266dd054a37d619083c49e76d936471e7","modified":1691592496783},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/1.png","hash":"5f3d151b0ef530ec331a88871f4c790ad1e7de76","modified":1691589073455},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/4.png","hash":"0ed7fed4738e93c716e7d8947eb29ec60bbcb3b3","modified":1691590339553},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/3.png","hash":"554d3cbfb2d7a8276695dfab55b6fa00d6b41e29","modified":1691589958934},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/7.png","hash":"b0407aed45fdf2778c37aeb86e16f0d76246bd1b","modified":1691590661218},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/6.png","hash":"f70727738f1d45d51a0b5ace85e38f9ef4fbefbc","modified":1691746574409},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/7.png","hash":"430730c045a26ff7a2671b3bf42b81d36e288ec3","modified":1691746756084},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/18.png","hash":"23ab682c9b0e7ed5a5372d575801e89b1735a9c8","modified":1691743941833},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/2.png","hash":"30c586539ef983e91f127a9d117be4334832c7b4","modified":1691734075098},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/22.png","hash":"6db8e47e30d615832eebb062a162791b7c310fd4","modified":1691744785301},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/26.png","hash":"186dae57f64593ba80a9484c2b1746c1f8d29999","modified":1691745783999},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/25.png","hash":"04097ccd7e31337fc15b0b4e6590f0e46ed5e92c","modified":1691745493311},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/4.png","hash":"7a3bb1906f0ad5afccbed87ff851e3819cbafc36","modified":1691734224044},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/6.png","hash":"5617cd959a09a2687fe2cb9a32abfdf070d389fa","modified":1691734588767},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/8.png","hash":"177c49dc3942bb19e887c89c2e795bc944d2994c","modified":1691735103874},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/3.png","hash":"8736726d7645894dc84807c3e9ce0e54fa76c717","modified":1693034747447},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png","hash":"ddf8ab48eb171c8ef1e1f0114616ad849ddfb034","modified":1691757712933},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png","hash":"f09b3c157a8364de40821317b2677a175b3f4dc6","modified":1691757797077},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png","hash":"bfe530abb9fac2ea1b2eb295a832de6b1f725218","modified":1691756495914},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png","hash":"707dbf184c801ed3e8a6f0c333ab4797dda2b238","modified":1691757023476},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png","hash":"daf3d4a4a195019ed2629e892f3fd8e2aee5978c","modified":1691757032146},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png","hash":"4320444060e2fa35d0b0e4dc8f33a03cec5bea7d","modified":1691757043016},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/1.png","hash":"55a425118fb566256fc2dcb7267670c2e0c8b6be","modified":1691765227262},{"_id":"themes/yilia/source/img/datastruct/7_search/search/3.png","hash":"b167c48347e3f40f71169249aa9e57149f456030","modified":1691764704613},{"_id":"themes/yilia/source/img/datastruct/7_search/search/6.png","hash":"ec0afe78ba75251e35923d39189ae047b28b0898","modified":1691764882087},{"_id":"themes/yilia/source/img/datastruct/7_search/red/3.png","hash":"e07c568186d1ff720b927af647502bf84095c922","modified":1693036644495},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/7.png","hash":"b0c033daaece2d1342f4017cd64850e19e1973ea","modified":1706094875609},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SRDiff/2.png","hash":"bc499602dd3514cfa3e48a170a0254f98de118a9","modified":1706338981638},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/12.png","hash":"35982c423def1509d333ab9842840239de01b7d2","modified":1706008939838},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/9.png","hash":"2d2e66a07ec289a15511a707862c44c0fa9b9c6e","modified":1706008781907},{"_id":"themes/yilia/source/img/datastruct/4_string/1.png","hash":"dd8f568d408f4066857dcaf5f837b76ff72681ea","modified":1691498978232},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png","hash":"ca655c8903c294c2561adf00e03115d85daac0d3","modified":1691383605503},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png","hash":"7f6f39075bd9d99fc80bed11a9572929861608fe","modified":1691384213543},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/3.png","hash":"de128228b37c7f67472db3f69319469c15577bb1","modified":1691487846644},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/6.png","hash":"5796e5f5deedd912d609d786b9bcdf81e5952265","modified":1691498424660},{"_id":"themes/yilia/source/img/datastruct/3_stack/matrix/5.png","hash":"ddc34b510edf878733390cf6280c17e24430ca44","modified":1691498193472},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/10.png","hash":"809602cc17c15b735981b02272c065543b829903","modified":1691573912441},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/18.png","hash":"0c53deb30a095262bace6fe55d49b9528d79932b","modified":1691575069273},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/8.png","hash":"da3f2d7eb809212e929a5124c89161424edb4b19","modified":1691565191904},{"_id":"themes/yilia/source/img/datastruct/5_tree/set/5.png","hash":"28d6733723d49340995dec2fde9e88dd9f0adb05","modified":1691593008586},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png","hash":"6e0aa2e3cb77d483683e3d0d11cf91ed42a1b86f","modified":1691591459593},{"_id":"themes/yilia/source/img/datastruct/5_tree/tree/1.png","hash":"adf29d834bac15c3cbb5a59ffe8ad8beb0e84a37","modified":1691555053411},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/2.png","hash":"a3b2cc5ec1d3f6641c562ec91fd67158681d54fd","modified":1691589184598},{"_id":"themes/yilia/source/img/datastruct/5_tree/treesave/6.png","hash":"29ebb70f952f15f45953541376e244d40361dce0","modified":1691590617234},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/3.png","hash":"ab89866de5a90543cb94ba68f91772cbea6885c0","modified":1691759917325},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/20.png","hash":"e1ea39884791587ef05f620d70bea10cad4517ca","modified":1691744388175},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/7.png","hash":"17fe699b83593d7b5a5a63cf6f8e96850e5a0c78","modified":1691734656378},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/7.png","hash":"8cdb063bca970837e89246b7c242aa8df4ef69ab","modified":1693035869074},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png","hash":"904d546f835be088ef8c6431fcba3099f29a89b6","modified":1691757619745},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png","hash":"e5fe49cda495ad811654a44c5c4df75c58a26b15","modified":1691757816077},{"_id":"themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png","hash":"4a56bcbe87473960ae402584e0da20c8c16cfee1","modified":1691756527686},{"_id":"themes/yilia/source/img/datastruct/7_search/search/4.png","hash":"52e1734955fdec29f5967e9ee9474d2cddc98d86","modified":1691764731437},{"_id":"themes/yilia/source/img/datastruct/7_search/search/7.png","hash":"66712ddccabed87d61c763cac232635c37dfba4c","modified":1691764955669},{"_id":"themes/yilia/source/img/datastruct/7_search/red/4.png","hash":"1565be0433a56f3b59c04e9ac45580ed38c6e49e","modified":1693039041843},{"_id":"themes/yilia/source/img/datastruct/4_string/4.png","hash":"7838d4d94535fa7a23ea70e174f18224109af7a3","modified":1691499621674},{"_id":"themes/yilia/source/img/datastruct/3_stack/stack/2.png","hash":"a908d6604057c26915ac3f6755cbb618fc315bac","modified":1691419128920},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/22.png","hash":"b42865762e3f79e13238c99d3fea6e9a34b48b7a","modified":1691588893459},{"_id":"themes/yilia/source/img/datastruct/6_graph/generatetree/1.png","hash":"a38f3f3818fb59ffa2e0c2f149baae5ad3e08906","modified":1691746022745},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/15.png","hash":"ddaa0073e7a050c6da2e15bb92edef4b263e71f8","modified":1691743828007},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/23.png","hash":"507a10492249735e4eff71110dccc08e32d75723","modified":1691745075647},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/5.png","hash":"e526a1db7825500f3915b81cff0b2a0649501224","modified":1691734323307},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/9.png","hash":"af0f3d264f6346953c00662e13262590c718288d","modified":1691742551640},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/2.png","hash":"62329d059d1524ccb694e74674724d123b1d1ccb","modified":1693034737641},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/6.png","hash":"81c02a6561ed5dfb1a5d2523c54f6f3d033c1828","modified":1693035044769},{"_id":"themes/yilia/source/img/datastruct/7_search/red/2.png","hash":"561a4f0a6d89e9dc5059fe6ad41fcf3ccb064c71","modified":1693036214634},{"_id":"themes/yilia/source/img/datastruct/2_linearlist/5.png","hash":"d4eecc47637ac57e721533941890b5db93c6cd96","modified":1690710397035},{"_id":"themes/yilia/source/img/datastruct/5_tree/bintree/17.png","hash":"7e9e417dd7e92cf4518e7478df7a61dc792b5c79","modified":1691574473511},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/6.png","hash":"160fc9cbaf10916bf63315abe80c023af57cb663","modified":1691760482169},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/8.png","hash":"6d7b99c9cfe359e941a1a0a9f733fd37ca979430","modified":1691761005967},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/24.png","hash":"24195d899250ca557aa68f3c5b50872ebf724b25","modified":1691745314935},{"_id":"themes/yilia/source/img/datastruct/7_search/AVL/1.png","hash":"1cba4a7760b4e3198c1d948e381a13e76b5522a5","modified":1693034311826},{"_id":"themes/yilia/source/img/datastruct/7_search/BST/3.png","hash":"9d522c4b3ed9fc8d4cad85e1d574895e0edf5ffd","modified":1691765512206},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/8.png","hash":"a057c763efb0ce8ad6ed81c7fcc687b8cfd61d64","modified":1706008706238},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/5.png","hash":"70eb4243c88e9cb6f9d64dc4b1ce0123f93d7b70","modified":1691483230497},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/1.png","hash":"3c95625309a2e2f7fddf78c14bc972a018c82916","modified":1691725714454},{"_id":"themes/yilia/source/img/datastruct/6_graph/graph/3.png","hash":"1c63775db55f4624289bc1ef592ed88d4c2258ab","modified":1691734140060},{"_id":"themes/yilia/source/img/datastruct/7_search/search/5.png","hash":"1be79056d4fb1d9c03850ce2161c2f2c22373751","modified":1691764808300},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/2.png","hash":"23650f4e8a06111ed5639cc0891fd7490c8eb7b7","modified":1691476660769},{"_id":"themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png","hash":"20d3db5968e55586130cdf0fc98d5dcf77d79408","modified":1691591377972},{"_id":"themes/yilia/source/img/datastruct/6_graph/DAG/4.png","hash":"1aee5cdce7b83cbb17cc5c7c14ac9d0a02a787f8","modified":1691760000494},{"_id":"themes/yilia/source/img/datastruct/7_search/B/1.png","hash":"bba1aaa2fb53ede0dff30e60d86ac9c9e7ad3cc8","modified":1693039964839},{"_id":"themes/yilia/source/img/datastruct/3_stack/exam/6.png","hash":"721fc6eedb785c67120633ed94159a0d4ea49270","modified":1691484394221},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/13.png","hash":"75213541cc70afc1d1918c479ac78f8d56850e52","modified":1706009262701},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/SwinIR/10.png","hash":"88289ae9893a394b64ec2faf0759100abbf224a1","modified":1706009183949},{"_id":"themes/yilia/source/img/deeplearning/paper/SR/HAT/9.png","hash":"a43c143ea90005eb68c6b17343f20d5526e99d2e","modified":1706096356459},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz","hash":"5edda96c6d8c36ff915115a0e8136d370a021576","modified":1707047904123},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/t10k-images-idx3-ubyte","hash":"880056926db704f9f713097915f99da346f5b1d1","modified":1707047904219},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/train-images-idx3-ubyte.gz","hash":"95978b76b6897f6ca69a25145d01716efb615989","modified":1707047894428},{"_id":"source/_posts/deeplearning/code/pytorch/data/FashionMNIST/raw/train-images-idx3-ubyte","hash":"b9bd999c0106c9b8b4b0cefce58c9a6060f27095","modified":1707047894898},{"_id":"public/content.json","hash":"53dbc63872645bad505ef048d23835a0a3f9d309","modified":1713450786300},{"_id":"public/categories/index.html","hash":"ca5ffc935e990a50e4974051e59c0ef8b30733ff","modified":1713450786300},{"_id":"public/tags/index.html","hash":"0ddb990273ff40023e2c02b0f8216ab0580796c9","modified":1713450786300},{"_id":"public/2024/02/24/experience/website/kaggle/index.html","hash":"a4af6f01e251df06281d27bf55e6bd988b8ce87f","modified":1713450786300},{"_id":"public/2024/02/07/deeplearning/code/pytorch/3_mlp/6_deopout/index.html","hash":"3f1b5941a03897cdb59b2a6bfc17ca40c92ecdc5","modified":1713450786300},{"_id":"public/2024/02/06/deeplearning/code/pytorch/3_mlp/5_weight_decay/index.html","hash":"b13c6ecc56863d1e7d47f1e79d0518af10f29f65","modified":1713450786300},{"_id":"public/2024/02/05/deeplearning/code/pytorch/3_mlp/2_mlp_realize/index.html","hash":"30703dfd5acf08594a538254857b04c43c3425c9","modified":1713450786300},{"_id":"public/2024/02/05/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple/index.html","hash":"49a3d495a85e82df119ed676fbc0ce923f7bb2b4","modified":1713450786300},{"_id":"public/2024/02/05/deeplearning/code/pytorch/3_mlp/4_overfitting/index.html","hash":"bb968f80e29a2c748f0fdda3accf0d53d8d338e2","modified":1713450786300},{"_id":"public/2024/02/04/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset/index.html","hash":"8423002da2497d1e72d80804948868387575c32b","modified":1713450786300},{"_id":"public/2024/02/04/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize/index.html","hash":"a638b8e859409efa92caf08ba8503b97336ce7b9","modified":1713450786300},{"_id":"public/2024/02/04/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple/index.html","hash":"f33789ebed7cd9ec6c7e6462420836d1fec50123","modified":1713450786300},{"_id":"public/2024/02/04/deeplearning/code/pytorch/3_mlp/1_mlp/index.html","hash":"e4a661d78811b3be02681253b6d903696593f547","modified":1713450786300},{"_id":"public/2024/02/03/deeplearning/code/pytorch/1_prepare/7_api/index.html","hash":"4dca41809e04177ca7133c95cbcaa79fa572b460","modified":1710752864910},{"_id":"public/2024/02/03/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression/index.html","hash":"b87128845e53e2c1ab02cd6ea7416fbe3cf87864","modified":1713450786300},{"_id":"public/2024/02/03/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize/index.html","hash":"a4018fc076f2367da767de8d99679b822b8e5a24","modified":1713450786300},{"_id":"public/2024/02/03/deeplearning/code/pytorch/2_linear_neural_network/3_linear_regression_simplerealize/index.html","hash":"57f7cd6b260711a0af3f70814de896df95e3cf86","modified":1713450786300},{"_id":"public/2024/02/03/deeplearning/code/pytorch/2_linear_neural_network/4_softmax_regression/index.html","hash":"950e0a7e58ca5cd0bc38aea7fc6c00eac460c9dc","modified":1713450786300},{"_id":"public/2024/02/02/deeplearning/code/pytorch/1_prepare/6_probability/index.html","hash":"e02e404076abcb980e21e95f3815c5fdd8930d26","modified":1713450786300},{"_id":"public/2024/02/01/deeplearning/code/pytorch/1_prepare/3_linearalgebra/index.html","hash":"a7d7babffd8d7d49ee8a8de87950a24139859c00","modified":1713450786300},{"_id":"public/2024/02/01/deeplearning/code/pytorch/1_prepare/4_calculus/index.html","hash":"03d1e495f92ed2c12a4713ffd57ed14727b89876","modified":1713450786300},{"_id":"public/2024/02/01/deeplearning/code/pytorch/1_prepare/5_autodifferential/index.html","hash":"9981782d8b96f1fda67eacf58d78a08cc3fbc153","modified":1713450786300},{"_id":"public/2024/01/30/hexo/latex/index.html","hash":"eeda4c6212ddfbc51158302e3fff4a098c0e7ae9","modified":1713450786300},{"_id":"public/2024/01/30/hexo/sourcecode/index.html","hash":"a1f734836e75d842baeff6dd91c423d1bb59afcb","modified":1713450786300},{"_id":"public/2024/01/27/deeplearning/paper/SR/Resshift/index.html","hash":"cf1591882b8fbe4669ecda9b1d9a3e79d009dcca","modified":1713450786300},{"_id":"public/2024/01/27/deeplearning/paper/SR/SRDiff/index.html","hash":"23e11a94bdbbdc14d16e963643fd3eaf51dee54b","modified":1713450786300},{"_id":"public/2024/01/26/deeplearning/paper/SR/CDM/index.html","hash":"1323c14ef13f335fba1be1773d5f5299acd73cd8","modified":1713450786300},{"_id":"public/2024/01/25/deeplearning/paper/SR/HAT/index.html","hash":"dcc1c1e57d6e08868c52bb0bbb4855788bb970ef","modified":1713450786300},{"_id":"public/2024/01/25/deeplearning/paper/SR/SwinIR/index.html","hash":"ffb6c88bf125be0bb06092b247ae4a40095ebac7","modified":1713450786300},{"_id":"public/2023/12/17/experience/pycharm/link_server/index.html","hash":"8f2fa27f7809b95cf0c91b831cef0f4d3a12280f","modified":1713450786300},{"_id":"public/2023/12/12/experience/app/lrc_to_smi/index.html","hash":"0c35ec427e88d34daf3a1b2d08b4856e22736b63","modified":1713450786300},{"_id":"public/2023/11/27/deeplearning/code/pytorch/1_prepare/2_preprocessing/index.html","hash":"0bce2843ac66a97175e42eebdedc7796d455abc9","modified":1713450786300},{"_id":"public/2023/11/11/deeplearning/code/pytorch/1_prepare/1_dataoperation/index.html","hash":"905dbedb0a4bb5171bdce779e36445e366f76b15","modified":1713450786300},{"_id":"public/2023/10/02/algorithm/1_base/1_base/index.html","hash":"42884695b4e1f6bc6fa041e3d0a1ae06d6f22f35","modified":1710247262450},{"_id":"public/2023/08/26/datastruct/7_search/5_Btree/index.html","hash":"a3f20bd7b6a3c21d15dfc5f7fb8b847f34540be3","modified":1713450786300},{"_id":"public/2023/08/26/datastruct/7_search/4_redblacktree/index.html","hash":"f6b7acc3da4c3b37538b2f5d14d1098f908af2f6","modified":1713450786300},{"_id":"public/2023/08/26/datastruct/7_search/3_AVL/index.html","hash":"387c8a0143d8c00d1f1e548c9e68f53e02ba231c","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/3_stack/1_stack/index.html","hash":"11a4ecace12f233f58cf686a90f16bd2395dc7e5","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/3_stack/4_matrix/index.html","hash":"e3df71621c3c597a0f1d6e10ca8849df88cd4665","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/3_stack/2_queue/index.html","hash":"03e94baf6e110937eb3826d73d3c0c0f7d526d81","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/3_stack/3_exam/index.html","hash":"6c996d3e17f5e089dcfc22ada5452d55dba3f97f","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/4_string/1_string/index.html","hash":"ce2cb790f621c3b4ff4305d8d7e6dcd1e0550764","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/5_tree/2_bintree/index.html","hash":"1ae18fb1e27a4d092aa72f74768fb26c94140fbe","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/5_tree/3_treesave/index.html","hash":"e56574eef85f6b27d4a33fcca94b2873825c5461","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/5_tree/1_tree/index.html","hash":"b177c60c3e6ee5bd84d0696a91fba6b45d7a015f","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/5_tree/4_Hafmantree/index.html","hash":"1cfed3b68958a00c89b20c86c882c890f0a136ae","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/5_tree/5_set/index.html","hash":"e34776f72b19a9cf04809e24ef2fcd34663a9dd6","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/7_search/1_search/index.html","hash":"0a6e7c2b2106ea8f8bbbcac5cb3391318fa85ffd","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/7_search/2_BST/index.html","hash":"6a353c982289e9ed635d82c2be3ef3e03e5c15f9","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/6_graph/1_graph/index.html","hash":"2e645b4d16f53205f420247518ddf1646e2abca0","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/6_graph/3_shortestpath/index.html","hash":"7775d9c2507d193d918f836a8b31eff8f4245067","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/6_graph/4_DAG/index.html","hash":"83a018673eb4a8ac9349e1180b36d32e23f465ab","modified":1713450786300},{"_id":"public/2023/08/07/datastruct/6_graph/2_generatetree/index.html","hash":"794d848063704c571ed1aa32ca0538308d342ca9","modified":1713450786300},{"_id":"public/2023/08/05/datastruct/2_linearlist/2_linklist/index.html","hash":"2b6c3327533c3116d2fb26f901c351fd29c28fe9","modified":1713450786300},{"_id":"public/2023/08/05/datastruct/2_linearlist/3_doublelinklist/index.html","hash":"796fc2f87f771ac9d30d4c35536897b05248ae01","modified":1713450786300},{"_id":"public/2023/07/25/hexo/hexo搭建/index.html","hash":"63265fed0513309086371c896c6c2b604de09397","modified":1713450786300},{"_id":"public/2023/02/01/datastruct/1_extract/1_基础/index.html","hash":"fb91d710c287dc1796d825e0507856a2dcf18a4f","modified":1713450786300},{"_id":"public/2023/02/01/datastruct/2_linearlist/1_linearlist/index.html","hash":"c258c75d4eb94fd8bee106243e9187861357d636","modified":1713450786300},{"_id":"public/2021/03/01/linux/Linux_0安装/index.html","hash":"5e11b34f2689e1ec3dcecaa081e8bd83fc2d5888","modified":1709349180136},{"_id":"public/2021/03/01/linux/Linux_2.用户和权限/index.html","hash":"ebda9a7fcb0f2d29b01c2886cfeabe0d0275edd2","modified":1709284125391},{"_id":"public/2021/03/01/linux/Linux_1.基础命令/index.html","hash":"02618d47e07bd2f3bdb4cf64afcb6d353c1269fa","modified":1709284125391},{"_id":"public/2021/03/01/wechartapp/weixin/index.html","hash":"2d462326b1dc0ae608cbdc24da5fd2989954e270","modified":1713450786300},{"_id":"public/2021/03/01/experience/vscode/vscode/index.html","hash":"c04a448b1abf97ed8c463e5564a5e31b1e865f08","modified":1713450786300},{"_id":"public/2014/12/24/hexo/hello-world/index.html","hash":"c8e90238ce71d774300d00a9b6c4b1206686b888","modified":1713450786300},{"_id":"public/categories/深度学习/index.html","hash":"12385de9ef22df0a5ccf982d34049daf773f2c9f","modified":1713450786300},{"_id":"public/categories/Linux/index.html","hash":"17032eea03ed9092e378c4fda3d791399b043594","modified":1713450786300},{"_id":"public/categories/博客/index.html","hash":"02ce1a622c9a414774ee557817b237be7a1ebea0","modified":1713450786300},{"_id":"public/categories/微信小程序/index.html","hash":"5e31a5249fbc9c00b23bac6c36db0a2b8c80ba70","modified":1713450786300},{"_id":"public/categories/其他/index.html","hash":"d0ae9057b946a495870cb3a61a206a2f7fb58e64","modified":1709284125391},{"_id":"public/categories/vscode/index.html","hash":"dab0266c1af82e9887a85dbd89833ea0aba44cdb","modified":1709284125391},{"_id":"public/categories/算法/index.html","hash":"d229fc79527b1c162ebf70813be3adf593491e5c","modified":1713450786300},{"_id":"public/categories/经验/index.html","hash":"b4f79483763e85e418a012869b2649d2718c72e0","modified":1713450786300},{"_id":"public/categories/数据结构/index.html","hash":"d9300c9a80b2c9bd0238fb3e5c1a00078fa2306d","modified":1713450786300},{"_id":"public/categories/数据结构/page/2/index.html","hash":"9913038878cdf5804ceb40bb4b4a8cf39c2a8be2","modified":1713450786300},{"_id":"public/categories/数据结构/page/3/index.html","hash":"c873b9de06e59a593c03d91899a25a7d2c25ac99","modified":1713450786300},{"_id":"public/categories/数据结构/page/4/index.html","hash":"4aeafde57580cf07adb0f2ae2e0de5b7a8dd9df4","modified":1713450786300},{"_id":"public/categories/数据结构/page/5/index.html","hash":"8f32af0ab9d63ac9b1d56b360d5893b6814013d6","modified":1713450786300},{"_id":"public/categories/博客/hexo/index.html","hash":"de9e85d0c3b708bfb74fc3fe63dca22bdb059852","modified":1713450786300},{"_id":"public/categories/博客/git/index.html","hash":"d2616b7f2832b3140397d0cf325d3dd566192038","modified":1713450786300},{"_id":"public/categories/机器学习/index.html","hash":"3759ed3f664ba1b72520c32e25a6c7778984c921","modified":1713450786300},{"_id":"public/categories/机器学习/page/2/index.html","hash":"5e1bff07a962f0d4e132a6c42fc0b753473aab52","modified":1713450786300},{"_id":"public/categories/机器学习/page/3/index.html","hash":"a95132aa829d1f706b7796d493192a9e1c168f5e","modified":1713450786300},{"_id":"public/categories/机器学习/page/4/index.html","hash":"8f8da3ff03bee4a9f2459f9a015c2ea71f4c91b8","modified":1713450786300},{"_id":"public/archives/index.html","hash":"61c48e2989415f43694e5ac956edb2ab47dc14c3","modified":1713450786300},{"_id":"public/archives/page/2/index.html","hash":"5adc29b0f418466ba6143efea398763809c60041","modified":1713450786300},{"_id":"public/archives/page/3/index.html","hash":"10e1210faa572a0dc4d2d42bc0b467fa53b8c154","modified":1713450786300},{"_id":"public/archives/page/4/index.html","hash":"6cea7aa3d14bf9ced14c7702e5e2b71ba678aa98","modified":1713450786300},{"_id":"public/archives/page/5/index.html","hash":"535a6b1c76dd63ba50d91d253b60877a5c307106","modified":1713450786300},{"_id":"public/archives/page/6/index.html","hash":"53af1015dc4342c7b27e6d7b98ef51469dcec457","modified":1713450786300},{"_id":"public/archives/page/7/index.html","hash":"6580ece41d370c8831eb4eadc54313c5a5ebc9ba","modified":1713450786300},{"_id":"public/archives/page/8/index.html","hash":"859d63f66b58797200e8fccd1a197f0d815775eb","modified":1713450786300},{"_id":"public/archives/page/9/index.html","hash":"09db23c5d0982f11ee1b807e04d310c98178f3a7","modified":1713450786300},{"_id":"public/archives/page/10/index.html","hash":"90c31439f151077f1bd55cb7aed73693c8005589","modified":1713450786300},{"_id":"public/archives/page/11/index.html","hash":"790c3f873696e16ea3cd0fe5282a482e71500dc7","modified":1713450786300},{"_id":"public/archives/page/12/index.html","hash":"534042e88407f7448e58a6b6452e8d8aa3fbce0b","modified":1713450786300},{"_id":"public/archives/page/13/index.html","hash":"923b4b1c7c54a692357ef238680d5aea894d0f38","modified":1713450786300},{"_id":"public/archives/2014/index.html","hash":"60f9e2fbf17474f14ba746a1451da8a2c0ac6ec7","modified":1713450786300},{"_id":"public/archives/2014/12/index.html","hash":"4916817ce62c6c9d40b2ddf76c4766ffb3f4a23a","modified":1713450786300},{"_id":"public/archives/2021/index.html","hash":"f46fac07f992ac778de78238a4167b0c97cf506d","modified":1713450786300},{"_id":"public/archives/2021/03/index.html","hash":"4c8a3223cc66bfaf2763caade9588ee419e83ad6","modified":1713450786300},{"_id":"public/archives/2023/index.html","hash":"5e92c0d070dfc3fed86f36d7df9837a9d10fc309","modified":1713450786300},{"_id":"public/archives/2023/page/2/index.html","hash":"496399f0517715a622ebfa4cb745a3f8fcc3a6d5","modified":1713450786300},{"_id":"public/archives/2023/page/3/index.html","hash":"f167965c163ea98610715904fd7c881813e350ba","modified":1713450786300},{"_id":"public/archives/2023/page/4/index.html","hash":"f458265d162c7827d3d83204c9cc5035e598051c","modified":1713450786300},{"_id":"public/archives/2023/page/5/index.html","hash":"785d2b1868e889598c07144304ca676d8d80276f","modified":1713450786300},{"_id":"public/archives/2023/page/6/index.html","hash":"13c00be0b0cfaba5139e4cf675b251ed89df98a5","modified":1713450786300},{"_id":"public/archives/2023/02/index.html","hash":"f0b11da900df982988b1f57a04e201ff21e99bf3","modified":1713450786300},{"_id":"public/archives/2023/07/index.html","hash":"738af0ecf97f8c16684508f5c7d4df33c6ff3ee2","modified":1713450786300},{"_id":"public/archives/2023/08/index.html","hash":"cd7279042ff622751d6ceb1f1e07cb96489dc6bf","modified":1713450786300},{"_id":"public/archives/2023/08/page/2/index.html","hash":"061b80036e755e23b8b76279c8c41801bdeed963","modified":1713450786300},{"_id":"public/archives/2023/08/page/3/index.html","hash":"8950d324830ba74c3ea7957ad84b02b627c557cc","modified":1713450786300},{"_id":"public/archives/2023/08/page/4/index.html","hash":"85a0a31523e889f8bcebf1f2bf4d5b479e009a5d","modified":1713450786300},{"_id":"public/archives/2023/08/page/5/index.html","hash":"68d4da9ff6ef937f170edd08c9ff758aca60f306","modified":1713450786300},{"_id":"public/archives/2023/10/index.html","hash":"4d5b613267bea127f2e2251a1e2ef807640f69d9","modified":1713450786300},{"_id":"public/archives/2023/11/index.html","hash":"579eb1587a4adc470033a706024c55d49ce24b86","modified":1713450786300},{"_id":"public/archives/2023/12/index.html","hash":"f83b0c5984192566b4aaac11a3c9883fa1790d30","modified":1713450786300},{"_id":"public/archives/2024/index.html","hash":"15cf010477643fd14829ba382f0697a7b7cfacbb","modified":1713450786300},{"_id":"public/archives/2024/page/2/index.html","hash":"072b9667e52c0e0715cb4dea4e4d3ea2e1d3cd52","modified":1713450786300},{"_id":"public/archives/2024/page/3/index.html","hash":"824fdfb65cd87ddae03d231a57c7389db1d626d8","modified":1713450786300},{"_id":"public/archives/2024/page/4/index.html","hash":"21f39f156110767196c01860b714f53c7582aaa6","modified":1713450786300},{"_id":"public/archives/2024/page/5/index.html","hash":"f7d4629f3d4d5bf52a9e8abd5f16a23497cc5cdd","modified":1713450786300},{"_id":"public/archives/2024/page/6/index.html","hash":"1d31d42c2707f58445894837fe29ae5ab703e0c2","modified":1713450786300},{"_id":"public/archives/2024/01/index.html","hash":"036ea3c79857658ae90b9a7fbc45a4c3f2647d0c","modified":1713450786300},{"_id":"public/archives/2024/01/page/2/index.html","hash":"d6be09a4f24db5d7bb68c1feb47939405da710cd","modified":1713450786300},{"_id":"public/archives/2024/02/index.html","hash":"51f56627467f9fe290c6c46c1327d853d1dd656f","modified":1713450786300},{"_id":"public/archives/2024/02/page/2/index.html","hash":"4496118009d89b890f66ca159f9cbc7b74d99697","modified":1713450786300},{"_id":"public/archives/2024/02/page/3/index.html","hash":"0e6d8194aa93fb90a3274c3e35c0016ef8ac542a","modified":1713450786300},{"_id":"public/archives/2024/02/page/4/index.html","hash":"6d73bfaeaf8d7cbfdcb428564b530849abb560bc","modified":1713450786300},{"_id":"public/index.html","hash":"73d9a456660734d086a27c126224b1fe9d47a7a6","modified":1713450786300},{"_id":"public/page/2/index.html","hash":"9edbaf94b149620c94b669bafafcde3db991753c","modified":1713450786300},{"_id":"public/page/3/index.html","hash":"0f33723a918cd4b301ff77e1166abba363ea9954","modified":1713450786300},{"_id":"public/page/4/index.html","hash":"fa9b76e101cb3d8a6fe9fe2f5a69702a825dd210","modified":1713450786300},{"_id":"public/page/5/index.html","hash":"5e94c4b69ff2eea30a37b2bef12bb060f6218d65","modified":1713450786300},{"_id":"public/page/6/index.html","hash":"f32752ebc99ffde74781eaa7bab9030489fb7a44","modified":1713450786300},{"_id":"public/page/7/index.html","hash":"927c31d3cb07664a1956aa7bd44edd8cbc56d879","modified":1713450786300},{"_id":"public/page/8/index.html","hash":"7a517ac33f643c516c6d6d093e467ecc7bd1b78b","modified":1713450786300},{"_id":"public/page/9/index.html","hash":"83709c5c29c7c0aa5cc1db481b93f76a86cad27b","modified":1713450786300},{"_id":"public/page/10/index.html","hash":"4c1629606f0a2969f6bd6b7974fcb13756d5c1cf","modified":1713450786300},{"_id":"public/page/11/index.html","hash":"9d2a95bbb678253a694560dcfc7a3a343d1a6b1d","modified":1713450786300},{"_id":"public/page/12/index.html","hash":"6f3ef53afbd54d8ce8383aeb94e9cf92826d3cef","modified":1713450786300},{"_id":"public/page/13/index.html","hash":"b8629da38724e5a0da7b44d119af19e67c893567","modified":1713450786300},{"_id":"public/tags/深度学习/index.html","hash":"29704a8750fd3392302828972d5935e970703608","modified":1713450786300},{"_id":"public/tags/Linux/index.html","hash":"785584b9b31ab093cc1f9768d1581936fadd9954","modified":1713450786300},{"_id":"public/tags/博客/index.html","hash":"508f350aa9fb69f8e138c74b9c83332c7efa8e50","modified":1713450786300},{"_id":"public/tags/hexo/index.html","hash":"bd3575b3c328d1119ea657a85aa2475a2e25220e","modified":1713450786300},{"_id":"public/tags/微信小程序/index.html","hash":"ee463bb6ccbb76c6e248bf2d65aadc78d705fe2f","modified":1713450786300},{"_id":"public/tags/其他/index.html","hash":"3836b763849bcc793eba53e7e6e4dee0c8d4d9ac","modified":1709284125391},{"_id":"public/tags/pycharm/index.html","hash":"4f2b09c3e89114658c60fb4653663b5e1a0e835d","modified":1713450786300},{"_id":"public/tags/vscode/index.html","hash":"84a8edcf81a697b8d7b08bc91de5063bda4c029e","modified":1713450786300},{"_id":"public/tags/算法，排序/index.html","hash":"3a6cb6c6dba9f7db293922a3df45f2f7377c937d","modified":1713450786300},{"_id":"public/tags/经验/index.html","hash":"ffeb6da18f8d66c345cc5eb572f235be5c2d92e5","modified":1713450786300},{"_id":"public/tags/kaggle/index.html","hash":"a025db2f41fa0f3b0bb41ab5662aa0c914c35dd7","modified":1713450786300},{"_id":"public/tags/数据结构/index.html","hash":"e0af1f20d0f1de3a5b67b71f400a81927c00f404","modified":1713450786300},{"_id":"public/tags/数据结构/page/2/index.html","hash":"9d86c7b5e609314dbfc1a285c77dd1d19aa1e6cc","modified":1713450786300},{"_id":"public/tags/数据结构/page/3/index.html","hash":"2809b8b5793258dc4902d8320e2755f7e6774da9","modified":1713450786300},{"_id":"public/tags/数据结构/page/4/index.html","hash":"cdf98df0d752e40ec1318e19f0e46e31e9392e19","modified":1713450786300},{"_id":"public/tags/数据结构/page/5/index.html","hash":"dec87ac6db142d5a9878caa047f551c111ce3d3b","modified":1713450786300},{"_id":"public/tags/栈/index.html","hash":"5a25b8998a4a97b3501bf3f0d7eaf8acc8f76f96","modified":1713450786300},{"_id":"public/tags/队列/index.html","hash":"2398a415430c7a9250df4c9ffdb0783158827c04","modified":1713450786300},{"_id":"public/tags/线性表/index.html","hash":"21246ae2a47dad7cf8a5e4f735254ccbf116bca3","modified":1713450786300},{"_id":"public/tags/单链表/index.html","hash":"624b776f71d788116463d5cd59e53ad939675c1a","modified":1713450786300},{"_id":"public/tags/串/index.html","hash":"8c01b7476293f858001e1f72ce541f2b780160f7","modified":1713450786300},{"_id":"public/tags/双链表/index.html","hash":"314c504e16a1f175a33b250e585b00583ceda190","modified":1713450786300},{"_id":"public/tags/树/index.html","hash":"31388098d4c0dfdb374541e156cb8d1ecab44f0c","modified":1713450786300},{"_id":"public/tags/二叉树/index.html","hash":"bd093afe86f9aacda07e0a3c0a619700a311c016","modified":1713450786300},{"_id":"public/tags/哈夫曼树/index.html","hash":"af02be139d40b91a11385f1c587d644690e8d042","modified":1713450786300},{"_id":"public/tags/并查集/index.html","hash":"300d1f6d00e8e573c73b5556ffe68fd87592363b","modified":1713450786300},{"_id":"public/tags/查找/index.html","hash":"e735562e13a656aa0e63fcc45e9fee74563a1247","modified":1713450786300},{"_id":"public/tags/二叉排序树/index.html","hash":"08c03e3c544ac524399d6fe34732a4f620adb26e","modified":1713450786300},{"_id":"public/tags/平衡二叉树/index.html","hash":"ed29f7ca7d13c40c02315624216103ef99b6a049","modified":1713450786300},{"_id":"public/tags/B树/index.html","hash":"0119c01ab084715fcb598c6b96429a4d4b9ab93f","modified":1713450786300},{"_id":"public/tags/图/index.html","hash":"8134f779aff5dfab4654bf0d392bf704208bcdaf","modified":1713450786300},{"_id":"public/tags/最短路径/index.html","hash":"7e08e0c692ceb4133ffdbc2558276f4a94878c57","modified":1713450786300},{"_id":"public/tags/最小生成树/index.html","hash":"5c2c37351130916d29556c1b0d736fcd13acc7f6","modified":1713450786300},{"_id":"public/tags/论文/index.html","hash":"14853bda724fa364ab2526e10712d3817174ecf1","modified":1713450786300},{"_id":"public/tags/超分/index.html","hash":"e0bf143416b0668f53c57a27c7f311a64f1e05d7","modified":1713450786300},{"_id":"public/tags/机器学习/index.html","hash":"a0add9a0ac3b28f2e5c34b685aec9fc19acaec69","modified":1713450786300},{"_id":"public/tags/机器学习/page/2/index.html","hash":"cc1e8604ddc3598d19b435b2c12c60cf0b60da7e","modified":1713450786300},{"_id":"public/tags/机器学习/page/3/index.html","hash":"a51d7d051f3ce78e9baee19fcebbcf750df9be56","modified":1713450786300},{"_id":"public/tags/机器学习/page/4/index.html","hash":"bfb52cd03d437011835846926cc9f6972f3cc2aa","modified":1713450786300},{"_id":"public/tags/pytorch/index.html","hash":"1c599680c08df68ba950259605aa8bbe6d00aa49","modified":1713450786300},{"_id":"public/tags/pytorch/page/2/index.html","hash":"51ecf8c2adb34a74d86ee28450b05cbacb71536a","modified":1713450786300},{"_id":"public/tags/pytorch/page/3/index.html","hash":"7222937c7df0fa7a4b6436073e528293261e9ec1","modified":1713450786300},{"_id":"public/tags/pytorch/page/4/index.html","hash":"f73085e3197ec946a04fdc9a14ab53148c3438b2","modified":1713450786300},{"_id":"public/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1708850095561},{"_id":"public/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1708850095561},{"_id":"public/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1708850095561},{"_id":"public/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1708850095561},{"_id":"public/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1708850095561},{"_id":"public/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1708850095561},{"_id":"public/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1708850095561},{"_id":"public/img/hexo/1.png","hash":"eb5d590c866b115b711b6b18e688d0fb750b0fbc","modified":1708850095561},{"_id":"public/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1708850095561},{"_id":"public/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1708850095561},{"_id":"public/img/hexo/3.png","hash":"1c144b98e4d21f31d06466142a48efaf2a94d5e2","modified":1708850095561},{"_id":"public/img/hexo/4.png","hash":"1386eb7152ca993db6bb1b73ec224640ed73ace1","modified":1708850095561},{"_id":"public/img/hexo/2.png","hash":"1a2488cab647b2d9ee0645f8b1404f20d8f6391b","modified":1708850095561},{"_id":"public/img/hexo/6.png","hash":"e48c5ecbd482f3d30befe212e0bdbb7edfc8e1ce","modified":1708850095561},{"_id":"public/img/hexo/7.png","hash":"e6b833a8a600ccde88c4204782cc3e8004e0edb2","modified":1708850095561},{"_id":"public/img/hexo/8.png","hash":"2caad5ef038d9170ea58f0a0026bc8306280ec37","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/2.png","hash":"6d1421cc038218e94daff7ef39c7d3ac9d2e881c","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/3.png","hash":"571cded10b5c4269a889e56dab07bc689818e102","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/4.png","hash":"743e8d48e403ebd444289b1668ec6512099c9bb5","modified":1708850095561},{"_id":"public/img/experience/website/3.png","hash":"aa0520b3b2ccc24d5cb1bdd6f0470f39156e50d6","modified":1708850095561},{"_id":"public/img/hexo/config/2.png","hash":"368052a20c17d974130d81cad86bf9eefbe696e6","modified":1708850095561},{"_id":"public/img/linux/install/1.png","hash":"f5e18416748c8cc86938da9ae1f1ff42e91e08bd","modified":1708850095561},{"_id":"public/img/linux/install/2.png","hash":"23d49dab591d627c6673fb2a75fd5d2eb9d2fed3","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/3.png","hash":"8f35efb483252f734fcce32a59701f95ae08ca08","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/11.png","hash":"b6ebbcce0e705315d2b9d49cfe47a5b0c7d738ef","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/10.png","hash":"39b9fd6684a084dab653c885553bdfb48e616d96","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/2.png","hash":"155e96cd73c2a354ba31581c3ae7990c35f1e77f","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/3.png","hash":"d5c06088084abdd3d3f791266baf3e490353fa8e","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/5.png","hash":"528b88149b3eab3ef15c7cd04f18cf14463a9f8e","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/4.png","hash":"c2347bb419ce0b59e6a10bf13e67aabb6f1d6000","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/7.png","hash":"8998704ce34bfa8d04b681a1b979c2ec712511df","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/8.png","hash":"faedba9e3148fa893311cd9ddf820ae269dcc09a","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/9.png","hash":"d38b41763eab121538504eba96a933f860d3fca0","modified":1708850095561},{"_id":"public/img/experience/vscode/relative_path/1.png","hash":"5bf68e898eaedce375a846d2766c9d3c5f2c21c6","modified":1708850095561},{"_id":"public/img/experience/app/lrc_to_smi/2.png","hash":"29999d449f335d959a928b47ee573094d6407e6f","modified":1708850095561},{"_id":"public/img/experience/app/lrc_to_smi/1.png","hash":"3e6bf1d0664a78945a62cb8efe7291c559bdd95f","modified":1708850095561},{"_id":"public/img/experience/app/lrc_to_smi/4.png","hash":"2739ef20646d80910f98405f596227832d73dca7","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/CDM/2.png","hash":"7e63a4151dc6c4e94cf281abe73dcdd544fe67e1","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/3.png","hash":"8557ef65ec097d18405fe25075ce508a569cdf3c","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/4.png","hash":"bd2061a683d43542f298d3b6c369a7a73e940802","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/6.png","hash":"f626d8e52052327ea89c2ef3f164331a2c5813e6","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_1_1.svg","hash":"2268e578363aa8e3ea0d9fc6f9048b5476965606","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/1_prepare/4_calculus_files/4_calculus_3_1.svg","hash":"4388b61bde02e3677bad2d58f1cc537f2ce40879","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg","hash":"117d33ae7e24490dd351cb3dda9f01697604a260","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg","hash":"286de42a50f439d72b9a4431c26633c68c9e5244","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg","hash":"e7326b636020ee834dedefa365a0bc50df191fcf","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg","hash":"916e9f81fd64d864e8928b2d075bbf51b853735f","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg","hash":"0b967ebe55c0efd5a10943f13da50b17012b8d9b","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg","hash":"0aeb69df6b54fa10fc0bba6dd6b8f74bc906c713","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg","hash":"15de8b4f4bdc9f439bd6567de0e4a4a511710dd1","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg","hash":"b40bd446671c91e8423328496f591d47f9b855fe","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg","hash":"2cdad356448f53f436b46f6a1dfb3301d9edeca1","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg","hash":"893bf7bd6b1facaafeaa59f0a74e1ec9efbcb4d9","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/4img/1.png","hash":"acef488b314a0eafa2b537f365d5fc373e271623","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg","hash":"430b01e4581ecbbdfa0b2bf4990c15efdcab7603","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg","hash":"c4a09daa3725c074825db20b1ae97145f33cbb24","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg","hash":"aeac8a3e0b2759086aaaa1c870717c441ead05c6","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg","hash":"ef90ef3ede804f998cc308e825b05d226570b0ca","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg","hash":"28bfe489d1ba3253bd9a1369f8ecf0deb413a211","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg","hash":"0cb1e259525ec525d6356f7f8c112a6e9f91977e","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg","hash":"53c269365154a5776b6af1b449e163d41f59fa77","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg","hash":"06c12519eeda924c77fc54eb45521bc677fb69ca","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg","hash":"90fa91d6679990bbb69a51ae6fba74606e031747","modified":1708850095561},{"_id":"public/img/0.png","hash":"18cd3f368afc326152fddaf38353d0a3a5b88cce","modified":1708850095561},{"_id":"public/img/hexo/5.png","hash":"795caa1da3dd3b5194ca066cc4a3dc684ae5c4a7","modified":1708850095561},{"_id":"public/img/linux/commend/4.png","hash":"312407c7570bf5d0226a98c51f1e400f9e426418","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/4.png","hash":"cd2d22e47a4ccf7d698aa886967d484994fe68c7","modified":1708850095561},{"_id":"public/main.0cf68a.css","hash":"c35f1df998abd0f1d2f6a733f74e35723875635e","modified":1708850095561},{"_id":"public/slider.e37972.js","hash":"6dec4e220c89049037eebc44404abd8455d22ad7","modified":1708850095561},{"_id":"public/main.0cf68a.js","hash":"993fadeb5f6d296e9d997a49ee20dc97333ceab7","modified":1708850095561},{"_id":"public/mobile.992cbe.js","hash":"01b35e71e37aa2849664eb5daf26daede2278398","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/1.png","hash":"18f61385a1aa2a42b57ed9fd4eb058988038bc79","modified":1708850095561},{"_id":"public/img/experience/pycharm/link_server/6.png","hash":"8e2eb0e6a096b258aa6d87f122a6901cadc81c22","modified":1708850095561},{"_id":"public/img/experience/app/lrc_to_smi/3.png","hash":"a1fce07f832cae4b3b251dde1c87376f4386ad2c","modified":1708850095561},{"_id":"public/img/experience/app/lrc_to_smi/5.png","hash":"fe826175ce8041af3cd87afada1a66204a489e4e","modified":1708850095561},{"_id":"public/img/experience/vscode/relative_path/2.png","hash":"6845b7d833c89764ce7e87a437079bc76022ad43","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SRDiff/3.png","hash":"12aefac57158ded661913fee37c1348baeb1fb5f","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/2.png","hash":"c62663719646ff08f57958e388c64cadf00bec40","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg","hash":"4fb11c7574654e616736bb655a7365c62e42810c","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png","hash":"29edd99abc43a64b80c27ae3404d354bbaf2e1aa","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg","hash":"7745038901e6c501386a5bc1d7afda51874a0a9f","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png","hash":"a65d5f49e5bb5f2cdc688e75966e4f8d23530336","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg","hash":"a84269a32f13a9403e16b3b83416bbe856798469","modified":1708850095561},{"_id":"public/img/experience/website/1.png","hash":"e3f3761e0a8d13765d07c62356c8cb531085832f","modified":1708850095561},{"_id":"public/img/hexo/config/1.png","hash":"57c220f0666493e9aa46e655dd3e4c8d8769526f","modified":1708850095561},{"_id":"public/img/linux/install/3.png","hash":"aff317a4f01469d43aea727220d5f35dda5ad82f","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/doublelinklist/3.png","hash":"1be61897417af386bdaab09257f60b624fa4b7a7","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SRDiff/1.png","hash":"8859dd1b37ba832fcf39bea466172166a4872ca1","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/3.png","hash":"ad4657eb56551df2f18233832075681a371be953","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/5.png","hash":"05264fcc3adc2b358081b88c0f8cbb3a3ac7bce9","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/1img/1.png","hash":"32187b3f3d27abf58d84102ec722a3bdfc1aaa95","modified":1708850095561},{"_id":"public/img/head.png","hash":"c695336ba203c92400d8801be883217f516ccfa9","modified":1708850095561},{"_id":"public/img/datastruct/4_string/22.png","hash":"69fc98bbd8b19f77b749ff2aac2fc1d84da041fc","modified":1708850095561},{"_id":"public/img/datastruct/4_string/6.png","hash":"02c58cbb86448ab130e8de56a8ed30190a270441","modified":1708850095561},{"_id":"public/img/datastruct/4_string/7.png","hash":"5045a59070a4dc3abf0b75adc7ea361e417a9ac6","modified":1708850095561},{"_id":"public/img/experience/website/2.png","hash":"386f3140232edd163a74963d3f1fb71b631c7ccc","modified":1708850095561},{"_id":"public/img/linux/commend/7.png","hash":"b5334dff05fddfb776b67cfa62e1bde08ad5a7d1","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/5.png","hash":"53bae744eb1d75032b76b2a34393b483c507d45d","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/身份证1.jpg","hash":"f4ad46fab9a1874986ccd963cb4f4d8a8602554c","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/CDM/1.png","hash":"d0284a0aa9cfc0bb236b9b2d21da006c12aeba82","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/CDM/3.png","hash":"f1489a76081146c43436f33662b8fb24dd93705b","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/11.png","hash":"d1c328c62f3a3894356be5017e148cf82228ccb3","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/2.png","hash":"4949684eeb63cf7260e919617454a2d551b3f64d","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/6.png","hash":"13827355692c474261b3db2cd451e6704ac78953","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/7.png","hash":"e6e1d6e4486b4a67ccf1de20a0c3fcd7e12fc168","modified":1708850095561},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/6img/1.png","hash":"9e19fa51e5bb17e6afa8a8fc5ff26081074e890d","modified":1708850095561},{"_id":"public/img/datastruct/4_string/11.png","hash":"16f3b25aabe8fabac62e4dee790ebd76f9f5cd7b","modified":1708850095561},{"_id":"public/img/datastruct/4_string/33.png","hash":"51078f091563b3fc4126d3a1ff3e46adb6dbf1dd","modified":1708850095561},{"_id":"public/img/datastruct/4_string/9.png","hash":"89fb11a7191f94bd33c84aad1f97b63e15def4e5","modified":1708850095561},{"_id":"public/img/linux/commend/5.png","hash":"9877ec4411499460626515956172ac17c0461194","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/5.png","hash":"c3b59117bc61e06960711487d2c9faae1d8490af","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/6.png","hash":"37e2c7e31f6b34a0c678c3241da2028ea694b61a","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/stack/4.png","hash":"ccf102d7ac6a969e1bdcd81001538a5e14bc0685","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/2.png","hash":"cfd647157788822a1ee87152474331d6b72983c1","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/3.png","hash":"bb65dc7f7d243290cdfc39e6ad91d29a44a5a978","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/1.png","hash":"f518bf1aa4309d3129066c1f7a4de9d0126bfc64","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/身份证2.jpg","hash":"c7248cff105487f06b45d89d6b51e972489f667a","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/4.png","hash":"d5be991310455fd4f492c541ef0b327914c7c15b","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/4.png","hash":"b0f7022db8b8bdf2dfd25b3be51b483c35c86632","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/1.png","hash":"f62dbc992f719d4edde6745400129010f2df805f","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/6.png","hash":"58eecabd401a7bb5dab4706e4a65b0ad3ab55d3e","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/5.png","hash":"f8bc031e79eea55114892711cede3ef873029495","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/7.png","hash":"303a2e13032a6ab2b2e45c50c1e3666232dc39ef","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/queue/1.png","hash":"c188269b5cbcbb8fbc67391b7be94cfea7ca8ecb","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/7.png","hash":"a4960ce0bb113834995b83f1e72a5f1d59b5b580","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/6.png","hash":"dc6fafa3d3c1dac6a0df6a46537738fb955991bc","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/set/1.png","hash":"f1791e355115d078e7858dcb207f8e87bbd736d6","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/set/2.png","hash":"33126a20ebac6b4dd33fda2b1337f0132e432f28","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/tree/2.png","hash":"c36f61b2f331b4794bb7affb5653a3c70b6bf7eb","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/2.png","hash":"3a0427868ede3bc4fbd980e1eb44d1ddcf8ba662","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/3.png","hash":"273b817773cfca2cefedf37e00beffce3aac979d","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/2.png","hash":"7e507b8326c93a6720e559066f42886e7a8255e9","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/4.png","hash":"42244dfc16a8545eb1d6f29cbefa1d7b10b8908f","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/8.png","hash":"090cb62b2d7077ec1bddd563b06245be0a144a7e","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/1.png","hash":"103d09498654fe7acde2c2bd20371fe75cba9456","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/11.png","hash":"5f5dd2e2cdc0161d68f514f5f6fa92a17097cc15","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/2.png","hash":"8c9d5f586b67d8973d280205ad376279861d9fa3","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/8.png","hash":"f46809238bf064e700e57d6e341b568072b9c1ef","modified":1708850095561},{"_id":"public/img/datastruct/4_string/8.png","hash":"c6fff07a1454c9886d48afe21a3b2dcf4190090e","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/doublelinklist/1.png","hash":"400a7006ed7e701ecf338868d027fa9d4fc09aa4","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/1.png","hash":"0355d11dc2d67894016a00819bb2f9fa048e3456","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/queue/3.png","hash":"7389121d9a2981d2f7a913f27ceb495c9b3e3f85","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/9.png","hash":"483683c7cd2491fcaab026f2501fb097a99e5af2","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/stack/1.png","hash":"320bb1490c7237abc6cfa31f75d80a2ff667d10e","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/queue/5.png","hash":"1d3549ac63517ed5a5fdb36c60ec68570530c6ee","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/stack/3.png","hash":"bbfeff2baa2a09d1cfde6efd8ced65950969d451","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/1.png","hash":"f2ab94acf03f8427536230e7e4492f6286a8863b","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/5.png","hash":"0ef37d1a33ac8f7adfc64f2df93ddc46db02a255","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/4.png","hash":"4bd74ef02a7ce777be6d6be132b809eadd333795","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/10.png","hash":"f8f49b35a8464be6d441c4d1c9d89eacd46c99d0","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/17.png","hash":"96a3732857d13b320d44a5d2bba58b24e63eb2c3","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/21.png","hash":"96cd917e4e00ec460d56bf1497a6ecf875ac2412","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/5.png","hash":"2ac3fdffca3ece0b482b346dc80124c9b1a9b293","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/4.png","hash":"f198322bd8b57e7f7730ad78a1502b72d34af28b","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/1.png","hash":"abcd55aa8269afb2ec7d383f5bc03379182b18e3","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/8.png","hash":"b86ec6b6a477e655a484cb62d2a8372e71bbf398","modified":1708850095561},{"_id":"public/img/datastruct/7_search/red/1.png","hash":"24ed2aaf9c398cf0bd548949cc530a82f26bbe3b","modified":1708850095561},{"_id":"public/img/datastruct/7_search/red/5.png","hash":"91fa356e862977aedcd8380883ebba68ce55ff51","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/1.png","hash":"f3127e2c823a2115d3eee9c9186e66775f7c8c56","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/9.png","hash":"352ebd7320c0daf59164cc606c54748d4461364c","modified":1708850095561},{"_id":"public/img/datastruct/1_extract/7.png","hash":"719ea9a0ff7bdeb47bb6068bacaf8799080544bd","modified":1708850095561},{"_id":"public/img/datastruct/4_string/3.png","hash":"0263d9a7b8552db5293da17683a78fc6b18add52","modified":1708850095561},{"_id":"public/img/datastruct/4_string/5.png","hash":"48c8a60a2eade60271df902361219dc60182b147","modified":1708850095561},{"_id":"public/img/linux/commend/6.png","hash":"1ad966f50410b760b5c4da236b00fa3c87d6e794","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/1.png","hash":"93d909b592f79bb93cb05e461f1cfe5b19975588","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/3.png","hash":"d4697e7aa4faf3faaec31795d056369aee9a0747","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/8.png","hash":"a14b20161150d5ec27c26a8769d2fbc63882cc02","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/11.png","hash":"d6da827299c4424e820f13b641b8cf1d7dcc8647","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/14.png","hash":"e09f44ccfd173d7e22a664ba1da0496578fe71fa","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/16.png","hash":"ea7d466a5c4df3dab2b7d5fd1db34983ad20bcc9","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/21.png","hash":"01cce10b1c97bfe85564457670c02523f9e22bbf","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/4.png","hash":"a1a7f2f52dea3bb78b7e610b99cd46c8eb638324","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/9.png","hash":"617b5e71fbb4b6cbde53988e84b7db14227521aa","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/hafmantree/2.png","hash":"4b489a3880d5c72496e6bb3e9a0fb1867c72a61e","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/tree/3.png","hash":"5c23b6d576d9ab930ff7bed0ef93f7286fece156","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/8.png","hash":"fa5bb9c206f9d820b4829b82a815acfe9535f698","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/11.png","hash":"2c57ffd92b97d2c5cb9cd6e86d45ba7a7c3ef152","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/12.png","hash":"2c57ffd92b97d2c5cb9cd6e86d45ba7a7c3ef152","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/13.png","hash":"f82c00b83d4707743244ced4344eb173088f6537","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/10.png","hash":"367b5db4a5df4056bc852b4d15d90569f16d47ad","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/7.png","hash":"1640ed8edab3a2235f8d1890dd911df427202d5b","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/9.png","hash":"1c087e833e9d95f77fdfc1c5393872f67b161620","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/10.png","hash":"8f1df1e8b36321baa8454a6e408fc3132f3a0b49","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/5.png","hash":"c31e028791baa33832977eba8885d7c2fa495f5a","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/9.png","hash":"9af35488623060bb152e66796eed3d11de500b69","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/8.png","hash":"ad9e53a5806f86ec4f2e076279d81ba1faf82b80","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/11.png","hash":"3b8f079b47feb4ead637c8e8799668081da3b3c7","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/12.png","hash":"f5f8a7f60d80bdea3901f24d757d71f354b21076","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/13.png","hash":"1a0b6b8999306d37bb4e5e021dcd2860fb91003a","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/14.png","hash":"ad20949a8476a1eab20b23a627f5d1c2c5245b72","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/16.png","hash":"8accfd8baed48f5129fd22bc026b3baeea3f53dc","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/19.png","hash":"3b6cc333c977fabc8759d19010d40eadfec4e126","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/1.png","hash":"4f739f585dcd7d2fadc90c2ec487d810e50b12b5","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/12.png","hash":"8af073f178b71de473f6779005b693b6fe931e35","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/5.png","hash":"ccabac77b9f87025d39cb178c736ab08be966a53","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/9.png","hash":"6cdb024dea1b8f80280a985b970deb30f92229dc","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/2.png","hash":"11152e9108147bf5ddaf92da0a6ae3b40310f0f3","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/4.png","hash":"4ce88adb5b069d4d0f3e019c8baaff3daf93577d","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/2.png","hash":"ee0dcdd98d36ebf968203e086842f82983833393","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/1.png","hash":"9645f93ecfba9f5b9206fde1c0aa73917896f582","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/5.png","hash":"a743c446dfcf9b937205f58dc028f41d070e48b5","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/3.png","hash":"5a8a80187065f83608b3d27cf134ca2b1345ea50","modified":1708850095561},{"_id":"public/img/datastruct/4_string/2.png","hash":"fc16f97df3cd583499ebfdc08a17a59d584f5dbe","modified":1708850095561},{"_id":"public/img/linux/user/8.png","hash":"0b8417b51075ac859bcf37582f6ca9cdc6d1ed9e","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/doublelinklist/5.png","hash":"2fd148d973e964c5a66a6677e08c8d40bb4086a7","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/linklist/2.png","hash":"e9347e1f225c5cbb9c549e8dfb9f5bec9b0aeb0c","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/2.png","hash":"e5f12710a7ee824a071f4b667c21c6adcacf57f8","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/4.png","hash":"a3e580c7a52b96615056d54e0901e927210ec6bd","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/1.png","hash":"4232903681e5acd2874ed02adbb613f650cbd3a4","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/4.png","hash":"52cfb649fee62c2d0248b8a19634016a6e7dfeb0","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/queue/2.png","hash":"372e33824e44870739b0b2dd31473891d8be39d5","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/queue/4.png","hash":"ccc7388fe9d234b85dfaf0f13df2011fdd448cc9","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/13.png","hash":"5c51b87683faf0b42ff105b4b509847ce28f033c","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/12.png","hash":"7b9ec3a8aeea46a650d5f324f6bcd450d7c6f1ce","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/15.png","hash":"642ac58ff76d07fdb5f34aa690c5d9198947b50b","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/19.png","hash":"4850932f1aa82436d5d483bf8c65762911e63d5d","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/20.png","hash":"e3ccd07772d3937fe059f7030cb5637d07272705","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/5.png","hash":"5606a7bf100e9f72e25622c5364701c62e995057","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/set/4.png","hash":"60b7cd6266dd054a37d619083c49e76d936471e7","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/set/3.png","hash":"2656e0c353bab48a03f657aff960e69d4ccf488e","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/hafmantree/1.png","hash":"c93b19d02e8eecbcd748e4e7d0b212fdb258e3d2","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/4.png","hash":"0ed7fed4738e93c716e7d8947eb29ec60bbcb3b3","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/1.png","hash":"5f3d151b0ef530ec331a88871f4c790ad1e7de76","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/3.png","hash":"554d3cbfb2d7a8276695dfab55b6fa00d6b41e29","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/7.png","hash":"b0407aed45fdf2778c37aeb86e16f0d76246bd1b","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/6.png","hash":"f70727738f1d45d51a0b5ace85e38f9ef4fbefbc","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/7.png","hash":"430730c045a26ff7a2671b3bf42b81d36e288ec3","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/18.png","hash":"23ab682c9b0e7ed5a5372d575801e89b1735a9c8","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/2.png","hash":"30c586539ef983e91f127a9d117be4334832c7b4","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/22.png","hash":"6db8e47e30d615832eebb062a162791b7c310fd4","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/25.png","hash":"04097ccd7e31337fc15b0b4e6590f0e46ed5e92c","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/26.png","hash":"186dae57f64593ba80a9484c2b1746c1f8d29999","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/4.png","hash":"7a3bb1906f0ad5afccbed87ff851e3819cbafc36","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/6.png","hash":"5617cd959a09a2687fe2cb9a32abfdf070d389fa","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/8.png","hash":"177c49dc3942bb19e887c89c2e795bc944d2994c","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/3.png","hash":"8736726d7645894dc84807c3e9ce0e54fa76c717","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/11.png","hash":"ddf8ab48eb171c8ef1e1f0114616ad849ddfb034","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/13.png","hash":"f09b3c157a8364de40821317b2677a175b3f4dc6","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/2.png","hash":"bfe530abb9fac2ea1b2eb295a832de6b1f725218","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/7.png","hash":"daf3d4a4a195019ed2629e892f3fd8e2aee5978c","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/6.png","hash":"707dbf184c801ed3e8a6f0c333ab4797dda2b238","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/8.png","hash":"4320444060e2fa35d0b0e4dc8f33a03cec5bea7d","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/1.png","hash":"55a425118fb566256fc2dcb7267670c2e0c8b6be","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/3.png","hash":"b167c48347e3f40f71169249aa9e57149f456030","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/6.png","hash":"ec0afe78ba75251e35923d39189ae047b28b0898","modified":1708850095561},{"_id":"public/img/datastruct/7_search/red/3.png","hash":"e07c568186d1ff720b927af647502bf84095c922","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/7.png","hash":"b0c033daaece2d1342f4017cd64850e19e1973ea","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SRDiff/2.png","hash":"bc499602dd3514cfa3e48a170a0254f98de118a9","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/12.png","hash":"35982c423def1509d333ab9842840239de01b7d2","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/9.png","hash":"2d2e66a07ec289a15511a707862c44c0fa9b9c6e","modified":1708850095561},{"_id":"public/img/datastruct/4_string/1.png","hash":"dd8f568d408f4066857dcaf5f837b76ff72681ea","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/doublelinklist/2.png","hash":"ca655c8903c294c2561adf00e03115d85daac0d3","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/doublelinklist/4.png","hash":"7f6f39075bd9d99fc80bed11a9572929861608fe","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/3.png","hash":"de128228b37c7f67472db3f69319469c15577bb1","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/6.png","hash":"5796e5f5deedd912d609d786b9bcdf81e5952265","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/matrix/5.png","hash":"ddc34b510edf878733390cf6280c17e24430ca44","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/10.png","hash":"809602cc17c15b735981b02272c065543b829903","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/18.png","hash":"0c53deb30a095262bace6fe55d49b9528d79932b","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/8.png","hash":"da3f2d7eb809212e929a5124c89161424edb4b19","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/set/5.png","hash":"28d6733723d49340995dec2fde9e88dd9f0adb05","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/hafmantree/4.png","hash":"6e0aa2e3cb77d483683e3d0d11cf91ed42a1b86f","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/tree/1.png","hash":"adf29d834bac15c3cbb5a59ffe8ad8beb0e84a37","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/2.png","hash":"a3b2cc5ec1d3f6641c562ec91fd67158681d54fd","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/treesave/6.png","hash":"29ebb70f952f15f45953541376e244d40361dce0","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/3.png","hash":"ab89866de5a90543cb94ba68f91772cbea6885c0","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/20.png","hash":"e1ea39884791587ef05f620d70bea10cad4517ca","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/7.png","hash":"17fe699b83593d7b5a5a63cf6f8e96850e5a0c78","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/7.png","hash":"8cdb063bca970837e89246b7c242aa8df4ef69ab","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/10.png","hash":"904d546f835be088ef8c6431fcba3099f29a89b6","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/14.png","hash":"e5fe49cda495ad811654a44c5c4df75c58a26b15","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/shortestpath/3.png","hash":"4a56bcbe87473960ae402584e0da20c8c16cfee1","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/4.png","hash":"52e1734955fdec29f5967e9ee9474d2cddc98d86","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/7.png","hash":"66712ddccabed87d61c763cac232635c37dfba4c","modified":1708850095561},{"_id":"public/img/datastruct/7_search/red/4.png","hash":"1565be0433a56f3b59c04e9ac45580ed38c6e49e","modified":1708850095561},{"_id":"public/img/datastruct/4_string/4.png","hash":"7838d4d94535fa7a23ea70e174f18224109af7a3","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/stack/2.png","hash":"a908d6604057c26915ac3f6755cbb618fc315bac","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/22.png","hash":"b42865762e3f79e13238c99d3fea6e9a34b48b7a","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/generatetree/1.png","hash":"a38f3f3818fb59ffa2e0c2f149baae5ad3e08906","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/15.png","hash":"ddaa0073e7a050c6da2e15bb92edef4b263e71f8","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/23.png","hash":"507a10492249735e4eff71110dccc08e32d75723","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/5.png","hash":"e526a1db7825500f3915b81cff0b2a0649501224","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/9.png","hash":"af0f3d264f6346953c00662e13262590c718288d","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/2.png","hash":"62329d059d1524ccb694e74674724d123b1d1ccb","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/6.png","hash":"81c02a6561ed5dfb1a5d2523c54f6f3d033c1828","modified":1708850095561},{"_id":"public/img/datastruct/7_search/red/2.png","hash":"561a4f0a6d89e9dc5059fe6ad41fcf3ccb064c71","modified":1708850095561},{"_id":"public/img/datastruct/2_linearlist/5.png","hash":"d4eecc47637ac57e721533941890b5db93c6cd96","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/bintree/17.png","hash":"7e9e417dd7e92cf4518e7478df7a61dc792b5c79","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/6.png","hash":"160fc9cbaf10916bf63315abe80c023af57cb663","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/8.png","hash":"6d7b99c9cfe359e941a1a0a9f733fd37ca979430","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/24.png","hash":"24195d899250ca557aa68f3c5b50872ebf724b25","modified":1708850095561},{"_id":"public/img/datastruct/7_search/AVL/1.png","hash":"1cba4a7760b4e3198c1d948e381a13e76b5522a5","modified":1708850095561},{"_id":"public/img/datastruct/7_search/BST/3.png","hash":"9d522c4b3ed9fc8d4cad85e1d574895e0edf5ffd","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/8.png","hash":"a057c763efb0ce8ad6ed81c7fcc687b8cfd61d64","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/5.png","hash":"70eb4243c88e9cb6f9d64dc4b1ce0123f93d7b70","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/1.png","hash":"3c95625309a2e2f7fddf78c14bc972a018c82916","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/graph/3.png","hash":"1c63775db55f4624289bc1ef592ed88d4c2258ab","modified":1708850095561},{"_id":"public/img/datastruct/7_search/search/5.png","hash":"1be79056d4fb1d9c03850ce2161c2f2c22373751","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/2.png","hash":"23650f4e8a06111ed5639cc0891fd7490c8eb7b7","modified":1708850095561},{"_id":"public/img/datastruct/6_graph/DAG/4.png","hash":"1aee5cdce7b83cbb17cc5c7c14ac9d0a02a787f8","modified":1708850095561},{"_id":"public/img/datastruct/5_tree/hafmantree/3.png","hash":"20d3db5968e55586130cdf0fc98d5dcf77d79408","modified":1708850095561},{"_id":"public/img/datastruct/7_search/B/1.png","hash":"bba1aaa2fb53ede0dff30e60d86ac9c9e7ad3cc8","modified":1708850095561},{"_id":"public/img/datastruct/3_stack/exam/6.png","hash":"721fc6eedb785c67120633ed94159a0d4ea49270","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/13.png","hash":"75213541cc70afc1d1918c479ac78f8d56850e52","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/SwinIR/10.png","hash":"88289ae9893a394b64ec2faf0759100abbf224a1","modified":1708850095561},{"_id":"public/img/deeplearning/paper/SR/HAT/9.png","hash":"a43c143ea90005eb68c6b17343f20d5526e99d2e","modified":1708850095561},{"_id":"themes/yilia/source/img/java/produce_practice/1.png","hash":"30554ce2998b7e51ad6c95ba0a8dd64d7184e7d5","modified":1709254499920},{"_id":"themes/yilia/source/img/java/produce_practice/10.png","hash":"e24850fd076e7deb6510d6eab70e1b983a8143de","modified":1709275557514},{"_id":"themes/yilia/source/img/java/produce_practice/11.png","hash":"a1dca93a880850cf39a90afe2ab00b2d4af3d05d","modified":1709275580280},{"_id":"themes/yilia/source/img/java/produce_practice/12.png","hash":"a6083435996c6b697b5b5b9c64cdf1bed6a119f8","modified":1709275784997},{"_id":"themes/yilia/source/img/java/produce_practice/14.png","hash":"d454f6af516b04b392c643aff34c133c27c89566","modified":1709277999305},{"_id":"themes/yilia/source/img/java/produce_practice/13.png","hash":"5a8cba5a88ea57b8fbc0b3d03e170bd78d63c9d6","modified":1709275909052},{"_id":"themes/yilia/source/img/java/produce_practice/16.png","hash":"05fe99b97b36da5852d48717d487cd7bcdaa62ea","modified":1709278477364},{"_id":"themes/yilia/source/img/java/produce_practice/18.png","hash":"662e19f9ede67fbf97ba64db2b1dd570493f42bc","modified":1709278709707},{"_id":"themes/yilia/source/img/java/produce_practice/19.png","hash":"5b6c4d4ca1fafa15fc502684b8ef690dd783b1f0","modified":1709278987299},{"_id":"themes/yilia/source/img/java/produce_practice/23.png","hash":"5bfb5c0dfd8a20cb41b6c8fa1c0f066de5b58ce0","modified":1709282806971},{"_id":"themes/yilia/source/img/java/produce_practice/35.png","hash":"b598e1f3995b79f9ca23beecec9f286ff5ee7637","modified":1709268114873},{"_id":"themes/yilia/source/img/java/produce_practice/4.png","hash":"4ba2f5dd63299422bc74f7debefac14fc5c2abbf","modified":1709272041206},{"_id":"themes/yilia/source/img/java/produce_practice/6.png","hash":"68d24416da9cf00e2c1f3389d69780fe7b0aefcc","modified":1709272713646},{"_id":"themes/yilia/source/img/java/produce_practice/8.png","hash":"2d231f50629980b55a959bbbb7ce4b44627428da","modified":1709272836338},{"_id":"themes/yilia/source/img/java/produce_practice/9.png","hash":"2c930e47793ff23442b7e0047e667d26b2ce652f","modified":1709274595282},{"_id":"source/_posts/java/produce_practice/1_setup.md","hash":"b16bb9ff383e9670a868d00412d30c29f9432fd2","modified":1709721354176},{"_id":"themes/yilia/source/img/java/produce_practice/15.png","hash":"a5b0974e97c1c0c5f5f2dcfde1bd5aeefd7d09e8","modified":1709278254941},{"_id":"themes/yilia/source/img/java/produce_practice/20.png","hash":"82240a09e18c6fcb0f38ff232c5329f0ca2baf23","modified":1709280982522},{"_id":"themes/yilia/source/img/java/produce_practice/21.png","hash":"1656f0f4f2fc7ce8069b11669560fb868f96ffd4","modified":1709281324094},{"_id":"themes/yilia/source/img/java/produce_practice/3.png","hash":"c2852be662928c0650e58095caa3ad963ef79b32","modified":1709271574203},{"_id":"themes/yilia/source/img/java/produce_practice/5.png","hash":"cafffe809df3332e48b3f9fb6d2c2519e4d08be7","modified":1709272306923},{"_id":"themes/yilia/source/img/java/produce_practice/7.png","hash":"981d763df9f521ac01471891dffc8c42c1bcf2d5","modified":1709272743602},{"_id":"themes/yilia/source/img/java/produce_practice/17.png","hash":"694d762b0dd7a91ef0118f3cbb744cfa92f1d6c7","modified":1709278609673},{"_id":"public/2024/03/01/java/produce_practice/1_setup/index.html","hash":"5253d94a037b665910142d03f76634dafe6fce49","modified":1709721140200},{"_id":"public/archives/2024/03/index.html","hash":"ad595580719fec705ae526ac42ccd9589c84a520","modified":1713450786300},{"_id":"public/categories/java/index.html","hash":"f4842d46dd114f957e2bea0be386a00641b059a8","modified":1713450786300},{"_id":"public/tags/生产实习/index.html","hash":"9a9bcd7b42ac1e280befca7ca763474e9135e3e3","modified":1713450786300},{"_id":"public/tags/java/index.html","hash":"76fa92dca2f88205645134f1f76f76cfe0b8b5c2","modified":1713450786300},{"_id":"public/tags/springboot/index.html","hash":"202460937999314dfee287484c26ed452dcb5ce6","modified":1713450786300},{"_id":"public/img/java/produce_practice/11.png","hash":"a1dca93a880850cf39a90afe2ab00b2d4af3d05d","modified":1709284125391},{"_id":"public/img/java/produce_practice/10.png","hash":"e24850fd076e7deb6510d6eab70e1b983a8143de","modified":1709284125391},{"_id":"public/img/java/produce_practice/12.png","hash":"a6083435996c6b697b5b5b9c64cdf1bed6a119f8","modified":1709284125391},{"_id":"public/img/java/produce_practice/1.png","hash":"30554ce2998b7e51ad6c95ba0a8dd64d7184e7d5","modified":1709284125391},{"_id":"public/img/java/produce_practice/13.png","hash":"5a8cba5a88ea57b8fbc0b3d03e170bd78d63c9d6","modified":1709284125391},{"_id":"public/img/java/produce_practice/14.png","hash":"d454f6af516b04b392c643aff34c133c27c89566","modified":1709284125391},{"_id":"public/img/java/produce_practice/18.png","hash":"662e19f9ede67fbf97ba64db2b1dd570493f42bc","modified":1709284125391},{"_id":"public/img/java/produce_practice/16.png","hash":"05fe99b97b36da5852d48717d487cd7bcdaa62ea","modified":1709284125391},{"_id":"public/img/java/produce_practice/19.png","hash":"5b6c4d4ca1fafa15fc502684b8ef690dd783b1f0","modified":1709284125391},{"_id":"public/img/java/produce_practice/23.png","hash":"5bfb5c0dfd8a20cb41b6c8fa1c0f066de5b58ce0","modified":1709284125391},{"_id":"public/img/java/produce_practice/35.png","hash":"b598e1f3995b79f9ca23beecec9f286ff5ee7637","modified":1709284125391},{"_id":"public/img/java/produce_practice/4.png","hash":"4ba2f5dd63299422bc74f7debefac14fc5c2abbf","modified":1709284125391},{"_id":"public/img/java/produce_practice/6.png","hash":"68d24416da9cf00e2c1f3389d69780fe7b0aefcc","modified":1709284125391},{"_id":"public/img/java/produce_practice/8.png","hash":"2d231f50629980b55a959bbbb7ce4b44627428da","modified":1709284125391},{"_id":"public/img/java/produce_practice/9.png","hash":"2c930e47793ff23442b7e0047e667d26b2ce652f","modified":1709284125391},{"_id":"public/img/java/produce_practice/15.png","hash":"a5b0974e97c1c0c5f5f2dcfde1bd5aeefd7d09e8","modified":1709284125391},{"_id":"public/img/java/produce_practice/20.png","hash":"82240a09e18c6fcb0f38ff232c5329f0ca2baf23","modified":1709284125391},{"_id":"public/img/java/produce_practice/3.png","hash":"c2852be662928c0650e58095caa3ad963ef79b32","modified":1709284125391},{"_id":"public/img/java/produce_practice/21.png","hash":"1656f0f4f2fc7ce8069b11669560fb868f96ffd4","modified":1709284125391},{"_id":"public/img/java/produce_practice/5.png","hash":"cafffe809df3332e48b3f9fb6d2c2519e4d08be7","modified":1709284125391},{"_id":"public/img/java/produce_practice/7.png","hash":"981d763df9f521ac01471891dffc8c42c1bcf2d5","modified":1709284125391},{"_id":"public/img/java/produce_practice/17.png","hash":"694d762b0dd7a91ef0118f3cbb744cfa92f1d6c7","modified":1709284125391},{"_id":"public/2021/03/03/linux/Linux_2.用户和权限/index.html","hash":"a54683dff0a0f4d123a36a64db51b920e59862b1","modified":1709349180136},{"_id":"public/2021/03/02/linux/Linux_1.基础命令/index.html","hash":"8080ec104c2f5abc93131b7b6364e3f66e75d4c6","modified":1709349180136},{"_id":"source/_posts/linux/Linux_0install.md","hash":"87c6ad8b50edf4efeaaf5d0916c205539a8a27ee","modified":1709347458204},{"_id":"source/_posts/linux/Linux_2.user.md","hash":"014ea6c643408e34faa2f6cd822a2e509e7e9f5f","modified":1709360144848},{"_id":"source/_posts/linux/Linux_1.command.md","hash":"7eb3949d938d93e4ae2a987fb2bf8211b3948930","modified":1709358161789},{"_id":"source/_posts/linux/Linux_3.usage.md","hash":"de60d1164062cd60c0fd9d7413c1d08014dc57fc","modified":1709380499742},{"_id":"source/_posts/linux/Linux_5.usage3.md","hash":"7e708889ffefc4e4bc8f49bf4fae3fe91897de90","modified":1709383659959},{"_id":"source/_posts/linux/Linux_4.usage2.md","hash":"db28e33512e8e71c4c875491329924be3736c7d9","modified":1709383646719},{"_id":"themes/yilia/source/img/linux/usage/1.png","hash":"672cdb2ff4bef0cb1db9fd9dc7af2c64ee49a689","modified":1709371943275},{"_id":"themes/yilia/source/img/linux/usage/2.png","hash":"ecb6b7300ecb1e57a5ec396896b31f5076e30a29","modified":1709371960021},{"_id":"themes/yilia/source/img/linux/usage/3.png","hash":"53692b5667fdd9f5018856c35d6fc71be66fdd10","modified":1709371973803},{"_id":"themes/yilia/source/img/linux/usage/4.png","hash":"30492036c274902af6117aceadc01bb6f7ad421b","modified":1709371979026},{"_id":"themes/yilia/source/img/linux/usage/7.png","hash":"81ea48b124c5945df2b299db4f45d459449c7b49","modified":1709379300345},{"_id":"themes/yilia/source/img/linux/usage/8.png","hash":"bd109f6a36e82cfed8d9b84d2a151852037c9d74","modified":1709379372098},{"_id":"themes/yilia/source/img/linux/usage/9.png","hash":"00fd2fdb4fa8668c63949e5d6b78a8ea1a046ec2","modified":1709379835031},{"_id":"themes/yilia/source/img/linux/usage/10.png","hash":"ea8380762314a5543160492a0c0dc4b74bd82244","modified":1709380166394},{"_id":"themes/yilia/source/img/linux/usage/5.png","hash":"dd649fda55ce139c7604954518cd6ebdb5d535f1","modified":1709374508794},{"_id":"themes/yilia/source/img/linux/usage/6.png","hash":"3596c1c5283d231a1b453e01963033a8d698611b","modified":1709378392775},{"_id":"public/2024/03/02/linux/Linux_3.usage/index.html","hash":"c12bc008f2d0ca9b0c02d6207847e22be999b760","modified":1713450786300},{"_id":"public/2024/03/02/linux/Linux_4.usage2/index.html","hash":"d9d6d27a87a63129c9b3e06e791959465209900d","modified":1713450786300},{"_id":"public/2024/03/02/linux/Linux_5.usage3/index.html","hash":"e20fc0d03dd2cd9355336812a4d23377537c9880","modified":1713450786300},{"_id":"public/2021/03/03/linux/Linux_2.user/index.html","hash":"e477547497e0ca97eb63724036a55c2b2d3aab79","modified":1713450786300},{"_id":"public/2021/03/02/linux/Linux_1.command/index.html","hash":"d09e4be84e332a6ade253d2e86b28f0ceb26907e","modified":1713450786300},{"_id":"public/2021/03/01/linux/Linux_0install/index.html","hash":"c36b99921197459113ccce8665e211a0dec73ed5","modified":1713450786300},{"_id":"public/categories/Linux/page/2/index.html","hash":"8612e1f2ccdb02c07eeca5008aaf278256b7bbca","modified":1713450786300},{"_id":"public/tags/Linux/page/2/index.html","hash":"150dfd3bf55dbbfa07535b30cae519a63fa30745","modified":1713450786300},{"_id":"public/img/linux/usage/1.png","hash":"672cdb2ff4bef0cb1db9fd9dc7af2c64ee49a689","modified":1709383339486},{"_id":"public/img/linux/usage/2.png","hash":"ecb6b7300ecb1e57a5ec396896b31f5076e30a29","modified":1709383339486},{"_id":"public/img/linux/usage/3.png","hash":"53692b5667fdd9f5018856c35d6fc71be66fdd10","modified":1709383339486},{"_id":"public/img/linux/usage/4.png","hash":"30492036c274902af6117aceadc01bb6f7ad421b","modified":1709383339486},{"_id":"public/img/linux/usage/7.png","hash":"81ea48b124c5945df2b299db4f45d459449c7b49","modified":1709383339486},{"_id":"public/img/linux/usage/8.png","hash":"bd109f6a36e82cfed8d9b84d2a151852037c9d74","modified":1709383339486},{"_id":"public/img/linux/usage/9.png","hash":"00fd2fdb4fa8668c63949e5d6b78a8ea1a046ec2","modified":1709383339486},{"_id":"public/img/linux/usage/10.png","hash":"ea8380762314a5543160492a0c0dc4b74bd82244","modified":1709383339486},{"_id":"public/img/linux/usage/5.png","hash":"dd649fda55ce139c7604954518cd6ebdb5d535f1","modified":1709383339486},{"_id":"public/img/linux/usage/6.png","hash":"3596c1c5283d231a1b453e01963033a8d698611b","modified":1709383339486},{"_id":"source/_posts/java/produce_practice/5_usermanage.md","hash":"129f242824d72f1ae419264118514673588f60f8","modified":1709640972394},{"_id":"source/_posts/java/produce_practice/3_userbase.md","hash":"4bbd91111372f42c3aa6c69d64b7675465f503ce","modified":1709876915083},{"_id":"source/_posts/experience/app/word.md","hash":"113e8dea70c662f1b2d7a95f3b8f4df3ae17fc17","modified":1713108162247},{"_id":"source/_posts/java/produce_practice/4_login.md","hash":"b7794b3846b3d0b6fd6dd81056a9d4f37dccb97f","modified":1709638762574},{"_id":"source/_posts/java/produce_practice/6_testlog.md","hash":"74d874b3df741e45b19eb7aca9c7458c8b46cec7","modified":1709649669469},{"_id":"source/_posts/java/produce_practice/2_static.md","hash":"8666c408a2bf1d9924d30a1a807bcd6ce7e1f436","modified":1709864004383},{"_id":"themes/yilia/source/img/experience/app/word/1.png","hash":"ade633e21e81c9671297135c43eb0a4c465b391f","modified":1709468931510},{"_id":"themes/yilia/source/img/java/produce_practice/2/1.png","hash":"bfc399b235e2f301d714db59b129576937bd9206","modified":1709519502904},{"_id":"themes/yilia/source/img/java/produce_practice/2/5.png","hash":"0252bf34bb632f23d60ceff347041279a3f88f74","modified":1709556171122},{"_id":"themes/yilia/source/img/java/produce_practice/2/8.png","hash":"2643438edc15e378358aca36a1d02428a208f50f","modified":1709558547046},{"_id":"themes/yilia/source/img/java/produce_practice/4/8.png","hash":"6590259d237e2ff2b1c2d6a2053180a455f1a2ab","modified":1709625524733},{"_id":"themes/yilia/source/img/java/produce_practice/2/10.png","hash":"41aa473866a58bc198e011888355e70b6ea2334b","modified":1709559046368},{"_id":"themes/yilia/source/img/java/produce_practice/2/2.png","hash":"cd5fc603a9c1d337e47c5c8352248bb0043246fe","modified":1709519667039},{"_id":"themes/yilia/source/img/java/produce_practice/2/4.png","hash":"8d1f48fe6aa2854cba53710b6942543408d68fae","modified":1709522243114},{"_id":"themes/yilia/source/img/java/produce_practice/5/2.png","hash":"42a50479f9b6e7b69169ac6cda432a1c3ad3bf54","modified":1709643397549},{"_id":"themes/yilia/source/img/java/produce_practice/2/3.png","hash":"3927e0ec015178ba68fece35c1c15af61cdf92f8","modified":1709519815611},{"_id":"themes/yilia/source/img/java/produce_practice/3/3.png","hash":"e5deb84f3ed4c4cf16923a0445dbed94fd3ed1e6","modified":1709566464870},{"_id":"themes/yilia/source/img/java/produce_practice/2/9.png","hash":"281e0c904285464473694e159791cdcc61f2810b","modified":1709619712584},{"_id":"themes/yilia/source/img/java/produce_practice/4/3.png","hash":"ede885e2c91398a34f7cb88932988e37f6ab1832","modified":1709623178020},{"_id":"themes/yilia/source/img/java/produce_practice/4/4.png","hash":"61b4c8cc0c2cb7965d620a69e04039a7f97b19da","modified":1709623509738},{"_id":"themes/yilia/source/img/java/produce_practice/2/7.png","hash":"f3cc060659d39dbff8cb3438dd057fb21aa27ffa","modified":1709558065095},{"_id":"themes/yilia/source/img/java/produce_practice/3/2.png","hash":"dccb5e6caaad6984015fb8dfbb63b95cedb1a785","modified":1709563332056},{"_id":"themes/yilia/source/img/java/produce_practice/4/1.png","hash":"bc477c350f3cdad28016bda6c01802a952e04be4","modified":1709599092830},{"_id":"themes/yilia/source/img/java/produce_practice/4/7.png","hash":"957c4beb4e68c29a672dd19e7f81010a225c1f61","modified":1709624743709},{"_id":"themes/yilia/source/img/java/produce_practice/4/6.png","hash":"fe08d6dc598eac909afdf2849420e3816ac9bf7c","modified":1709624008241},{"_id":"themes/yilia/source/img/java/produce_practice/3/1.png","hash":"b61d9c32cd346e8d35c477d176c55900a84a2ecb","modified":1709561407668},{"_id":"themes/yilia/source/img/java/produce_practice/5/1.png","hash":"67e90e725f052ff9e17461f0c081cf0881ea2b92","modified":1709636805028},{"_id":"themes/yilia/source/img/java/produce_practice/5/3.png","hash":"e07018c0b52ce32b9f326c49a7544b22750aec19","modified":1709644058944},{"_id":"themes/yilia/source/img/java/produce_practice/4/2.png","hash":"6645a10d38500e53719a0c399ed9809d7a51a914","modified":1709607717051},{"_id":"themes/yilia/source/img/java/produce_practice/4/5.png","hash":"e73081332379c3fd8f6f2ae1f620359d0a757fa5","modified":1709623988958},{"_id":"themes/yilia/source/img/java/produce_practice/2/6.png","hash":"d36ac357d5632da635fc28f525bda84457954a28","modified":1709557855900},{"_id":"public/2024/03/05/java/produce_practice/6_testlog/index.html","hash":"77746719fe9265f02fc1074bee28510674b19531","modified":1713450786300},{"_id":"public/2024/03/05/java/produce_practice/5_usermanage/index.html","hash":"5352749906be821f10d5e2220b376964d1a953d3","modified":1713450786300},{"_id":"public/2024/03/04/java/produce_practice/3_userbase/index.html","hash":"a4ee0167ba108be77c47f0be61259bd3f57c4729","modified":1713450786300},{"_id":"public/2024/03/04/java/produce_practice/2_static/index.html","hash":"da3ed62b73ce6e6d0d8805715d038e51cb1d562c","modified":1713450786300},{"_id":"public/2024/03/03/experience/app/word/index.html","hash":"46e041ea9409177e286c1329f48429eead3b6812","modified":1710752864910},{"_id":"public/2024/03/05/java/produce_practice/4_login/index.html","hash":"38aa7b96e15432deb448e9ef929b3e908cef3424","modified":1713450786300},{"_id":"public/archives/page/14/index.html","hash":"42989cd974e18927c3ed1a6dd5758767b76d70ad","modified":1713450786300},{"_id":"public/archives/page/15/index.html","hash":"9008412d1c8567f00f97145701b7d92844266dff","modified":1713450786300},{"_id":"public/archives/2024/page/7/index.html","hash":"1b1c739fc6e6a3637eb21e211a8c4028852444a0","modified":1713450786300},{"_id":"public/archives/2024/page/8/index.html","hash":"0e091e487127753fd18413e1085110e9c19191c7","modified":1713450786300},{"_id":"public/archives/2024/03/page/2/index.html","hash":"6a962c48017d2281fbb42b8e0f34d9865b7f88fa","modified":1713450786300},{"_id":"public/categories/java/page/2/index.html","hash":"d94a3bba993814d3b6f81189373e44e2cc1049ab","modified":1713450786300},{"_id":"public/page/14/index.html","hash":"0af3865344502f3b86300b6648e3fc287472f783","modified":1713450786300},{"_id":"public/page/15/index.html","hash":"d51b4c1e1c82d101e99e4e102d8d417337ff1e03","modified":1713450786300},{"_id":"public/tags/生产实习/page/2/index.html","hash":"c4788debdcd72ef3dabb8a9fd8a732d6e633ec7d","modified":1713450786300},{"_id":"public/tags/java/page/2/index.html","hash":"770caca1730a8247d99213b3112e684b115deeee","modified":1713450786300},{"_id":"public/tags/springboot/page/2/index.html","hash":"52b126dfe5ba2812d10328883e6195f7df135a07","modified":1713450786300},{"_id":"public/img/experience/app/word/1.png","hash":"ade633e21e81c9671297135c43eb0a4c465b391f","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/1.png","hash":"bfc399b235e2f301d714db59b129576937bd9206","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/5.png","hash":"0252bf34bb632f23d60ceff347041279a3f88f74","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/8.png","hash":"2643438edc15e378358aca36a1d02428a208f50f","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/8.png","hash":"6590259d237e2ff2b1c2d6a2053180a455f1a2ab","modified":1709721140200},{"_id":"public/img/java/produce_practice/5/2.png","hash":"42a50479f9b6e7b69169ac6cda432a1c3ad3bf54","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/3.png","hash":"3927e0ec015178ba68fece35c1c15af61cdf92f8","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/2.png","hash":"cd5fc603a9c1d337e47c5c8352248bb0043246fe","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/10.png","hash":"41aa473866a58bc198e011888355e70b6ea2334b","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/4.png","hash":"8d1f48fe6aa2854cba53710b6942543408d68fae","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/9.png","hash":"281e0c904285464473694e159791cdcc61f2810b","modified":1709721140200},{"_id":"public/img/java/produce_practice/3/3.png","hash":"e5deb84f3ed4c4cf16923a0445dbed94fd3ed1e6","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/3.png","hash":"ede885e2c91398a34f7cb88932988e37f6ab1832","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/4.png","hash":"61b4c8cc0c2cb7965d620a69e04039a7f97b19da","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/7.png","hash":"f3cc060659d39dbff8cb3438dd057fb21aa27ffa","modified":1709721140200},{"_id":"public/img/java/produce_practice/3/2.png","hash":"dccb5e6caaad6984015fb8dfbb63b95cedb1a785","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/1.png","hash":"bc477c350f3cdad28016bda6c01802a952e04be4","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/7.png","hash":"957c4beb4e68c29a672dd19e7f81010a225c1f61","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/6.png","hash":"fe08d6dc598eac909afdf2849420e3816ac9bf7c","modified":1709721140200},{"_id":"public/img/java/produce_practice/5/1.png","hash":"67e90e725f052ff9e17461f0c081cf0881ea2b92","modified":1709721140200},{"_id":"public/img/java/produce_practice/5/3.png","hash":"e07018c0b52ce32b9f326c49a7544b22750aec19","modified":1709721140200},{"_id":"public/img/java/produce_practice/3/1.png","hash":"b61d9c32cd346e8d35c477d176c55900a84a2ecb","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/2.png","hash":"6645a10d38500e53719a0c399ed9809d7a51a914","modified":1709721140200},{"_id":"public/img/java/produce_practice/4/5.png","hash":"e73081332379c3fd8f6f2ae1f620359d0a757fa5","modified":1709721140200},{"_id":"public/img/java/produce_practice/2/6.png","hash":"d36ac357d5632da635fc28f525bda84457954a28","modified":1709721140200},{"_id":"themes/yilia/source/img/java/produce_practice/0/10.png","hash":"4535da2390045add4db4e2657210d660907fe0aa","modified":1709726180752},{"_id":"themes/yilia/source/img/java/produce_practice/0/6.png","hash":"0ed212c966e155fd3a6d64e67b54d3fb0639e090","modified":1709725715235},{"_id":"source/_posts/java/produce_practice/0_config.md","hash":"73755c9eb4f88205e8c55580d87a3d54d0b4bace","modified":1709726756798},{"_id":"themes/yilia/source/img/java/produce_practice/0/1.png","hash":"bfbc6e4bc6036266324cc25c8e0b9be9872062d3","modified":1709721631734},{"_id":"themes/yilia/source/img/java/produce_practice/0/11.png","hash":"77fdc5313f871e514dda20d85bf727faef13d880","modified":1709726368560},{"_id":"themes/yilia/source/img/java/produce_practice/0/4.png","hash":"2be74d8a0d882cb4176c475ae0f35562886b6cf3","modified":1709723397584},{"_id":"themes/yilia/source/img/java/produce_practice/0/2.png","hash":"f8686690ba00c0c1c374c0d5c04ef51699a04df2","modified":1709721909644},{"_id":"themes/yilia/source/img/java/produce_practice/0/7.png","hash":"6afbf6573f8ffa9d2d5708e8c59573b556e81748","modified":1709725799816},{"_id":"themes/yilia/source/img/java/produce_practice/0/8.png","hash":"d5c39a047fad558afc3c38242590c366caf693c1","modified":1709725817464},{"_id":"themes/yilia/source/img/java/produce_practice/0/9.png","hash":"44c3143a2eabc2dfce309be0e275767a54abde6e","modified":1709725994533},{"_id":"themes/yilia/source/img/java/produce_practice/0/12.png","hash":"47a42a001aebf4be7c404c0c7fa033197239c850","modified":1709726618615},{"_id":"themes/yilia/source/img/java/produce_practice/0/5.png","hash":"ec4f869a042f2f354585e3767eca5d69d788a4c9","modified":1709725325226},{"_id":"public/2024/03/02/java/produce_practice/1_setup/index.html","hash":"634047c848df95ad2a2dfdbf46e496daa37e9226","modified":1713450786300},{"_id":"public/2024/03/01/java/produce_practice/0_config/index.html","hash":"6e8f531204c852eb2b7b06533ad45b90d92b5892","modified":1713450786300},{"_id":"public/archives/2024/03/page/3/index.html","hash":"8bedaa76b98b160a4adfa0b5aa8e145f8c024af7","modified":1713450786300},{"_id":"public/img/java/produce_practice/0/10.png","hash":"4535da2390045add4db4e2657210d660907fe0aa","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/1.png","hash":"bfbc6e4bc6036266324cc25c8e0b9be9872062d3","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/6.png","hash":"0ed212c966e155fd3a6d64e67b54d3fb0639e090","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/11.png","hash":"77fdc5313f871e514dda20d85bf727faef13d880","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/4.png","hash":"2be74d8a0d882cb4176c475ae0f35562886b6cf3","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/7.png","hash":"6afbf6573f8ffa9d2d5708e8c59573b556e81748","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/2.png","hash":"f8686690ba00c0c1c374c0d5c04ef51699a04df2","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/12.png","hash":"47a42a001aebf4be7c404c0c7fa033197239c850","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/9.png","hash":"44c3143a2eabc2dfce309be0e275767a54abde6e","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/8.png","hash":"d5c39a047fad558afc3c38242590c366caf693c1","modified":1709726766751},{"_id":"public/img/java/produce_practice/0/5.png","hash":"ec4f869a042f2f354585e3767eca5d69d788a4c9","modified":1709726766751},{"_id":"themes/yilia/source/img/experience/windows/ssh/1.png","hash":"83b6719725d0d73dba3041940c7d2f71777087f0","modified":1710147462362},{"_id":"themes/yilia/source/img/experience/keyboard/1.png","hash":"b0bcd7c8a2b79784fe255d793deba3680dfa8393","modified":1709810565136},{"_id":"source/_posts/linux/Linux_nopassword.md","hash":"3f1a0fad54b7007399c9c1806edd948bdd1ecd63","modified":1710160275983},{"_id":"source/_posts/python/tips.md","hash":"e98a80fff463ad7e8b67033c0a774f7553e20b23","modified":1711982207058},{"_id":"source/_posts/experience/keyboard/keymap.md","hash":"35ad4542c9d48157170b409365462a2e0f35b390","modified":1709812706971},{"_id":"source/_posts/experience/windows/ssh.md","hash":"a7620a7b0fed3b7e19174eb81b18ee3ecf2c5bff","modified":1710206666668},{"_id":"source/_posts/java/produce_practice/7_project.md","hash":"be1a4ef9e138b0b40271d61efb0fc4489aef07d4","modified":1709888945970},{"_id":"themes/yilia/source/img/experience/keyboard/2.png","hash":"bb2c5f88eb5f2530ec237baa4b3bb634252d7138","modified":1709810821276},{"_id":"themes/yilia/source/img/java/produce_practice/6/3.png","hash":"1f6b9d58a0f8d67c607bd6de71c8988b246b6d77","modified":1709860405279},{"_id":"themes/yilia/source/img/java/produce_practice/6/1.png","hash":"9a4b59e5330ed14ecca4ff8976b9882602877694","modified":1709860334359},{"_id":"themes/yilia/source/img/java/produce_practice/6/0.png","hash":"831b58c87c051ac4f9aa08c9b1f8059e94b4910c","modified":1709882932954},{"_id":"themes/yilia/source/img/experience/keyboard/4.png","hash":"cd17b09ae23e58c49be9116984329ffb5799a8e8","modified":1709811806387},{"_id":"themes/yilia/source/img/experience/keyboard/3.png","hash":"dcd35a10bf55442eba698de5c53edead0edac20b","modified":1709811366344},{"_id":"themes/yilia/source/img/experience/keyboard/7.png","hash":"0d09d0ed585febea50d08c80671eb9f67a86fc2f","modified":1709812365173},{"_id":"themes/yilia/source/img/experience/keyboard/6.png","hash":"a61ddd048d5a3e6db9da2d0e1ddc9117122c0cc0","modified":1709812315849},{"_id":"themes/yilia/source/img/java/produce_practice/6/2.png","hash":"788b890ce1947fbbf3d21a303346b245f91fa2e0","modified":1709860355659},{"_id":"themes/yilia/source/img/experience/keyboard/5.png","hash":"25b5d4f99e72c3c14b56c0eedc0a5f27c31b64b2","modified":1709812265655},{"_id":"themes/yilia/source/img/experience/windows/ssh/2.png","hash":"3c96724ab9a9441e1e483a9f178cc1a5d093bd27","modified":1710148477056},{"_id":"themes/yilia/source/img/experience/windows/ssh/3.png","hash":"afca0a1a9ac95645e8929fb982258508361b9824","modified":1710148528755},{"_id":"themes/yilia/source/img/experience/keyboard/8.png","hash":"4c1c98aa0f39491c23244e6a1031c976c2eb464a","modified":1709812383021},{"_id":"themes/yilia/source/img/experience/keyboard/9.png","hash":"4b16a65451bb3a20785c60d2a02fb3d1a1bd0a0b","modified":1709812391646},{"_id":"public/2024/03/11/experience/windows/ssh/index.html","hash":"624f2aeead5db8e8a923e82ba6b62b5cba06f97f","modified":1713450786300},{"_id":"public/2024/03/10/python/tips/index.html","hash":"5bd692c0492860ec096dfabd4d6a7bf6d91d3563","modified":1713450786300},{"_id":"public/2024/03/09/linux/Linux_nopassword/index.html","hash":"6a1684c7396c48ecb9b4bb2ad673d3cfb26ce9a5","modified":1713450786300},{"_id":"public/2024/03/08/java/produce_practice/7_project/index.html","hash":"ae5cda1cf56c1dac41d4958b6bad83fc234104cb","modified":1713450786300},{"_id":"public/2024/03/07/experience/keyboard/keymap/index.html","hash":"426989e6eb19e7709f3c17c0b4f249976efa2ae1","modified":1713450786300},{"_id":"public/categories/python/index.html","hash":"7c9845ea0372088c6c0585d5ce9bbfe47d0f2d0a","modified":1713450786300},{"_id":"public/page/16/index.html","hash":"761089e71de02d9b542862d5cee283be3f272b58","modified":1713450786300},{"_id":"public/archives/page/16/index.html","hash":"90d41bde2aa03f24ae10b8592393d1d19225ff0c","modified":1713450786300},{"_id":"public/archives/2024/page/9/index.html","hash":"81d9e0f5bfb2b81ac255ad8447293f20220c1b45","modified":1713450786300},{"_id":"public/archives/2024/03/page/4/index.html","hash":"fd372924d0aa2d1caea8cd0439bbddde08c9e236","modified":1713450786300},{"_id":"public/tags/python/index.html","hash":"4e6a67ba214951ed11d11ba1878d814fe0a5de11","modified":1713450786300},{"_id":"public/tags/Windows/index.html","hash":"e3662c862b0ba69fde6bf496f52bb1516eb607d6","modified":1713450786300},{"_id":"public/tags/键盘/index.html","hash":"2284e138fd0f81cbbafd03ac981ae2e4ef5e041e","modified":1713450786300},{"_id":"public/img/experience/keyboard/1.png","hash":"b0bcd7c8a2b79784fe255d793deba3680dfa8393","modified":1710156464201},{"_id":"public/img/experience/windows/ssh/1.png","hash":"83b6719725d0d73dba3041940c7d2f71777087f0","modified":1710156464201},{"_id":"public/img/java/produce_practice/6/1.png","hash":"9a4b59e5330ed14ecca4ff8976b9882602877694","modified":1710156464201},{"_id":"public/img/experience/keyboard/2.png","hash":"bb2c5f88eb5f2530ec237baa4b3bb634252d7138","modified":1710156464201},{"_id":"public/img/java/produce_practice/6/3.png","hash":"1f6b9d58a0f8d67c607bd6de71c8988b246b6d77","modified":1710156464201},{"_id":"public/img/java/produce_practice/6/0.png","hash":"831b58c87c051ac4f9aa08c9b1f8059e94b4910c","modified":1710156464201},{"_id":"public/img/java/produce_practice/6/2.png","hash":"788b890ce1947fbbf3d21a303346b245f91fa2e0","modified":1710156464201},{"_id":"public/img/experience/keyboard/3.png","hash":"dcd35a10bf55442eba698de5c53edead0edac20b","modified":1710156464201},{"_id":"public/img/experience/keyboard/4.png","hash":"cd17b09ae23e58c49be9116984329ffb5799a8e8","modified":1710156464201},{"_id":"public/img/experience/keyboard/7.png","hash":"0d09d0ed585febea50d08c80671eb9f67a86fc2f","modified":1710156464201},{"_id":"public/img/experience/keyboard/6.png","hash":"a61ddd048d5a3e6db9da2d0e1ddc9117122c0cc0","modified":1710156464201},{"_id":"public/img/experience/keyboard/5.png","hash":"25b5d4f99e72c3c14b56c0eedc0a5f27c31b64b2","modified":1710156464201},{"_id":"public/img/experience/keyboard/8.png","hash":"4c1c98aa0f39491c23244e6a1031c976c2eb464a","modified":1710156464201},{"_id":"public/img/experience/keyboard/9.png","hash":"4b16a65451bb3a20785c60d2a02fb3d1a1bd0a0b","modified":1710156464201},{"_id":"public/img/experience/windows/ssh/3.png","hash":"afca0a1a9ac95645e8929fb982258508361b9824","modified":1710156464201},{"_id":"public/img/experience/windows/ssh/2.png","hash":"3c96724ab9a9441e1e483a9f178cc1a5d093bd27","modified":1710156464201},{"_id":"source/_posts/experience/windows/powershell.md","hash":"012c21870b3fd290aa4f1f3636361a2381b5d1b6","modified":1710208645668},{"_id":"themes/yilia/source/img/experience/windows/powershell/2.png","hash":"06b19fe5ed694fd898dd53e01267d41885e75544","modified":1710208484344},{"_id":"source/_drafts/MarkDown.md","hash":"2b3be08ff18b21a8859e4a57a7655c34794d253a","modified":1710752425526},{"_id":"source/_posts/linux/tmux.md","hash":"dc155431eccc43b7890dbc8d4c5443aa74101b6c","modified":1710166748051},{"_id":"themes/yilia/source/img/experience/windows/powershell/1.png","hash":"0dbea432a36d62b157691a5eec9ca69a7f994d9d","modified":1710208476780},{"_id":"public/2024/03/12/experience/windows/powershell/index.html","hash":"3973f57256c65fca30c9441354da81b2c8f26aa2","modified":1713450786300},{"_id":"public/2024/03/11/linux/tmux/index.html","hash":"390fbe7643880562dd4fac8228d780559c188b88","modified":1713450786300},{"_id":"public/categories/windows/index.html","hash":"f9bb6e594c9b1bd148ac8ded786d8cc62d993bc2","modified":1713450786300},{"_id":"public/tags/windows/index.html","hash":"59a4685a963e0cf9da6cd986073f9da5eed610e1","modified":1713450786300},{"_id":"public/img/experience/windows/powershell/2.png","hash":"06b19fe5ed694fd898dd53e01267d41885e75544","modified":1710247262450},{"_id":"public/img/experience/windows/powershell/1.png","hash":"0dbea432a36d62b157691a5eec9ca69a7f994d9d","modified":1710247262450},{"_id":"source/_posts/algorithm/1_base/3_dichotomy.md","hash":"16b28d4d43a606bc775882ba880934a59407d5f2","modified":1713439224711},{"_id":"themes/yilia/source/img/experience/app/mouse/1.png","hash":"45d7532c50960f7a6770563e0c462b831dd478f0","modified":1710751013278},{"_id":"themes/yilia/source/img/experience/app/mouse/3.png","hash":"c0202f1aaf6cd8c29563e94172ba1a5664ca80eb","modified":1710751340931},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/7/1.png","hash":"67738f990d722b9ab6d296d108ebfb303b9c1246","modified":1710561944677},{"_id":"source/_posts/algorithm/1_base/1_sqsort.cpp","hash":"85a4e2aad7365560216e7247ad65e2a08cc17459","modified":1710671706971},{"_id":"source/_posts/experience/app/mouse.md","hash":"6aa6265babc3f0c96a5e97adc0f64922c7b6270a","modified":1710752128271},{"_id":"source/_posts/algorithm/1_base/1_qsort.md","hash":"f8d38d777351b51cc22877a69cbd1bc0035c7ee1","modified":1713418296551},{"_id":"source/_posts/algorithm/1_base/2_mergesort.md","hash":"22c8da3220874b6272c8f8da9fb61ca8a7e260c4","modified":1713418419799},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/7_backward.md","hash":"dabcfa30bc84fbabe64b7cbf4501dfe8f6025661","modified":1710753525165},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/8_init.ipynb","hash":"25e90b2a2e6b241d926dd0d9e5e82b1b4b7c9cd0","modified":1710659410583},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/9_distribution_shift.ipynb","hash":"74002a21b8e591c0f7ee0d4f6e49f6699a53ae28","modified":1710854457941},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/8_init.md","hash":"b14faaea1739fb27dcea91a7db73e807512635d7","modified":1710933339508},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg","hash":"8bdf2739f73260fef223d873c4de25d11de3b380","modified":1710659696509},{"_id":"themes/yilia/source/img/experience/app/mouse/2.png","hash":"2f146858a80f46078881f11bc45721aa9bff1646","modified":1710751222696},{"_id":"source/_posts/algorithm/1_base/a.exe","hash":"9b9960863d836de96027d3211221a722abfde0a8","modified":1710671148656},{"_id":"public/2024/03/18/experience/app/mouse/index.html","hash":"1ca3eafbf94dce194d124dde57d3dee8151eb800","modified":1713450786300},{"_id":"public/2024/03/17/algorithm/1_base/3_dichotomy/index.html","hash":"1297716d64378cee99c0acf0d3d31d133f5fbdcd","modified":1710752864910},{"_id":"public/2024/03/16/deeplearning/code/pytorch/3_mlp/8_init/index.html","hash":"ca9f247f30c90c9666b6b1611fc7df819c10e7e1","modified":1713450786300},{"_id":"public/2024/02/07/deeplearning/code/pytorch/3_mlp/7_backward/index.html","hash":"798fb907fe2e4359e004551efb00b5358a396458","modified":1713450786300},{"_id":"public/2023/10/02/algorithm/1_base/2_mergesort/index.html","hash":"e2d83b45a612c0f12e8775b469301ef3d2c28737","modified":1713450786300},{"_id":"public/2023/10/02/algorithm/1_base/1_qsort/index.html","hash":"dd9b24c8097cba4c7b28f581efaeb5b73be279c9","modified":1713450786300},{"_id":"public/archives/page/17/index.html","hash":"d463ea7f750f43966ba339ebbe57040955b5b08f","modified":1713450786300},{"_id":"public/archives/2024/page/10/index.html","hash":"ab6b8d2f354fe5a9f97cc94ccbfab9561c9f77a2","modified":1713450786300},{"_id":"public/archives/2024/03/page/5/index.html","hash":"301e8397853c2a38d3ea5bb4f3df5718ed0a57e8","modified":1713450786300},{"_id":"public/page/17/index.html","hash":"7bfd03a8bdfa99234c284f5fee214c589616b984","modified":1713450786300},{"_id":"public/categories/经验/page/2/index.html","hash":"8ade38787f94c1032296b55846a5b67a813129d1","modified":1713450786300},{"_id":"public/categories/机器学习/page/5/index.html","hash":"5cee18d5e9c5bd63cc1689cd48645b397f2d13cb","modified":1713450786300},{"_id":"public/tags/机器学习/page/5/index.html","hash":"412df4e382d321c2e8bb96e75271e9d50242e75c","modified":1713450786300},{"_id":"public/tags/pytorch/page/5/index.html","hash":"efb2bff272923bf0dd78c58fb232a37f5f032dda","modified":1713450786300},{"_id":"public/tags/鼠标/index.html","hash":"33b36ee2f33f286da981fb27dc6071f3795c7232","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/7/1.png","hash":"67738f990d722b9ab6d296d108ebfb303b9c1246","modified":1710752864910},{"_id":"public/img/experience/app/mouse/3.png","hash":"c0202f1aaf6cd8c29563e94172ba1a5664ca80eb","modified":1710752864910},{"_id":"public/img/experience/app/mouse/1.png","hash":"45d7532c50960f7a6770563e0c462b831dd478f0","modified":1710752864910},{"_id":"public/img/experience/app/mouse/2.png","hash":"2f146858a80f46078881f11bc45721aa9bff1646","modified":1710752864910},{"_id":"source/_posts/deeplearning/code/pytorch/4_calculate/1_block.ipynb","hash":"c7d38bfee49001809ac96b64d34b28f3dcea0d06","modified":1713450628979},{"_id":"source/_posts/python/PIL.md","hash":"b06be3305bb3d48fb90c73745a0bf657d6cf90fe","modified":1711983955971},{"_id":"source/_posts/python/re.md","hash":"51b1e502e9c039447b69eb6621de3d0fd478b6a3","modified":1711981987619},{"_id":"source/_posts/python/os.md","hash":"554378d29ba8c8d4565f0cae27447f7b74280d0d","modified":1711983515646},{"_id":"source/_posts/deeplearning/code/pytorch/4_calculate/1_block.md","hash":"9346d35dfae00117cded9e5ba99194a0e6cccdfb","modified":1713450746169},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/submission.csv","hash":"47282f5a962c44b477d3fc486b9e2569a50472a3","modified":1710931839699},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/9_distribution_shift.md","hash":"4610184f921f014e4230dfabe89b655c78884a52","modified":1710854651480},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price.md","hash":"678a220bea863b54a64d15c983676adcbd859128","modified":1710933484769},{"_id":"themes/yilia/source/img/experience/app/word/page/0.png","hash":"172b9a8e838a56f3034cf412ad5374822235bc49","modified":1713105721334},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/2.png","hash":"866042909a57b337001a6ccdb384fca0de6b0aef","modified":1713446232300},{"_id":"themes/yilia/source/img/experience/app/word/page/2.png","hash":"d6a0322ad9d5a6ab3b811be1262f93a739c67c01","modified":1713106272841},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/2_linear_neural_network/4img/3.png","hash":"be26c997c7cfb8f358d42d65b6defe79a7d98bf9","modified":1713446388209},{"_id":"themes/yilia/source/img/experience/app/word/page/5.png","hash":"723a629f7ce633859822d10bf34e9346542869b1","modified":1713106928201},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg","hash":"8bdf2739f73260fef223d873c4de25d11de3b380","modified":1710659696509},{"_id":"themes/yilia/source/img/experience/app/word/page/6.png","hash":"fa9c6834203e9e4fcf6a5ea0840c2268691c5df9","modified":1713107380308},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg","hash":"52dcc486e79b2bcb5727ecad64f1672ee4f36279","modified":1710932210220},{"_id":"themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg","hash":"f44ae9c476fc897885aa995ec11c55c79cc47821","modified":1710932210219},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price.ipynb","hash":"6536fe3a67d1e67f3579ad57146537cf9ac2323d","modified":1710931840985},{"_id":"themes/yilia/source/img/experience/app/word/to_pdf/1.png","hash":"de6a40d1ed287d516dac9cc7cbcd09a88f046169","modified":1713101911231},{"_id":"themes/yilia/source/img/experience/app/word/to_pdf/2.png","hash":"aed291bef545d63c6f694c87cf59d8392f8f17c4","modified":1713103651138},{"_id":"themes/yilia/source/img/experience/app/word/page/1.png","hash":"dbd95e4b6418abac3b4a5f9619f61c7e8b330c7a","modified":1713105939961},{"_id":"themes/yilia/source/img/experience/app/word/page/4.png","hash":"7b389400f80ea6131ed37c3499d00ca678c62580","modified":1713106996647},{"_id":"themes/yilia/source/img/experience/app/word/page/3.png","hash":"4c46804b2a6a460cbb32ad520fb5199bf32a7e7f","modified":1713106763531},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/data/kaggle_house_pred_test.csv","hash":"fa19780a7b011d9b009e8bff8e99922a8ee2eb90","modified":1710930250729},{"_id":"source/_posts/deeplearning/code/pytorch/3_mlp/data/kaggle_house_pred_train.csv","hash":"585e9cc93e70b39160e7921475f9bcd7d31219ce","modified":1710930249885},{"_id":"public/2024/04/18/deeplearning/code/pytorch/4_calculate/1_block/index.html","hash":"a4f4d4082d7fb9f3f981d1384d3a0144507db629","modified":1713450786300},{"_id":"public/2024/04/18/algorithm/1_base/3_dichotomy/index.html","hash":"1ab89ff82a0b6e2d7e5353b50bda45dcdec1e947","modified":1713450786300},{"_id":"public/2024/04/01/python/PIL/index.html","hash":"b018b3a1a66fff012a03a568217fd5e72c18159c","modified":1713450786300},{"_id":"public/2024/04/14/experience/app/word/index.html","hash":"c13808c9efa67428ddae046d1d10f2464cc41a77","modified":1713450786300},{"_id":"public/2024/04/01/python/os/index.html","hash":"8da5b905ced99d14ccf8b113bd2a77a2b661ce21","modified":1713450786300},{"_id":"public/2024/04/01/python/re/index.html","hash":"6663947226a9f01479b9b39a5e8cfd17325e5a60","modified":1713450786300},{"_id":"public/2024/03/19/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price/index.html","hash":"ef8f11a08815f6256611169692d486e0d77ed696","modified":1713450786300},{"_id":"public/2024/03/17/deeplearning/code/pytorch/3_mlp/9_distribution_shift/index.html","hash":"3575b90e061e6aed9acab63bef2d7dab1adc97e5","modified":1713450786300},{"_id":"public/2024/02/02/deeplearning/code/pytorch/1_prepare/7_api/index.html","hash":"1719152bd45bcfa374f28a76d0c793862ed853ef","modified":1713450786300},{"_id":"public/archives/page/18/index.html","hash":"80f7beed35460d02c86c4d57fe4eeb67dbf37114","modified":1713450786300},{"_id":"public/archives/2024/page/11/index.html","hash":"0a5a6d5167fa2f19d91b508f0c4f03338dc1a1df","modified":1713450786300},{"_id":"public/archives/2024/04/index.html","hash":"b83c34d1d4dc7b14f036f2f60cca00096123afc5","modified":1713450786300},{"_id":"public/archives/2024/04/page/2/index.html","hash":"ed1d7752d7d8dcaa63b37bfd1a84e35a8ebad93c","modified":1713450786300},{"_id":"public/page/18/index.html","hash":"15315187ba2225be99da80bacab5321537b1b71f","modified":1713450786300},{"_id":"public/img/experience/app/word/page/2.png","hash":"d6a0322ad9d5a6ab3b811be1262f93a739c67c01","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/4img/3.png","hash":"be26c997c7cfb8f358d42d65b6defe79a7d98bf9","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg","hash":"f44ae9c476fc897885aa995ec11c55c79cc47821","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/2_linear_neural_network/4img/2.png","hash":"866042909a57b337001a6ccdb384fca0de6b0aef","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg","hash":"52dcc486e79b2bcb5727ecad64f1672ee4f36279","modified":1713450786300},{"_id":"public/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg","hash":"8bdf2739f73260fef223d873c4de25d11de3b380","modified":1713450786300},{"_id":"public/img/experience/app/word/page/0.png","hash":"172b9a8e838a56f3034cf412ad5374822235bc49","modified":1713450786300},{"_id":"public/img/experience/app/word/page/5.png","hash":"723a629f7ce633859822d10bf34e9346542869b1","modified":1713450786300},{"_id":"public/img/experience/app/word/page/6.png","hash":"fa9c6834203e9e4fcf6a5ea0840c2268691c5df9","modified":1713450786300},{"_id":"public/img/experience/app/word/to_pdf/2.png","hash":"aed291bef545d63c6f694c87cf59d8392f8f17c4","modified":1713450786300},{"_id":"public/img/experience/app/word/to_pdf/1.png","hash":"de6a40d1ed287d516dac9cc7cbcd09a88f046169","modified":1713450786300},{"_id":"public/img/experience/app/word/page/1.png","hash":"dbd95e4b6418abac3b4a5f9619f61c7e8b330c7a","modified":1713450786300},{"_id":"public/img/experience/app/word/page/3.png","hash":"4c46804b2a6a460cbb32ad520fb5199bf32a7e7f","modified":1713450786300},{"_id":"public/img/experience/app/word/page/4.png","hash":"7b389400f80ea6131ed37c3499d00ca678c62580","modified":1713450786300}],"Category":[{"name":"深度学习","_id":"clt19858b00047svwderu8ki9"},{"name":"Linux","_id":"clt19858f000a7svw2vl4djcw"},{"name":"博客","_id":"clt19858l000r7svw0i2z7epx"},{"name":"微信小程序","_id":"clt19858r001e7svwc6jz0ggl"},{"name":"其他","_id":"clt19858s001l7svwght7hovo"},{"name":"vscode","_id":"clt19858v001w7svwebgf5dye"},{"name":"算法","_id":"clt19858x00247svw2vuk6md5"},{"name":"经验","_id":"clt19858y002a7svw8ortfswl"},{"name":"数据结构","_id":"clt19858z002g7svw95zh57rn"},{"name":"hexo","parent":"clt19858l000r7svw0i2z7epx","_id":"clt198591002m7svwgr9phivn"},{"name":"git","parent":"clt19858l000r7svw0i2z7epx","_id":"clt19859600387svw26ld2ehq"},{"name":"机器学习","_id":"clt19859l005m7svwgbh2001y"},{"name":"java","_id":"clt8fmx0h0001mkvw64mfd8ov"},{"name":"python","_id":"cltmv05yz0002lkvwbjshccfv"},{"name":"windows","_id":"cltod2agw000250vwevzac83h"}],"Data":[],"Page":[{"title":"categories","date":"2023-07-20T02:18:50.000Z","type":"categories","layout":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2023-07-20 10:18:50\ntype: \"categories\"\nlayout: \"categories\"\ncomments: false\n---\n","updated":"2023-07-26T04:04:21.211Z","path":"categories/index.html","_id":"clt19858300007svw3t0f2aud","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2020-02-14T14:20:43.000Z","type":"tags","layout":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: \"标签\"\ndate: \"2020-02-14 22:20:43\"\ntype: \"tags\"\nlayout: \"tags\"\ncomments: false\n\n---\n","updated":"2023-10-23T10:04:10.779Z","path":"tags/index.html","_id":"clt19858900027svw1dii9394","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"1. DDPM论文理解","date":"2023-10-24T02:28:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n- 文章：[去噪扩散概率模型](https://arxiv.org/pdf/2006.11239.pdf)\n\n- 代码：https://github.com/hojonathanho/diffusion\n# 一. 论文摘要\n\n- 提出了扩散概率模型\n- 潜在变量模型来源于非平衡热力学\n- 在加权变分界限上进行训练（变分界限是根据“扩散概率模型” 和 “采用了去噪分数匹配与朗之万动力学的训练方法“之间的联系\n- 模型允许渐进的有损解压（可以解释为自回归解码的推广）\n- 在无条件CIFAR10上Inception=9.46，FID=3.17。在256*256 LSUN上与Progressive GAV相似\n","source":"_drafts/1_DDPM.md","raw":"---\ntitle: 1. DDPM论文理解\ndate: 2023-10-24 10:28:00\ntags: [深度学习,DDPM,生成模型]\ncategories: [深度学习]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n- 文章：[去噪扩散概率模型](https://arxiv.org/pdf/2006.11239.pdf)\n\n- 代码：https://github.com/hojonathanho/diffusion\n# 一. 论文摘要\n\n- 提出了扩散概率模型\n- 潜在变量模型来源于非平衡热力学\n- 在加权变分界限上进行训练（变分界限是根据“扩散概率模型” 和 “采用了去噪分数匹配与朗之万动力学的训练方法“之间的联系\n- 模型允许渐进的有损解压（可以解释为自回归解码的推广）\n- 在无条件CIFAR10上Inception=9.46，FID=3.17。在256*256 LSUN上与Progressive GAV相似\n","slug":"1_DDPM","published":0,"updated":"2023-10-24T03:38:31.023Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858600017svwbz9ab1ko","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>文章：<a href=\"https://arxiv.org/pdf/2006.11239.pdf\">去噪扩散概率模型</a></p>\n</li>\n<li><p>代码：<a href=\"https://github.com/hojonathanho/diffusion\">https://github.com/hojonathanho/diffusion</a></p>\n</li>\n</ul>\n<h1 id=\"一-论文摘要\"><a href=\"#一-论文摘要\" class=\"headerlink\" title=\"一. 论文摘要\"></a>一. 论文摘要</h1><ul>\n<li>提出了扩散概率模型</li>\n<li>潜在变量模型来源于非平衡热力学</li>\n<li>在加权变分界限上进行训练（变分界限是根据“扩散概率模型” 和 “采用了去噪分数匹配与朗之万动力学的训练方法“之间的联系</li>\n<li>模型允许渐进的有损解压（可以解释为自回归解码的推广）</li>\n<li>在无条件CIFAR10上Inception&#x3D;9.46，FID&#x3D;3.17。在256*256 LSUN上与Progressive GAV相似</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>文章：<a href=\"https://arxiv.org/pdf/2006.11239.pdf\">去噪扩散概率模型</a></p>\n</li>\n<li><p>代码：<a href=\"https://github.com/hojonathanho/diffusion\">https://github.com/hojonathanho/diffusion</a></p>\n</li>\n</ul>\n<h1 id=\"一-论文摘要\"><a href=\"#一-论文摘要\" class=\"headerlink\" title=\"一. 论文摘要\"></a>一. 论文摘要</h1><ul>\n<li>提出了扩散概率模型</li>\n<li>潜在变量模型来源于非平衡热力学</li>\n<li>在加权变分界限上进行训练（变分界限是根据“扩散概率模型” 和 “采用了去噪分数匹配与朗之万动力学的训练方法“之间的联系</li>\n<li>模型允许渐进的有损解压（可以解释为自回归解码的推广）</li>\n<li>在无条件CIFAR10上Inception&#x3D;9.46，FID&#x3D;3.17。在256*256 LSUN上与Progressive GAV相似</li>\n</ul>"},{"_content":"## 1. pytorch网课\n### Introduction\n- format\n- calculate\n- variable\n- activation\n### Regression\n- 给定x , y（变量）\n- 搭建网络\n  - init重写（输入，输出，神经元个数）\n    - 每一层用Linear\n  - forward前向传递（输入数据）\n    - x依次经过init里面的层，最后返回\n- 定义网络、优化器、误差MSELoss\n- 训练（for)\n  - x输入网络得到y^\n  - 根据y与y^得到误差\n  - 优化器梯度为0\n  - backward\n  - 优化\n\n### Classification\n- 定义feature,label\n    - x0为y0类点，x1为y1类点\n    - 数据形式（[a,b] , 1)\n- 搭建网络\n    - init\n    - forward\n- 定义网络、优化器、误差CrossEntropyLoss\n- 训练（for)\n\n### quick_setup\n- net=torch.nn.Sequential()边定义边实例化\n\n### save and refine\n- save \n    - 训练完(for)后\n    - torch.save(net1,'net.pkl')#保留整个图\n    - torch.save(net1.state_dict(),'net_params.pkl')#保留结点参数\n- refine\n    - 直接提取：\n        - net2=torch.load('net.pkl')\n    - 参数提取：\n        - 先搭建一模一样的网络n\n        - 再n.load_state_dict(torch.load('net_params.pkl'))\n\n### minibize_train(批数据训练)\n- 定义batch_size，feature,label\n- 定义数据库：torch_dataset=Data.TensorDataset(x,y)\n- 定义loader：loader=Data.DataLoader( dataset,batch,shuffle,num_workers)\n- 定义网络等\n- 训练： for epoch in range(3):  \n&emsp;&nbsp;&emsp;&emsp;&emsp;for step,(batch_x,batch_y) in enumerate(loader):\n\n### optimizer\n- 用Adam\n\n### cnn\n- 下载数据集train_data,定义loader\n\n","source":"_drafts/progress1.md","raw":"## 1. pytorch网课\n### Introduction\n- format\n- calculate\n- variable\n- activation\n### Regression\n- 给定x , y（变量）\n- 搭建网络\n  - init重写（输入，输出，神经元个数）\n    - 每一层用Linear\n  - forward前向传递（输入数据）\n    - x依次经过init里面的层，最后返回\n- 定义网络、优化器、误差MSELoss\n- 训练（for)\n  - x输入网络得到y^\n  - 根据y与y^得到误差\n  - 优化器梯度为0\n  - backward\n  - 优化\n\n### Classification\n- 定义feature,label\n    - x0为y0类点，x1为y1类点\n    - 数据形式（[a,b] , 1)\n- 搭建网络\n    - init\n    - forward\n- 定义网络、优化器、误差CrossEntropyLoss\n- 训练（for)\n\n### quick_setup\n- net=torch.nn.Sequential()边定义边实例化\n\n### save and refine\n- save \n    - 训练完(for)后\n    - torch.save(net1,'net.pkl')#保留整个图\n    - torch.save(net1.state_dict(),'net_params.pkl')#保留结点参数\n- refine\n    - 直接提取：\n        - net2=torch.load('net.pkl')\n    - 参数提取：\n        - 先搭建一模一样的网络n\n        - 再n.load_state_dict(torch.load('net_params.pkl'))\n\n### minibize_train(批数据训练)\n- 定义batch_size，feature,label\n- 定义数据库：torch_dataset=Data.TensorDataset(x,y)\n- 定义loader：loader=Data.DataLoader( dataset,batch,shuffle,num_workers)\n- 定义网络等\n- 训练： for epoch in range(3):  \n&emsp;&nbsp;&emsp;&emsp;&emsp;for step,(batch_x,batch_y) in enumerate(loader):\n\n### optimizer\n- 用Adam\n\n### cnn\n- 下载数据集train_data,定义loader\n\n","slug":"progress1","published":0,"date":"2023-07-25T05:21:57.764Z","updated":"2023-02-23T10:16:58.035Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858a00037svwh7db9lpm","content":"<h2 id=\"1-pytorch网课\"><a href=\"#1-pytorch网课\" class=\"headerlink\" title=\"1. pytorch网课\"></a>1. pytorch网课</h2><h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><ul>\n<li>format</li>\n<li>calculate</li>\n<li>variable</li>\n<li>activation</li>\n</ul>\n<h3 id=\"Regression\"><a href=\"#Regression\" class=\"headerlink\" title=\"Regression\"></a>Regression</h3><ul>\n<li>给定x , y（变量）</li>\n<li>搭建网络<ul>\n<li>init重写（输入，输出，神经元个数）<ul>\n<li>每一层用Linear</li>\n</ul>\n</li>\n<li>forward前向传递（输入数据）<ul>\n<li>x依次经过init里面的层，最后返回</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>定义网络、优化器、误差MSELoss</li>\n<li>训练（for)<ul>\n<li>x输入网络得到y^</li>\n<li>根据y与y^得到误差</li>\n<li>优化器梯度为0</li>\n<li>backward</li>\n<li>优化</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Classification\"><a href=\"#Classification\" class=\"headerlink\" title=\"Classification\"></a>Classification</h3><ul>\n<li>定义feature,label<ul>\n<li>x0为y0类点，x1为y1类点</li>\n<li>数据形式（[a,b] , 1)</li>\n</ul>\n</li>\n<li>搭建网络<ul>\n<li>init</li>\n<li>forward</li>\n</ul>\n</li>\n<li>定义网络、优化器、误差CrossEntropyLoss</li>\n<li>训练（for)</li>\n</ul>\n<h3 id=\"quick-setup\"><a href=\"#quick-setup\" class=\"headerlink\" title=\"quick_setup\"></a>quick_setup</h3><ul>\n<li>net&#x3D;torch.nn.Sequential()边定义边实例化</li>\n</ul>\n<h3 id=\"save-and-refine\"><a href=\"#save-and-refine\" class=\"headerlink\" title=\"save and refine\"></a>save and refine</h3><ul>\n<li>save <ul>\n<li>训练完(for)后</li>\n<li>torch.save(net1,’net.pkl’)#保留整个图</li>\n<li>torch.save(net1.state_dict(),’net_params.pkl’)#保留结点参数</li>\n</ul>\n</li>\n<li>refine<ul>\n<li>直接提取：<ul>\n<li>net2&#x3D;torch.load(‘net.pkl’)</li>\n</ul>\n</li>\n<li>参数提取：<ul>\n<li>先搭建一模一样的网络n</li>\n<li>再n.load_state_dict(torch.load(‘net_params.pkl’))</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"minibize-train-批数据训练\"><a href=\"#minibize-train-批数据训练\" class=\"headerlink\" title=\"minibize_train(批数据训练)\"></a>minibize_train(批数据训练)</h3><ul>\n<li>定义batch_size，feature,label</li>\n<li>定义数据库：torch_dataset&#x3D;Data.TensorDataset(x,y)</li>\n<li>定义loader：loader&#x3D;Data.DataLoader( dataset,batch,shuffle,num_workers)</li>\n<li>定义网络等</li>\n<li>训练： for epoch in range(3):<br>&emsp;&nbsp;&emsp;&emsp;&emsp;for step,(batch_x,batch_y) in enumerate(loader):</li>\n</ul>\n<h3 id=\"optimizer\"><a href=\"#optimizer\" class=\"headerlink\" title=\"optimizer\"></a>optimizer</h3><ul>\n<li>用Adam</li>\n</ul>\n<h3 id=\"cnn\"><a href=\"#cnn\" class=\"headerlink\" title=\"cnn\"></a>cnn</h3><ul>\n<li>下载数据集train_data,定义loader</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-pytorch网课\"><a href=\"#1-pytorch网课\" class=\"headerlink\" title=\"1. pytorch网课\"></a>1. pytorch网课</h2><h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><ul>\n<li>format</li>\n<li>calculate</li>\n<li>variable</li>\n<li>activation</li>\n</ul>\n<h3 id=\"Regression\"><a href=\"#Regression\" class=\"headerlink\" title=\"Regression\"></a>Regression</h3><ul>\n<li>给定x , y（变量）</li>\n<li>搭建网络<ul>\n<li>init重写（输入，输出，神经元个数）<ul>\n<li>每一层用Linear</li>\n</ul>\n</li>\n<li>forward前向传递（输入数据）<ul>\n<li>x依次经过init里面的层，最后返回</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>定义网络、优化器、误差MSELoss</li>\n<li>训练（for)<ul>\n<li>x输入网络得到y^</li>\n<li>根据y与y^得到误差</li>\n<li>优化器梯度为0</li>\n<li>backward</li>\n<li>优化</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Classification\"><a href=\"#Classification\" class=\"headerlink\" title=\"Classification\"></a>Classification</h3><ul>\n<li>定义feature,label<ul>\n<li>x0为y0类点，x1为y1类点</li>\n<li>数据形式（[a,b] , 1)</li>\n</ul>\n</li>\n<li>搭建网络<ul>\n<li>init</li>\n<li>forward</li>\n</ul>\n</li>\n<li>定义网络、优化器、误差CrossEntropyLoss</li>\n<li>训练（for)</li>\n</ul>\n<h3 id=\"quick-setup\"><a href=\"#quick-setup\" class=\"headerlink\" title=\"quick_setup\"></a>quick_setup</h3><ul>\n<li>net&#x3D;torch.nn.Sequential()边定义边实例化</li>\n</ul>\n<h3 id=\"save-and-refine\"><a href=\"#save-and-refine\" class=\"headerlink\" title=\"save and refine\"></a>save and refine</h3><ul>\n<li>save <ul>\n<li>训练完(for)后</li>\n<li>torch.save(net1,’net.pkl’)#保留整个图</li>\n<li>torch.save(net1.state_dict(),’net_params.pkl’)#保留结点参数</li>\n</ul>\n</li>\n<li>refine<ul>\n<li>直接提取：<ul>\n<li>net2&#x3D;torch.load(‘net.pkl’)</li>\n</ul>\n</li>\n<li>参数提取：<ul>\n<li>先搭建一模一样的网络n</li>\n<li>再n.load_state_dict(torch.load(‘net_params.pkl’))</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"minibize-train-批数据训练\"><a href=\"#minibize-train-批数据训练\" class=\"headerlink\" title=\"minibize_train(批数据训练)\"></a>minibize_train(批数据训练)</h3><ul>\n<li>定义batch_size，feature,label</li>\n<li>定义数据库：torch_dataset&#x3D;Data.TensorDataset(x,y)</li>\n<li>定义loader：loader&#x3D;Data.DataLoader( dataset,batch,shuffle,num_workers)</li>\n<li>定义网络等</li>\n<li>训练： for epoch in range(3):<br>&emsp;&nbsp;&emsp;&emsp;&emsp;for step,(batch_x,batch_y) in enumerate(loader):</li>\n</ul>\n<h3 id=\"optimizer\"><a href=\"#optimizer\" class=\"headerlink\" title=\"optimizer\"></a>optimizer</h3><ul>\n<li>用Adam</li>\n</ul>\n<h3 id=\"cnn\"><a href=\"#cnn\" class=\"headerlink\" title=\"cnn\"></a>cnn</h3><ul>\n<li>下载数据集train_data,定义loader</li>\n</ul>\n"},{"_content":"(需要修改的地方)\n显示分类时修改source/category里的index:\n\ntitle: categories\ndate: 2023-07-20 10:18:50\ntype: \"categories\"\nlayout: \"categories\"\ncomments: false\n\n\n- 换头像\ntheme/yilia/config文件\n看到：avatar: img/head.png\n将head.png放到：blog/themes/yilia/source/img\n将blog/config文件中post_asset_folder: true\n\n\n\n\n\n- 代码块自动换行\n```\npre {\n    overflow: auto;\n    white-space: pre;\n    /*white-space: pre-wrap;*/\n    word-wrap: break-word\n}\n```\n- 代码块滚动条颜色：\n\n```\n::-webkit-scrollbar-thumb { /*滚动条的滑块*/\n\n  border-radius: 8px;\n\n  background-color: rgb(189, 189, 189)\n\n}```\n```","source":"_drafts/yilia配置.md","raw":"(需要修改的地方)\n显示分类时修改source/category里的index:\n\ntitle: categories\ndate: 2023-07-20 10:18:50\ntype: \"categories\"\nlayout: \"categories\"\ncomments: false\n\n\n- 换头像\ntheme/yilia/config文件\n看到：avatar: img/head.png\n将head.png放到：blog/themes/yilia/source/img\n将blog/config文件中post_asset_folder: true\n\n\n\n\n\n- 代码块自动换行\n```\npre {\n    overflow: auto;\n    white-space: pre;\n    /*white-space: pre-wrap;*/\n    word-wrap: break-word\n}\n```\n- 代码块滚动条颜色：\n\n```\n::-webkit-scrollbar-thumb { /*滚动条的滑块*/\n\n  border-radius: 8px;\n\n  background-color: rgb(189, 189, 189)\n\n}```\n```","slug":"yilia配置","published":0,"date":"2023-07-26T04:08:04.455Z","updated":"2024-02-22T04:05:09.517Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858c00067svw6tpi74sw","content":"<p>(需要修改的地方)<br>显示分类时修改source&#x2F;category里的index:</p>\n<p>title: categories<br>date: 2023-07-20 10:18:50<br>type: “categories”<br>layout: “categories”<br>comments: false</p>\n<ul>\n<li><p>换头像<br>theme&#x2F;yilia&#x2F;config文件<br>看到：avatar: img&#x2F;head.png<br>将head.png放到：blog&#x2F;themes&#x2F;yilia&#x2F;source&#x2F;img<br>将blog&#x2F;config文件中post_asset_folder: true</p>\n</li>\n<li><p>代码块自动换行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pre &#123;</span><br><span class=\"line\">    overflow: auto;</span><br><span class=\"line\">    white-space: pre;</span><br><span class=\"line\">    /*white-space: pre-wrap;*/</span><br><span class=\"line\">    word-wrap: break-word</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>代码块滚动条颜色：</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">::-webkit-scrollbar-thumb &#123; /*滚动条的滑块*/</span><br><span class=\"line\"></span><br><span class=\"line\">  border-radius: 8px;</span><br><span class=\"line\"></span><br><span class=\"line\">  background-color: rgb(189, 189, 189)</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;```</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>(需要修改的地方)<br>显示分类时修改source&#x2F;category里的index:</p>\n<p>title: categories<br>date: 2023-07-20 10:18:50<br>type: “categories”<br>layout: “categories”<br>comments: false</p>\n<ul>\n<li><p>换头像<br>theme&#x2F;yilia&#x2F;config文件<br>看到：avatar: img&#x2F;head.png<br>将head.png放到：blog&#x2F;themes&#x2F;yilia&#x2F;source&#x2F;img<br>将blog&#x2F;config文件中post_asset_folder: true</p>\n</li>\n<li><p>代码块自动换行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pre &#123;</span><br><span class=\"line\">    overflow: auto;</span><br><span class=\"line\">    white-space: pre;</span><br><span class=\"line\">    /*white-space: pre-wrap;*/</span><br><span class=\"line\">    word-wrap: break-word</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>代码块滚动条颜色：</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">::-webkit-scrollbar-thumb &#123; /*滚动条的滑块*/</span><br><span class=\"line\"></span><br><span class=\"line\">  border-radius: 8px;</span><br><span class=\"line\"></span><br><span class=\"line\">  background-color: rgb(189, 189, 189)</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;```</span><br></pre></td></tr></table></figure>"},{"title":"hexo博客搭建","toc":true,"_content":"## 1.安装git\n\n <!-- more --> \n\n- 输入网址https://npm.taobao.org/mirrors/git-for-windows/（你也可以去官网下载）\n- 点击你想下载的版本\n![](../../../themes/yilia/source/img/hexo/6.png)\n![](./img/hexo/6.png)\n- 下载exe文件\n![](../../../themes/yilia/source/img/hexo/7.png)\n![](./img/hexo/7.png)\n- 一路next即可\n![](../../../themes/yilia/source/img/hexo/8.png)\n![](./img/hexo/8.png)\n## 2.安装nodejs\n- 输入网址：nodejs.org\n- 按装左边长期支持版本\n![](../../../themes/yilia/source/img/hexo/1.png)\n![](./img/hexo/1.png)\n- 安装点击next即可\n## 3.通过cnpm安装hexo\n- 进入控制台使用管理员身份\n- 输入：npm install -g cnpm --registry=https://registry.npm.taobao.org<回车>\n![](../../../themes/yilia/source/img/hexo/2.png)\n![](./img/hexo/2.png)\n- 输入：cnpm install -g hexo-cli<回车>\n## 4.搭建博客\n- 创建一个空文件夹(d:/blog/test)\n- 进入该文件夹：cd /d d:/blog/test<回车>\n- 初始化：hexo init<回车>\n- 打开：hexo s<回车>\n- 浏览器访问：http://localhost:4000/\n- 命令行点击ctr+c输入y<回车>即可关闭\n## 5.操作博客\n- 新建博客：hexo n \"test1.md\"(保存在了blog\\test\\source\\_posts\\test1.md)（也可直接在该目录下新建.md文件）\n- 编辑博客：使用vscode/typora等\n## 6.将博客部署到GitHub\n- 登录GitHub\n- 新建仓库\n![](../../../themes/yilia/source/img/hexo/3.png)\n![](./img/hexo/3.png)\n- 注意前面部分要跟自己的名字一样（以后通过\n![](../../../themes/yilia/source/img/hexo/4.png)\n![](./img/hexo/4.png)\n- 安装插件：命令行输入：cnpm install --save hexo-deployer-git\n- 找到_config.yml文件,将最后面加上：\n```\ntype: git\n  repo: git@github.com:lankeren035/lankeren035.github.io.git\n  branch: main\n```\n- 输入hexo d即可部署到远端（在test文件夹下）\n- 浏览器输入仓库名：lankeren035.github.io即可访问\n\n## 7.换主题\n- 找到目标主题：github.com/litten/hexo-theme-yilia\n- 命令行输入：git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia则会在theme下创建yilia文件夹\n- 在_config.yml中将theme后的改为yilia\n![](../../../themes/yilia/source/img/hexo/5.png)\n![](./img/hexo/5.png)\n- hexo g再hexo s通过本地看看\n- 最后hexo d再把远端的也更新了","source":"_posts/hexo/hexo搭建.md","raw":"---\ntitle: hexo博客搭建\ntoc: true\ncategories: [博客]\ntags: [博客,hexo]\n---\n## 1.安装git\n\n <!-- more --> \n\n- 输入网址https://npm.taobao.org/mirrors/git-for-windows/（你也可以去官网下载）\n- 点击你想下载的版本\n![](../../../themes/yilia/source/img/hexo/6.png)\n![](./img/hexo/6.png)\n- 下载exe文件\n![](../../../themes/yilia/source/img/hexo/7.png)\n![](./img/hexo/7.png)\n- 一路next即可\n![](../../../themes/yilia/source/img/hexo/8.png)\n![](./img/hexo/8.png)\n## 2.安装nodejs\n- 输入网址：nodejs.org\n- 按装左边长期支持版本\n![](../../../themes/yilia/source/img/hexo/1.png)\n![](./img/hexo/1.png)\n- 安装点击next即可\n## 3.通过cnpm安装hexo\n- 进入控制台使用管理员身份\n- 输入：npm install -g cnpm --registry=https://registry.npm.taobao.org<回车>\n![](../../../themes/yilia/source/img/hexo/2.png)\n![](./img/hexo/2.png)\n- 输入：cnpm install -g hexo-cli<回车>\n## 4.搭建博客\n- 创建一个空文件夹(d:/blog/test)\n- 进入该文件夹：cd /d d:/blog/test<回车>\n- 初始化：hexo init<回车>\n- 打开：hexo s<回车>\n- 浏览器访问：http://localhost:4000/\n- 命令行点击ctr+c输入y<回车>即可关闭\n## 5.操作博客\n- 新建博客：hexo n \"test1.md\"(保存在了blog\\test\\source\\_posts\\test1.md)（也可直接在该目录下新建.md文件）\n- 编辑博客：使用vscode/typora等\n## 6.将博客部署到GitHub\n- 登录GitHub\n- 新建仓库\n![](../../../themes/yilia/source/img/hexo/3.png)\n![](./img/hexo/3.png)\n- 注意前面部分要跟自己的名字一样（以后通过\n![](../../../themes/yilia/source/img/hexo/4.png)\n![](./img/hexo/4.png)\n- 安装插件：命令行输入：cnpm install --save hexo-deployer-git\n- 找到_config.yml文件,将最后面加上：\n```\ntype: git\n  repo: git@github.com:lankeren035/lankeren035.github.io.git\n  branch: main\n```\n- 输入hexo d即可部署到远端（在test文件夹下）\n- 浏览器输入仓库名：lankeren035.github.io即可访问\n\n## 7.换主题\n- 找到目标主题：github.com/litten/hexo-theme-yilia\n- 命令行输入：git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia则会在theme下创建yilia文件夹\n- 在_config.yml中将theme后的改为yilia\n![](../../../themes/yilia/source/img/hexo/5.png)\n![](./img/hexo/5.png)\n- hexo g再hexo s通过本地看看\n- 最后hexo d再把远端的也更新了","slug":"hexo/hexo搭建","published":1,"date":"2023-07-25T05:05:51.620Z","updated":"2024-01-25T11:34:17.268Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858f000c7svwc46oacgf","content":"<h2 id=\"1-安装git\"><a href=\"#1-安装git\" class=\"headerlink\" title=\"1.安装git\"></a>1.安装git</h2> <span id=\"more\"></span> \n\n<ul>\n<li>输入网址<a href=\"https://npm.taobao.org/mirrors/git-for-windows/%EF%BC%88%E4%BD%A0%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%8E%BB%E5%AE%98%E7%BD%91%E4%B8%8B%E8%BD%BD%EF%BC%89\">https://npm.taobao.org/mirrors/git-for-windows/（你也可以去官网下载）</a></li>\n<li>点击你想下载的版本<br><img src=\"/../../../themes/yilia/source/img/hexo/6.png\"><br><img src=\"/./img/hexo/6.png\"></li>\n<li>下载exe文件<br><img src=\"/../../../themes/yilia/source/img/hexo/7.png\"><br><img src=\"/./img/hexo/7.png\"></li>\n<li>一路next即可<br><img src=\"/../../../themes/yilia/source/img/hexo/8.png\"><br><img src=\"/./img/hexo/8.png\"></li>\n</ul>\n<h2 id=\"2-安装nodejs\"><a href=\"#2-安装nodejs\" class=\"headerlink\" title=\"2.安装nodejs\"></a>2.安装nodejs</h2><ul>\n<li>输入网址：nodejs.org</li>\n<li>按装左边长期支持版本<br><img src=\"/../../../themes/yilia/source/img/hexo/1.png\"><br><img src=\"/./img/hexo/1.png\"></li>\n<li>安装点击next即可</li>\n</ul>\n<h2 id=\"3-通过cnpm安装hexo\"><a href=\"#3-通过cnpm安装hexo\" class=\"headerlink\" title=\"3.通过cnpm安装hexo\"></a>3.通过cnpm安装hexo</h2><ul>\n<li>进入控制台使用管理员身份</li>\n<li>输入：npm install -g cnpm –registry&#x3D;<a href=\"https://registry.npm.taobao.org/\">https://registry.npm.taobao.org</a>&lt;回车&gt;<br><img src=\"/../../../themes/yilia/source/img/hexo/2.png\"><br><img src=\"/./img/hexo/2.png\"></li>\n<li>输入：cnpm install -g hexo-cli&lt;回车&gt;</li>\n</ul>\n<h2 id=\"4-搭建博客\"><a href=\"#4-搭建博客\" class=\"headerlink\" title=\"4.搭建博客\"></a>4.搭建博客</h2><ul>\n<li>创建一个空文件夹(d:&#x2F;blog&#x2F;test)</li>\n<li>进入该文件夹：cd &#x2F;d d:&#x2F;blog&#x2F;test&lt;回车&gt;</li>\n<li>初始化：hexo init&lt;回车&gt;</li>\n<li>打开：hexo s&lt;回车&gt;</li>\n<li>浏览器访问：<a href=\"http://localhost:4000/\">http://localhost:4000/</a></li>\n<li>命令行点击ctr+c输入y&lt;回车&gt;即可关闭</li>\n</ul>\n<h2 id=\"5-操作博客\"><a href=\"#5-操作博客\" class=\"headerlink\" title=\"5.操作博客\"></a>5.操作博客</h2><ul>\n<li>新建博客：hexo n “test1.md”(保存在了blog\\test\\source_posts\\test1.md)（也可直接在该目录下新建.md文件）</li>\n<li>编辑博客：使用vscode&#x2F;typora等</li>\n</ul>\n<h2 id=\"6-将博客部署到GitHub\"><a href=\"#6-将博客部署到GitHub\" class=\"headerlink\" title=\"6.将博客部署到GitHub\"></a>6.将博客部署到GitHub</h2><ul>\n<li>登录GitHub</li>\n<li>新建仓库<br><img src=\"/../../../themes/yilia/source/img/hexo/3.png\"><br><img src=\"/./img/hexo/3.png\"></li>\n<li>注意前面部分要跟自己的名字一样（以后通过<br><img src=\"/../../../themes/yilia/source/img/hexo/4.png\"><br><img src=\"/./img/hexo/4.png\"></li>\n<li>安装插件：命令行输入：cnpm install –save hexo-deployer-git</li>\n<li>找到_config.yml文件,将最后面加上：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type: git</span><br><span class=\"line\">  repo: git@github.com:lankeren035/lankeren035.github.io.git</span><br><span class=\"line\">  branch: main</span><br></pre></td></tr></table></figure></li>\n<li>输入hexo d即可部署到远端（在test文件夹下）</li>\n<li>浏览器输入仓库名：lankeren035.github.io即可访问</li>\n</ul>\n<h2 id=\"7-换主题\"><a href=\"#7-换主题\" class=\"headerlink\" title=\"7.换主题\"></a>7.换主题</h2><ul>\n<li>找到目标主题：github.com&#x2F;litten&#x2F;hexo-theme-yilia</li>\n<li>命令行输入：git clone <a href=\"https://github.com/litten/hexo-theme-yilia.git\">https://github.com/litten/hexo-theme-yilia.git</a> themes&#x2F;yilia则会在theme下创建yilia文件夹</li>\n<li>在_config.yml中将theme后的改为yilia<br><img src=\"/../../../themes/yilia/source/img/hexo/5.png\"><br><img src=\"/./img/hexo/5.png\"></li>\n<li>hexo g再hexo s通过本地看看</li>\n<li>最后hexo d再把远端的也更新了</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-安装git\"><a href=\"#1-安装git\" class=\"headerlink\" title=\"1.安装git\"></a>1.安装git</h2>","more":"<ul>\n<li>输入网址<a href=\"https://npm.taobao.org/mirrors/git-for-windows/%EF%BC%88%E4%BD%A0%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%8E%BB%E5%AE%98%E7%BD%91%E4%B8%8B%E8%BD%BD%EF%BC%89\">https://npm.taobao.org/mirrors/git-for-windows/（你也可以去官网下载）</a></li>\n<li>点击你想下载的版本<br><img src=\"/../../../themes/yilia/source/img/hexo/6.png\"><br><img src=\"/./img/hexo/6.png\"></li>\n<li>下载exe文件<br><img src=\"/../../../themes/yilia/source/img/hexo/7.png\"><br><img src=\"/./img/hexo/7.png\"></li>\n<li>一路next即可<br><img src=\"/../../../themes/yilia/source/img/hexo/8.png\"><br><img src=\"/./img/hexo/8.png\"></li>\n</ul>\n<h2 id=\"2-安装nodejs\"><a href=\"#2-安装nodejs\" class=\"headerlink\" title=\"2.安装nodejs\"></a>2.安装nodejs</h2><ul>\n<li>输入网址：nodejs.org</li>\n<li>按装左边长期支持版本<br><img src=\"/../../../themes/yilia/source/img/hexo/1.png\"><br><img src=\"/./img/hexo/1.png\"></li>\n<li>安装点击next即可</li>\n</ul>\n<h2 id=\"3-通过cnpm安装hexo\"><a href=\"#3-通过cnpm安装hexo\" class=\"headerlink\" title=\"3.通过cnpm安装hexo\"></a>3.通过cnpm安装hexo</h2><ul>\n<li>进入控制台使用管理员身份</li>\n<li>输入：npm install -g cnpm –registry&#x3D;<a href=\"https://registry.npm.taobao.org/\">https://registry.npm.taobao.org</a>&lt;回车&gt;<br><img src=\"/../../../themes/yilia/source/img/hexo/2.png\"><br><img src=\"/./img/hexo/2.png\"></li>\n<li>输入：cnpm install -g hexo-cli&lt;回车&gt;</li>\n</ul>\n<h2 id=\"4-搭建博客\"><a href=\"#4-搭建博客\" class=\"headerlink\" title=\"4.搭建博客\"></a>4.搭建博客</h2><ul>\n<li>创建一个空文件夹(d:&#x2F;blog&#x2F;test)</li>\n<li>进入该文件夹：cd &#x2F;d d:&#x2F;blog&#x2F;test&lt;回车&gt;</li>\n<li>初始化：hexo init&lt;回车&gt;</li>\n<li>打开：hexo s&lt;回车&gt;</li>\n<li>浏览器访问：<a href=\"http://localhost:4000/\">http://localhost:4000/</a></li>\n<li>命令行点击ctr+c输入y&lt;回车&gt;即可关闭</li>\n</ul>\n<h2 id=\"5-操作博客\"><a href=\"#5-操作博客\" class=\"headerlink\" title=\"5.操作博客\"></a>5.操作博客</h2><ul>\n<li>新建博客：hexo n “test1.md”(保存在了blog\\test\\source_posts\\test1.md)（也可直接在该目录下新建.md文件）</li>\n<li>编辑博客：使用vscode&#x2F;typora等</li>\n</ul>\n<h2 id=\"6-将博客部署到GitHub\"><a href=\"#6-将博客部署到GitHub\" class=\"headerlink\" title=\"6.将博客部署到GitHub\"></a>6.将博客部署到GitHub</h2><ul>\n<li>登录GitHub</li>\n<li>新建仓库<br><img src=\"/../../../themes/yilia/source/img/hexo/3.png\"><br><img src=\"/./img/hexo/3.png\"></li>\n<li>注意前面部分要跟自己的名字一样（以后通过<br><img src=\"/../../../themes/yilia/source/img/hexo/4.png\"><br><img src=\"/./img/hexo/4.png\"></li>\n<li>安装插件：命令行输入：cnpm install –save hexo-deployer-git</li>\n<li>找到_config.yml文件,将最后面加上：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type: git</span><br><span class=\"line\">  repo: git@github.com:lankeren035/lankeren035.github.io.git</span><br><span class=\"line\">  branch: main</span><br></pre></td></tr></table></figure></li>\n<li>输入hexo d即可部署到远端（在test文件夹下）</li>\n<li>浏览器输入仓库名：lankeren035.github.io即可访问</li>\n</ul>\n<h2 id=\"7-换主题\"><a href=\"#7-换主题\" class=\"headerlink\" title=\"7.换主题\"></a>7.换主题</h2><ul>\n<li>找到目标主题：github.com&#x2F;litten&#x2F;hexo-theme-yilia</li>\n<li>命令行输入：git clone <a href=\"https://github.com/litten/hexo-theme-yilia.git\">https://github.com/litten/hexo-theme-yilia.git</a> themes&#x2F;yilia则会在theme下创建yilia文件夹</li>\n<li>在_config.yml中将theme后的改为yilia<br><img src=\"/../../../themes/yilia/source/img/hexo/5.png\"><br><img src=\"/./img/hexo/5.png\"></li>\n<li>hexo g再hexo s通过本地看看</li>\n<li>最后hexo d再把远端的也更新了</li>\n</ul>"},{"title":"Hello World","date":"2014-12-24T15:57:18.000Z","toc":true,"_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n<!-- more -->\n\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hexo/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2014-12-24 23:57:18\ntoc: true\ncategories: [博客]\ntags: [博客,hexo]\n\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n<!-- more -->\n\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hexo/hello-world","published":1,"updated":"2023-10-23T09:55:30.261Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858g000f7svwcbxn9bg6","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<span id=\"more\"></span>\n\n\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>","more":"<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>"},{"title":"hexo博客关于latex公式","date":"2024-01-29T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n\n<!--more-->\n\n- 在yilia主题文件夹下的config文件中设置\n\n  `mathjax: true`\n\n- 一些网页无法渲染的公式\n\n|                                                              |                                                              |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 网页上无法渲染：$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X}_{ij}) } { \\sum_k \\exp(\\mathbf{X}_{ik}) } $$ | 在后面的下标ij的下划线前加上空格$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$ |\n| 用左括号并列的公式无法渲染：$h ^\\prime =\\left\\{ \\begin{matrix}0 &amp;p \\\\\\frac{h}{1-p} &amp;1-p \\\\\\end{matrix}\\right.$ | 使用cases，并用html换行：<span style=\"display:block\"> $h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$   </span> |\n\n","source":"_posts/hexo/latex.md","raw":"---\ntitle: hexo博客关于latex公式\n\ndate: 2024-1-30\n\ntags: [博客]\n\ncategories: [博客,hexo]\n\ncomment: true\n\ntoc: true\n\n\n\n---\n\n#\n\n<!--more-->\n\n- 在yilia主题文件夹下的config文件中设置\n\n  `mathjax: true`\n\n- 一些网页无法渲染的公式\n\n|                                                              |                                                              |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 网页上无法渲染：$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X}_{ij}) } { \\sum_k \\exp(\\mathbf{X}_{ik}) } $$ | 在后面的下标ij的下划线前加上空格$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$ |\n| 用左括号并列的公式无法渲染：$h ^\\prime =\\left\\{ \\begin{matrix}0 &amp;p \\\\\\frac{h}{1-p} &amp;1-p \\\\\\end{matrix}\\right.$ | 使用cases，并用html换行：<span style=\"display:block\"> $h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$   </span> |\n\n","slug":"hexo/latex","published":1,"updated":"2024-02-25T11:42:41.152Z","_id":"clt19858i000h7svw6wjif9gf","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>在yilia主题文件夹下的config文件中设置</p>\n<p><code>mathjax: true</code></p>\n</li>\n<li><p>一些网页无法渲染的公式</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>网页上无法渲染：$$ softmax(\\mathbf{X})<em>{ij} &#x3D; \\frac{ \\exp(\\mathbf{X}</em>{ij}) } { \\sum_k \\exp(\\mathbf{X}_{ik}) } $$</td>\n<td>在后面的下标ij的下划线前加上空格$$ softmax(\\mathbf{X})_{ij} &#x3D; \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$</td>\n</tr>\n<tr>\n<td>用左括号并列的公式无法渲染：$h ^\\prime &#x3D;\\left{ \\begin{matrix}0 &amp;p \\\\frac{h}{1-p} &amp;1-p \\\\end{matrix}\\right.$</td>\n<td>使用cases，并用html换行：<span style=\"display:block\"> $h ^\\prime &#x3D;\\begin{cases}0 &amp;p \\ \\frac{h}{1-p} &amp;1-p \\ \\end{cases}.$   </span></td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>在yilia主题文件夹下的config文件中设置</p>\n<p><code>mathjax: true</code></p>\n</li>\n<li><p>一些网页无法渲染的公式</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>网页上无法渲染：$$ softmax(\\mathbf{X})<em>{ij} &#x3D; \\frac{ \\exp(\\mathbf{X}</em>{ij}) } { \\sum_k \\exp(\\mathbf{X}_{ik}) } $$</td>\n<td>在后面的下标ij的下划线前加上空格$$ softmax(\\mathbf{X})_{ij} &#x3D; \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$</td>\n</tr>\n<tr>\n<td>用左括号并列的公式无法渲染：$h ^\\prime &#x3D;\\left{ \\begin{matrix}0 &amp;p \\\\frac{h}{1-p} &amp;1-p \\\\end{matrix}\\right.$</td>\n<td>使用cases，并用html换行：<span style=\"display:block\"> $h ^\\prime &#x3D;\\begin{cases}0 &amp;p \\ \\frac{h}{1-p} &amp;1-p \\ \\end{cases}.$   </span></td>\n</tr>\n</tbody></table>"},{"title":"git部署博客源码","date":"2024-01-29T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n\n <!--more-->\n\n# git部署博客源码\n\n- 在blog/config文件里面确定了hexo s将博客部署到仓库的main分支，但是部署的是渲染后的代码，如何保存源码进行备份。\n\n\n\n## 1 创建分支\n\n在blog下打开gitbash\n\n```\ngit init \n```\n\n去掉blog/.gitignore文件中这三项：\n\n```\ndb.json,\nThumbs.db\nnode-modules/,\n```\n\n运行\n\n```\ngit add *\ngit commit -m \"first commit\"\n```\n\n创建一个source分支，上传源码（注意此处仓库地址，参考blog/config文件里面的部署部分，是带@符号的那个名字，不是简单的博客地址）\n\n```\ngit checkout -b source\ngit remote add github 远程仓库地址\ngit push -u github source\n```\n\n\n\n## 2 设置默认分支\n\n建议将source分支设置成默认分支，防止误删\n\n![](D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\1.png)\n\n![](img/hexo/config/1.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\2.png)\n\n![](img/hexo/config/2.png)\n\n\n\n- 以后只需要执行：\n\n  ```bash\n  git add .\n  git commit -m \"Your commit message\"\n  git push -u github source\n  \n  ```\n\n  ","source":"_posts/hexo/sourcecode.md","raw":"---\ntitle: git部署博客源码\n\ndate: 2024-1-30\n\ntags: [博客]\n\ncategories: [博客,git]\n\ncomment: true\n\ntoc: true\n\n\n---\n\n#\n\n <!--more-->\n\n# git部署博客源码\n\n- 在blog/config文件里面确定了hexo s将博客部署到仓库的main分支，但是部署的是渲染后的代码，如何保存源码进行备份。\n\n\n\n## 1 创建分支\n\n在blog下打开gitbash\n\n```\ngit init \n```\n\n去掉blog/.gitignore文件中这三项：\n\n```\ndb.json,\nThumbs.db\nnode-modules/,\n```\n\n运行\n\n```\ngit add *\ngit commit -m \"first commit\"\n```\n\n创建一个source分支，上传源码（注意此处仓库地址，参考blog/config文件里面的部署部分，是带@符号的那个名字，不是简单的博客地址）\n\n```\ngit checkout -b source\ngit remote add github 远程仓库地址\ngit push -u github source\n```\n\n\n\n## 2 设置默认分支\n\n建议将source分支设置成默认分支，防止误删\n\n![](D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\1.png)\n\n![](img/hexo/config/1.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\2.png)\n\n![](img/hexo/config/2.png)\n\n\n\n- 以后只需要执行：\n\n  ```bash\n  git add .\n  git commit -m \"Your commit message\"\n  git push -u github source\n  \n  ```\n\n  ","slug":"hexo/sourcecode","published":1,"updated":"2024-03-11T11:27:02.043Z","_id":"clt19858j000j7svwgmhmezqj","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1> <span id=\"more\"></span>\n\n<h1 id=\"git部署博客源码\"><a href=\"#git部署博客源码\" class=\"headerlink\" title=\"git部署博客源码\"></a>git部署博客源码</h1><ul>\n<li>在blog&#x2F;config文件里面确定了hexo s将博客部署到仓库的main分支，但是部署的是渲染后的代码，如何保存源码进行备份。</li>\n</ul>\n<h2 id=\"1-创建分支\"><a href=\"#1-创建分支\" class=\"headerlink\" title=\"1 创建分支\"></a>1 创建分支</h2><p>在blog下打开gitbash</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git init </span><br></pre></td></tr></table></figure>\n\n<p>去掉blog&#x2F;.gitignore文件中这三项：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.json,</span><br><span class=\"line\">Thumbs.db</span><br><span class=\"line\">node-modules/,</span><br></pre></td></tr></table></figure>\n\n<p>运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add *</span><br><span class=\"line\">git commit -m &quot;first commit&quot;</span><br></pre></td></tr></table></figure>\n\n<p>创建一个source分支，上传源码（注意此处仓库地址，参考blog&#x2F;config文件里面的部署部分，是带@符号的那个名字，不是简单的博客地址）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b source</span><br><span class=\"line\">git remote add github 远程仓库地址</span><br><span class=\"line\">git push -u github source</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"2-设置默认分支\"><a href=\"#2-设置默认分支\" class=\"headerlink\" title=\"2 设置默认分支\"></a>2 设置默认分支</h2><p>建议将source分支设置成默认分支，防止误删</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\1.png\"></p>\n<p><img src=\"/img/hexo/config/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\2.png\"></p>\n<p><img src=\"/img/hexo/config/2.png\"></p>\n<ul>\n<li><p>以后只需要执行：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;Your commit message&quot;</span></span><br><span class=\"line\">git push -u github <span class=\"built_in\">source</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"git部署博客源码\"><a href=\"#git部署博客源码\" class=\"headerlink\" title=\"git部署博客源码\"></a>git部署博客源码</h1><ul>\n<li>在blog&#x2F;config文件里面确定了hexo s将博客部署到仓库的main分支，但是部署的是渲染后的代码，如何保存源码进行备份。</li>\n</ul>\n<h2 id=\"1-创建分支\"><a href=\"#1-创建分支\" class=\"headerlink\" title=\"1 创建分支\"></a>1 创建分支</h2><p>在blog下打开gitbash</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git init </span><br></pre></td></tr></table></figure>\n\n<p>去掉blog&#x2F;.gitignore文件中这三项：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.json,</span><br><span class=\"line\">Thumbs.db</span><br><span class=\"line\">node-modules/,</span><br></pre></td></tr></table></figure>\n\n<p>运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add *</span><br><span class=\"line\">git commit -m &quot;first commit&quot;</span><br></pre></td></tr></table></figure>\n\n<p>创建一个source分支，上传源码（注意此处仓库地址，参考blog&#x2F;config文件里面的部署部分，是带@符号的那个名字，不是简单的博客地址）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b source</span><br><span class=\"line\">git remote add github 远程仓库地址</span><br><span class=\"line\">git push -u github source</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"2-设置默认分支\"><a href=\"#2-设置默认分支\" class=\"headerlink\" title=\"2 设置默认分支\"></a>2 设置默认分支</h2><p>建议将source分支设置成默认分支，防止误删</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\1.png\"></p>\n<p><img src=\"/img/hexo/config/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\hexo\\config\\2.png\"></p>\n<p><img src=\"/img/hexo/config/2.png\"></p>\n<ul>\n<li><p>以后只需要执行：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;Your commit message&quot;</span></span><br><span class=\"line\">git push -u github <span class=\"built_in\">source</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"微信小程序基础","date":"2021-03-01T12:00:00.000Z","toc":true,"_content":"#\n\n<!--more-->\n\n## 1.总体结构\n\n### （1）概述\n#### 1)项目结构\n- page：存放所有页面\n- utils: 存放工具模块（如格式化时间的自定义模块）\n- app.js: 项目入口\n- app.json: 项目全局配置\n- app.wxss: 项目全局样式\n- project.config.json: 项目配置文件\n- sitemap.json: 配置小程序及其页面是否允许被微信索引\n\n#### 2）页面组成\n- .js文件：页面脚本，存放页面数据、事件处理函数等\n- .json文件：配置文件，配置窗口外观、表现等\n- .wxml文件：模板结构文件\n- .wxss文件: 样式表文件\n\n### （2）详述\n#### 1）json文件\n json是一种数据格式，在开发中json总是以配置文件的形式出现。\n|app.json|afadsf|\n|-------------------|------|\n|project.config.json|\n|sitemap.json|\n|每个页面的json|","source":"_posts/wechartapp/weixin.md","raw":"---\ntitle: 微信小程序基础\ndate: 2021-03-01 20:00:00\ntoc: true\ntags: [微信小程序]\ncategories: [微信小程序]\n\n---\n#\n\n<!--more-->\n\n## 1.总体结构\n\n### （1）概述\n#### 1)项目结构\n- page：存放所有页面\n- utils: 存放工具模块（如格式化时间的自定义模块）\n- app.js: 项目入口\n- app.json: 项目全局配置\n- app.wxss: 项目全局样式\n- project.config.json: 项目配置文件\n- sitemap.json: 配置小程序及其页面是否允许被微信索引\n\n#### 2）页面组成\n- .js文件：页面脚本，存放页面数据、事件处理函数等\n- .json文件：配置文件，配置窗口外观、表现等\n- .wxml文件：模板结构文件\n- .wxss文件: 样式表文件\n\n### （2）详述\n#### 1）json文件\n json是一种数据格式，在开发中json总是以配置文件的形式出现。\n|app.json|afadsf|\n|-------------------|------|\n|project.config.json|\n|sitemap.json|\n|每个页面的json|","slug":"wechartapp/weixin","published":1,"updated":"2024-01-18T04:36:36.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858k000n7svwhg56ef2h","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h2 id=\"1-总体结构\"><a href=\"#1-总体结构\" class=\"headerlink\" title=\"1.总体结构\"></a>1.总体结构</h2><h3 id=\"（1）概述\"><a href=\"#（1）概述\" class=\"headerlink\" title=\"（1）概述\"></a>（1）概述</h3><h4 id=\"1-项目结构\"><a href=\"#1-项目结构\" class=\"headerlink\" title=\"1)项目结构\"></a>1)项目结构</h4><ul>\n<li>page：存放所有页面</li>\n<li>utils: 存放工具模块（如格式化时间的自定义模块）</li>\n<li>app.js: 项目入口</li>\n<li>app.json: 项目全局配置</li>\n<li>app.wxss: 项目全局样式</li>\n<li>project.config.json: 项目配置文件</li>\n<li>sitemap.json: 配置小程序及其页面是否允许被微信索引</li>\n</ul>\n<h4 id=\"2）页面组成\"><a href=\"#2）页面组成\" class=\"headerlink\" title=\"2）页面组成\"></a>2）页面组成</h4><ul>\n<li>.js文件：页面脚本，存放页面数据、事件处理函数等</li>\n<li>.json文件：配置文件，配置窗口外观、表现等</li>\n<li>.wxml文件：模板结构文件</li>\n<li>.wxss文件: 样式表文件</li>\n</ul>\n<h3 id=\"（2）详述\"><a href=\"#（2）详述\" class=\"headerlink\" title=\"（2）详述\"></a>（2）详述</h3><h4 id=\"1）json文件\"><a href=\"#1）json文件\" class=\"headerlink\" title=\"1）json文件\"></a>1）json文件</h4><p> json是一种数据格式，在开发中json总是以配置文件的形式出现。</p>\n<table>\n<thead>\n<tr>\n<th>app.json</th>\n<th>afadsf</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>project.config.json</td>\n<td></td>\n</tr>\n<tr>\n<td>sitemap.json</td>\n<td></td>\n</tr>\n<tr>\n<td>每个页面的json</td>\n<td></td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h2 id=\"1-总体结构\"><a href=\"#1-总体结构\" class=\"headerlink\" title=\"1.总体结构\"></a>1.总体结构</h2><h3 id=\"（1）概述\"><a href=\"#（1）概述\" class=\"headerlink\" title=\"（1）概述\"></a>（1）概述</h3><h4 id=\"1-项目结构\"><a href=\"#1-项目结构\" class=\"headerlink\" title=\"1)项目结构\"></a>1)项目结构</h4><ul>\n<li>page：存放所有页面</li>\n<li>utils: 存放工具模块（如格式化时间的自定义模块）</li>\n<li>app.js: 项目入口</li>\n<li>app.json: 项目全局配置</li>\n<li>app.wxss: 项目全局样式</li>\n<li>project.config.json: 项目配置文件</li>\n<li>sitemap.json: 配置小程序及其页面是否允许被微信索引</li>\n</ul>\n<h4 id=\"2）页面组成\"><a href=\"#2）页面组成\" class=\"headerlink\" title=\"2）页面组成\"></a>2）页面组成</h4><ul>\n<li>.js文件：页面脚本，存放页面数据、事件处理函数等</li>\n<li>.json文件：配置文件，配置窗口外观、表现等</li>\n<li>.wxml文件：模板结构文件</li>\n<li>.wxss文件: 样式表文件</li>\n</ul>\n<h3 id=\"（2）详述\"><a href=\"#（2）详述\" class=\"headerlink\" title=\"（2）详述\"></a>（2）详述</h3><h4 id=\"1）json文件\"><a href=\"#1）json文件\" class=\"headerlink\" title=\"1）json文件\"></a>1）json文件</h4><p> json是一种数据格式，在开发中json总是以配置文件的形式出现。</p>\n<table>\n<thead>\n<tr>\n<th>app.json</th>\n<th>afadsf</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>project.config.json</td>\n<td></td>\n</tr>\n<tr>\n<td>sitemap.json</td>\n<td></td>\n</tr>\n<tr>\n<td>每个页面的json</td>\n<td></td>\n</tr>\n</tbody></table>"},{"title":"win10中windows media player自动同步歌词","date":"2023-12-11T16:00:00.000Z","comment":false,"toc":true,"_content":"\n#\n<!--more-->\n\n- 需要提前下载歌词文件\n\n## 1. 歌词文件\n\n- 如果你的歌词文件是LRC文件，则需要转成SMI文件\n\n  1. [在线转换](https://www.lrccon.com/convert?lang=zh-hans)(只能转单个，想转多个可以找找别的)\n\n     ![](/img/experience/app/lrc_to_smi/2.png)\n\n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/2.png)\n\n     ![](/img/experience/app/lrc_to_smi/3.png)\n\n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/3.png)\n\n     注意编码\n  \n     ![](/img/experience/app/lrc_to_smi/4.png)\n  \n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/4.png)\n  \n  2. 将SMI文件与歌曲mp3文件放在同一文件夹下\n\n## 2. 设置播放器\n\n1. 右键歌曲 -> 打开方式 -> windows media player\n\n![](/img/experience/app/lrc_to_smi/1.png)\n\n![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/1.png)\n\n2.  右键 -> 歌词 -> 开\n\n3.  ![](/img/experience/app/lrc_to_smi/5.png)\n\n    ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/5.png)\n\n     \n\n4. 关闭软件再重新打开音乐就ok了。","source":"_posts/experience/app/lrc_to_smi.md","raw":"---\ntitle: win10中windows media player自动同步歌词\n\ndate: 2023-12-12\n\ntags: [Windows]\n\ncategories: [经验]\n\ncomment: false\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n- 需要提前下载歌词文件\n\n## 1. 歌词文件\n\n- 如果你的歌词文件是LRC文件，则需要转成SMI文件\n\n  1. [在线转换](https://www.lrccon.com/convert?lang=zh-hans)(只能转单个，想转多个可以找找别的)\n\n     ![](/img/experience/app/lrc_to_smi/2.png)\n\n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/2.png)\n\n     ![](/img/experience/app/lrc_to_smi/3.png)\n\n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/3.png)\n\n     注意编码\n  \n     ![](/img/experience/app/lrc_to_smi/4.png)\n  \n     ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/4.png)\n  \n  2. 将SMI文件与歌曲mp3文件放在同一文件夹下\n\n## 2. 设置播放器\n\n1. 右键歌曲 -> 打开方式 -> windows media player\n\n![](/img/experience/app/lrc_to_smi/1.png)\n\n![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/1.png)\n\n2.  右键 -> 歌词 -> 开\n\n3.  ![](/img/experience/app/lrc_to_smi/5.png)\n\n    ![](../../../../themes/yilia/source/img/experience/app/lrc_to_smi/5.png)\n\n     \n\n4. 关闭软件再重新打开音乐就ok了。","slug":"experience/app/lrc_to_smi","published":1,"updated":"2024-03-07T11:19:12.644Z","_id":"clt19858l000q7svw9jkp1hfm","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li>需要提前下载歌词文件</li>\n</ul>\n<h2 id=\"1-歌词文件\"><a href=\"#1-歌词文件\" class=\"headerlink\" title=\"1. 歌词文件\"></a>1. 歌词文件</h2><ul>\n<li><p>如果你的歌词文件是LRC文件，则需要转成SMI文件</p>\n<ol>\n<li><p><a href=\"https://www.lrccon.com/convert?lang=zh-hans\">在线转换</a>(只能转单个，想转多个可以找找别的)</p>\n<p><img src=\"/img/experience/app/lrc_to_smi/2.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/2.png\"></p>\n<p><img src=\"/img/experience/app/lrc_to_smi/3.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/3.png\"></p>\n<p>注意编码</p>\n<p><img src=\"/img/experience/app/lrc_to_smi/4.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/4.png\"></p>\n</li>\n<li><p>将SMI文件与歌曲mp3文件放在同一文件夹下</p>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"2-设置播放器\"><a href=\"#2-设置播放器\" class=\"headerlink\" title=\"2. 设置播放器\"></a>2. 设置播放器</h2><ol>\n<li>右键歌曲 -&gt; 打开方式 -&gt; windows media player</li>\n</ol>\n<p><img src=\"/img/experience/app/lrc_to_smi/1.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/1.png\"></p>\n<ol start=\"2\">\n<li><p>右键 -&gt; 歌词 -&gt; 开</p>\n</li>\n<li><p><img src=\"/img/experience/app/lrc_to_smi/5.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/5.png\"></p>\n</li>\n<li><p>关闭软件再重新打开音乐就ok了。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li>需要提前下载歌词文件</li>\n</ul>\n<h2 id=\"1-歌词文件\"><a href=\"#1-歌词文件\" class=\"headerlink\" title=\"1. 歌词文件\"></a>1. 歌词文件</h2><ul>\n<li><p>如果你的歌词文件是LRC文件，则需要转成SMI文件</p>\n<ol>\n<li><p><a href=\"https://www.lrccon.com/convert?lang=zh-hans\">在线转换</a>(只能转单个，想转多个可以找找别的)</p>\n<p><img src=\"/img/experience/app/lrc_to_smi/2.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/2.png\"></p>\n<p><img src=\"/img/experience/app/lrc_to_smi/3.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/3.png\"></p>\n<p>注意编码</p>\n<p><img src=\"/img/experience/app/lrc_to_smi/4.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/4.png\"></p>\n</li>\n<li><p>将SMI文件与歌曲mp3文件放在同一文件夹下</p>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"2-设置播放器\"><a href=\"#2-设置播放器\" class=\"headerlink\" title=\"2. 设置播放器\"></a>2. 设置播放器</h2><ol>\n<li>右键歌曲 -&gt; 打开方式 -&gt; windows media player</li>\n</ol>\n<p><img src=\"/img/experience/app/lrc_to_smi/1.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/1.png\"></p>\n<ol start=\"2\">\n<li><p>右键 -&gt; 歌词 -&gt; 开</p>\n</li>\n<li><p><img src=\"/img/experience/app/lrc_to_smi/5.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/app/lrc_to_smi/5.png\"></p>\n</li>\n<li><p>关闭软件再重新打开音乐就ok了。</p>\n</li>\n</ol>"},{"title":"pycharm连接服务器--","date":"2023-12-16T16:00:00.000Z","comment":false,"toc":true,"_content":"\n#\n<!--more-->\n\n- 需要提前准备好：IP/端口/user/password\n\n## 1. 连接\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/1.png)\n\n![](/img/experience/pycharm/link_server/1.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/2.png)\n\n![](/img/experience/pycharm/link_server/2.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/3.png)\n\n![](/img/experience/pycharm/link_server/3.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/4.png)\n\n![](/img/experience/pycharm/link_server/4.png)\n\n测试成功即可。\n\n\n\n## 2. 打开服务器\n\n- 打开终端\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/5.png)\n\n![](/img/experience/pycharm/link_server/5.png)\n\n-  打开文件\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/6.png)\n\n![](/img/experience/pycharm/link_server/6.png)\n\n右侧就会显示。如果你想显示特定目录，请在连接的时候填写根路径。\n\n## 3. 使用服务器运行代码\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/7.png)\n\n ![](/img/experience/pycharm/link_server/7.png) \n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/8.png)\n\n ![](/img/experience/pycharm/link_server/8.png) \n\n点击添加。\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/9.png)\n\n ![](/img/experience/pycharm/link_server/9.png) \n\n选择你的python解释器路径（通常在虚拟环境的/bin/python文件\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/10.png)\n\n ![](/img/experience/pycharm/link_server/10.png) \n\n点击右下角即可更改python解释器。\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/11.png)\n\n ![](/img/experience/pycharm/link_server/11.png) \n\n","source":"_posts/experience/pycharm/link_server.md","raw":"---\ntitle: pycharm连接服务器--\n\ndate: 2023-12-17\n\ntags: [pycharm]\n\ncategories: [经验]\n\ncomment: false\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n- 需要提前准备好：IP/端口/user/password\n\n## 1. 连接\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/1.png)\n\n![](/img/experience/pycharm/link_server/1.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/2.png)\n\n![](/img/experience/pycharm/link_server/2.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/3.png)\n\n![](/img/experience/pycharm/link_server/3.png)\n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/4.png)\n\n![](/img/experience/pycharm/link_server/4.png)\n\n测试成功即可。\n\n\n\n## 2. 打开服务器\n\n- 打开终端\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/5.png)\n\n![](/img/experience/pycharm/link_server/5.png)\n\n-  打开文件\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/6.png)\n\n![](/img/experience/pycharm/link_server/6.png)\n\n右侧就会显示。如果你想显示特定目录，请在连接的时候填写根路径。\n\n## 3. 使用服务器运行代码\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/7.png)\n\n ![](/img/experience/pycharm/link_server/7.png) \n\n\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/8.png)\n\n ![](/img/experience/pycharm/link_server/8.png) \n\n点击添加。\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/9.png)\n\n ![](/img/experience/pycharm/link_server/9.png) \n\n选择你的python解释器路径（通常在虚拟环境的/bin/python文件\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/10.png)\n\n ![](/img/experience/pycharm/link_server/10.png) \n\n点击右下角即可更改python解释器。\n\n![](../../../../themes/yilia/source/img/experience/pycharm/link_server/11.png)\n\n ![](/img/experience/pycharm/link_server/11.png) \n\n","slug":"experience/pycharm/link_server","published":1,"updated":"2024-03-07T11:18:44.296Z","_id":"clt19858m000u7svw5niw3s5n","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li>需要提前准备好：IP&#x2F;端口&#x2F;user&#x2F;password</li>\n</ul>\n<h2 id=\"1-连接\"><a href=\"#1-连接\" class=\"headerlink\" title=\"1. 连接\"></a>1. 连接</h2><p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/1.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/1.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/2.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/2.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/3.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/3.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/4.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/4.png\"></p>\n<p>测试成功即可。</p>\n<h2 id=\"2-打开服务器\"><a href=\"#2-打开服务器\" class=\"headerlink\" title=\"2. 打开服务器\"></a>2. 打开服务器</h2><ul>\n<li>打开终端</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/5.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/5.png\"></p>\n<ul>\n<li>打开文件</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/6.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/6.png\"></p>\n<p>右侧就会显示。如果你想显示特定目录，请在连接的时候填写根路径。</p>\n<h2 id=\"3-使用服务器运行代码\"><a href=\"#3-使用服务器运行代码\" class=\"headerlink\" title=\"3. 使用服务器运行代码\"></a>3. 使用服务器运行代码</h2><p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/7.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/7.png\"> </p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/8.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/8.png\"> </p>\n<p>点击添加。</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/9.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/9.png\"> </p>\n<p>选择你的python解释器路径（通常在虚拟环境的&#x2F;bin&#x2F;python文件</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/10.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/10.png\"> </p>\n<p>点击右下角即可更改python解释器。</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/11.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/11.png\"> </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li>需要提前准备好：IP&#x2F;端口&#x2F;user&#x2F;password</li>\n</ul>\n<h2 id=\"1-连接\"><a href=\"#1-连接\" class=\"headerlink\" title=\"1. 连接\"></a>1. 连接</h2><p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/1.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/1.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/2.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/2.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/3.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/3.png\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/4.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/4.png\"></p>\n<p>测试成功即可。</p>\n<h2 id=\"2-打开服务器\"><a href=\"#2-打开服务器\" class=\"headerlink\" title=\"2. 打开服务器\"></a>2. 打开服务器</h2><ul>\n<li>打开终端</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/5.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/5.png\"></p>\n<ul>\n<li>打开文件</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/6.png\"></p>\n<p><img src=\"/img/experience/pycharm/link_server/6.png\"></p>\n<p>右侧就会显示。如果你想显示特定目录，请在连接的时候填写根路径。</p>\n<h2 id=\"3-使用服务器运行代码\"><a href=\"#3-使用服务器运行代码\" class=\"headerlink\" title=\"3. 使用服务器运行代码\"></a>3. 使用服务器运行代码</h2><p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/7.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/7.png\"> </p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/8.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/8.png\"> </p>\n<p>点击添加。</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/9.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/9.png\"> </p>\n<p>选择你的python解释器路径（通常在虚拟环境的&#x2F;bin&#x2F;python文件</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/10.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/10.png\"> </p>\n<p>点击右下角即可更改python解释器。</p>\n<p><img src=\"/../../../../themes/yilia/source/img/experience/pycharm/link_server/11.png\"></p>\n<p> <img src=\"/img/experience/pycharm/link_server/11.png\"> </p>"},{"title":"vscode","date":"2021-03-01T12:00:00.000Z","toc":true,"_content":"# vscode中python相对路径无法使用\n\n<!--more-->\n\n## 解决方案：\n\n- 写绝对路径\n注意用/不要用\\\n- 修改配置文件\n![](../../themes/yilia/source/img/experience/vscode/relative_path/1.png)\n![](img/experience/vscode/relative_path/1.png)\n![](../../themes/yilia/source/img/experience/vscode/relative_path/2.png)\n![](img/experience/vscode/relative_path/2.png)","source":"_posts/experience/vscode/vscode.md","raw":"---\ntitle: vscode\ndate: 2021-03-01 20:00:00\ntoc: true\ntags: [vscode]\ncategories: [经验]\n---\n# vscode中python相对路径无法使用\n\n<!--more-->\n\n## 解决方案：\n\n- 写绝对路径\n注意用/不要用\\\n- 修改配置文件\n![](../../themes/yilia/source/img/experience/vscode/relative_path/1.png)\n![](img/experience/vscode/relative_path/1.png)\n![](../../themes/yilia/source/img/experience/vscode/relative_path/2.png)\n![](img/experience/vscode/relative_path/2.png)","slug":"experience/vscode/vscode","published":1,"updated":"2024-03-07T11:18:32.314Z","_id":"clt19858m000x7svw6rpk33n9","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"vscode中python相对路径无法使用\"><a href=\"#vscode中python相对路径无法使用\" class=\"headerlink\" title=\"vscode中python相对路径无法使用\"></a>vscode中python相对路径无法使用</h1><span id=\"more\"></span>\n\n<h2 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h2><ul>\n<li>写绝对路径<br>注意用&#x2F;不要用\\</li>\n<li>修改配置文件<br><img src=\"/../../themes/yilia/source/img/experience/vscode/relative_path/1.png\"><br><img src=\"/img/experience/vscode/relative_path/1.png\"><br><img src=\"/../../themes/yilia/source/img/experience/vscode/relative_path/2.png\"><br><img src=\"/img/experience/vscode/relative_path/2.png\"></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"vscode中python相对路径无法使用\"><a href=\"#vscode中python相对路径无法使用\" class=\"headerlink\" title=\"vscode中python相对路径无法使用\"></a>vscode中python相对路径无法使用</h1>","more":"<h2 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h2><ul>\n<li>写绝对路径<br>注意用&#x2F;不要用\\</li>\n<li>修改配置文件<br><img src=\"/../../themes/yilia/source/img/experience/vscode/relative_path/1.png\"><br><img src=\"/img/experience/vscode/relative_path/1.png\"><br><img src=\"/../../themes/yilia/source/img/experience/vscode/relative_path/2.png\"><br><img src=\"/img/experience/vscode/relative_path/2.png\"></li>\n</ul>"},{"title":"linux中下载kaggle上的数据集","date":"2024-02-23T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n- 登录kaggle，点击头像，点击设置，下划找到Create New Token，点击下载json文件\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\1.png)\n\n![](img\\experience\\website\\1.png)\n\n- 在linux中\n\n```\npip install kaggle\n```\n\n- 将json文件放到用户根目录下的.kaggle文件夹下\n\n```\ncd ~\nmkdir .kaggle\ncd ~/.kaggle\n```\n\n- 下载数据集\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\2.png)\n\n![](img\\experience\\website\\2.png)\n\n- 如果你使用的远程服务器无法科学上网，需要在国内找到下载地址，然后进行下载，右键正在下载的文件，复制下载地址，然后在服务器上通过`wget 网址`进行下载\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\3.png)\n\n![](img\\experience\\website\\3.png)\n\n","source":"_posts/experience/website/kaggle.md","raw":"---\ntitle: linux中下载kaggle上的数据集\n\ndate: 2024-2-24\n\ntags: [kaggle]\n\ncategories: [经验]\n\ncomment: true\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n- 登录kaggle，点击头像，点击设置，下划找到Create New Token，点击下载json文件\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\1.png)\n\n![](img\\experience\\website\\1.png)\n\n- 在linux中\n\n```\npip install kaggle\n```\n\n- 将json文件放到用户根目录下的.kaggle文件夹下\n\n```\ncd ~\nmkdir .kaggle\ncd ~/.kaggle\n```\n\n- 下载数据集\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\2.png)\n\n![](img\\experience\\website\\2.png)\n\n- 如果你使用的远程服务器无法科学上网，需要在国内找到下载地址，然后进行下载，右键正在下载的文件，复制下载地址，然后在服务器上通过`wget 网址`进行下载\n\n![](D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\3.png)\n\n![](img\\experience\\website\\3.png)\n\n","slug":"experience/website/kaggle","published":1,"updated":"2024-03-07T11:18:28.689Z","_id":"clt19858o00137svw52io5ukv","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li>登录kaggle，点击头像，点击设置，下划找到Create New Token，点击下载json文件</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\1.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C1.png\"></p>\n<ul>\n<li>在linux中</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install kaggle</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>将json文件放到用户根目录下的.kaggle文件夹下</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~</span><br><span class=\"line\">mkdir .kaggle</span><br><span class=\"line\">cd ~/.kaggle</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>下载数据集</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\2.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C2.png\"></p>\n<ul>\n<li>如果你使用的远程服务器无法科学上网，需要在国内找到下载地址，然后进行下载，右键正在下载的文件，复制下载地址，然后在服务器上通过<code>wget 网址</code>进行下载</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\3.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C3.png\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li>登录kaggle，点击头像，点击设置，下划找到Create New Token，点击下载json文件</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\1.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C1.png\"></p>\n<ul>\n<li>在linux中</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install kaggle</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>将json文件放到用户根目录下的.kaggle文件夹下</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~</span><br><span class=\"line\">mkdir .kaggle</span><br><span class=\"line\">cd ~/.kaggle</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>下载数据集</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\2.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C2.png\"></p>\n<ul>\n<li>如果你使用的远程服务器无法科学上网，需要在国内找到下载地址，然后进行下载，右键正在下载的文件，复制下载地址，然后在服务器上通过<code>wget 网址</code>进行下载</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\experience\\website\\3.png\"></p>\n<p><img src=\"/img%5Cexperience%5Cwebsite%5C3.png\"></p>"},{"title":"1. 数据结构基本概念","date":"2023-01-31T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n![数据结构]<!--more-->\n(/img/datastruct/1_extract/1.png)\n![](../../../../themes/yilia/source/img/datastruct/1_extract/1.png)\n\n\n## 1.1 数据\n- 信息的载体，被计算机程序识别和处理的符号的集合\n## 1.2 数据元素\n- 数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。\n- 例如一个人的信息\n## 1.3 数据项\n- 数据不可分割的最小单位。\n- 例如姓名字段\n## 1.4 数据对象\n- 性质相同的数据元素的集合，是数据的一个子集。\n- 例如所有人的信息\n\n|概念|定义|举例|\n|:---:|:---:|:---:|\n|数据|信息的载体，被计算机程序识别和处理的符号的集合|一个人的信息|\n|数据元素|数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。|一个人的信息|\n|数据项|数据不可分割的最小单位。|姓名字段|\n|数据对象|性质相同的数据元素的集合，是数据的一个子集。|所有人的信息|\n\n\n## 1.5 数据结构\n- 相互之间存在一种或多种特定关系的数据元素的集合。\n- 例如所有人的信息按照年龄排序\n## 1.6 逻辑结构\n- 数据对象中数据元素之间的相互关系\n- 例如所有人的信息按照年龄排序\n## 1.7 物理结构\n- 数据的逻辑结构在计算机中的存储形式\n- 例如所有人的信息按照年龄排序，存储在数组中\n## 1.8 数据类型\n- 一组性质相同的值的集合及定义在此集合上的一些操作的总称\n- 例如整数类型，浮点数类型\n## 1.9 抽象数据类型\n- 一个数学模型及定义在该模型上的一组操作\n- 例如整数类型，浮点数类型\n## 1.10 算法\n- 为解决特定问题而规定的一个有限长的操作序列\n- 例如排序算法\n## 1.11 数据类型\n- 一个值的集合和定义在此集合上的一组操作的总称\n\n|原子类型|其值不可再分的数据类型|\n|:---:|:---:|\n|结构类型|其值可再分为若干成分的数据类型|\n## 1.12 抽象数据类型\n- 一个数学模型及定义在该模型上的一组操作\n---\n\n# 2 数据结构三要素\n## 2.1 逻辑结构\n- 数据元素之间的逻辑关系\n- 集合、线性、树形、图形\n\n## 2.2 数据运算\n- 增删查改\n\n## 2.3 物理结构（存储结构）\n- 用计算机表示数据元素的逻辑关系\n插入表格：\n\n|顺序存储|链式存储|索引存储|散列存储|\n|:---:|:---:|:---:|:---:|\n|数组|链表|索引表|散列表|\n|逻辑相邻则物理相邻|逻辑相邻则物理不一定相邻|附加索引表|根据关键字得到存储地址|\n|![](../../../../themes/yilia/source/img/datastruct/1_extract/2.png)![数据结构](/img/datastruct/1_extract/2.png)|![](../../../../themes/yilia/source/img/datastruct/1_extract/3.png)![数据结构](/img/datastruct/1_extract/3.png)|![](../../../../themes/yilia/source/img/datastruct/1_extract/4.png)![数据结构](/img/datastruct/1_extract/4.png)||\n---\n# 3 算法的基本概念\n![](../../../../themes/yilia/source/img/datastruct/1_extract/5.png)![数据结构](/img/datastruct/1_extract/5.png)\n## 3.1 啥是算法\n- 对特定问题求解步骤的一种描述\n- 指令的有限序列\n- 每条指令表示一个或多个操作\n## 3.2 算法特性\n- 有穷性\n\n   ·执行有限步骤后结束\n   \n   ·每一步都可在有限时间内完成\n\n- 确定性\n \n   ·每一步都有确定的含义\n   \n   ·对于相同的输入只能得出相同的输出\n\n- 可行性\n\n   ·可以通过已经实现的基本运算执行有限次得出结果\n\n- 输入\n\n   ·有0个或多个输入\n\n- 输出\n\n   ·至少有1个或多个输出\n\n## 3.3 算法设计的要求\n- 正确性\n\n   ·算法能够得出正确的结果\n\n- 可读性\n\n   ·算法要便于阅读、理解和交流\n\n- 健壮性\n\n   ·算法对不合理数据输入有适当的处理能力\n\n- 时间效率高和存储量低\n\n   ·算法执行时间短，占用存储空间少\n\n## 3.4 算法效率的度量方法\n### 3.4.1 事后统计方法\n\n- 运行时间取决于计算机的硬件、软件环境\n\n### 3.4.2 事前分析估算方法\n- O(1)<O(log<sub>n</sub>)<O(n)<O(nlog<sub>n</sub>)<O(n<sup>2</sup>)<O(n<sup>3</sup>)<O(2<sup>n</sup>)<O(n!)<O(n<sup>n</sup>)\n- 时间复杂度\n![](../../../../themes/yilia/source/img/datastruct/1_extract/8.png)![数据结构](/img/datastruct/1_extract/8.png)\n- 空间复杂度\n![](../../../../themes/yilia/source/img/datastruct/1_extract/9.png)![数据结构](/img/datastruct/1_extract/9.png)\n- 例子：\n![](../../../../themes/yilia/source/img/datastruct/1_extract/6.png)![数据结构](/img/datastruct/1_extract/6.png)\n\n![](../../../../themes/yilia/source/img/datastruct/1_extract/7.png)![数据结构](/img/datastruct/1_extract/7.png)","source":"_posts/datastruct/1_extract/1_基础.md","raw":"---\ntitle: 1. 数据结构基本概念\ndate: 2023-02-01 00:00:00\ntags: [数据结构]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n![数据结构]<!--more-->\n(/img/datastruct/1_extract/1.png)\n![](../../../../themes/yilia/source/img/datastruct/1_extract/1.png)\n\n\n## 1.1 数据\n- 信息的载体，被计算机程序识别和处理的符号的集合\n## 1.2 数据元素\n- 数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。\n- 例如一个人的信息\n## 1.3 数据项\n- 数据不可分割的最小单位。\n- 例如姓名字段\n## 1.4 数据对象\n- 性质相同的数据元素的集合，是数据的一个子集。\n- 例如所有人的信息\n\n|概念|定义|举例|\n|:---:|:---:|:---:|\n|数据|信息的载体，被计算机程序识别和处理的符号的集合|一个人的信息|\n|数据元素|数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。|一个人的信息|\n|数据项|数据不可分割的最小单位。|姓名字段|\n|数据对象|性质相同的数据元素的集合，是数据的一个子集。|所有人的信息|\n\n\n## 1.5 数据结构\n- 相互之间存在一种或多种特定关系的数据元素的集合。\n- 例如所有人的信息按照年龄排序\n## 1.6 逻辑结构\n- 数据对象中数据元素之间的相互关系\n- 例如所有人的信息按照年龄排序\n## 1.7 物理结构\n- 数据的逻辑结构在计算机中的存储形式\n- 例如所有人的信息按照年龄排序，存储在数组中\n## 1.8 数据类型\n- 一组性质相同的值的集合及定义在此集合上的一些操作的总称\n- 例如整数类型，浮点数类型\n## 1.9 抽象数据类型\n- 一个数学模型及定义在该模型上的一组操作\n- 例如整数类型，浮点数类型\n## 1.10 算法\n- 为解决特定问题而规定的一个有限长的操作序列\n- 例如排序算法\n## 1.11 数据类型\n- 一个值的集合和定义在此集合上的一组操作的总称\n\n|原子类型|其值不可再分的数据类型|\n|:---:|:---:|\n|结构类型|其值可再分为若干成分的数据类型|\n## 1.12 抽象数据类型\n- 一个数学模型及定义在该模型上的一组操作\n---\n\n# 2 数据结构三要素\n## 2.1 逻辑结构\n- 数据元素之间的逻辑关系\n- 集合、线性、树形、图形\n\n## 2.2 数据运算\n- 增删查改\n\n## 2.3 物理结构（存储结构）\n- 用计算机表示数据元素的逻辑关系\n插入表格：\n\n|顺序存储|链式存储|索引存储|散列存储|\n|:---:|:---:|:---:|:---:|\n|数组|链表|索引表|散列表|\n|逻辑相邻则物理相邻|逻辑相邻则物理不一定相邻|附加索引表|根据关键字得到存储地址|\n|![](../../../../themes/yilia/source/img/datastruct/1_extract/2.png)![数据结构](/img/datastruct/1_extract/2.png)|![](../../../../themes/yilia/source/img/datastruct/1_extract/3.png)![数据结构](/img/datastruct/1_extract/3.png)|![](../../../../themes/yilia/source/img/datastruct/1_extract/4.png)![数据结构](/img/datastruct/1_extract/4.png)||\n---\n# 3 算法的基本概念\n![](../../../../themes/yilia/source/img/datastruct/1_extract/5.png)![数据结构](/img/datastruct/1_extract/5.png)\n## 3.1 啥是算法\n- 对特定问题求解步骤的一种描述\n- 指令的有限序列\n- 每条指令表示一个或多个操作\n## 3.2 算法特性\n- 有穷性\n\n   ·执行有限步骤后结束\n   \n   ·每一步都可在有限时间内完成\n\n- 确定性\n \n   ·每一步都有确定的含义\n   \n   ·对于相同的输入只能得出相同的输出\n\n- 可行性\n\n   ·可以通过已经实现的基本运算执行有限次得出结果\n\n- 输入\n\n   ·有0个或多个输入\n\n- 输出\n\n   ·至少有1个或多个输出\n\n## 3.3 算法设计的要求\n- 正确性\n\n   ·算法能够得出正确的结果\n\n- 可读性\n\n   ·算法要便于阅读、理解和交流\n\n- 健壮性\n\n   ·算法对不合理数据输入有适当的处理能力\n\n- 时间效率高和存储量低\n\n   ·算法执行时间短，占用存储空间少\n\n## 3.4 算法效率的度量方法\n### 3.4.1 事后统计方法\n\n- 运行时间取决于计算机的硬件、软件环境\n\n### 3.4.2 事前分析估算方法\n- O(1)<O(log<sub>n</sub>)<O(n)<O(nlog<sub>n</sub>)<O(n<sup>2</sup>)<O(n<sup>3</sup>)<O(2<sup>n</sup>)<O(n!)<O(n<sup>n</sup>)\n- 时间复杂度\n![](../../../../themes/yilia/source/img/datastruct/1_extract/8.png)![数据结构](/img/datastruct/1_extract/8.png)\n- 空间复杂度\n![](../../../../themes/yilia/source/img/datastruct/1_extract/9.png)![数据结构](/img/datastruct/1_extract/9.png)\n- 例子：\n![](../../../../themes/yilia/source/img/datastruct/1_extract/6.png)![数据结构](/img/datastruct/1_extract/6.png)\n\n![](../../../../themes/yilia/source/img/datastruct/1_extract/7.png)![数据结构](/img/datastruct/1_extract/7.png)","slug":"datastruct/1_extract/1_基础","published":1,"updated":"2023-10-23T11:59:15.750Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858p00177svwayrr2k2h","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<p>![数据结构]<!--more--><br>(&#x2F;img&#x2F;datastruct&#x2F;1_extract&#x2F;1.png)<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/1.png\"></p>\n<h2 id=\"1-1-数据\"><a href=\"#1-1-数据\" class=\"headerlink\" title=\"1.1 数据\"></a>1.1 数据</h2><ul>\n<li>信息的载体，被计算机程序识别和处理的符号的集合</li>\n</ul>\n<h2 id=\"1-2-数据元素\"><a href=\"#1-2-数据元素\" class=\"headerlink\" title=\"1.2 数据元素\"></a>1.2 数据元素</h2><ul>\n<li>数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。</li>\n<li>例如一个人的信息</li>\n</ul>\n<h2 id=\"1-3-数据项\"><a href=\"#1-3-数据项\" class=\"headerlink\" title=\"1.3 数据项\"></a>1.3 数据项</h2><ul>\n<li>数据不可分割的最小单位。</li>\n<li>例如姓名字段</li>\n</ul>\n<h2 id=\"1-4-数据对象\"><a href=\"#1-4-数据对象\" class=\"headerlink\" title=\"1.4 数据对象\"></a>1.4 数据对象</h2><ul>\n<li>性质相同的数据元素的集合，是数据的一个子集。</li>\n<li>例如所有人的信息</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">概念</th>\n<th align=\"center\">定义</th>\n<th align=\"center\">举例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">数据</td>\n<td align=\"center\">信息的载体，被计算机程序识别和处理的符号的集合</td>\n<td align=\"center\">一个人的信息</td>\n</tr>\n<tr>\n<td align=\"center\">数据元素</td>\n<td align=\"center\">数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。</td>\n<td align=\"center\">一个人的信息</td>\n</tr>\n<tr>\n<td align=\"center\">数据项</td>\n<td align=\"center\">数据不可分割的最小单位。</td>\n<td align=\"center\">姓名字段</td>\n</tr>\n<tr>\n<td align=\"center\">数据对象</td>\n<td align=\"center\">性质相同的数据元素的集合，是数据的一个子集。</td>\n<td align=\"center\">所有人的信息</td>\n</tr>\n</tbody></table>\n<h2 id=\"1-5-数据结构\"><a href=\"#1-5-数据结构\" class=\"headerlink\" title=\"1.5 数据结构\"></a>1.5 数据结构</h2><ul>\n<li>相互之间存在一种或多种特定关系的数据元素的集合。</li>\n<li>例如所有人的信息按照年龄排序</li>\n</ul>\n<h2 id=\"1-6-逻辑结构\"><a href=\"#1-6-逻辑结构\" class=\"headerlink\" title=\"1.6 逻辑结构\"></a>1.6 逻辑结构</h2><ul>\n<li>数据对象中数据元素之间的相互关系</li>\n<li>例如所有人的信息按照年龄排序</li>\n</ul>\n<h2 id=\"1-7-物理结构\"><a href=\"#1-7-物理结构\" class=\"headerlink\" title=\"1.7 物理结构\"></a>1.7 物理结构</h2><ul>\n<li>数据的逻辑结构在计算机中的存储形式</li>\n<li>例如所有人的信息按照年龄排序，存储在数组中</li>\n</ul>\n<h2 id=\"1-8-数据类型\"><a href=\"#1-8-数据类型\" class=\"headerlink\" title=\"1.8 数据类型\"></a>1.8 数据类型</h2><ul>\n<li>一组性质相同的值的集合及定义在此集合上的一些操作的总称</li>\n<li>例如整数类型，浮点数类型</li>\n</ul>\n<h2 id=\"1-9-抽象数据类型\"><a href=\"#1-9-抽象数据类型\" class=\"headerlink\" title=\"1.9 抽象数据类型\"></a>1.9 抽象数据类型</h2><ul>\n<li>一个数学模型及定义在该模型上的一组操作</li>\n<li>例如整数类型，浮点数类型</li>\n</ul>\n<h2 id=\"1-10-算法\"><a href=\"#1-10-算法\" class=\"headerlink\" title=\"1.10 算法\"></a>1.10 算法</h2><ul>\n<li>为解决特定问题而规定的一个有限长的操作序列</li>\n<li>例如排序算法</li>\n</ul>\n<h2 id=\"1-11-数据类型\"><a href=\"#1-11-数据类型\" class=\"headerlink\" title=\"1.11 数据类型\"></a>1.11 数据类型</h2><ul>\n<li>一个值的集合和定义在此集合上的一组操作的总称</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">原子类型</th>\n<th align=\"center\">其值不可再分的数据类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">结构类型</td>\n<td align=\"center\">其值可再分为若干成分的数据类型</td>\n</tr>\n</tbody></table>\n<h2 id=\"1-12-抽象数据类型\"><a href=\"#1-12-抽象数据类型\" class=\"headerlink\" title=\"1.12 抽象数据类型\"></a>1.12 抽象数据类型</h2><ul>\n<li>一个数学模型及定义在该模型上的一组操作</li>\n</ul>\n<hr>\n<h1 id=\"2-数据结构三要素\"><a href=\"#2-数据结构三要素\" class=\"headerlink\" title=\"2 数据结构三要素\"></a>2 数据结构三要素</h1><h2 id=\"2-1-逻辑结构\"><a href=\"#2-1-逻辑结构\" class=\"headerlink\" title=\"2.1 逻辑结构\"></a>2.1 逻辑结构</h2><ul>\n<li>数据元素之间的逻辑关系</li>\n<li>集合、线性、树形、图形</li>\n</ul>\n<h2 id=\"2-2-数据运算\"><a href=\"#2-2-数据运算\" class=\"headerlink\" title=\"2.2 数据运算\"></a>2.2 数据运算</h2><ul>\n<li>增删查改</li>\n</ul>\n<h2 id=\"2-3-物理结构（存储结构）\"><a href=\"#2-3-物理结构（存储结构）\" class=\"headerlink\" title=\"2.3 物理结构（存储结构）\"></a>2.3 物理结构（存储结构）</h2><ul>\n<li>用计算机表示数据元素的逻辑关系<br>插入表格：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">顺序存储</th>\n<th align=\"center\">链式存储</th>\n<th align=\"center\">索引存储</th>\n<th align=\"center\">散列存储</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">数组</td>\n<td align=\"center\">链表</td>\n<td align=\"center\">索引表</td>\n<td align=\"center\">散列表</td>\n</tr>\n<tr>\n<td align=\"center\">逻辑相邻则物理相邻</td>\n<td align=\"center\">逻辑相邻则物理不一定相邻</td>\n<td align=\"center\">附加索引表</td>\n<td align=\"center\">根据关键字得到存储地址</td>\n</tr>\n<tr>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/2.png\"><img src=\"/img/datastruct/1_extract/2.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/3.png\"><img src=\"/img/datastruct/1_extract/3.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/4.png\"><img src=\"/img/datastruct/1_extract/4.png\" alt=\"数据结构\"></td>\n<td align=\"center\"></td>\n</tr>\n</tbody></table>\n<hr>\n<h1 id=\"3-算法的基本概念\"><a href=\"#3-算法的基本概念\" class=\"headerlink\" title=\"3 算法的基本概念\"></a>3 算法的基本概念</h1><p><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/5.png\"><img src=\"/img/datastruct/1_extract/5.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-1-啥是算法\"><a href=\"#3-1-啥是算法\" class=\"headerlink\" title=\"3.1 啥是算法\"></a>3.1 啥是算法</h2><ul>\n<li>对特定问题求解步骤的一种描述</li>\n<li>指令的有限序列</li>\n<li>每条指令表示一个或多个操作</li>\n</ul>\n<h2 id=\"3-2-算法特性\"><a href=\"#3-2-算法特性\" class=\"headerlink\" title=\"3.2 算法特性\"></a>3.2 算法特性</h2><ul>\n<li><p>有穷性</p>\n<p> ·执行有限步骤后结束</p>\n<p> ·每一步都可在有限时间内完成</p>\n</li>\n<li><p>确定性</p>\n<p> ·每一步都有确定的含义</p>\n<p> ·对于相同的输入只能得出相同的输出</p>\n</li>\n<li><p>可行性</p>\n<p> ·可以通过已经实现的基本运算执行有限次得出结果</p>\n</li>\n<li><p>输入</p>\n<p> ·有0个或多个输入</p>\n</li>\n<li><p>输出</p>\n<p> ·至少有1个或多个输出</p>\n</li>\n</ul>\n<h2 id=\"3-3-算法设计的要求\"><a href=\"#3-3-算法设计的要求\" class=\"headerlink\" title=\"3.3 算法设计的要求\"></a>3.3 算法设计的要求</h2><ul>\n<li><p>正确性</p>\n<p> ·算法能够得出正确的结果</p>\n</li>\n<li><p>可读性</p>\n<p> ·算法要便于阅读、理解和交流</p>\n</li>\n<li><p>健壮性</p>\n<p> ·算法对不合理数据输入有适当的处理能力</p>\n</li>\n<li><p>时间效率高和存储量低</p>\n<p> ·算法执行时间短，占用存储空间少</p>\n</li>\n</ul>\n<h2 id=\"3-4-算法效率的度量方法\"><a href=\"#3-4-算法效率的度量方法\" class=\"headerlink\" title=\"3.4 算法效率的度量方法\"></a>3.4 算法效率的度量方法</h2><h3 id=\"3-4-1-事后统计方法\"><a href=\"#3-4-1-事后统计方法\" class=\"headerlink\" title=\"3.4.1 事后统计方法\"></a>3.4.1 事后统计方法</h3><ul>\n<li>运行时间取决于计算机的硬件、软件环境</li>\n</ul>\n<h3 id=\"3-4-2-事前分析估算方法\"><a href=\"#3-4-2-事前分析估算方法\" class=\"headerlink\" title=\"3.4.2 事前分析估算方法\"></a>3.4.2 事前分析估算方法</h3><ul>\n<li>O(1)&lt;O(log<sub>n</sub>)&lt;O(n)&lt;O(nlog<sub>n</sub>)&lt;O(n<sup>2</sup>)&lt;O(n<sup>3</sup>)&lt;O(2<sup>n</sup>)&lt;O(n!)&lt;O(n<sup>n</sup>)</li>\n<li>时间复杂度<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/8.png\"><img src=\"/img/datastruct/1_extract/8.png\" alt=\"数据结构\"></li>\n<li>空间复杂度<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/9.png\"><img src=\"/img/datastruct/1_extract/9.png\" alt=\"数据结构\"></li>\n<li>例子：<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/6.png\"><img src=\"/img/datastruct/1_extract/6.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/7.png\"><img src=\"/img/datastruct/1_extract/7.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p>![数据结构]<!--more--><br>(&#x2F;img&#x2F;datastruct&#x2F;1_extract&#x2F;1.png)<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/1.png\"></p>\n<h2 id=\"1-1-数据\"><a href=\"#1-1-数据\" class=\"headerlink\" title=\"1.1 数据\"></a>1.1 数据</h2><ul>\n<li>信息的载体，被计算机程序识别和处理的符号的集合</li>\n</ul>\n<h2 id=\"1-2-数据元素\"><a href=\"#1-2-数据元素\" class=\"headerlink\" title=\"1.2 数据元素\"></a>1.2 数据元素</h2><ul>\n<li>数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。</li>\n<li>例如一个人的信息</li>\n</ul>\n<h2 id=\"1-3-数据项\"><a href=\"#1-3-数据项\" class=\"headerlink\" title=\"1.3 数据项\"></a>1.3 数据项</h2><ul>\n<li>数据不可分割的最小单位。</li>\n<li>例如姓名字段</li>\n</ul>\n<h2 id=\"1-4-数据对象\"><a href=\"#1-4-数据对象\" class=\"headerlink\" title=\"1.4 数据对象\"></a>1.4 数据对象</h2><ul>\n<li>性质相同的数据元素的集合，是数据的一个子集。</li>\n<li>例如所有人的信息</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">概念</th>\n<th align=\"center\">定义</th>\n<th align=\"center\">举例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">数据</td>\n<td align=\"center\">信息的载体，被计算机程序识别和处理的符号的集合</td>\n<td align=\"center\">一个人的信息</td>\n</tr>\n<tr>\n<td align=\"center\">数据元素</td>\n<td align=\"center\">数据的基本单位，常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成。</td>\n<td align=\"center\">一个人的信息</td>\n</tr>\n<tr>\n<td align=\"center\">数据项</td>\n<td align=\"center\">数据不可分割的最小单位。</td>\n<td align=\"center\">姓名字段</td>\n</tr>\n<tr>\n<td align=\"center\">数据对象</td>\n<td align=\"center\">性质相同的数据元素的集合，是数据的一个子集。</td>\n<td align=\"center\">所有人的信息</td>\n</tr>\n</tbody></table>\n<h2 id=\"1-5-数据结构\"><a href=\"#1-5-数据结构\" class=\"headerlink\" title=\"1.5 数据结构\"></a>1.5 数据结构</h2><ul>\n<li>相互之间存在一种或多种特定关系的数据元素的集合。</li>\n<li>例如所有人的信息按照年龄排序</li>\n</ul>\n<h2 id=\"1-6-逻辑结构\"><a href=\"#1-6-逻辑结构\" class=\"headerlink\" title=\"1.6 逻辑结构\"></a>1.6 逻辑结构</h2><ul>\n<li>数据对象中数据元素之间的相互关系</li>\n<li>例如所有人的信息按照年龄排序</li>\n</ul>\n<h2 id=\"1-7-物理结构\"><a href=\"#1-7-物理结构\" class=\"headerlink\" title=\"1.7 物理结构\"></a>1.7 物理结构</h2><ul>\n<li>数据的逻辑结构在计算机中的存储形式</li>\n<li>例如所有人的信息按照年龄排序，存储在数组中</li>\n</ul>\n<h2 id=\"1-8-数据类型\"><a href=\"#1-8-数据类型\" class=\"headerlink\" title=\"1.8 数据类型\"></a>1.8 数据类型</h2><ul>\n<li>一组性质相同的值的集合及定义在此集合上的一些操作的总称</li>\n<li>例如整数类型，浮点数类型</li>\n</ul>\n<h2 id=\"1-9-抽象数据类型\"><a href=\"#1-9-抽象数据类型\" class=\"headerlink\" title=\"1.9 抽象数据类型\"></a>1.9 抽象数据类型</h2><ul>\n<li>一个数学模型及定义在该模型上的一组操作</li>\n<li>例如整数类型，浮点数类型</li>\n</ul>\n<h2 id=\"1-10-算法\"><a href=\"#1-10-算法\" class=\"headerlink\" title=\"1.10 算法\"></a>1.10 算法</h2><ul>\n<li>为解决特定问题而规定的一个有限长的操作序列</li>\n<li>例如排序算法</li>\n</ul>\n<h2 id=\"1-11-数据类型\"><a href=\"#1-11-数据类型\" class=\"headerlink\" title=\"1.11 数据类型\"></a>1.11 数据类型</h2><ul>\n<li>一个值的集合和定义在此集合上的一组操作的总称</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">原子类型</th>\n<th align=\"center\">其值不可再分的数据类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">结构类型</td>\n<td align=\"center\">其值可再分为若干成分的数据类型</td>\n</tr>\n</tbody></table>\n<h2 id=\"1-12-抽象数据类型\"><a href=\"#1-12-抽象数据类型\" class=\"headerlink\" title=\"1.12 抽象数据类型\"></a>1.12 抽象数据类型</h2><ul>\n<li>一个数学模型及定义在该模型上的一组操作</li>\n</ul>\n<hr>\n<h1 id=\"2-数据结构三要素\"><a href=\"#2-数据结构三要素\" class=\"headerlink\" title=\"2 数据结构三要素\"></a>2 数据结构三要素</h1><h2 id=\"2-1-逻辑结构\"><a href=\"#2-1-逻辑结构\" class=\"headerlink\" title=\"2.1 逻辑结构\"></a>2.1 逻辑结构</h2><ul>\n<li>数据元素之间的逻辑关系</li>\n<li>集合、线性、树形、图形</li>\n</ul>\n<h2 id=\"2-2-数据运算\"><a href=\"#2-2-数据运算\" class=\"headerlink\" title=\"2.2 数据运算\"></a>2.2 数据运算</h2><ul>\n<li>增删查改</li>\n</ul>\n<h2 id=\"2-3-物理结构（存储结构）\"><a href=\"#2-3-物理结构（存储结构）\" class=\"headerlink\" title=\"2.3 物理结构（存储结构）\"></a>2.3 物理结构（存储结构）</h2><ul>\n<li>用计算机表示数据元素的逻辑关系<br>插入表格：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">顺序存储</th>\n<th align=\"center\">链式存储</th>\n<th align=\"center\">索引存储</th>\n<th align=\"center\">散列存储</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">数组</td>\n<td align=\"center\">链表</td>\n<td align=\"center\">索引表</td>\n<td align=\"center\">散列表</td>\n</tr>\n<tr>\n<td align=\"center\">逻辑相邻则物理相邻</td>\n<td align=\"center\">逻辑相邻则物理不一定相邻</td>\n<td align=\"center\">附加索引表</td>\n<td align=\"center\">根据关键字得到存储地址</td>\n</tr>\n<tr>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/2.png\"><img src=\"/img/datastruct/1_extract/2.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/3.png\"><img src=\"/img/datastruct/1_extract/3.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/4.png\"><img src=\"/img/datastruct/1_extract/4.png\" alt=\"数据结构\"></td>\n<td align=\"center\"></td>\n</tr>\n</tbody></table>\n<hr>\n<h1 id=\"3-算法的基本概念\"><a href=\"#3-算法的基本概念\" class=\"headerlink\" title=\"3 算法的基本概念\"></a>3 算法的基本概念</h1><p><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/5.png\"><img src=\"/img/datastruct/1_extract/5.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-1-啥是算法\"><a href=\"#3-1-啥是算法\" class=\"headerlink\" title=\"3.1 啥是算法\"></a>3.1 啥是算法</h2><ul>\n<li>对特定问题求解步骤的一种描述</li>\n<li>指令的有限序列</li>\n<li>每条指令表示一个或多个操作</li>\n</ul>\n<h2 id=\"3-2-算法特性\"><a href=\"#3-2-算法特性\" class=\"headerlink\" title=\"3.2 算法特性\"></a>3.2 算法特性</h2><ul>\n<li><p>有穷性</p>\n<p> ·执行有限步骤后结束</p>\n<p> ·每一步都可在有限时间内完成</p>\n</li>\n<li><p>确定性</p>\n<p> ·每一步都有确定的含义</p>\n<p> ·对于相同的输入只能得出相同的输出</p>\n</li>\n<li><p>可行性</p>\n<p> ·可以通过已经实现的基本运算执行有限次得出结果</p>\n</li>\n<li><p>输入</p>\n<p> ·有0个或多个输入</p>\n</li>\n<li><p>输出</p>\n<p> ·至少有1个或多个输出</p>\n</li>\n</ul>\n<h2 id=\"3-3-算法设计的要求\"><a href=\"#3-3-算法设计的要求\" class=\"headerlink\" title=\"3.3 算法设计的要求\"></a>3.3 算法设计的要求</h2><ul>\n<li><p>正确性</p>\n<p> ·算法能够得出正确的结果</p>\n</li>\n<li><p>可读性</p>\n<p> ·算法要便于阅读、理解和交流</p>\n</li>\n<li><p>健壮性</p>\n<p> ·算法对不合理数据输入有适当的处理能力</p>\n</li>\n<li><p>时间效率高和存储量低</p>\n<p> ·算法执行时间短，占用存储空间少</p>\n</li>\n</ul>\n<h2 id=\"3-4-算法效率的度量方法\"><a href=\"#3-4-算法效率的度量方法\" class=\"headerlink\" title=\"3.4 算法效率的度量方法\"></a>3.4 算法效率的度量方法</h2><h3 id=\"3-4-1-事后统计方法\"><a href=\"#3-4-1-事后统计方法\" class=\"headerlink\" title=\"3.4.1 事后统计方法\"></a>3.4.1 事后统计方法</h3><ul>\n<li>运行时间取决于计算机的硬件、软件环境</li>\n</ul>\n<h3 id=\"3-4-2-事前分析估算方法\"><a href=\"#3-4-2-事前分析估算方法\" class=\"headerlink\" title=\"3.4.2 事前分析估算方法\"></a>3.4.2 事前分析估算方法</h3><ul>\n<li>O(1)&lt;O(log<sub>n</sub>)&lt;O(n)&lt;O(nlog<sub>n</sub>)&lt;O(n<sup>2</sup>)&lt;O(n<sup>3</sup>)&lt;O(2<sup>n</sup>)&lt;O(n!)&lt;O(n<sup>n</sup>)</li>\n<li>时间复杂度<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/8.png\"><img src=\"/img/datastruct/1_extract/8.png\" alt=\"数据结构\"></li>\n<li>空间复杂度<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/9.png\"><img src=\"/img/datastruct/1_extract/9.png\" alt=\"数据结构\"></li>\n<li>例子：<br><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/6.png\"><img src=\"/img/datastruct/1_extract/6.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/1_extract/7.png\"><img src=\"/img/datastruct/1_extract/7.png\" alt=\"数据结构\"></p>"},{"title":"3.1 栈的定义","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/1.png)\n![数据结构](/img/datastruct/3_stack/stack/1.png)\n\n\n## 3.1 定义\n- 栈是限定仅在表尾进行插入和删除操作的线性表\n\n## 3.2 基本操作\n|操作|描述|\n|:---:|:---:|\n|InitStack(&S)|初始化栈S，构造一个空栈|\n|DestroyStack(&S)|若栈存在，则销毁它|\n|Push(&S,x)|若栈S存在，插入新元素x到栈S中并成为栈顶元素|\n|Pop(&S,&x)|删除栈S中栈顶元素，并用x返回其值|\n|GetTop(S,&x)|返回栈S中栈顶元素，不修改栈顶指针|\n|StackEmpty(S)|若栈为空，返回true，否则返回false|\n\n- （常考：给你一个出栈序列，问你能不能通过入栈操作得到这个出栈序列）共有卡特兰数种出栈序列：$C_n=\\frac{1}{n+1}\\binom{2n}{n}$\n\n## 3.3 顺序栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/2.png)\n![数据结构](/img/datastruct/3_stack/stack/2.png)\n\n- 顺序栈的实现\n```c\n#include<stdio.h>\n#include<stdlib.h>\n#define MAXSIZE 10\ntypedef struct{\n    int data[MAXSIZE];\n    int top;\n} SqStack;\n\n//初始化\nvoid InitStack(SqStack *S){\n    S->top=-1;\n}\n\n//判空\nint StackEmpty(SqStack S){\n    if(S.top==-1)\n        return 1;\n    else\n        return 0;\n}\n\n//入栈\nint Push(SqStack *S, int x){\n    if(S->top==MAXSIZE-1)\n        return 0;\n    S->top++;\n    S->data[S->top]=x;\n    return 1;\n}\n\n//出栈\nint Pop(SqStack *S, int *x){\n    if(S->top==-1)\n        return 0;\n    *x=S->data[S->top];\n    S->top--;\n    return 1;\n}\n\n//取栈顶元素\nint GetTop(SqStack S, int *x){\n    if(S.top==-1)\n        return 0;\n    *x=S.data[S.top];\n    return 1;\n}\n```\n\n- 共享栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/3.png)\n![数据结构](/img/datastruct/3_stack/stack/3.png)\n\n## 3.4 链栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/4.png)\n![数据结构](/img/datastruct/3_stack/stack/4.png)\n- 链栈的实现\n```c\n\n```","source":"_posts/datastruct/3_stack/1_stack.md","raw":"---\ntitle: 3.1 栈的定义\ndate: 2023-08-07 00:00:00\ntags: [数据结构,栈]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/1.png)\n![数据结构](/img/datastruct/3_stack/stack/1.png)\n\n\n## 3.1 定义\n- 栈是限定仅在表尾进行插入和删除操作的线性表\n\n## 3.2 基本操作\n|操作|描述|\n|:---:|:---:|\n|InitStack(&S)|初始化栈S，构造一个空栈|\n|DestroyStack(&S)|若栈存在，则销毁它|\n|Push(&S,x)|若栈S存在，插入新元素x到栈S中并成为栈顶元素|\n|Pop(&S,&x)|删除栈S中栈顶元素，并用x返回其值|\n|GetTop(S,&x)|返回栈S中栈顶元素，不修改栈顶指针|\n|StackEmpty(S)|若栈为空，返回true，否则返回false|\n\n- （常考：给你一个出栈序列，问你能不能通过入栈操作得到这个出栈序列）共有卡特兰数种出栈序列：$C_n=\\frac{1}{n+1}\\binom{2n}{n}$\n\n## 3.3 顺序栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/2.png)\n![数据结构](/img/datastruct/3_stack/stack/2.png)\n\n- 顺序栈的实现\n```c\n#include<stdio.h>\n#include<stdlib.h>\n#define MAXSIZE 10\ntypedef struct{\n    int data[MAXSIZE];\n    int top;\n} SqStack;\n\n//初始化\nvoid InitStack(SqStack *S){\n    S->top=-1;\n}\n\n//判空\nint StackEmpty(SqStack S){\n    if(S.top==-1)\n        return 1;\n    else\n        return 0;\n}\n\n//入栈\nint Push(SqStack *S, int x){\n    if(S->top==MAXSIZE-1)\n        return 0;\n    S->top++;\n    S->data[S->top]=x;\n    return 1;\n}\n\n//出栈\nint Pop(SqStack *S, int *x){\n    if(S->top==-1)\n        return 0;\n    *x=S->data[S->top];\n    S->top--;\n    return 1;\n}\n\n//取栈顶元素\nint GetTop(SqStack S, int *x){\n    if(S.top==-1)\n        return 0;\n    *x=S.data[S.top];\n    return 1;\n}\n```\n\n- 共享栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/3.png)\n![数据结构](/img/datastruct/3_stack/stack/3.png)\n\n## 3.4 链栈\n![](../../../../themes/yilia/source/img/datastruct/3_stack/stack/4.png)\n![数据结构](/img/datastruct/3_stack/stack/4.png)\n- 链栈的实现\n```c\n\n```","slug":"datastruct/3_stack/1_stack","published":1,"updated":"2023-10-23T13:20:15.453Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858p00187svwgmhuc5m6","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/1.png\"><br><img src=\"/img/datastruct/3_stack/stack/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-1-定义\"><a href=\"#3-1-定义\" class=\"headerlink\" title=\"3.1 定义\"></a>3.1 定义</h2><ul>\n<li>栈是限定仅在表尾进行插入和删除操作的线性表</li>\n</ul>\n<h2 id=\"3-2-基本操作\"><a href=\"#3-2-基本操作\" class=\"headerlink\" title=\"3.2 基本操作\"></a>3.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">操作</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitStack(&amp;S)</td>\n<td align=\"center\">初始化栈S，构造一个空栈</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyStack(&amp;S)</td>\n<td align=\"center\">若栈存在，则销毁它</td>\n</tr>\n<tr>\n<td align=\"center\">Push(&amp;S,x)</td>\n<td align=\"center\">若栈S存在，插入新元素x到栈S中并成为栈顶元素</td>\n</tr>\n<tr>\n<td align=\"center\">Pop(&amp;S,&amp;x)</td>\n<td align=\"center\">删除栈S中栈顶元素，并用x返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">GetTop(S,&amp;x)</td>\n<td align=\"center\">返回栈S中栈顶元素，不修改栈顶指针</td>\n</tr>\n<tr>\n<td align=\"center\">StackEmpty(S)</td>\n<td align=\"center\">若栈为空，返回true，否则返回false</td>\n</tr>\n</tbody></table>\n<ul>\n<li>（常考：给你一个出栈序列，问你能不能通过入栈操作得到这个出栈序列）共有卡特兰数种出栈序列：$C_n&#x3D;\\frac{1}{n+1}\\binom{2n}{n}$</li>\n</ul>\n<h2 id=\"3-3-顺序栈\"><a href=\"#3-3-顺序栈\" class=\"headerlink\" title=\"3.3 顺序栈\"></a>3.3 顺序栈</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/2.png\"><br><img src=\"/img/datastruct/3_stack/stack/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>顺序栈的实现</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> top;</span><br><span class=\"line\">&#125; SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitStack</span><span class=\"params\">(SqStack *S)</span>&#123;</span><br><span class=\"line\">    S-&gt;top=<span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StackEmpty</span><span class=\"params\">(SqStack S)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Push</span><span class=\"params\">(SqStack *S, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==MAXSIZE<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    S-&gt;top++;</span><br><span class=\"line\">    S-&gt;data[S-&gt;top]=x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Pop</span><span class=\"params\">(SqStack *S, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S-&gt;data[S-&gt;top];</span><br><span class=\"line\">    S-&gt;top--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//取栈顶元素</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetTop</span><span class=\"params\">(SqStack S, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S.data[S.top];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>共享栈<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/3.png\"><br><img src=\"/img/datastruct/3_stack/stack/3.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<h2 id=\"3-4-链栈\"><a href=\"#3-4-链栈\" class=\"headerlink\" title=\"3.4 链栈\"></a>3.4 链栈</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/4.png\"><br><img src=\"/img/datastruct/3_stack/stack/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>链栈的实现<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/1.png\"><br><img src=\"/img/datastruct/3_stack/stack/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-1-定义\"><a href=\"#3-1-定义\" class=\"headerlink\" title=\"3.1 定义\"></a>3.1 定义</h2><ul>\n<li>栈是限定仅在表尾进行插入和删除操作的线性表</li>\n</ul>\n<h2 id=\"3-2-基本操作\"><a href=\"#3-2-基本操作\" class=\"headerlink\" title=\"3.2 基本操作\"></a>3.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">操作</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitStack(&amp;S)</td>\n<td align=\"center\">初始化栈S，构造一个空栈</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyStack(&amp;S)</td>\n<td align=\"center\">若栈存在，则销毁它</td>\n</tr>\n<tr>\n<td align=\"center\">Push(&amp;S,x)</td>\n<td align=\"center\">若栈S存在，插入新元素x到栈S中并成为栈顶元素</td>\n</tr>\n<tr>\n<td align=\"center\">Pop(&amp;S,&amp;x)</td>\n<td align=\"center\">删除栈S中栈顶元素，并用x返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">GetTop(S,&amp;x)</td>\n<td align=\"center\">返回栈S中栈顶元素，不修改栈顶指针</td>\n</tr>\n<tr>\n<td align=\"center\">StackEmpty(S)</td>\n<td align=\"center\">若栈为空，返回true，否则返回false</td>\n</tr>\n</tbody></table>\n<ul>\n<li>（常考：给你一个出栈序列，问你能不能通过入栈操作得到这个出栈序列）共有卡特兰数种出栈序列：$C_n&#x3D;\\frac{1}{n+1}\\binom{2n}{n}$</li>\n</ul>\n<h2 id=\"3-3-顺序栈\"><a href=\"#3-3-顺序栈\" class=\"headerlink\" title=\"3.3 顺序栈\"></a>3.3 顺序栈</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/2.png\"><br><img src=\"/img/datastruct/3_stack/stack/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>顺序栈的实现</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> top;</span><br><span class=\"line\">&#125; SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitStack</span><span class=\"params\">(SqStack *S)</span>&#123;</span><br><span class=\"line\">    S-&gt;top=<span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StackEmpty</span><span class=\"params\">(SqStack S)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Push</span><span class=\"params\">(SqStack *S, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==MAXSIZE<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    S-&gt;top++;</span><br><span class=\"line\">    S-&gt;data[S-&gt;top]=x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Pop</span><span class=\"params\">(SqStack *S, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S-&gt;data[S-&gt;top];</span><br><span class=\"line\">    S-&gt;top--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//取栈顶元素</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetTop</span><span class=\"params\">(SqStack S, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S.data[S.top];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>共享栈<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/3.png\"><br><img src=\"/img/datastruct/3_stack/stack/3.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<h2 id=\"3-4-链栈\"><a href=\"#3-4-链栈\" class=\"headerlink\" title=\"3.4 链栈\"></a>3.4 链栈</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/stack/4.png\"><br><img src=\"/img/datastruct/3_stack/stack/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>链栈的实现<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"3.4 矩阵压缩","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/1.png)\n![数据结构](/img/datastruct/3_stack/matrix/1.png)\n\n## 3.4.1 对称矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/2.png)\n![数据结构](/img/datastruct/3_stack/matrix/2.png)\n- 存主对角线+下三角\n\n    $$a_{k}=a_{ij}=a_{ji} (i>=j)$$\n\n    - 列优先\n\n        $$k=\\frac{i(i-1)}{2}+j-1$$\n    - 行优先\n\n        $$k=\\frac{j(j-1)}{2}+i-1$$\n\n## 3.4.2 三角矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/3.png)\n![数据结构](/img/datastruct/3_stack/matrix/3.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/4.png)\n![数据结构](/img/datastruct/3_stack/matrix/4.png)\n- 存主对角线+下三角/上三角+c\n\n    $$a_{k}=a_{ij} (i>=j)$$\n\n- 下三角，行优先\n\n    $$k=\\left\\{\\begin{array}{l}{\\frac{i(i-1)}{2}+j-1} & {i \\geq j} \\\\ {\\frac{n(n-1)}{2}} & {i<j}\\end{array}\\right.$$\n\n- 上三角，行优先\n    \n    $$k=\\left\\{\\begin{array}{l}{\\frac{(i-1)(2n-i+2)}{2}+j-i} & {i \\leq j} \\\\ {\\frac{n(n-1)}{2}} & {i>j}\\end{array}\\right.$$\n\n## 3.4.3 三对角矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/5.png)\n![数据结构](/img/datastruct/3_stack/matrix/5.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/6.png)\n![数据结构](/img/datastruct/3_stack/matrix/6.png)\n- $$k=2i+j-3$$\n\n## 3.4.4 稀疏矩阵\n- 顺序存储\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/7.png)\n![数据结构](/img/datastruct/3_stack/matrix/7.png)\n\n- 链式存储\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/8.png)\n![数据结构](/img/datastruct/3_stack/matrix/8.png)\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/9.png)\n![数据结构](/img/datastruct/3_stack/matrix/9.png)","source":"_posts/datastruct/3_stack/4_matrix.md","raw":"---\ntitle: 3.4 矩阵压缩\ndate: 2023-08-07 00:00:00\ntags: [数据结构]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/1.png)\n![数据结构](/img/datastruct/3_stack/matrix/1.png)\n\n## 3.4.1 对称矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/2.png)\n![数据结构](/img/datastruct/3_stack/matrix/2.png)\n- 存主对角线+下三角\n\n    $$a_{k}=a_{ij}=a_{ji} (i>=j)$$\n\n    - 列优先\n\n        $$k=\\frac{i(i-1)}{2}+j-1$$\n    - 行优先\n\n        $$k=\\frac{j(j-1)}{2}+i-1$$\n\n## 3.4.2 三角矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/3.png)\n![数据结构](/img/datastruct/3_stack/matrix/3.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/4.png)\n![数据结构](/img/datastruct/3_stack/matrix/4.png)\n- 存主对角线+下三角/上三角+c\n\n    $$a_{k}=a_{ij} (i>=j)$$\n\n- 下三角，行优先\n\n    $$k=\\left\\{\\begin{array}{l}{\\frac{i(i-1)}{2}+j-1} & {i \\geq j} \\\\ {\\frac{n(n-1)}{2}} & {i<j}\\end{array}\\right.$$\n\n- 上三角，行优先\n    \n    $$k=\\left\\{\\begin{array}{l}{\\frac{(i-1)(2n-i+2)}{2}+j-i} & {i \\leq j} \\\\ {\\frac{n(n-1)}{2}} & {i>j}\\end{array}\\right.$$\n\n## 3.4.3 三对角矩阵\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/5.png)\n![数据结构](/img/datastruct/3_stack/matrix/5.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/6.png)\n![数据结构](/img/datastruct/3_stack/matrix/6.png)\n- $$k=2i+j-3$$\n\n## 3.4.4 稀疏矩阵\n- 顺序存储\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/7.png)\n![数据结构](/img/datastruct/3_stack/matrix/7.png)\n\n- 链式存储\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/8.png)\n![数据结构](/img/datastruct/3_stack/matrix/8.png)\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/matrix/9.png)\n![数据结构](/img/datastruct/3_stack/matrix/9.png)","slug":"datastruct/3_stack/4_matrix","published":1,"updated":"2023-10-23T12:09:13.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858q001c7svw7w4h1ksm","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/1.png\"><br><img src=\"/img/datastruct/3_stack/matrix/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-4-1-对称矩阵\"><a href=\"#3-4-1-对称矩阵\" class=\"headerlink\" title=\"3.4.1 对称矩阵\"></a>3.4.1 对称矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/2.png\"><br><img src=\"/img/datastruct/3_stack/matrix/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>存主对角线+下三角</p>\n<p>  $$a_{k}&#x3D;a_{ij}&#x3D;a_{ji} (i&gt;&#x3D;j)$$</p>\n<ul>\n<li><p>列优先</p>\n<p>  $$k&#x3D;\\frac{i(i-1)}{2}+j-1$$</p>\n</li>\n<li><p>行优先</p>\n<p>  $$k&#x3D;\\frac{j(j-1)}{2}+i-1$$</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-4-2-三角矩阵\"><a href=\"#3-4-2-三角矩阵\" class=\"headerlink\" title=\"3.4.2 三角矩阵\"></a>3.4.2 三角矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/3.png\"><br><img src=\"/img/datastruct/3_stack/matrix/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/4.png\"><br><img src=\"/img/datastruct/3_stack/matrix/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>存主对角线+下三角&#x2F;上三角+c</p>\n<p>  $$a_{k}&#x3D;a_{ij} (i&gt;&#x3D;j)$$</p>\n</li>\n<li><p>下三角，行优先</p>\n<p>  $$k&#x3D;\\left{\\begin{array}{l}{\\frac{i(i-1)}{2}+j-1} &amp; {i \\geq j} \\ {\\frac{n(n-1)}{2}} &amp; {i&lt;j}\\end{array}\\right.$$</p>\n</li>\n<li><p>上三角，行优先</p>\n<p>  $$k&#x3D;\\left{\\begin{array}{l}{\\frac{(i-1)(2n-i+2)}{2}+j-i} &amp; {i \\leq j} \\ {\\frac{n(n-1)}{2}} &amp; {i&gt;j}\\end{array}\\right.$$</p>\n</li>\n</ul>\n<h2 id=\"3-4-3-三对角矩阵\"><a href=\"#3-4-3-三对角矩阵\" class=\"headerlink\" title=\"3.4.3 三对角矩阵\"></a>3.4.3 三对角矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/5.png\"><br><img src=\"/img/datastruct/3_stack/matrix/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/6.png\"><br><img src=\"/img/datastruct/3_stack/matrix/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>$$k&#x3D;2i+j-3$$</li>\n</ul>\n<h2 id=\"3-4-4-稀疏矩阵\"><a href=\"#3-4-4-稀疏矩阵\" class=\"headerlink\" title=\"3.4.4 稀疏矩阵\"></a>3.4.4 稀疏矩阵</h2><ul>\n<li><p>顺序存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/7.png\"><br><img src=\"/img/datastruct/3_stack/matrix/7.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>链式存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/8.png\"><br><img src=\"/img/datastruct/3_stack/matrix/8.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/9.png\"><br><img src=\"/img/datastruct/3_stack/matrix/9.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/1.png\"><br><img src=\"/img/datastruct/3_stack/matrix/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-4-1-对称矩阵\"><a href=\"#3-4-1-对称矩阵\" class=\"headerlink\" title=\"3.4.1 对称矩阵\"></a>3.4.1 对称矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/2.png\"><br><img src=\"/img/datastruct/3_stack/matrix/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>存主对角线+下三角</p>\n<p>  $$a_{k}&#x3D;a_{ij}&#x3D;a_{ji} (i&gt;&#x3D;j)$$</p>\n<ul>\n<li><p>列优先</p>\n<p>  $$k&#x3D;\\frac{i(i-1)}{2}+j-1$$</p>\n</li>\n<li><p>行优先</p>\n<p>  $$k&#x3D;\\frac{j(j-1)}{2}+i-1$$</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-4-2-三角矩阵\"><a href=\"#3-4-2-三角矩阵\" class=\"headerlink\" title=\"3.4.2 三角矩阵\"></a>3.4.2 三角矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/3.png\"><br><img src=\"/img/datastruct/3_stack/matrix/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/4.png\"><br><img src=\"/img/datastruct/3_stack/matrix/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>存主对角线+下三角&#x2F;上三角+c</p>\n<p>  $$a_{k}&#x3D;a_{ij} (i&gt;&#x3D;j)$$</p>\n</li>\n<li><p>下三角，行优先</p>\n<p>  $$k&#x3D;\\left{\\begin{array}{l}{\\frac{i(i-1)}{2}+j-1} &amp; {i \\geq j} \\ {\\frac{n(n-1)}{2}} &amp; {i&lt;j}\\end{array}\\right.$$</p>\n</li>\n<li><p>上三角，行优先</p>\n<p>  $$k&#x3D;\\left{\\begin{array}{l}{\\frac{(i-1)(2n-i+2)}{2}+j-i} &amp; {i \\leq j} \\ {\\frac{n(n-1)}{2}} &amp; {i&gt;j}\\end{array}\\right.$$</p>\n</li>\n</ul>\n<h2 id=\"3-4-3-三对角矩阵\"><a href=\"#3-4-3-三对角矩阵\" class=\"headerlink\" title=\"3.4.3 三对角矩阵\"></a>3.4.3 三对角矩阵</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/5.png\"><br><img src=\"/img/datastruct/3_stack/matrix/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/6.png\"><br><img src=\"/img/datastruct/3_stack/matrix/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>$$k&#x3D;2i+j-3$$</li>\n</ul>\n<h2 id=\"3-4-4-稀疏矩阵\"><a href=\"#3-4-4-稀疏矩阵\" class=\"headerlink\" title=\"3.4.4 稀疏矩阵\"></a>3.4.4 稀疏矩阵</h2><ul>\n<li><p>顺序存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/7.png\"><br><img src=\"/img/datastruct/3_stack/matrix/7.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>链式存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/8.png\"><br><img src=\"/img/datastruct/3_stack/matrix/8.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/matrix/9.png\"><br><img src=\"/img/datastruct/3_stack/matrix/9.png\" alt=\"数据结构\"></p>"},{"title":"3.2 队列","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/1.png)\n![数据结构](/img/datastruct/3_stack/queue/1.png)\n\n\n## 3.2.1 定义\n- 队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表\n\n## 3.2.2 基本操作\n|操作|描述|\n|:---:|:---:|\n|InitQueue(&Q)|初始化队列Q，构造一个空队列|\n|DestroyQueue(&Q)|若队列Q存在，则销毁它|\n|EnQueue(&Q,x)|若队列Q存在，插入新元素x到队列Q中并成为队尾元素|\n|DeQueue(&Q,&x)|删除队列Q中队头元素，并用x返回其值|\n|GetHead(Q,&x)|返回队列Q中队头元素，不修改队头指针|\n|QueueEmpty(Q)|若队列为空，返回true，否则返回false|\n\n## 3.2.3 顺序队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/2.png)\n![数据结构](/img/datastruct/3_stack/queue/2.png)\n\n- 顺序队列的实现\n```c\n#include<stdio.h>\n#include<stdlib.h>\n#define MAXSIZE 10\ntypedef struct{\n    int data[MAXSIZE];\n    int front,rear;\n} SqQueue;\n\n//初始化\nvoid InitQueue(SqQueue *Q){\n    int i;\n    for(i=0;i<MAXSIZE;i++)\n        Q->data[i]=0;\n}\n\n//判空\nint QueueEmpty(SqQueue Q){\n    if(Q.front==Q.rear)\n        return 1;\n    else\n        return 0;\n}\n\n//入队\nint EnQueue(SqQueue *Q, int x){\n    if((Q->rear+1)%MAXSIZE==Q->front)\n        return 0;\n    Q->data[Q->rear]=x;\n    Q->rear=(Q->rear+1)%MAXSIZE;\n    return 1;\n}\n\n//出队\nint DeQueue(SqQueue *Q, int *x){\n    if(Q->front==Q->rear)\n        return 0;\n    *x=Q->data[Q->front];\n    Q->front=(Q->front+1)%MAXSIZE;\n    return 1;\n}\n\n```\n-  循环队列\n    - 入队：\n    \n            Q.data[Q.rear]=x\n            Q.rear=(Q.rear+1)%MaxSize\n\n    - 出队：\n\n            x=Q.data[Q.front]\n            Q.front=(Q.front+1)%MaxSize \n\n\n    - 元素个数：\n            (rear+MaxSize-front)%MaxSize\n\n||队满|队空|\n|:---:|:---:|:---:|\n|1|(Q.rear+1)%MaxSize==Q.front|Q.rear==Q.front\n|2|size==MaxSize|size=0\n(删除成功时flag=0,插入成功时flag=1)|front==rear && flag==1|front==rear && flag==0\n\n## 3.2.4 链式队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/3.png)\n![数据结构](/img/datastruct/3_stack/queue/3.png)\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct LinkNode\n{\n    int data;\n    struct LinkNode *next;\n}LinkNode;\n\ntypedef struct\n{\n    LinkNode *front,*rear;\n}LinkQueue;\n\n//初始化\nvoid InitQueue(LinkQueue *Q){\n    Q->front=Q->rear=(LinkNode*)malloc(sizeof(LinkNode));\n    Q->front->next=NULL;\n}\n\n//判空\nint QueueEmpty(LinkQueue Q){\n    if(Q.front==Q.rear)\n        return 1;\n    else\n        return 0;\n}\n\n//入队\nint EnQueue(LinkQueue *Q, int x){\n    LinkNode *s=(LinkNode*)malloc(sizeof(LinkNode));\n    s->data=x;\n    s->next=NULL;\n    Q->rear->next=s;\n    Q->rear=s;\n    return 1;\n}\n\n//出队\nint DeQueue(LinkQueue *Q, int *x){\n    if(Q->front==Q->rear)\n        return 0;\n    LinkNode *p=Q->front->next;\n    *x=p->data;\n    Q->front->next=p->next;\n    if(Q->rear==p)\n        Q->rear=Q->front;\n    free(p);\n    return 1;\n}\n```\n\n- 双端队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/4.png)\n![数据结构](/img/datastruct/3_stack/queue/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/5.png)\n![数据结构](/img/datastruct/3_stack/queue/5.png)","source":"_posts/datastruct/3_stack/2_queue.md","raw":"---\ntitle: 3.2 队列\ndate: 2023-08-07 00:00:00\ntags: [数据结构,队列]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/1.png)\n![数据结构](/img/datastruct/3_stack/queue/1.png)\n\n\n## 3.2.1 定义\n- 队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表\n\n## 3.2.2 基本操作\n|操作|描述|\n|:---:|:---:|\n|InitQueue(&Q)|初始化队列Q，构造一个空队列|\n|DestroyQueue(&Q)|若队列Q存在，则销毁它|\n|EnQueue(&Q,x)|若队列Q存在，插入新元素x到队列Q中并成为队尾元素|\n|DeQueue(&Q,&x)|删除队列Q中队头元素，并用x返回其值|\n|GetHead(Q,&x)|返回队列Q中队头元素，不修改队头指针|\n|QueueEmpty(Q)|若队列为空，返回true，否则返回false|\n\n## 3.2.3 顺序队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/2.png)\n![数据结构](/img/datastruct/3_stack/queue/2.png)\n\n- 顺序队列的实现\n```c\n#include<stdio.h>\n#include<stdlib.h>\n#define MAXSIZE 10\ntypedef struct{\n    int data[MAXSIZE];\n    int front,rear;\n} SqQueue;\n\n//初始化\nvoid InitQueue(SqQueue *Q){\n    int i;\n    for(i=0;i<MAXSIZE;i++)\n        Q->data[i]=0;\n}\n\n//判空\nint QueueEmpty(SqQueue Q){\n    if(Q.front==Q.rear)\n        return 1;\n    else\n        return 0;\n}\n\n//入队\nint EnQueue(SqQueue *Q, int x){\n    if((Q->rear+1)%MAXSIZE==Q->front)\n        return 0;\n    Q->data[Q->rear]=x;\n    Q->rear=(Q->rear+1)%MAXSIZE;\n    return 1;\n}\n\n//出队\nint DeQueue(SqQueue *Q, int *x){\n    if(Q->front==Q->rear)\n        return 0;\n    *x=Q->data[Q->front];\n    Q->front=(Q->front+1)%MAXSIZE;\n    return 1;\n}\n\n```\n-  循环队列\n    - 入队：\n    \n            Q.data[Q.rear]=x\n            Q.rear=(Q.rear+1)%MaxSize\n\n    - 出队：\n\n            x=Q.data[Q.front]\n            Q.front=(Q.front+1)%MaxSize \n\n\n    - 元素个数：\n            (rear+MaxSize-front)%MaxSize\n\n||队满|队空|\n|:---:|:---:|:---:|\n|1|(Q.rear+1)%MaxSize==Q.front|Q.rear==Q.front\n|2|size==MaxSize|size=0\n(删除成功时flag=0,插入成功时flag=1)|front==rear && flag==1|front==rear && flag==0\n\n## 3.2.4 链式队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/3.png)\n![数据结构](/img/datastruct/3_stack/queue/3.png)\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct LinkNode\n{\n    int data;\n    struct LinkNode *next;\n}LinkNode;\n\ntypedef struct\n{\n    LinkNode *front,*rear;\n}LinkQueue;\n\n//初始化\nvoid InitQueue(LinkQueue *Q){\n    Q->front=Q->rear=(LinkNode*)malloc(sizeof(LinkNode));\n    Q->front->next=NULL;\n}\n\n//判空\nint QueueEmpty(LinkQueue Q){\n    if(Q.front==Q.rear)\n        return 1;\n    else\n        return 0;\n}\n\n//入队\nint EnQueue(LinkQueue *Q, int x){\n    LinkNode *s=(LinkNode*)malloc(sizeof(LinkNode));\n    s->data=x;\n    s->next=NULL;\n    Q->rear->next=s;\n    Q->rear=s;\n    return 1;\n}\n\n//出队\nint DeQueue(LinkQueue *Q, int *x){\n    if(Q->front==Q->rear)\n        return 0;\n    LinkNode *p=Q->front->next;\n    *x=p->data;\n    Q->front->next=p->next;\n    if(Q->rear==p)\n        Q->rear=Q->front;\n    free(p);\n    return 1;\n}\n```\n\n- 双端队列\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/4.png)\n![数据结构](/img/datastruct/3_stack/queue/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/3_stack/queue/5.png)\n![数据结构](/img/datastruct/3_stack/queue/5.png)","slug":"datastruct/3_stack/2_queue","published":1,"updated":"2023-10-23T12:08:20.396Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858q001d7svw84r93fq2","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/1.png\"><br><img src=\"/img/datastruct/3_stack/queue/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-2-1-定义\"><a href=\"#3-2-1-定义\" class=\"headerlink\" title=\"3.2.1 定义\"></a>3.2.1 定义</h2><ul>\n<li>队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表</li>\n</ul>\n<h2 id=\"3-2-2-基本操作\"><a href=\"#3-2-2-基本操作\" class=\"headerlink\" title=\"3.2.2 基本操作\"></a>3.2.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">操作</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitQueue(&amp;Q)</td>\n<td align=\"center\">初始化队列Q，构造一个空队列</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyQueue(&amp;Q)</td>\n<td align=\"center\">若队列Q存在，则销毁它</td>\n</tr>\n<tr>\n<td align=\"center\">EnQueue(&amp;Q,x)</td>\n<td align=\"center\">若队列Q存在，插入新元素x到队列Q中并成为队尾元素</td>\n</tr>\n<tr>\n<td align=\"center\">DeQueue(&amp;Q,&amp;x)</td>\n<td align=\"center\">删除队列Q中队头元素，并用x返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">GetHead(Q,&amp;x)</td>\n<td align=\"center\">返回队列Q中队头元素，不修改队头指针</td>\n</tr>\n<tr>\n<td align=\"center\">QueueEmpty(Q)</td>\n<td align=\"center\">若队列为空，返回true，否则返回false</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-3-顺序队列\"><a href=\"#3-2-3-顺序队列\" class=\"headerlink\" title=\"3.2.3 顺序队列\"></a>3.2.3 顺序队列</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/2.png\"><br><img src=\"/img/datastruct/3_stack/queue/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>顺序队列的实现<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> front,rear;</span><br><span class=\"line\">&#125; SqQueue;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitQueue</span><span class=\"params\">(SqQueue *Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;MAXSIZE;i++)</span><br><span class=\"line\">        Q-&gt;data[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">QueueEmpty</span><span class=\"params\">(SqQueue Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==Q.rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">EnQueue</span><span class=\"params\">(SqQueue *Q, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>((Q-&gt;rear+<span class=\"number\">1</span>)%MAXSIZE==Q-&gt;front)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    Q-&gt;data[Q-&gt;rear]=x;</span><br><span class=\"line\">    Q-&gt;rear=(Q-&gt;rear+<span class=\"number\">1</span>)%MAXSIZE;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeQueue</span><span class=\"params\">(SqQueue *Q, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;front==Q-&gt;rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=Q-&gt;data[Q-&gt;front];</span><br><span class=\"line\">    Q-&gt;front=(Q-&gt;front+<span class=\"number\">1</span>)%MAXSIZE;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n<li>循环队列<ul>\n<li><p>入队：</p>\n<pre><code>  Q.data[Q.rear]=x\n  Q.rear=(Q.rear+1)%MaxSize\n</code></pre>\n</li>\n<li><p>出队：</p>\n<pre><code>  x=Q.data[Q.front]\n  Q.front=(Q.front+1)%MaxSize \n</code></pre>\n</li>\n<li><p>元素个数：<br>  (rear+MaxSize-front)%MaxSize</p>\n</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">队满</th>\n<th align=\"center\">队空</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">(Q.rear+1)%MaxSize&#x3D;&#x3D;Q.front</td>\n<td align=\"center\">Q.rear&#x3D;&#x3D;Q.front</td>\n</tr>\n<tr>\n<td align=\"center\">2</td>\n<td align=\"center\">size&#x3D;&#x3D;MaxSize</td>\n<td align=\"center\">size&#x3D;0</td>\n</tr>\n<tr>\n<td align=\"center\">(删除成功时flag&#x3D;0,插入成功时flag&#x3D;1)</td>\n<td align=\"center\">front&#x3D;&#x3D;rear &amp;&amp; flag&#x3D;&#x3D;1</td>\n<td align=\"center\">front&#x3D;&#x3D;rear &amp;&amp; flag&#x3D;&#x3D;0</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-4-链式队列\"><a href=\"#3-2-4-链式队列\" class=\"headerlink\" title=\"3.2.4 链式队列\"></a>3.2.4 链式队列</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/3.png\"><br><img src=\"/img/datastruct/3_stack/queue/3.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LinkNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LinkNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;LinkNode;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    LinkNode *front,*rear;</span><br><span class=\"line\">&#125;LinkQueue;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitQueue</span><span class=\"params\">(LinkQueue *Q)</span>&#123;</span><br><span class=\"line\">    Q-&gt;front=Q-&gt;rear=(LinkNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LinkNode));</span><br><span class=\"line\">    Q-&gt;front-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">QueueEmpty</span><span class=\"params\">(LinkQueue Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==Q.rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">EnQueue</span><span class=\"params\">(LinkQueue *Q, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    LinkNode *s=(LinkNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LinkNode));</span><br><span class=\"line\">    s-&gt;data=x;</span><br><span class=\"line\">    s-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Q-&gt;rear-&gt;next=s;</span><br><span class=\"line\">    Q-&gt;rear=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeQueue</span><span class=\"params\">(LinkQueue *Q, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;front==Q-&gt;rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LinkNode *p=Q-&gt;front-&gt;next;</span><br><span class=\"line\">    *x=p-&gt;data;</span><br><span class=\"line\">    Q-&gt;front-&gt;next=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;rear==p)</span><br><span class=\"line\">        Q-&gt;rear=Q-&gt;front;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>双端队列<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/4.png\"><br><img src=\"/img/datastruct/3_stack/queue/4.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/5.png\"><br><img src=\"/img/datastruct/3_stack/queue/5.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/1.png\"><br><img src=\"/img/datastruct/3_stack/queue/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"3-2-1-定义\"><a href=\"#3-2-1-定义\" class=\"headerlink\" title=\"3.2.1 定义\"></a>3.2.1 定义</h2><ul>\n<li>队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表</li>\n</ul>\n<h2 id=\"3-2-2-基本操作\"><a href=\"#3-2-2-基本操作\" class=\"headerlink\" title=\"3.2.2 基本操作\"></a>3.2.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">操作</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitQueue(&amp;Q)</td>\n<td align=\"center\">初始化队列Q，构造一个空队列</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyQueue(&amp;Q)</td>\n<td align=\"center\">若队列Q存在，则销毁它</td>\n</tr>\n<tr>\n<td align=\"center\">EnQueue(&amp;Q,x)</td>\n<td align=\"center\">若队列Q存在，插入新元素x到队列Q中并成为队尾元素</td>\n</tr>\n<tr>\n<td align=\"center\">DeQueue(&amp;Q,&amp;x)</td>\n<td align=\"center\">删除队列Q中队头元素，并用x返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">GetHead(Q,&amp;x)</td>\n<td align=\"center\">返回队列Q中队头元素，不修改队头指针</td>\n</tr>\n<tr>\n<td align=\"center\">QueueEmpty(Q)</td>\n<td align=\"center\">若队列为空，返回true，否则返回false</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-3-顺序队列\"><a href=\"#3-2-3-顺序队列\" class=\"headerlink\" title=\"3.2.3 顺序队列\"></a>3.2.3 顺序队列</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/2.png\"><br><img src=\"/img/datastruct/3_stack/queue/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>顺序队列的实现<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> front,rear;</span><br><span class=\"line\">&#125; SqQueue;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitQueue</span><span class=\"params\">(SqQueue *Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;MAXSIZE;i++)</span><br><span class=\"line\">        Q-&gt;data[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">QueueEmpty</span><span class=\"params\">(SqQueue Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==Q.rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">EnQueue</span><span class=\"params\">(SqQueue *Q, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>((Q-&gt;rear+<span class=\"number\">1</span>)%MAXSIZE==Q-&gt;front)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    Q-&gt;data[Q-&gt;rear]=x;</span><br><span class=\"line\">    Q-&gt;rear=(Q-&gt;rear+<span class=\"number\">1</span>)%MAXSIZE;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeQueue</span><span class=\"params\">(SqQueue *Q, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;front==Q-&gt;rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=Q-&gt;data[Q-&gt;front];</span><br><span class=\"line\">    Q-&gt;front=(Q-&gt;front+<span class=\"number\">1</span>)%MAXSIZE;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n<li>循环队列<ul>\n<li><p>入队：</p>\n<pre><code>  Q.data[Q.rear]=x\n  Q.rear=(Q.rear+1)%MaxSize\n</code></pre>\n</li>\n<li><p>出队：</p>\n<pre><code>  x=Q.data[Q.front]\n  Q.front=(Q.front+1)%MaxSize \n</code></pre>\n</li>\n<li><p>元素个数：<br>  (rear+MaxSize-front)%MaxSize</p>\n</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">队满</th>\n<th align=\"center\">队空</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">(Q.rear+1)%MaxSize&#x3D;&#x3D;Q.front</td>\n<td align=\"center\">Q.rear&#x3D;&#x3D;Q.front</td>\n</tr>\n<tr>\n<td align=\"center\">2</td>\n<td align=\"center\">size&#x3D;&#x3D;MaxSize</td>\n<td align=\"center\">size&#x3D;0</td>\n</tr>\n<tr>\n<td align=\"center\">(删除成功时flag&#x3D;0,插入成功时flag&#x3D;1)</td>\n<td align=\"center\">front&#x3D;&#x3D;rear &amp;&amp; flag&#x3D;&#x3D;1</td>\n<td align=\"center\">front&#x3D;&#x3D;rear &amp;&amp; flag&#x3D;&#x3D;0</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-4-链式队列\"><a href=\"#3-2-4-链式队列\" class=\"headerlink\" title=\"3.2.4 链式队列\"></a>3.2.4 链式队列</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/3.png\"><br><img src=\"/img/datastruct/3_stack/queue/3.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LinkNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LinkNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;LinkNode;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    LinkNode *front,*rear;</span><br><span class=\"line\">&#125;LinkQueue;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitQueue</span><span class=\"params\">(LinkQueue *Q)</span>&#123;</span><br><span class=\"line\">    Q-&gt;front=Q-&gt;rear=(LinkNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LinkNode));</span><br><span class=\"line\">    Q-&gt;front-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">QueueEmpty</span><span class=\"params\">(LinkQueue Q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==Q.rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">EnQueue</span><span class=\"params\">(LinkQueue *Q, <span class=\"type\">int</span> x)</span>&#123;</span><br><span class=\"line\">    LinkNode *s=(LinkNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LinkNode));</span><br><span class=\"line\">    s-&gt;data=x;</span><br><span class=\"line\">    s-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Q-&gt;rear-&gt;next=s;</span><br><span class=\"line\">    Q-&gt;rear=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出队</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeQueue</span><span class=\"params\">(LinkQueue *Q, <span class=\"type\">int</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;front==Q-&gt;rear)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LinkNode *p=Q-&gt;front-&gt;next;</span><br><span class=\"line\">    *x=p-&gt;data;</span><br><span class=\"line\">    Q-&gt;front-&gt;next=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q-&gt;rear==p)</span><br><span class=\"line\">        Q-&gt;rear=Q-&gt;front;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>双端队列<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/4.png\"><br><img src=\"/img/datastruct/3_stack/queue/4.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/queue/5.png\"><br><img src=\"/img/datastruct/3_stack/queue/5.png\" alt=\"数据结构\"></p>"},{"title":"3.3 栈与队列的应用","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n## 3.3.1 括号匹配问题\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/1.png)\n![数据结构](/img/datastruct/3_stack/exam/1.png)\n\n```c\n#include<stdio.h>\n#define MAXSIZE 10\ntypedef struct{\n    char data[MAXSIZE];\n    int top;\n} SqStack;\n\n//初始化\nvoid InitStack(SqStack *S){\n    S->top=-1;\n}\n\n//判空\nint StackEmpty(SqStack S){\n    if(S.top==-1)\n        return 1;\n    else\n        return 0;\n}\n\n//入栈\nint Push(SqStack *S, char x){\n    if(S->top==MAXSIZE-1)\n        return 0;\n    S->top++;\n    S->data[S->top]=x;\n    return 1;\n}\n\n//出栈\nint Pop(SqStack *S, char *x){\n    if(S->top==-1)\n        return 0;\n    *x=S->data[S->top];\n    S->top--;\n    return 1;\n}\n\n//取栈顶元素\nint GetTop(SqStack S, char *x){\n    if(S.top==-1)\n        return 0;\n    *x=S.data[S.top];\n    return 1;\n}\n\nint main(){\n    //1. 括号匹配\n    char str1[100] = \"((())){[]}\"; //合法\n    char str2[100] = \"((()){[]})\"; //合法\n    char str3[100] = \"((()){[]}\"; //不合法\n    printf(\"%d\",match(str1));\n    printf(\"%d\",match(str2));\n    printf(\"%d\",match(str3));\n}\n\nint match(char str[]){\n    SqStack stack;\n    InitStack(&stack);\n    int i=0;\n    char x;\n    for(;str[i]!='\\0';i++){\n        switch (str[i])\n        {\n        case '(':\n        case '[':\n        case '{':\n            Push(&stack, str[i]);\n            break;\n        case ')':\n            if(!Pop(&stack, &x) || x!='(')\n                return 0;\n            break;\n        case ']':\n            if(!Pop(&stack, &x) || x!='[')\n                return 0;\n            break;\n        case '}':\n            if(!Pop(&stack, &x) || x!='{')\n                return 0;\n            break;\n        default:\n            break;\n        }\n    }\n    if(!StackEmpty(stack))\n        return 0;\n    return 1;\n}\n```\n\n## 3.3.2 表达式求值\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/2.png)\n![数据结构](/img/datastruct/3_stack/exam/2.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/6.png)\n![数据结构](/img/datastruct/3_stack/exam/6.png)\n- 中缀->后缀\n    - 手算\n\n            1）确定各个运算符的运算顺序\n            2）选择下一个运算符(左右符)\n            3）还有符号则返回2）\n\n    - 代码\n        ![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/4.png)\n        ![数据结构](/img/datastruct/3_stack/exam/4.png)\n\n- 中缀表达式的计算\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/5.png)\n![数据结构](/img/datastruct/3_stack/exam/5.png)\n\n\n- 用栈实现后缀表达式的计算\n\n        1）从左往右扫描下一个元素，直到处理完所有元素\n        2）若扫描到操作数则入栈，返回1）\n        3）若扫描到运算符，弹出两个栈顶，执行运算后入栈(先出栈的是右操作数)\n\n- 中缀->前缀\n\n        1）确定各个运算符的运算顺序\n        2）选择下一个运算符(符左右)\n        3）还有符号则返回2）\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/3.png)\n![数据结构](/img/datastruct/3_stack/exam/3.png)","source":"_posts/datastruct/3_stack/3_exam.md","raw":"---\ntitle: 3.3 栈与队列的应用\ndate: 2023-08-07 00:00:00\ntags: [数据结构,栈,队列]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n## 3.3.1 括号匹配问题\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/1.png)\n![数据结构](/img/datastruct/3_stack/exam/1.png)\n\n```c\n#include<stdio.h>\n#define MAXSIZE 10\ntypedef struct{\n    char data[MAXSIZE];\n    int top;\n} SqStack;\n\n//初始化\nvoid InitStack(SqStack *S){\n    S->top=-1;\n}\n\n//判空\nint StackEmpty(SqStack S){\n    if(S.top==-1)\n        return 1;\n    else\n        return 0;\n}\n\n//入栈\nint Push(SqStack *S, char x){\n    if(S->top==MAXSIZE-1)\n        return 0;\n    S->top++;\n    S->data[S->top]=x;\n    return 1;\n}\n\n//出栈\nint Pop(SqStack *S, char *x){\n    if(S->top==-1)\n        return 0;\n    *x=S->data[S->top];\n    S->top--;\n    return 1;\n}\n\n//取栈顶元素\nint GetTop(SqStack S, char *x){\n    if(S.top==-1)\n        return 0;\n    *x=S.data[S.top];\n    return 1;\n}\n\nint main(){\n    //1. 括号匹配\n    char str1[100] = \"((())){[]}\"; //合法\n    char str2[100] = \"((()){[]})\"; //合法\n    char str3[100] = \"((()){[]}\"; //不合法\n    printf(\"%d\",match(str1));\n    printf(\"%d\",match(str2));\n    printf(\"%d\",match(str3));\n}\n\nint match(char str[]){\n    SqStack stack;\n    InitStack(&stack);\n    int i=0;\n    char x;\n    for(;str[i]!='\\0';i++){\n        switch (str[i])\n        {\n        case '(':\n        case '[':\n        case '{':\n            Push(&stack, str[i]);\n            break;\n        case ')':\n            if(!Pop(&stack, &x) || x!='(')\n                return 0;\n            break;\n        case ']':\n            if(!Pop(&stack, &x) || x!='[')\n                return 0;\n            break;\n        case '}':\n            if(!Pop(&stack, &x) || x!='{')\n                return 0;\n            break;\n        default:\n            break;\n        }\n    }\n    if(!StackEmpty(stack))\n        return 0;\n    return 1;\n}\n```\n\n## 3.3.2 表达式求值\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/2.png)\n![数据结构](/img/datastruct/3_stack/exam/2.png)\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/6.png)\n![数据结构](/img/datastruct/3_stack/exam/6.png)\n- 中缀->后缀\n    - 手算\n\n            1）确定各个运算符的运算顺序\n            2）选择下一个运算符(左右符)\n            3）还有符号则返回2）\n\n    - 代码\n        ![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/4.png)\n        ![数据结构](/img/datastruct/3_stack/exam/4.png)\n\n- 中缀表达式的计算\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/5.png)\n![数据结构](/img/datastruct/3_stack/exam/5.png)\n\n\n- 用栈实现后缀表达式的计算\n\n        1）从左往右扫描下一个元素，直到处理完所有元素\n        2）若扫描到操作数则入栈，返回1）\n        3）若扫描到运算符，弹出两个栈顶，执行运算后入栈(先出栈的是右操作数)\n\n- 中缀->前缀\n\n        1）确定各个运算符的运算顺序\n        2）选择下一个运算符(符左右)\n        3）还有符号则返回2）\n![](../../../../themes/yilia/source/img/datastruct/3_stack/exam/3.png)\n![数据结构](/img/datastruct/3_stack/exam/3.png)","slug":"datastruct/3_stack/3_exam","published":1,"updated":"2023-10-23T12:08:38.400Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858r001g7svw4ucc11df","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h2 id=\"3-3-1-括号匹配问题\"><a href=\"#3-3-1-括号匹配问题\" class=\"headerlink\" title=\"3.3.1 括号匹配问题\"></a>3.3.1 括号匹配问题</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/1.png\"><br><img src=\"/img/datastruct/3_stack/exam/1.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> top;</span><br><span class=\"line\">&#125; SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitStack</span><span class=\"params\">(SqStack *S)</span>&#123;</span><br><span class=\"line\">    S-&gt;top=<span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StackEmpty</span><span class=\"params\">(SqStack S)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Push</span><span class=\"params\">(SqStack *S, <span class=\"type\">char</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==MAXSIZE<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    S-&gt;top++;</span><br><span class=\"line\">    S-&gt;data[S-&gt;top]=x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Pop</span><span class=\"params\">(SqStack *S, <span class=\"type\">char</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S-&gt;data[S-&gt;top];</span><br><span class=\"line\">    S-&gt;top--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//取栈顶元素</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetTop</span><span class=\"params\">(SqStack S, <span class=\"type\">char</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S.data[S.top];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 括号匹配</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str1[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((()))&#123;[]&#125;&quot;</span>; <span class=\"comment\">//合法</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str2[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((())&#123;[]&#125;)&quot;</span>; <span class=\"comment\">//合法</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str3[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((())&#123;[]&#125;&quot;</span>; <span class=\"comment\">//不合法</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str1));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str2));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str3));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">match</span><span class=\"params\">(<span class=\"type\">char</span> str[])</span>&#123;</span><br><span class=\"line\">    SqStack <span class=\"built_in\">stack</span>;</span><br><span class=\"line\">    InitStack(&amp;<span class=\"built_in\">stack</span>);</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">char</span> x;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;str[i]!=<span class=\"string\">&#x27;\\0&#x27;</span>;i++)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (str[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;(&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;[&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;&#123;&#x27;</span>:</span><br><span class=\"line\">            Push(&amp;<span class=\"built_in\">stack</span>, str[i]);</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;)&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;(&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;]&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;[&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;&#125;&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;&#123;&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">default</span>:</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!StackEmpty(<span class=\"built_in\">stack</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-3-2-表达式求值\"><a href=\"#3-3-2-表达式求值\" class=\"headerlink\" title=\"3.3.2 表达式求值\"></a>3.3.2 表达式求值</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/2.png\"><br><img src=\"/img/datastruct/3_stack/exam/2.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/6.png\"><br><img src=\"/img/datastruct/3_stack/exam/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>中缀-&gt;后缀</p>\n<ul>\n<li><p>手算</p>\n<pre><code>  1）确定各个运算符的运算顺序\n  2）选择下一个运算符(左右符)\n  3）还有符号则返回2）\n</code></pre>\n</li>\n<li><p>代码<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/4.png\"><br>  <img src=\"/img/datastruct/3_stack/exam/4.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n</li>\n<li><p>中缀表达式的计算<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/5.png\"><br><img src=\"/img/datastruct/3_stack/exam/5.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>用栈实现后缀表达式的计算</p>\n<pre><code>  1）从左往右扫描下一个元素，直到处理完所有元素\n  2）若扫描到操作数则入栈，返回1）\n  3）若扫描到运算符，弹出两个栈顶，执行运算后入栈(先出栈的是右操作数)\n</code></pre>\n</li>\n<li><p>中缀-&gt;前缀</p>\n<pre><code>  1）确定各个运算符的运算顺序\n  2）选择下一个运算符(符左右)\n  3）还有符号则返回2）\n</code></pre>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/3.png\"><br><img src=\"/img/datastruct/3_stack/exam/3.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h2 id=\"3-3-1-括号匹配问题\"><a href=\"#3-3-1-括号匹配问题\" class=\"headerlink\" title=\"3.3.1 括号匹配问题\"></a>3.3.1 括号匹配问题</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/1.png\"><br><img src=\"/img/datastruct/3_stack/exam/1.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXSIZE 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> data[MAXSIZE];</span><br><span class=\"line\">    <span class=\"type\">int</span> top;</span><br><span class=\"line\">&#125; SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitStack</span><span class=\"params\">(SqStack *S)</span>&#123;</span><br><span class=\"line\">    S-&gt;top=<span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判空</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StackEmpty</span><span class=\"params\">(SqStack S)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Push</span><span class=\"params\">(SqStack *S, <span class=\"type\">char</span> x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==MAXSIZE<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    S-&gt;top++;</span><br><span class=\"line\">    S-&gt;data[S-&gt;top]=x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//出栈</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Pop</span><span class=\"params\">(SqStack *S, <span class=\"type\">char</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S-&gt;top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S-&gt;data[S-&gt;top];</span><br><span class=\"line\">    S-&gt;top--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//取栈顶元素</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetTop</span><span class=\"params\">(SqStack S, <span class=\"type\">char</span> *x)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(S.top==<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *x=S.data[S.top];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 括号匹配</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str1[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((()))&#123;[]&#125;&quot;</span>; <span class=\"comment\">//合法</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str2[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((())&#123;[]&#125;)&quot;</span>; <span class=\"comment\">//合法</span></span><br><span class=\"line\">    <span class=\"type\">char</span> str3[<span class=\"number\">100</span>] = <span class=\"string\">&quot;((())&#123;[]&#125;&quot;</span>; <span class=\"comment\">//不合法</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str1));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str2));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d&quot;</span>,match(str3));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">match</span><span class=\"params\">(<span class=\"type\">char</span> str[])</span>&#123;</span><br><span class=\"line\">    SqStack <span class=\"built_in\">stack</span>;</span><br><span class=\"line\">    InitStack(&amp;<span class=\"built_in\">stack</span>);</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">char</span> x;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;str[i]!=<span class=\"string\">&#x27;\\0&#x27;</span>;i++)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (str[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;(&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;[&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;&#123;&#x27;</span>:</span><br><span class=\"line\">            Push(&amp;<span class=\"built_in\">stack</span>, str[i]);</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;)&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;(&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;]&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;[&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> <span class=\"string\">&#x27;&#125;&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!Pop(&amp;<span class=\"built_in\">stack</span>, &amp;x) || x!=<span class=\"string\">&#x27;&#123;&#x27;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">default</span>:</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!StackEmpty(<span class=\"built_in\">stack</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-3-2-表达式求值\"><a href=\"#3-3-2-表达式求值\" class=\"headerlink\" title=\"3.3.2 表达式求值\"></a>3.3.2 表达式求值</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/2.png\"><br><img src=\"/img/datastruct/3_stack/exam/2.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/6.png\"><br><img src=\"/img/datastruct/3_stack/exam/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>中缀-&gt;后缀</p>\n<ul>\n<li><p>手算</p>\n<pre><code>  1）确定各个运算符的运算顺序\n  2）选择下一个运算符(左右符)\n  3）还有符号则返回2）\n</code></pre>\n</li>\n<li><p>代码<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/4.png\"><br>  <img src=\"/img/datastruct/3_stack/exam/4.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n</li>\n<li><p>中缀表达式的计算<br><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/5.png\"><br><img src=\"/img/datastruct/3_stack/exam/5.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>用栈实现后缀表达式的计算</p>\n<pre><code>  1）从左往右扫描下一个元素，直到处理完所有元素\n  2）若扫描到操作数则入栈，返回1）\n  3）若扫描到运算符，弹出两个栈顶，执行运算后入栈(先出栈的是右操作数)\n</code></pre>\n</li>\n<li><p>中缀-&gt;前缀</p>\n<pre><code>  1）确定各个运算符的运算顺序\n  2）选择下一个运算符(符左右)\n  3）还有符号则返回2）\n</code></pre>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/3_stack/exam/3.png\"><br><img src=\"/img/datastruct/3_stack/exam/3.png\" alt=\"数据结构\"></p>"},{"title":"2.1 线性表的定义","date":"2023-01-31T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n\n## 2.1 定义\n- L=(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,...,a<sub>n</sub>)\n- 有限个相同数据类型的数据元素的有序序列\n- 一些概念\n   \n   ·位序：数据元素在线性表中的位置\n   \n   ·表头：第一个元素a<sub>1</sub>\n\n   ·表尾：最后一个元素a<sub>n</sub>\n\n- 一些性质\n\n   ·除第一个元素外，每个元素有且仅有一个直接前驱\n   ·除最后一个元素外，每个元素有且仅有一个直接后继\n## 2.2 基本操作\n\n|函数|功能|说明|\n|:---:|:---:|:---:|\n|InitList(&L)|初始化|构造一个空的线性表L，分配内存空间|\n|DestroyList(&L)|销毁|销毁线性表，并释放内存空间|\n|ClearList(&L)|清空|清空线性表，保留内存空间|\n|Empty(L)|判空|判断线性表是否为空|\n|Length(L)|求长|返回线性表的长度|\n|GetElem(L,i,&e)|取值|返回线性表中第i个元素的值|\n|LocateElem(L,e,compare())|查找|返回线性表中第一个与e满足compare()的元素的位序|\n|PriorElem(L,cur_e,&pre_e)|前驱|返回线性表中元素cur_e的前驱元素的值|\n|NextElem(L,cur_e,&next_e)|后继|返回线性表中元素cur_e的后继元素的值|\n|ListInsert(&L,i,e)|插入|在线性表的第i个位置插入元素e|\n|ListDelete(&L,i,&e)|删除|删除线性表中第i个位置的元素，并返回其值|\n|ListTraverse(L,visit())|遍历|依次对线性表中每个元素调用visit()函数|\n\n## 2.3 顺序表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/2.png)\n![数据结构](/img/datastruct/2_linearlist/2.png)\n### 2.3.1 顺序存储实现线性表\n- 静态分配\n```c\n/*\n实现顺序表\n静态分配\n*/\n#include<stdio.h>\n#define MaxSize 10\ntypedef struct\n{\n    int data[MaxSize];\n    int length;\n}SqList;\n\n//初始化\nvoid InitList(SqList* L){\n    L->length=0;//逻辑归零\n}\n\nint main(){\n    SqList L;\n    InitList(&L);\n    //违规访问\n    for(int i=0;i<MaxSize;i++){\n        printf(\"ta[%d]=%d\\n\",i,L.data[i]);\n    }\n    return 0;\n}\n```\n- 动态分配\n```c\n/*\n顺序表\n动态分配\n*/\n#include<stdio.h>\n#include<stdlib.h>\n#define InitSize 10 //默认最大长度\ntypedef struct\n{\n    int *data ;//指针，用于动态分配\n    int MaxSize; \n    int length;\n}SeqList;\n//初始化\nvoid InitList(SeqList *L){\n    //申请空间\n    L->data=(int*)malloc(InitSize*sizeof(int));\n    L->length=0;\n    L->MaxSize=InitSize;\n}\n\n//动态增长\nvoid IncreaseSize(SeqList *L, int len){\n    int* p=L->data;\n    L->data=(int *)malloc((L->MaxSize+len)*sizeof(int));\n    //将数据复制到新的区域\n    int i=0;\n    for(i=0;i<L->length;i++){\n        L->data[i]=p[i];\n    }\n    L->MaxSize=L->MaxSize+len;\n    free(p);\n}\n\nint main(){\n    SeqList L;\n    //初始化\n    InitList(&L);\n    printf(\"最大长度：%d\\n\",L.MaxSize);\n    //增长\n    IncreaseSize(&L,5);\n    printf(\"+5\\n\");\n    printf(\"最大长度：%d\",L.MaxSize);\n    return 0;\n}\n```\n- 基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/3.png)\n![数据结构](/img/datastruct/2_linearlist/3.png)\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/4.png)\n![数据结构](/img/datastruct/2_linearlist/4.png)\n```c\n/*\n顺序表\n静态分配\n*/\n#include<stdio.h>\n#define MaxSize 10\ntypedef struct\n{\n    int data[MaxSize];\n    int length;\n}SqList;\n//初始化\nvoid InitList(SqList* L){\n    L->length=0;//逻辑上置零\n}\nvoid PrintList(SqList L){\n    //判空\n    if(L.data==NULL || L.length==0)\n        return;\n    int i=0;\n    for(i=0;i<L.length;i++)\n        printf(\"%d \",L.data[i]);\n}\n\nint main(){\n    SqList L;\n    InitList(&L);\n    ListInsert(&L,1,1);\n    ListInsert(&L,2,2);\n    ListInsert(&L,3,4);\n    ListInsert(&L,4,5);\n    printf(\"前：\");\n    PrintList(L);\n    ListInsert(&L,3,3);\n    printf(\"\\n位序：3，插入：3\");\n    printf(\"\\n后：\");\n    PrintList(L);\n\n    //删除\n    int x=0;\n    ListDelete(&L,1,&x);\n    printf(\"\\n删除第%d个元素：%d\",1,x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    ListDelete(&L,2,&x);\n    printf(\"\\n删除第%d个元素：%d\",2,x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    printf(\"\\n删除第%d个元素：%d\",L.length,x);\n    ListDelete(&L,L.length,&x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    //按位查找\n    printf(\"\\n第1个：%d\",GetElement(L,0));\n    printf(\"\\n第2个：%d\",GetElement(L,1));\n\n    //按值查找\n    printf(\"\\n2的位序：%d\",LocateElement(L,2));\n    printf(\"\\n4的位序：：%d\",LocateElement(L,4));\n    printf(\"\\n5的位序：：%d\",LocateElement(L,5));\n    return 0;\n}\n\n//位序插入\nint ListInsert(SqList *L,int i, int e){\n    //满否\n    if (L->length>=MaxSize || i<1 || i>L->length+1) return 0;\n    int j=0;\n    for(j=L->length;j>=i;j--)//后移\n        L->data[j]=L->data[j-1];\n    L->data[j]=e;//插入\n    return ++(L->length);\n}\n\n//删除\nint ListDelete(SqList *L,int i, int *e){\n    if(i<1|| i>L->length) return 0;\n    *e=L->data[i-1];\n    int j=i;\n    for(;j<L->length;j++) L->data[j-1]=L->data[j];\n    L->length--;\n    return 1;\n}\n\n//按位查找\nint GetElement(SqList L,int i){\n    if(i<1 || i>L.length) return 0;\n    return L.data[i-1];\n}\n\n//按值查找\nint LocateElement(SqList L,int e){\n    int i=0;\n    for(;i<L.length;i++)\n        if(L.data[i]==e)\n            return i+1;\n    return -1;\n}\n```\n\n\n||按位插入/删除||\n|:---:|:---:|:---:|\n|最好|尾插|O(1)|\n|最坏|头插|O(n)|\n|平均|$$p=\\frac{1}{n+1}$$ $$1p+2p+...+np$$|O(n)|\n\n||按位查找|按值查找|\n|:---:|:---:|:---:|\n|最好|O(1)|O(1)|\n|最坏|O(1)|O(n)|\n|平均|O(1)|O(n)|","source":"_posts/datastruct/2_linearlist/1_linearlist.md","raw":"---\ntitle: 2.1 线性表的定义\ndate: 2023-02-01 00:00:00\ntags: [数据结构,线性表]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n\n## 2.1 定义\n- L=(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,...,a<sub>n</sub>)\n- 有限个相同数据类型的数据元素的有序序列\n- 一些概念\n   \n   ·位序：数据元素在线性表中的位置\n   \n   ·表头：第一个元素a<sub>1</sub>\n\n   ·表尾：最后一个元素a<sub>n</sub>\n\n- 一些性质\n\n   ·除第一个元素外，每个元素有且仅有一个直接前驱\n   ·除最后一个元素外，每个元素有且仅有一个直接后继\n## 2.2 基本操作\n\n|函数|功能|说明|\n|:---:|:---:|:---:|\n|InitList(&L)|初始化|构造一个空的线性表L，分配内存空间|\n|DestroyList(&L)|销毁|销毁线性表，并释放内存空间|\n|ClearList(&L)|清空|清空线性表，保留内存空间|\n|Empty(L)|判空|判断线性表是否为空|\n|Length(L)|求长|返回线性表的长度|\n|GetElem(L,i,&e)|取值|返回线性表中第i个元素的值|\n|LocateElem(L,e,compare())|查找|返回线性表中第一个与e满足compare()的元素的位序|\n|PriorElem(L,cur_e,&pre_e)|前驱|返回线性表中元素cur_e的前驱元素的值|\n|NextElem(L,cur_e,&next_e)|后继|返回线性表中元素cur_e的后继元素的值|\n|ListInsert(&L,i,e)|插入|在线性表的第i个位置插入元素e|\n|ListDelete(&L,i,&e)|删除|删除线性表中第i个位置的元素，并返回其值|\n|ListTraverse(L,visit())|遍历|依次对线性表中每个元素调用visit()函数|\n\n## 2.3 顺序表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/2.png)\n![数据结构](/img/datastruct/2_linearlist/2.png)\n### 2.3.1 顺序存储实现线性表\n- 静态分配\n```c\n/*\n实现顺序表\n静态分配\n*/\n#include<stdio.h>\n#define MaxSize 10\ntypedef struct\n{\n    int data[MaxSize];\n    int length;\n}SqList;\n\n//初始化\nvoid InitList(SqList* L){\n    L->length=0;//逻辑归零\n}\n\nint main(){\n    SqList L;\n    InitList(&L);\n    //违规访问\n    for(int i=0;i<MaxSize;i++){\n        printf(\"ta[%d]=%d\\n\",i,L.data[i]);\n    }\n    return 0;\n}\n```\n- 动态分配\n```c\n/*\n顺序表\n动态分配\n*/\n#include<stdio.h>\n#include<stdlib.h>\n#define InitSize 10 //默认最大长度\ntypedef struct\n{\n    int *data ;//指针，用于动态分配\n    int MaxSize; \n    int length;\n}SeqList;\n//初始化\nvoid InitList(SeqList *L){\n    //申请空间\n    L->data=(int*)malloc(InitSize*sizeof(int));\n    L->length=0;\n    L->MaxSize=InitSize;\n}\n\n//动态增长\nvoid IncreaseSize(SeqList *L, int len){\n    int* p=L->data;\n    L->data=(int *)malloc((L->MaxSize+len)*sizeof(int));\n    //将数据复制到新的区域\n    int i=0;\n    for(i=0;i<L->length;i++){\n        L->data[i]=p[i];\n    }\n    L->MaxSize=L->MaxSize+len;\n    free(p);\n}\n\nint main(){\n    SeqList L;\n    //初始化\n    InitList(&L);\n    printf(\"最大长度：%d\\n\",L.MaxSize);\n    //增长\n    IncreaseSize(&L,5);\n    printf(\"+5\\n\");\n    printf(\"最大长度：%d\",L.MaxSize);\n    return 0;\n}\n```\n- 基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/3.png)\n![数据结构](/img/datastruct/2_linearlist/3.png)\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/4.png)\n![数据结构](/img/datastruct/2_linearlist/4.png)\n```c\n/*\n顺序表\n静态分配\n*/\n#include<stdio.h>\n#define MaxSize 10\ntypedef struct\n{\n    int data[MaxSize];\n    int length;\n}SqList;\n//初始化\nvoid InitList(SqList* L){\n    L->length=0;//逻辑上置零\n}\nvoid PrintList(SqList L){\n    //判空\n    if(L.data==NULL || L.length==0)\n        return;\n    int i=0;\n    for(i=0;i<L.length;i++)\n        printf(\"%d \",L.data[i]);\n}\n\nint main(){\n    SqList L;\n    InitList(&L);\n    ListInsert(&L,1,1);\n    ListInsert(&L,2,2);\n    ListInsert(&L,3,4);\n    ListInsert(&L,4,5);\n    printf(\"前：\");\n    PrintList(L);\n    ListInsert(&L,3,3);\n    printf(\"\\n位序：3，插入：3\");\n    printf(\"\\n后：\");\n    PrintList(L);\n\n    //删除\n    int x=0;\n    ListDelete(&L,1,&x);\n    printf(\"\\n删除第%d个元素：%d\",1,x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    ListDelete(&L,2,&x);\n    printf(\"\\n删除第%d个元素：%d\",2,x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    printf(\"\\n删除第%d个元素：%d\",L.length,x);\n    ListDelete(&L,L.length,&x);\n    printf(\"\\n删除后：\");\n    PrintList(L);\n\n    //按位查找\n    printf(\"\\n第1个：%d\",GetElement(L,0));\n    printf(\"\\n第2个：%d\",GetElement(L,1));\n\n    //按值查找\n    printf(\"\\n2的位序：%d\",LocateElement(L,2));\n    printf(\"\\n4的位序：：%d\",LocateElement(L,4));\n    printf(\"\\n5的位序：：%d\",LocateElement(L,5));\n    return 0;\n}\n\n//位序插入\nint ListInsert(SqList *L,int i, int e){\n    //满否\n    if (L->length>=MaxSize || i<1 || i>L->length+1) return 0;\n    int j=0;\n    for(j=L->length;j>=i;j--)//后移\n        L->data[j]=L->data[j-1];\n    L->data[j]=e;//插入\n    return ++(L->length);\n}\n\n//删除\nint ListDelete(SqList *L,int i, int *e){\n    if(i<1|| i>L->length) return 0;\n    *e=L->data[i-1];\n    int j=i;\n    for(;j<L->length;j++) L->data[j-1]=L->data[j];\n    L->length--;\n    return 1;\n}\n\n//按位查找\nint GetElement(SqList L,int i){\n    if(i<1 || i>L.length) return 0;\n    return L.data[i-1];\n}\n\n//按值查找\nint LocateElement(SqList L,int e){\n    int i=0;\n    for(;i<L.length;i++)\n        if(L.data[i]==e)\n            return i+1;\n    return -1;\n}\n```\n\n\n||按位插入/删除||\n|:---:|:---:|:---:|\n|最好|尾插|O(1)|\n|最坏|头插|O(n)|\n|平均|$$p=\\frac{1}{n+1}$$ $$1p+2p+...+np$$|O(n)|\n\n||按位查找|按值查找|\n|:---:|:---:|:---:|\n|最好|O(1)|O(1)|\n|最坏|O(1)|O(n)|\n|平均|O(1)|O(n)|","slug":"datastruct/2_linearlist/1_linearlist","published":1,"updated":"2023-10-23T12:02:34.209Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858s001i7svw6ut0ckf1","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"2-1-定义\"><a href=\"#2-1-定义\" class=\"headerlink\" title=\"2.1 定义\"></a>2.1 定义</h2><ul>\n<li><p>L&#x3D;(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,…,a<sub>n</sub>)</p>\n</li>\n<li><p>有限个相同数据类型的数据元素的有序序列</p>\n</li>\n<li><p>一些概念</p>\n<p> ·位序：数据元素在线性表中的位置</p>\n<p> ·表头：第一个元素a<sub>1</sub></p>\n<p> ·表尾：最后一个元素a<sub>n</sub></p>\n</li>\n<li><p>一些性质</p>\n<p> ·除第一个元素外，每个元素有且仅有一个直接前驱<br> ·除最后一个元素外，每个元素有且仅有一个直接后继</p>\n</li>\n</ul>\n<h2 id=\"2-2-基本操作\"><a href=\"#2-2-基本操作\" class=\"headerlink\" title=\"2.2 基本操作\"></a>2.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">函数</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitList(&amp;L)</td>\n<td align=\"center\">初始化</td>\n<td align=\"center\">构造一个空的线性表L，分配内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyList(&amp;L)</td>\n<td align=\"center\">销毁</td>\n<td align=\"center\">销毁线性表，并释放内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">ClearList(&amp;L)</td>\n<td align=\"center\">清空</td>\n<td align=\"center\">清空线性表，保留内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">Empty(L)</td>\n<td align=\"center\">判空</td>\n<td align=\"center\">判断线性表是否为空</td>\n</tr>\n<tr>\n<td align=\"center\">Length(L)</td>\n<td align=\"center\">求长</td>\n<td align=\"center\">返回线性表的长度</td>\n</tr>\n<tr>\n<td align=\"center\">GetElem(L,i,&amp;e)</td>\n<td align=\"center\">取值</td>\n<td align=\"center\">返回线性表中第i个元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">LocateElem(L,e,compare())</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">返回线性表中第一个与e满足compare()的元素的位序</td>\n</tr>\n<tr>\n<td align=\"center\">PriorElem(L,cur_e,&amp;pre_e)</td>\n<td align=\"center\">前驱</td>\n<td align=\"center\">返回线性表中元素cur_e的前驱元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">NextElem(L,cur_e,&amp;next_e)</td>\n<td align=\"center\">后继</td>\n<td align=\"center\">返回线性表中元素cur_e的后继元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">ListInsert(&amp;L,i,e)</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">在线性表的第i个位置插入元素e</td>\n</tr>\n<tr>\n<td align=\"center\">ListDelete(&amp;L,i,&amp;e)</td>\n<td align=\"center\">删除</td>\n<td align=\"center\">删除线性表中第i个位置的元素，并返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">ListTraverse(L,visit())</td>\n<td align=\"center\">遍历</td>\n<td align=\"center\">依次对线性表中每个元素调用visit()函数</td>\n</tr>\n</tbody></table>\n<h2 id=\"2-3-顺序表\"><a href=\"#2-3-顺序表\" class=\"headerlink\" title=\"2.3 顺序表\"></a>2.3 顺序表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-3-1-顺序存储实现线性表\"><a href=\"#2-3-1-顺序存储实现线性表\" class=\"headerlink\" title=\"2.3.1 顺序存储实现线性表\"></a>2.3.1 顺序存储实现线性表</h3><ul>\n<li>静态分配<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">实现顺序表</span></span><br><span class=\"line\"><span class=\"comment\">静态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SqList;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SqList* L)</span>&#123;</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;<span class=\"comment\">//逻辑归零</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SqList L;</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    <span class=\"comment\">//违规访问</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;MaxSize;i++)&#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;ta[%d]=%d\\n&quot;</span>,i,L.data[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li>动态分配<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">顺序表</span></span><br><span class=\"line\"><span class=\"comment\">动态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> InitSize 10 <span class=\"comment\">//默认最大长度</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> *data ;<span class=\"comment\">//指针，用于动态分配</span></span><br><span class=\"line\">    <span class=\"type\">int</span> MaxSize; </span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SeqList;</span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SeqList *L)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//申请空间</span></span><br><span class=\"line\">    L-&gt;data=(<span class=\"type\">int</span>*)<span class=\"built_in\">malloc</span>(InitSize*<span class=\"keyword\">sizeof</span>(<span class=\"type\">int</span>));</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;</span><br><span class=\"line\">    L-&gt;MaxSize=InitSize;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//动态增长</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">IncreaseSize</span><span class=\"params\">(SeqList *L, <span class=\"type\">int</span> len)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span>* p=L-&gt;data;</span><br><span class=\"line\">    L-&gt;data=(<span class=\"type\">int</span> *)<span class=\"built_in\">malloc</span>((L-&gt;MaxSize+len)*<span class=\"keyword\">sizeof</span>(<span class=\"type\">int</span>));</span><br><span class=\"line\">    <span class=\"comment\">//将数据复制到新的区域</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;L-&gt;length;i++)&#123;</span><br><span class=\"line\">        L-&gt;data[i]=p[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    L-&gt;MaxSize=L-&gt;MaxSize+len;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SeqList L;</span><br><span class=\"line\">    <span class=\"comment\">//初始化</span></span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;最大长度：%d\\n&quot;</span>,L.MaxSize);</span><br><span class=\"line\">    <span class=\"comment\">//增长</span></span><br><span class=\"line\">    IncreaseSize(&amp;L,<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;+5\\n&quot;</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;最大长度：%d&quot;</span>,L.MaxSize);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li>基本操作<br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/3.png\"><br><img src=\"/img/datastruct/2_linearlist/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/4.png\"><br><img src=\"/img/datastruct/2_linearlist/4.png\" alt=\"数据结构\"><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">顺序表</span></span><br><span class=\"line\"><span class=\"comment\">静态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SqList;</span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SqList* L)</span>&#123;</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;<span class=\"comment\">//逻辑上置零</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PrintList</span><span class=\"params\">(SqList L)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//判空</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(L.data==<span class=\"literal\">NULL</span> || L.length==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;L.length;i++)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,L.data[i]);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SqList L;</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">1</span>,<span class=\"number\">1</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">2</span>,<span class=\"number\">2</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">3</span>,<span class=\"number\">4</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">4</span>,<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;前：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">3</span>,<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n位序：3，插入：3&quot;</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//删除</span></span><br><span class=\"line\">    <span class=\"type\">int</span> x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    ListDelete(&amp;L,<span class=\"number\">1</span>,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,<span class=\"number\">1</span>,x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    ListDelete(&amp;L,<span class=\"number\">2</span>,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,<span class=\"number\">2</span>,x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,L.length,x);</span><br><span class=\"line\">    ListDelete(&amp;L,L.length,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第1个：%d&quot;</span>,GetElement(L,<span class=\"number\">0</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第2个：%d&quot;</span>,GetElement(L,<span class=\"number\">1</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按值查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n2的位序：%d&quot;</span>,LocateElement(L,<span class=\"number\">2</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n4的位序：：%d&quot;</span>,LocateElement(L,<span class=\"number\">4</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n5的位序：：%d&quot;</span>,LocateElement(L,<span class=\"number\">5</span>));</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//位序插入</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert</span><span class=\"params\">(SqList *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//满否</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (L-&gt;length&gt;=MaxSize || i&lt;<span class=\"number\">1</span> || i&gt;L-&gt;length+<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(j=L-&gt;length;j&gt;=i;j--)<span class=\"comment\">//后移</span></span><br><span class=\"line\">        L-&gt;data[j]=L-&gt;data[j<span class=\"number\">-1</span>];</span><br><span class=\"line\">    L-&gt;data[j]=e;<span class=\"comment\">//插入</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> ++(L-&gt;length);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListDelete</span><span class=\"params\">(SqList *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>|| i&gt;L-&gt;length) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *e=L-&gt;data[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">    <span class=\"type\">int</span> j=i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;j&lt;L-&gt;length;j++) L-&gt;data[j<span class=\"number\">-1</span>]=L-&gt;data[j];</span><br><span class=\"line\">    L-&gt;length--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位查找</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetElement</span><span class=\"params\">(SqList L,<span class=\"type\">int</span> i)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span> || i&gt;L.length) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L.data[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按值查找</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">LocateElement</span><span class=\"params\">(SqList L,<span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;i&lt;L.length;i++)</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(L.data[i]==e)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i+<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">按位插入&#x2F;删除</th>\n<th align=\"center\"></th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">最好</td>\n<td align=\"center\">尾插</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">最坏</td>\n<td align=\"center\">头插</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">平均</td>\n<td align=\"center\">$$p&#x3D;\\frac{1}{n+1}$$ $$1p+2p+…+np$$</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">按位查找</th>\n<th align=\"center\">按值查找</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">最好</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">最坏</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">平均</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"2-1-定义\"><a href=\"#2-1-定义\" class=\"headerlink\" title=\"2.1 定义\"></a>2.1 定义</h2><ul>\n<li><p>L&#x3D;(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,…,a<sub>n</sub>)</p>\n</li>\n<li><p>有限个相同数据类型的数据元素的有序序列</p>\n</li>\n<li><p>一些概念</p>\n<p> ·位序：数据元素在线性表中的位置</p>\n<p> ·表头：第一个元素a<sub>1</sub></p>\n<p> ·表尾：最后一个元素a<sub>n</sub></p>\n</li>\n<li><p>一些性质</p>\n<p> ·除第一个元素外，每个元素有且仅有一个直接前驱<br> ·除最后一个元素外，每个元素有且仅有一个直接后继</p>\n</li>\n</ul>\n<h2 id=\"2-2-基本操作\"><a href=\"#2-2-基本操作\" class=\"headerlink\" title=\"2.2 基本操作\"></a>2.2 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"center\">函数</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">InitList(&amp;L)</td>\n<td align=\"center\">初始化</td>\n<td align=\"center\">构造一个空的线性表L，分配内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">DestroyList(&amp;L)</td>\n<td align=\"center\">销毁</td>\n<td align=\"center\">销毁线性表，并释放内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">ClearList(&amp;L)</td>\n<td align=\"center\">清空</td>\n<td align=\"center\">清空线性表，保留内存空间</td>\n</tr>\n<tr>\n<td align=\"center\">Empty(L)</td>\n<td align=\"center\">判空</td>\n<td align=\"center\">判断线性表是否为空</td>\n</tr>\n<tr>\n<td align=\"center\">Length(L)</td>\n<td align=\"center\">求长</td>\n<td align=\"center\">返回线性表的长度</td>\n</tr>\n<tr>\n<td align=\"center\">GetElem(L,i,&amp;e)</td>\n<td align=\"center\">取值</td>\n<td align=\"center\">返回线性表中第i个元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">LocateElem(L,e,compare())</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">返回线性表中第一个与e满足compare()的元素的位序</td>\n</tr>\n<tr>\n<td align=\"center\">PriorElem(L,cur_e,&amp;pre_e)</td>\n<td align=\"center\">前驱</td>\n<td align=\"center\">返回线性表中元素cur_e的前驱元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">NextElem(L,cur_e,&amp;next_e)</td>\n<td align=\"center\">后继</td>\n<td align=\"center\">返回线性表中元素cur_e的后继元素的值</td>\n</tr>\n<tr>\n<td align=\"center\">ListInsert(&amp;L,i,e)</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">在线性表的第i个位置插入元素e</td>\n</tr>\n<tr>\n<td align=\"center\">ListDelete(&amp;L,i,&amp;e)</td>\n<td align=\"center\">删除</td>\n<td align=\"center\">删除线性表中第i个位置的元素，并返回其值</td>\n</tr>\n<tr>\n<td align=\"center\">ListTraverse(L,visit())</td>\n<td align=\"center\">遍历</td>\n<td align=\"center\">依次对线性表中每个元素调用visit()函数</td>\n</tr>\n</tbody></table>\n<h2 id=\"2-3-顺序表\"><a href=\"#2-3-顺序表\" class=\"headerlink\" title=\"2.3 顺序表\"></a>2.3 顺序表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-3-1-顺序存储实现线性表\"><a href=\"#2-3-1-顺序存储实现线性表\" class=\"headerlink\" title=\"2.3.1 顺序存储实现线性表\"></a>2.3.1 顺序存储实现线性表</h3><ul>\n<li>静态分配<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">实现顺序表</span></span><br><span class=\"line\"><span class=\"comment\">静态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SqList;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SqList* L)</span>&#123;</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;<span class=\"comment\">//逻辑归零</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SqList L;</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    <span class=\"comment\">//违规访问</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;MaxSize;i++)&#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;ta[%d]=%d\\n&quot;</span>,i,L.data[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li>动态分配<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">顺序表</span></span><br><span class=\"line\"><span class=\"comment\">动态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> InitSize 10 <span class=\"comment\">//默认最大长度</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> *data ;<span class=\"comment\">//指针，用于动态分配</span></span><br><span class=\"line\">    <span class=\"type\">int</span> MaxSize; </span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SeqList;</span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SeqList *L)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//申请空间</span></span><br><span class=\"line\">    L-&gt;data=(<span class=\"type\">int</span>*)<span class=\"built_in\">malloc</span>(InitSize*<span class=\"keyword\">sizeof</span>(<span class=\"type\">int</span>));</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;</span><br><span class=\"line\">    L-&gt;MaxSize=InitSize;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//动态增长</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">IncreaseSize</span><span class=\"params\">(SeqList *L, <span class=\"type\">int</span> len)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span>* p=L-&gt;data;</span><br><span class=\"line\">    L-&gt;data=(<span class=\"type\">int</span> *)<span class=\"built_in\">malloc</span>((L-&gt;MaxSize+len)*<span class=\"keyword\">sizeof</span>(<span class=\"type\">int</span>));</span><br><span class=\"line\">    <span class=\"comment\">//将数据复制到新的区域</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;L-&gt;length;i++)&#123;</span><br><span class=\"line\">        L-&gt;data[i]=p[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    L-&gt;MaxSize=L-&gt;MaxSize+len;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SeqList L;</span><br><span class=\"line\">    <span class=\"comment\">//初始化</span></span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;最大长度：%d\\n&quot;</span>,L.MaxSize);</span><br><span class=\"line\">    <span class=\"comment\">//增长</span></span><br><span class=\"line\">    IncreaseSize(&amp;L,<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;+5\\n&quot;</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;最大长度：%d&quot;</span>,L.MaxSize);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li>基本操作<br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/3.png\"><br><img src=\"/img/datastruct/2_linearlist/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/4.png\"><br><img src=\"/img/datastruct/2_linearlist/4.png\" alt=\"数据结构\"><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">顺序表</span></span><br><span class=\"line\"><span class=\"comment\">静态分配</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 10</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125;SqList;</span><br><span class=\"line\"><span class=\"comment\">//初始化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InitList</span><span class=\"params\">(SqList* L)</span>&#123;</span><br><span class=\"line\">    L-&gt;length=<span class=\"number\">0</span>;<span class=\"comment\">//逻辑上置零</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PrintList</span><span class=\"params\">(SqList L)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//判空</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(L.data==<span class=\"literal\">NULL</span> || L.length==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;L.length;i++)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,L.data[i]);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    SqList L;</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">1</span>,<span class=\"number\">1</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">2</span>,<span class=\"number\">2</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">3</span>,<span class=\"number\">4</span>);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">4</span>,<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;前：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\">    ListInsert(&amp;L,<span class=\"number\">3</span>,<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n位序：3，插入：3&quot;</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//删除</span></span><br><span class=\"line\">    <span class=\"type\">int</span> x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    ListDelete(&amp;L,<span class=\"number\">1</span>,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,<span class=\"number\">1</span>,x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    ListDelete(&amp;L,<span class=\"number\">2</span>,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,<span class=\"number\">2</span>,x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第%d个元素：%d&quot;</span>,L.length,x);</span><br><span class=\"line\">    ListDelete(&amp;L,L.length,&amp;x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除后：&quot;</span>);</span><br><span class=\"line\">    PrintList(L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第1个：%d&quot;</span>,GetElement(L,<span class=\"number\">0</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第2个：%d&quot;</span>,GetElement(L,<span class=\"number\">1</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按值查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n2的位序：%d&quot;</span>,LocateElement(L,<span class=\"number\">2</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n4的位序：：%d&quot;</span>,LocateElement(L,<span class=\"number\">4</span>));</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n5的位序：：%d&quot;</span>,LocateElement(L,<span class=\"number\">5</span>));</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//位序插入</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert</span><span class=\"params\">(SqList *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//满否</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (L-&gt;length&gt;=MaxSize || i&lt;<span class=\"number\">1</span> || i&gt;L-&gt;length+<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(j=L-&gt;length;j&gt;=i;j--)<span class=\"comment\">//后移</span></span><br><span class=\"line\">        L-&gt;data[j]=L-&gt;data[j<span class=\"number\">-1</span>];</span><br><span class=\"line\">    L-&gt;data[j]=e;<span class=\"comment\">//插入</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> ++(L-&gt;length);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListDelete</span><span class=\"params\">(SqList *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>|| i&gt;L-&gt;length) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    *e=L-&gt;data[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">    <span class=\"type\">int</span> j=i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;j&lt;L-&gt;length;j++) L-&gt;data[j<span class=\"number\">-1</span>]=L-&gt;data[j];</span><br><span class=\"line\">    L-&gt;length--;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位查找</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">GetElement</span><span class=\"params\">(SqList L,<span class=\"type\">int</span> i)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span> || i&gt;L.length) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L.data[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按值查找</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">LocateElement</span><span class=\"params\">(SqList L,<span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;i&lt;L.length;i++)</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(L.data[i]==e)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i+<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">按位插入&#x2F;删除</th>\n<th align=\"center\"></th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">最好</td>\n<td align=\"center\">尾插</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">最坏</td>\n<td align=\"center\">头插</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">平均</td>\n<td align=\"center\">$$p&#x3D;\\frac{1}{n+1}$$ $$1p+2p+…+np$$</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">按位查找</th>\n<th align=\"center\">按值查找</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">最好</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">最坏</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">平均</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>"},{"title":"2.2 单链表","date":"2023-08-04T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/1.png)\n### 2.4.1 定义\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/2.png)\n\n||顺序表|单链表|\n|:---:|:---:|:---:|\n|结构|![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png)![数据结构](/img/datastruct/2_linearlist/linklist/3.png)|![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png)![数据结构](/img/datastruct/2_linearlist/linklist/4.png)|\n|优点|随机存取，存储密度高|不要求大片连续空间，方便改容量|\n|缺点|要求大片连续空间，改容量不便|不可随机存取，额外指针空间|\n\n\n|带头结点|不带头结点|\n|:---:|:---:|\n||写代码更麻烦|\n||对第一个结点和后续结点的处理逻辑不同|\n||对空表和非空表的处理需要用不同的逻辑|\n\n### 2.4.2基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/5.png)\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/6.png)\n\n- 查找\n    - 按位查找\n    - 按值查找\n- 插入\n    - 位序插入\n    - 指定结点后插\n- 删除\n    - 按位删除\n    - 删除指定节点\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct LNode{\n    int data;\n    struct LNode *next;\n} LNode, *Linklist;\n//输出链表\nvoid printlist(LNode L){\n    LNode* p=&L;\n    for(;p!=NULL;p=p->next)\n        printf(\"%d \",p->data);\n}\n\n//头插法-带头结点\nLinklist HeadInsert(Linklist L){\n    LNode *s;\n    int i=0,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->next=NULL;\n    for(;input[i]!=-1;i++){\n        InsertNextNode(L,input[i]);\n    }\n    return L;\n}\n\n//尾插法-带头结点\nLinklist TailInsert(Linklist L){\n    LNode *s,*r;\n    int i=0,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->next=NULL;\n    r=L;\n    for(;input[i]!=-1;i++){\n        s=(LNode*)malloc(sizeof(LNode));\n        s->data=input[i];\n        r->next=s;\n        r=s;\n    }\n    r->next=NULL;\n    return L;\n}\n\n//尾插法-不带头结点\nLinklist HeadInsertNoHead(Linklist L){\n    LNode *s;\n    int i=1,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->data=input[0];\n    L->next=NULL;\n    for(;input[i]!=-1;i++){\n        s=(LNode*)malloc(sizeof(LNode));\n        s->next=L->next;\n        L->next=s;\n        s->data=input[i];\n    }\n    return L;\n}\n\n\n\n//按位查找\nLNode* GetElement(Linklist L,int i){\n    if(i<0) return NULL;\n    int j=0;\n    LNode* p=L;\n    for(;p!=NULL && j<i;j++)\n        p=p->next;\n    return p;\n}\n\n//按值查找\nLNode* LocateElem(Linklist L,int e){\n    LNode* p=L->next;\n    for(;p!=NULL && p->data!=e;p=p->next);\n    return p;\n}\n\n//求\nint Length(Linklist L){\n    int i=0;\n    LNode* p=L;\n    for(;p!=NULL;p=p->next)\n        i++;\n    return i;\n}\n\nvoid test_head(){\n    printf(\"带头结点测试：\");\n    Linklist L=NULL;\n    L=HeadInsert(L);\n    printlist(*(L->next));\n\n    //按位查找\n    printf(\"\\n第3个位置的元素为：%d\\n\",GetElement(L,3)->data);\n\n    //按位插入\n    printf(\"\\n在第1个位置插入11\\n\");\n    ListInsert_head(L,1,11);\n    printf(\"插入后：\");\n    printlist(*(L->next));    \n\n    //后插\n    printf(\"\\n在第2个位置后插22\\n\");\n    LNode *p=GetElement(L,2);\n    InsertNextNode(p,22);\n    printf(\"插入后：\");\n    printlist(*(L->next));\n\n    //前插\n    printf(\"\\n在第3个位置前插33\\n\");\n    p=GetElement(L,3);\n    InsertPriorNode(p,33);\n    printf(\"插入后：\");\n    printlist(*(L->next));\n\n    //按位删除\n    printf(\"\\n删除第1个位置\\n\");\n    int e;\n    ListDelete(L,1,&e);\n    printf(\"删除后：\");\n    printlist(*(L->next));\n\n    //逆置\n    printf(\"\\n逆置\\n\");\n    Reverse(&L);\n    printf(\"逆置后：\");\n    printlist(*(L->next));\n    \n}\nvoid test_nohead(){\n    Linklist L=NULL;\n    L=HeadInsertNoHead(L);\n    printf(\"\\n\\n\\n不带头结点测试：\");\n    printlist(*L);\n\n    //按位插入\n    printf(\"\\n在第1个位置插入11\\n\");\n    ListInsert_nohead(&L,1,11);\n    printf(\"插入后：\");\n    printlist(*L);\n\n    printf(\"\\n在第2个位置插入22\\n\");\n    ListInsert_nohead(&L,2,22);\n    printf(\"插入后：\");\n    printlist(*L);\n\n    \n}\nint main(){\n    test_head();\n    test_nohead();\n    return 0;\n}\n\n\n\n\n\n//按位插入_头\nint ListInsert_head(Linklist L, int i, int e){\n    if(i<1) return 0;\n    LNode *p=GetElement(L,i-1);\n    return InsertNextNode(p,e);\n}\n\n//按位插入_不头\nint ListInsert_nohead(Linklist *L,int i, int e){\n    if(i<1) return 0;\n    if(i==1){\n        LNode *s=(LNode*)malloc(sizeof(LNode));\n        s->data=e;\n        s->next=*L;\n        *L=s;\n        return 1;\n    }\n    LNode *p=*L;\n    int j=1;\n    for(;p!=NULL && j<i-1;j++) p=p->next;\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    s->data=e;\n    s->next=p->next;//顺序不能换        \n    p->next=s;\n    return 1;\n}\n\n//后插\nint InsertNextNode(LNode *p, int e){\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    s->data=e;\n    s->next=p->next;\n    p->next=s;\n    return 1;\n}\n\n//前插\nint InsertPriorNode(LNode *p, int e){//只需交换数据域\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    if(s==NULL) return 0;\n    s->next=p->next;\n    p->next=s;\n    s->data=p->data;\n    p->data=e;\n    return 1;\n}\n\n//按位删除\nint ListDelete(Linklist L, int i, int *e){\n    if(i<1) return 0;\n    LNode *p=L;\n    int j=0;\n    for(;p!=NULL && j<i-1;j++) p=p->next;\n    if(p==NULL) return 0;\n    LNode *q=p->next;\n    if(q==NULL) return 0;\n    p->next=q->next;\n    *e=q->data;\n    free(q);\n    return 1;\n}\n\n//逆置\nvoid Reverse(Linklist *L){\n    LNode *p=(*L)->next;\n    (*L)->next=NULL;\n    LNode *q;\n    while(p!=NULL){\n        q=p->next;\n        p->next=(*L)->next;\n        (*L)->next=p;\n        p=q;\n    }\n}\n```","source":"_posts/datastruct/2_linearlist/2_linklist.md","raw":"---\ntitle: 2.2 单链表\ndate: 2023-08-05 00:00:00\ntags: [数据结构,线性表,单链表]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/1.png)\n### 2.4.1 定义\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/2.png)\n\n||顺序表|单链表|\n|:---:|:---:|:---:|\n|结构|![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png)![数据结构](/img/datastruct/2_linearlist/linklist/3.png)|![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png)![数据结构](/img/datastruct/2_linearlist/linklist/4.png)|\n|优点|随机存取，存储密度高|不要求大片连续空间，方便改容量|\n|缺点|要求大片连续空间，改容量不便|不可随机存取，额外指针空间|\n\n\n|带头结点|不带头结点|\n|:---:|:---:|\n||写代码更麻烦|\n||对第一个结点和后续结点的处理逻辑不同|\n||对空表和非空表的处理需要用不同的逻辑|\n\n### 2.4.2基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/5.png)\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png)\n![数据结构](/img/datastruct/2_linearlist/linklist/6.png)\n\n- 查找\n    - 按位查找\n    - 按值查找\n- 插入\n    - 位序插入\n    - 指定结点后插\n- 删除\n    - 按位删除\n    - 删除指定节点\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct LNode{\n    int data;\n    struct LNode *next;\n} LNode, *Linklist;\n//输出链表\nvoid printlist(LNode L){\n    LNode* p=&L;\n    for(;p!=NULL;p=p->next)\n        printf(\"%d \",p->data);\n}\n\n//头插法-带头结点\nLinklist HeadInsert(Linklist L){\n    LNode *s;\n    int i=0,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->next=NULL;\n    for(;input[i]!=-1;i++){\n        InsertNextNode(L,input[i]);\n    }\n    return L;\n}\n\n//尾插法-带头结点\nLinklist TailInsert(Linklist L){\n    LNode *s,*r;\n    int i=0,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->next=NULL;\n    r=L;\n    for(;input[i]!=-1;i++){\n        s=(LNode*)malloc(sizeof(LNode));\n        s->data=input[i];\n        r->next=s;\n        r=s;\n    }\n    r->next=NULL;\n    return L;\n}\n\n//尾插法-不带头结点\nLinklist HeadInsertNoHead(Linklist L){\n    LNode *s;\n    int i=1,x=0;\n    int input[6]={5,4,3,2,1,-1};\n    L=(Linklist)malloc(sizeof(LNode));\n    L->data=input[0];\n    L->next=NULL;\n    for(;input[i]!=-1;i++){\n        s=(LNode*)malloc(sizeof(LNode));\n        s->next=L->next;\n        L->next=s;\n        s->data=input[i];\n    }\n    return L;\n}\n\n\n\n//按位查找\nLNode* GetElement(Linklist L,int i){\n    if(i<0) return NULL;\n    int j=0;\n    LNode* p=L;\n    for(;p!=NULL && j<i;j++)\n        p=p->next;\n    return p;\n}\n\n//按值查找\nLNode* LocateElem(Linklist L,int e){\n    LNode* p=L->next;\n    for(;p!=NULL && p->data!=e;p=p->next);\n    return p;\n}\n\n//求\nint Length(Linklist L){\n    int i=0;\n    LNode* p=L;\n    for(;p!=NULL;p=p->next)\n        i++;\n    return i;\n}\n\nvoid test_head(){\n    printf(\"带头结点测试：\");\n    Linklist L=NULL;\n    L=HeadInsert(L);\n    printlist(*(L->next));\n\n    //按位查找\n    printf(\"\\n第3个位置的元素为：%d\\n\",GetElement(L,3)->data);\n\n    //按位插入\n    printf(\"\\n在第1个位置插入11\\n\");\n    ListInsert_head(L,1,11);\n    printf(\"插入后：\");\n    printlist(*(L->next));    \n\n    //后插\n    printf(\"\\n在第2个位置后插22\\n\");\n    LNode *p=GetElement(L,2);\n    InsertNextNode(p,22);\n    printf(\"插入后：\");\n    printlist(*(L->next));\n\n    //前插\n    printf(\"\\n在第3个位置前插33\\n\");\n    p=GetElement(L,3);\n    InsertPriorNode(p,33);\n    printf(\"插入后：\");\n    printlist(*(L->next));\n\n    //按位删除\n    printf(\"\\n删除第1个位置\\n\");\n    int e;\n    ListDelete(L,1,&e);\n    printf(\"删除后：\");\n    printlist(*(L->next));\n\n    //逆置\n    printf(\"\\n逆置\\n\");\n    Reverse(&L);\n    printf(\"逆置后：\");\n    printlist(*(L->next));\n    \n}\nvoid test_nohead(){\n    Linklist L=NULL;\n    L=HeadInsertNoHead(L);\n    printf(\"\\n\\n\\n不带头结点测试：\");\n    printlist(*L);\n\n    //按位插入\n    printf(\"\\n在第1个位置插入11\\n\");\n    ListInsert_nohead(&L,1,11);\n    printf(\"插入后：\");\n    printlist(*L);\n\n    printf(\"\\n在第2个位置插入22\\n\");\n    ListInsert_nohead(&L,2,22);\n    printf(\"插入后：\");\n    printlist(*L);\n\n    \n}\nint main(){\n    test_head();\n    test_nohead();\n    return 0;\n}\n\n\n\n\n\n//按位插入_头\nint ListInsert_head(Linklist L, int i, int e){\n    if(i<1) return 0;\n    LNode *p=GetElement(L,i-1);\n    return InsertNextNode(p,e);\n}\n\n//按位插入_不头\nint ListInsert_nohead(Linklist *L,int i, int e){\n    if(i<1) return 0;\n    if(i==1){\n        LNode *s=(LNode*)malloc(sizeof(LNode));\n        s->data=e;\n        s->next=*L;\n        *L=s;\n        return 1;\n    }\n    LNode *p=*L;\n    int j=1;\n    for(;p!=NULL && j<i-1;j++) p=p->next;\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    s->data=e;\n    s->next=p->next;//顺序不能换        \n    p->next=s;\n    return 1;\n}\n\n//后插\nint InsertNextNode(LNode *p, int e){\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    s->data=e;\n    s->next=p->next;\n    p->next=s;\n    return 1;\n}\n\n//前插\nint InsertPriorNode(LNode *p, int e){//只需交换数据域\n    if(p==NULL) return 0;\n    LNode *s=(LNode*)malloc(sizeof(LNode));\n    if(s==NULL) return 0;\n    s->next=p->next;\n    p->next=s;\n    s->data=p->data;\n    p->data=e;\n    return 1;\n}\n\n//按位删除\nint ListDelete(Linklist L, int i, int *e){\n    if(i<1) return 0;\n    LNode *p=L;\n    int j=0;\n    for(;p!=NULL && j<i-1;j++) p=p->next;\n    if(p==NULL) return 0;\n    LNode *q=p->next;\n    if(q==NULL) return 0;\n    p->next=q->next;\n    *e=q->data;\n    free(q);\n    return 1;\n}\n\n//逆置\nvoid Reverse(Linklist *L){\n    LNode *p=(*L)->next;\n    (*L)->next=NULL;\n    LNode *q;\n    while(p!=NULL){\n        q=p->next;\n        p->next=(*L)->next;\n        (*L)->next=p;\n        p=q;\n    }\n}\n```","slug":"datastruct/2_linearlist/2_linklist","published":1,"updated":"2023-10-23T12:02:48.746Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858t001m7svw1i05c27h","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-4-1-定义\"><a href=\"#2-4-1-定义\" class=\"headerlink\" title=\"2.4.1 定义\"></a>2.4.1 定义</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/2.png\" alt=\"数据结构\"></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">顺序表</th>\n<th align=\"center\">单链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">结构</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png\"><img src=\"/img/datastruct/2_linearlist/linklist/3.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png\"><img src=\"/img/datastruct/2_linearlist/linklist/4.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"center\">优点</td>\n<td align=\"center\">随机存取，存储密度高</td>\n<td align=\"center\">不要求大片连续空间，方便改容量</td>\n</tr>\n<tr>\n<td align=\"center\">缺点</td>\n<td align=\"center\">要求大片连续空间，改容量不便</td>\n<td align=\"center\">不可随机存取，额外指针空间</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"center\">带头结点</th>\n<th align=\"center\">不带头结点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"></td>\n<td align=\"center\">写代码更麻烦</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">对第一个结点和后续结点的处理逻辑不同</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">对空表和非空表的处理需要用不同的逻辑</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-4-2基本操作\"><a href=\"#2-4-2基本操作\" class=\"headerlink\" title=\"2.4.2基本操作\"></a>2.4.2基本操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>查找<ul>\n<li>按位查找</li>\n<li>按值查找</li>\n</ul>\n</li>\n<li>插入<ul>\n<li>位序插入</li>\n<li>指定结点后插</li>\n</ul>\n</li>\n<li>删除<ul>\n<li>按位删除</li>\n<li>删除指定节点</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; LNode, *Linklist;</span><br><span class=\"line\"><span class=\"comment\">//输出链表</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">printlist</span><span class=\"params\">(LNode L)</span>&#123;</span><br><span class=\"line\">    LNode* p=&amp;L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,p-&gt;data);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//头插法-带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">HeadInsert</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        InsertNextNode(L,input[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//尾插法-带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">TailInsert</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s,*r;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    r=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data=input[i];</span><br><span class=\"line\">        r-&gt;next=s;</span><br><span class=\"line\">        r=s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    r-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//尾插法-不带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">HeadInsertNoHead</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;data=input[<span class=\"number\">0</span>];</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;next=L-&gt;next;</span><br><span class=\"line\">        L-&gt;next=s;</span><br><span class=\"line\">        s-&gt;data=input[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位查找</span></span><br><span class=\"line\">LNode* <span class=\"title function_\">GetElement</span><span class=\"params\">(Linklist L,<span class=\"type\">int</span> i)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i;j++)</span><br><span class=\"line\">        p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按值查找</span></span><br><span class=\"line\">LNode* <span class=\"title function_\">LocateElem</span><span class=\"params\">(Linklist L,<span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    LNode* p=L-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; p-&gt;data!=e;p=p-&gt;next);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Length</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">test_head</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;带头结点测试：&quot;</span>);</span><br><span class=\"line\">    Linklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    L=HeadInsert(L);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第3个位置的元素为：%d\\n&quot;</span>,GetElement(L,<span class=\"number\">3</span>)-&gt;data);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位插入</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第1个位置插入11\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_head(L,<span class=\"number\">1</span>,<span class=\"number\">11</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//后插</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第2个位置后插22\\n&quot;</span>);</span><br><span class=\"line\">    LNode *p=GetElement(L,<span class=\"number\">2</span>);</span><br><span class=\"line\">    InsertNextNode(p,<span class=\"number\">22</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//前插</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第3个位置前插33\\n&quot;</span>);</span><br><span class=\"line\">    p=GetElement(L,<span class=\"number\">3</span>);</span><br><span class=\"line\">    InsertPriorNode(p,<span class=\"number\">33</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位删除</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第1个位置\\n&quot;</span>);</span><br><span class=\"line\">    <span class=\"type\">int</span> e;</span><br><span class=\"line\">    ListDelete(L,<span class=\"number\">1</span>,&amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;删除后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//逆置</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n逆置\\n&quot;</span>);</span><br><span class=\"line\">    Reverse(&amp;L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;逆置后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">test_nohead</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    Linklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    L=HeadInsertNoHead(L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n\\n\\n不带头结点测试：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位插入</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第1个位置插入11\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_nohead(&amp;L,<span class=\"number\">1</span>,<span class=\"number\">11</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第2个位置插入22\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_nohead(&amp;L,<span class=\"number\">2</span>,<span class=\"number\">22</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    test_head();</span><br><span class=\"line\">    test_nohead();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位插入_头</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert_head</span><span class=\"params\">(Linklist L, <span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *p=GetElement(L,i<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> InsertNextNode(p,e);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位插入_不头</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert_nohead</span><span class=\"params\">(Linklist *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i==<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data=e;</span><br><span class=\"line\">        s-&gt;next=*L;</span><br><span class=\"line\">        *L=s;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    LNode *p=*L;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i<span class=\"number\">-1</span>;j++) p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    s-&gt;data=e;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;<span class=\"comment\">//顺序不能换        </span></span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//后插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertNextNode</span><span class=\"params\">(LNode *p, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    s-&gt;data=e;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//前插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertPriorNode</span><span class=\"params\">(LNode *p, <span class=\"type\">int</span> e)</span>&#123;<span class=\"comment\">//只需交换数据域</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    s-&gt;data=p-&gt;data;</span><br><span class=\"line\">    p-&gt;data=e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListDelete</span><span class=\"params\">(Linklist L, <span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *p=L;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i<span class=\"number\">-1</span>;j++) p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *q=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    p-&gt;next=q-&gt;next;</span><br><span class=\"line\">    *e=q-&gt;data;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(q);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//逆置</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">Reverse</span><span class=\"params\">(Linklist *L)</span>&#123;</span><br><span class=\"line\">    LNode *p=(*L)-&gt;next;</span><br><span class=\"line\">    (*L)-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    LNode *q;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p!=<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">        q=p-&gt;next;</span><br><span class=\"line\">        p-&gt;next=(*L)-&gt;next;</span><br><span class=\"line\">        (*L)-&gt;next=p;</span><br><span class=\"line\">        p=q;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-4-1-定义\"><a href=\"#2-4-1-定义\" class=\"headerlink\" title=\"2.4.1 定义\"></a>2.4.1 定义</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/2.png\" alt=\"数据结构\"></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">顺序表</th>\n<th align=\"center\">单链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">结构</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/3.png\"><img src=\"/img/datastruct/2_linearlist/linklist/3.png\" alt=\"数据结构\"></td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/4.png\"><img src=\"/img/datastruct/2_linearlist/linklist/4.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"center\">优点</td>\n<td align=\"center\">随机存取，存储密度高</td>\n<td align=\"center\">不要求大片连续空间，方便改容量</td>\n</tr>\n<tr>\n<td align=\"center\">缺点</td>\n<td align=\"center\">要求大片连续空间，改容量不便</td>\n<td align=\"center\">不可随机存取，额外指针空间</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"center\">带头结点</th>\n<th align=\"center\">不带头结点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"></td>\n<td align=\"center\">写代码更麻烦</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">对第一个结点和后续结点的处理逻辑不同</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">对空表和非空表的处理需要用不同的逻辑</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-4-2基本操作\"><a href=\"#2-4-2基本操作\" class=\"headerlink\" title=\"2.4.2基本操作\"></a>2.4.2基本操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/5.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/linklist/6.png\"><br><img src=\"/img/datastruct/2_linearlist/linklist/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>查找<ul>\n<li>按位查找</li>\n<li>按值查找</li>\n</ul>\n</li>\n<li>插入<ul>\n<li>位序插入</li>\n<li>指定结点后插</li>\n</ul>\n</li>\n<li>删除<ul>\n<li>按位删除</li>\n<li>删除指定节点</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; LNode, *Linklist;</span><br><span class=\"line\"><span class=\"comment\">//输出链表</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">printlist</span><span class=\"params\">(LNode L)</span>&#123;</span><br><span class=\"line\">    LNode* p=&amp;L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,p-&gt;data);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//头插法-带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">HeadInsert</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        InsertNextNode(L,input[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//尾插法-带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">TailInsert</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s,*r;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    r=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data=input[i];</span><br><span class=\"line\">        r-&gt;next=s;</span><br><span class=\"line\">        r=s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    r-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//尾插法-不带头结点</span></span><br><span class=\"line\">Linklist <span class=\"title function_\">HeadInsertNoHead</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    LNode *s;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>,x=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> input[<span class=\"number\">6</span>]=&#123;<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">-1</span>&#125;;</span><br><span class=\"line\">    L=(Linklist)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    L-&gt;data=input[<span class=\"number\">0</span>];</span><br><span class=\"line\">    L-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;input[i]!=<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">        s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;next=L-&gt;next;</span><br><span class=\"line\">        L-&gt;next=s;</span><br><span class=\"line\">        s-&gt;data=input[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位查找</span></span><br><span class=\"line\">LNode* <span class=\"title function_\">GetElement</span><span class=\"params\">(Linklist L,<span class=\"type\">int</span> i)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i;j++)</span><br><span class=\"line\">        p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按值查找</span></span><br><span class=\"line\">LNode* <span class=\"title function_\">LocateElem</span><span class=\"params\">(Linklist L,<span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    LNode* p=L-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; p-&gt;data!=e;p=p-&gt;next);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Length</span><span class=\"params\">(Linklist L)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">test_head</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;带头结点测试：&quot;</span>);</span><br><span class=\"line\">    Linklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    L=HeadInsert(L);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位查找</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n第3个位置的元素为：%d\\n&quot;</span>,GetElement(L,<span class=\"number\">3</span>)-&gt;data);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位插入</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第1个位置插入11\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_head(L,<span class=\"number\">1</span>,<span class=\"number\">11</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//后插</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第2个位置后插22\\n&quot;</span>);</span><br><span class=\"line\">    LNode *p=GetElement(L,<span class=\"number\">2</span>);</span><br><span class=\"line\">    InsertNextNode(p,<span class=\"number\">22</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//前插</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第3个位置前插33\\n&quot;</span>);</span><br><span class=\"line\">    p=GetElement(L,<span class=\"number\">3</span>);</span><br><span class=\"line\">    InsertPriorNode(p,<span class=\"number\">33</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位删除</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n删除第1个位置\\n&quot;</span>);</span><br><span class=\"line\">    <span class=\"type\">int</span> e;</span><br><span class=\"line\">    ListDelete(L,<span class=\"number\">1</span>,&amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;删除后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//逆置</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n逆置\\n&quot;</span>);</span><br><span class=\"line\">    Reverse(&amp;L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;逆置后：&quot;</span>);</span><br><span class=\"line\">    printlist(*(L-&gt;next));</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">test_nohead</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    Linklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    L=HeadInsertNoHead(L);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n\\n\\n不带头结点测试：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//按位插入</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第1个位置插入11\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_nohead(&amp;L,<span class=\"number\">1</span>,<span class=\"number\">11</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;\\n在第2个位置插入22\\n&quot;</span>);</span><br><span class=\"line\">    ListInsert_nohead(&amp;L,<span class=\"number\">2</span>,<span class=\"number\">22</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;插入后：&quot;</span>);</span><br><span class=\"line\">    printlist(*L);</span><br><span class=\"line\"></span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    test_head();</span><br><span class=\"line\">    test_nohead();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位插入_头</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert_head</span><span class=\"params\">(Linklist L, <span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *p=GetElement(L,i<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> InsertNextNode(p,e);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位插入_不头</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListInsert_nohead</span><span class=\"params\">(Linklist *L,<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i==<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data=e;</span><br><span class=\"line\">        s-&gt;next=*L;</span><br><span class=\"line\">        *L=s;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    LNode *p=*L;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i<span class=\"number\">-1</span>;j++) p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    s-&gt;data=e;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;<span class=\"comment\">//顺序不能换        </span></span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//后插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertNextNode</span><span class=\"params\">(LNode *p, <span class=\"type\">int</span> e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    s-&gt;data=e;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//前插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertPriorNode</span><span class=\"params\">(LNode *p, <span class=\"type\">int</span> e)</span>&#123;<span class=\"comment\">//只需交换数据域</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *s=(LNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    s-&gt;data=p-&gt;data;</span><br><span class=\"line\">    p-&gt;data=e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//按位删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ListDelete</span><span class=\"params\">(Linklist L, <span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *p=L;</span><br><span class=\"line\">    <span class=\"type\">int</span> j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span> &amp;&amp; j&lt;i<span class=\"number\">-1</span>;j++) p=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *q=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    p-&gt;next=q-&gt;next;</span><br><span class=\"line\">    *e=q-&gt;data;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(q);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//逆置</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">Reverse</span><span class=\"params\">(Linklist *L)</span>&#123;</span><br><span class=\"line\">    LNode *p=(*L)-&gt;next;</span><br><span class=\"line\">    (*L)-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    LNode *q;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p!=<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">        q=p-&gt;next;</span><br><span class=\"line\">        p-&gt;next=(*L)-&gt;next;</span><br><span class=\"line\">        (*L)-&gt;next=p;</span><br><span class=\"line\">        p=q;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"4. 串","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n### \n\n## 4.1 定义\n![](../../../../themes/yilia/source/img/datastruct/4_string/1.png)\n![数据结构](/img/datastruct/4_string/1.png)\n- 一种特殊的线性表\n\n## 4.2 串的存储结构\n![](../../../../themes/yilia/source/img/datastruct/4_string/2.png)\n![数据结构](/img/datastruct/4_string/2.png)\n\n- 顺序存储\n![](../../../../themes/yilia/source/img/datastruct/4_string/3.png)\n![数据结构](/img/datastruct/4_string/3.png)\n```c\n#define MAXLEN 255\ntypedef struct{\n    char ch[MAXLEN]; //静态数组\n    int length;\n} SString;\n\ntypedef struct{\n    char *ch; //动态数组\n    int length;\n} HString;\n```\n\n- 链式存储\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/5.png)\n![数据结构](/img/datastruct/4_string/5.png)\n```c\n//2. 链式存储\ntypedef struct StringNode{\n    char ch; //1：1\n    struct StringNode *next;\n} StringNode, *String;\n\ntypedef struct StringNode{\n    char ch[4]; //1：4\n    struct StringNode *next;\n} StringNode, *String;\n```\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/4.png)\n![数据结构](/img/datastruct/4_string/4.png)\n\n## 4.3 基本操作\n\n|函数名|功能|时间复杂度|\n|:---|:---|:---|\n|StrAssign(SString &T, char *chars)|生成一个其值等于chars的串T|O(n)|\n|StrCopy(SString &T, SString S)|由串S复制得串T|O(n)|\n|StrEmpty(SString S)|若S为空串，则返回true，否则返回false|O(1)|\n|StrLength(SString S)|返回串S的元素个数，即串的长度|O(1)|\n|ClearString(SString &S)|将串S清为空串|O(1)|\n|DestroyString(SString &S)|串S存在，则销毁它|O(1)|\n|Concat(SString &T, SString S1, SString S2)|用T返回由S1和S2联接而成的新串|O(n)|\n\n```c\n//求子串\nint SubString(SString *Sub, SString S, int pos, int len){\n    //1. 参数合法性判断\n    if(pos<1 || pos>S.length || len<0 || len>S.length-pos+1)\n        return 0;\n    //2. 子串赋值\n    for(int i=pos; i<pos+len; i++)\n        Sub->ch[i-pos+1]=S.ch[i];\n    Sub->length=len;\n    return 1;\n}\n\n//比较\nint StrCompare(SString S, SString T){\n    for(int i=1; i<=S.length && i<=T.length; i++){\n        if(S.ch[i]!=T.ch[i])\n            return S.ch[i]-T.ch[i];\n    }\n    return S.length-T.length;\n}\n\n//定位\nint Index(SString S, SString T){\n    int i=1, n=S.length, m=T.length;\n    SString sub;\n    while(i<=n-m+1){\n        SubString(&sub, S, i, m);\n        if(StrCompare(sub, T)!=0)\n            ++i;\n        else\n            return i;\n    }\n    return 0;\n}\n```\n\n## 4.4 模式匹配\n![](../../../../themes/yilia/source/img/datastruct/4_string/6.png)\n![数据结构](/img/datastruct/4_string/6.png)\n\n### 4.4.1 朴素模式匹配算法\n\n```c\n//朴素模式匹配算法\nint Index(SString S, SString T){\n    int i=1, n=S.length, m=T.length;\n    while(i<=n-m+1){\n        int j=1;\n        while(j<=m){\n            if(S.ch[i+j-1]==T.ch[j])\n                ++j;\n            else\n                break;\n        }\n        if(j>m)\n            return i;\n        else\n            ++i;\n    }\n    return 0;\n}\n//定位算法中，子串的长度是固定的，而模式匹配算法中，子串的长度是可变的\n```\n### 4.4.2 KMP模式匹配算法\n![](../../../../themes/yilia/source/img/datastruct/4_string/7.png)\n![数据结构](/img/datastruct/4_string/7.png)\n![](../../../../themes/yilia/source/img/datastruct/4_string/8.png)\n![数据结构](/img/datastruct/4_string/8.png)\n\n- 1）根据模式求next数组\n![](../../../../themes/yilia/source/img/datastruct/4_string/9.png)\n![数据结构](/img/datastruct/4_string/9.png)\n![](../../../../themes/yilia/source/img/datastruct/4_string/11.png)\n![数据结构](/img/datastruct/4_string/11.png)\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/22.png)\n![数据结构](/img/datastruct/4_string/22.png)\n\n- 算法优化\n![](../../../../themes/yilia/source/img/datastruct/4_string/33.png)\n![数据结构](/img/datastruct/4_string/33.png)\n\nnext[3]=1 , next[3]与next[1]相等，所以转到next[1]后也会失配，所以next[3]可以改为next[1]=0\n\n```c\n//KMP算法\n//求next\nvoid get_next(SString T, int next[]){\n    //1. 初始化\n    int i=1, j=0;\n    next[1]=0;\n    while(i<T.length){\n        if(j==0 || T.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n            next[i]=j;\n        }\n        else\n            j=next[j];\n    }\n}\n\n//求nextval\nvoid get_nextval(SString T, int nextval[]){\n    //1. 初始化\n    int i=1, j=0;\n    nextval[1]=0;\n    while(i<T.length){\n        if(j==0 || T.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n            if(T.ch[i]!=T.ch[j])\n                nextval[i]=j;\n            else\n                nextval[i]=nextval[j];\n        }\n        else\n            j=nextval[j];\n    }\n}\n\n\nint Index_KMP(SString S, SString T, int next[]){\n    int i=1, j=1;\n    while(i<=S.length && j<=T.length){\n        if(j==0 || S.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n        }\n        else\n            j=next[j];//i不回溯\n    }\n    if(j>T.length)\n        return i-T.length;\n    else\n        return 0;\n}\n```","source":"_posts/datastruct/4_string/1_string.md","raw":"---\ntitle: 4. 串\ndate: 2023-08-07 00:00:00\ntags: [数据结构,串]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n### \n\n## 4.1 定义\n![](../../../../themes/yilia/source/img/datastruct/4_string/1.png)\n![数据结构](/img/datastruct/4_string/1.png)\n- 一种特殊的线性表\n\n## 4.2 串的存储结构\n![](../../../../themes/yilia/source/img/datastruct/4_string/2.png)\n![数据结构](/img/datastruct/4_string/2.png)\n\n- 顺序存储\n![](../../../../themes/yilia/source/img/datastruct/4_string/3.png)\n![数据结构](/img/datastruct/4_string/3.png)\n```c\n#define MAXLEN 255\ntypedef struct{\n    char ch[MAXLEN]; //静态数组\n    int length;\n} SString;\n\ntypedef struct{\n    char *ch; //动态数组\n    int length;\n} HString;\n```\n\n- 链式存储\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/5.png)\n![数据结构](/img/datastruct/4_string/5.png)\n```c\n//2. 链式存储\ntypedef struct StringNode{\n    char ch; //1：1\n    struct StringNode *next;\n} StringNode, *String;\n\ntypedef struct StringNode{\n    char ch[4]; //1：4\n    struct StringNode *next;\n} StringNode, *String;\n```\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/4.png)\n![数据结构](/img/datastruct/4_string/4.png)\n\n## 4.3 基本操作\n\n|函数名|功能|时间复杂度|\n|:---|:---|:---|\n|StrAssign(SString &T, char *chars)|生成一个其值等于chars的串T|O(n)|\n|StrCopy(SString &T, SString S)|由串S复制得串T|O(n)|\n|StrEmpty(SString S)|若S为空串，则返回true，否则返回false|O(1)|\n|StrLength(SString S)|返回串S的元素个数，即串的长度|O(1)|\n|ClearString(SString &S)|将串S清为空串|O(1)|\n|DestroyString(SString &S)|串S存在，则销毁它|O(1)|\n|Concat(SString &T, SString S1, SString S2)|用T返回由S1和S2联接而成的新串|O(n)|\n\n```c\n//求子串\nint SubString(SString *Sub, SString S, int pos, int len){\n    //1. 参数合法性判断\n    if(pos<1 || pos>S.length || len<0 || len>S.length-pos+1)\n        return 0;\n    //2. 子串赋值\n    for(int i=pos; i<pos+len; i++)\n        Sub->ch[i-pos+1]=S.ch[i];\n    Sub->length=len;\n    return 1;\n}\n\n//比较\nint StrCompare(SString S, SString T){\n    for(int i=1; i<=S.length && i<=T.length; i++){\n        if(S.ch[i]!=T.ch[i])\n            return S.ch[i]-T.ch[i];\n    }\n    return S.length-T.length;\n}\n\n//定位\nint Index(SString S, SString T){\n    int i=1, n=S.length, m=T.length;\n    SString sub;\n    while(i<=n-m+1){\n        SubString(&sub, S, i, m);\n        if(StrCompare(sub, T)!=0)\n            ++i;\n        else\n            return i;\n    }\n    return 0;\n}\n```\n\n## 4.4 模式匹配\n![](../../../../themes/yilia/source/img/datastruct/4_string/6.png)\n![数据结构](/img/datastruct/4_string/6.png)\n\n### 4.4.1 朴素模式匹配算法\n\n```c\n//朴素模式匹配算法\nint Index(SString S, SString T){\n    int i=1, n=S.length, m=T.length;\n    while(i<=n-m+1){\n        int j=1;\n        while(j<=m){\n            if(S.ch[i+j-1]==T.ch[j])\n                ++j;\n            else\n                break;\n        }\n        if(j>m)\n            return i;\n        else\n            ++i;\n    }\n    return 0;\n}\n//定位算法中，子串的长度是固定的，而模式匹配算法中，子串的长度是可变的\n```\n### 4.4.2 KMP模式匹配算法\n![](../../../../themes/yilia/source/img/datastruct/4_string/7.png)\n![数据结构](/img/datastruct/4_string/7.png)\n![](../../../../themes/yilia/source/img/datastruct/4_string/8.png)\n![数据结构](/img/datastruct/4_string/8.png)\n\n- 1）根据模式求next数组\n![](../../../../themes/yilia/source/img/datastruct/4_string/9.png)\n![数据结构](/img/datastruct/4_string/9.png)\n![](../../../../themes/yilia/source/img/datastruct/4_string/11.png)\n![数据结构](/img/datastruct/4_string/11.png)\n\n![](../../../../themes/yilia/source/img/datastruct/4_string/22.png)\n![数据结构](/img/datastruct/4_string/22.png)\n\n- 算法优化\n![](../../../../themes/yilia/source/img/datastruct/4_string/33.png)\n![数据结构](/img/datastruct/4_string/33.png)\n\nnext[3]=1 , next[3]与next[1]相等，所以转到next[1]后也会失配，所以next[3]可以改为next[1]=0\n\n```c\n//KMP算法\n//求next\nvoid get_next(SString T, int next[]){\n    //1. 初始化\n    int i=1, j=0;\n    next[1]=0;\n    while(i<T.length){\n        if(j==0 || T.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n            next[i]=j;\n        }\n        else\n            j=next[j];\n    }\n}\n\n//求nextval\nvoid get_nextval(SString T, int nextval[]){\n    //1. 初始化\n    int i=1, j=0;\n    nextval[1]=0;\n    while(i<T.length){\n        if(j==0 || T.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n            if(T.ch[i]!=T.ch[j])\n                nextval[i]=j;\n            else\n                nextval[i]=nextval[j];\n        }\n        else\n            j=nextval[j];\n    }\n}\n\n\nint Index_KMP(SString S, SString T, int next[]){\n    int i=1, j=1;\n    while(i<=S.length && j<=T.length){\n        if(j==0 || S.ch[i]==T.ch[j]){\n            ++i;\n            ++j;\n        }\n        else\n            j=next[j];//i不回溯\n    }\n    if(j>T.length)\n        return i-T.length;\n    else\n        return 0;\n}\n```","slug":"datastruct/4_string/1_string","published":1,"updated":"2023-10-23T12:15:39.435Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858t001n7svwhp3g4dq9","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"4-1-定义\"><a href=\"#4-1-定义\" class=\"headerlink\" title=\"4.1 定义\"></a>4.1 定义</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/1.png\"><br><img src=\"/img/datastruct/4_string/1.png\" alt=\"数据结构\"></p>\n<ul>\n<li>一种特殊的线性表</li>\n</ul>\n<h2 id=\"4-2-串的存储结构\"><a href=\"#4-2-串的存储结构\" class=\"headerlink\" title=\"4.2 串的存储结构\"></a>4.2 串的存储结构</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/2.png\"><br><img src=\"/img/datastruct/4_string/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>顺序存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/3.png\"><br><img src=\"/img/datastruct/4_string/3.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXLEN 255</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch[MAXLEN]; <span class=\"comment\">//静态数组</span></span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125; SString;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> *ch; <span class=\"comment\">//动态数组</span></span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125; HString;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>链式存储</p>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/5.png\"><br><img src=\"/img/datastruct/4_string/5.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2. 链式存储</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch; <span class=\"comment\">//1：1</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; StringNode, *String;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch[<span class=\"number\">4</span>]; <span class=\"comment\">//1：4</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; StringNode, *String;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/4.png\"><br><img src=\"/img/datastruct/4_string/4.png\" alt=\"数据结构\"></p>\n<h2 id=\"4-3-基本操作\"><a href=\"#4-3-基本操作\" class=\"headerlink\" title=\"4.3 基本操作\"></a>4.3 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"left\">函数名</th>\n<th align=\"left\">功能</th>\n<th align=\"left\">时间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">StrAssign(SString &amp;T, char *chars)</td>\n<td align=\"left\">生成一个其值等于chars的串T</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">StrCopy(SString &amp;T, SString S)</td>\n<td align=\"left\">由串S复制得串T</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">StrEmpty(SString S)</td>\n<td align=\"left\">若S为空串，则返回true，否则返回false</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">StrLength(SString S)</td>\n<td align=\"left\">返回串S的元素个数，即串的长度</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">ClearString(SString &amp;S)</td>\n<td align=\"left\">将串S清为空串</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">DestroyString(SString &amp;S)</td>\n<td align=\"left\">串S存在，则销毁它</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">Concat(SString &amp;T, SString S1, SString S2)</td>\n<td align=\"left\">用T返回由S1和S2联接而成的新串</td>\n<td align=\"left\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//求子串</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">SubString</span><span class=\"params\">(SString *Sub, SString S, <span class=\"type\">int</span> pos, <span class=\"type\">int</span> len)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 参数合法性判断</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pos&lt;<span class=\"number\">1</span> || pos&gt;S.length || len&lt;<span class=\"number\">0</span> || len&gt;S.length-pos+<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">//2. 子串赋值</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=pos; i&lt;pos+len; i++)</span><br><span class=\"line\">        Sub-&gt;ch[i-pos+<span class=\"number\">1</span>]=S.ch[i];</span><br><span class=\"line\">    Sub-&gt;length=len;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//比较</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StrCompare</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>; i&lt;=S.length &amp;&amp; i&lt;=T.length; i++)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(S.ch[i]!=T.ch[i])</span><br><span class=\"line\">            <span class=\"keyword\">return</span> S.ch[i]-T.ch[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> S.length-T.length;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//定位</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, n=S.length, m=T.length;</span><br><span class=\"line\">    SString sub;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=n-m+<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        SubString(&amp;sub, S, i, m);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(StrCompare(sub, T)!=<span class=\"number\">0</span>)</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4-4-模式匹配\"><a href=\"#4-4-模式匹配\" class=\"headerlink\" title=\"4.4 模式匹配\"></a>4.4 模式匹配</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/6.png\"><br><img src=\"/img/datastruct/4_string/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"4-4-1-朴素模式匹配算法\"><a href=\"#4-4-1-朴素模式匹配算法\" class=\"headerlink\" title=\"4.4.1 朴素模式匹配算法\"></a>4.4.1 朴素模式匹配算法</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//朴素模式匹配算法</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, n=S.length, m=T.length;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=n-m+<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j=<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&lt;=m)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(S.ch[i+j<span class=\"number\">-1</span>]==T.ch[j])</span><br><span class=\"line\">                ++j;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j&gt;m)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//定位算法中，子串的长度是固定的，而模式匹配算法中，子串的长度是可变的</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-4-2-KMP模式匹配算法\"><a href=\"#4-4-2-KMP模式匹配算法\" class=\"headerlink\" title=\"4.4.2 KMP模式匹配算法\"></a>4.4.2 KMP模式匹配算法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/7.png\"><br><img src=\"/img/datastruct/4_string/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/8.png\"><br><img src=\"/img/datastruct/4_string/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>1）根据模式求next数组<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/9.png\"><br><img src=\"/img/datastruct/4_string/9.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/11.png\"><br><img src=\"/img/datastruct/4_string/11.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/22.png\"><br><img src=\"/img/datastruct/4_string/22.png\" alt=\"数据结构\"></p>\n<ul>\n<li>算法优化<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/33.png\"><br><img src=\"/img/datastruct/4_string/33.png\" alt=\"数据结构\"></li>\n</ul>\n<p>next[3]&#x3D;1 , next[3]与next[1]相等，所以转到next[1]后也会失配，所以next[3]可以改为next[1]&#x3D;0</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//KMP算法</span></span><br><span class=\"line\"><span class=\"comment\">//求next</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">get_next</span><span class=\"params\">(SString T, <span class=\"type\">int</span> next[])</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 初始化</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    next[<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || T.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">            next[i]=j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=next[j];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求nextval</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">get_nextval</span><span class=\"params\">(SString T, <span class=\"type\">int</span> nextval[])</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 初始化</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    nextval[<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || T.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(T.ch[i]!=T.ch[j])</span><br><span class=\"line\">                nextval[i]=j;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                nextval[i]=nextval[j];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=nextval[j];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index_KMP</span><span class=\"params\">(SString S, SString T, <span class=\"type\">int</span> next[])</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=S.length &amp;&amp; j&lt;=T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || S.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=next[j];<span class=\"comment\">//i不回溯</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(j&gt;T.length)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> i-T.length;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"4-1-定义\"><a href=\"#4-1-定义\" class=\"headerlink\" title=\"4.1 定义\"></a>4.1 定义</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/1.png\"><br><img src=\"/img/datastruct/4_string/1.png\" alt=\"数据结构\"></p>\n<ul>\n<li>一种特殊的线性表</li>\n</ul>\n<h2 id=\"4-2-串的存储结构\"><a href=\"#4-2-串的存储结构\" class=\"headerlink\" title=\"4.2 串的存储结构\"></a>4.2 串的存储结构</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/2.png\"><br><img src=\"/img/datastruct/4_string/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>顺序存储<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/3.png\"><br><img src=\"/img/datastruct/4_string/3.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MAXLEN 255</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch[MAXLEN]; <span class=\"comment\">//静态数组</span></span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125; SString;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> *ch; <span class=\"comment\">//动态数组</span></span><br><span class=\"line\">    <span class=\"type\">int</span> length;</span><br><span class=\"line\">&#125; HString;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>链式存储</p>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/5.png\"><br><img src=\"/img/datastruct/4_string/5.png\" alt=\"数据结构\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2. 链式存储</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch; <span class=\"comment\">//1：1</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; StringNode, *String;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">char</span> ch[<span class=\"number\">4</span>]; <span class=\"comment\">//1：4</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">StringNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; StringNode, *String;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/4.png\"><br><img src=\"/img/datastruct/4_string/4.png\" alt=\"数据结构\"></p>\n<h2 id=\"4-3-基本操作\"><a href=\"#4-3-基本操作\" class=\"headerlink\" title=\"4.3 基本操作\"></a>4.3 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"left\">函数名</th>\n<th align=\"left\">功能</th>\n<th align=\"left\">时间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">StrAssign(SString &amp;T, char *chars)</td>\n<td align=\"left\">生成一个其值等于chars的串T</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">StrCopy(SString &amp;T, SString S)</td>\n<td align=\"left\">由串S复制得串T</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">StrEmpty(SString S)</td>\n<td align=\"left\">若S为空串，则返回true，否则返回false</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">StrLength(SString S)</td>\n<td align=\"left\">返回串S的元素个数，即串的长度</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">ClearString(SString &amp;S)</td>\n<td align=\"left\">将串S清为空串</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">DestroyString(SString &amp;S)</td>\n<td align=\"left\">串S存在，则销毁它</td>\n<td align=\"left\">O(1)</td>\n</tr>\n<tr>\n<td align=\"left\">Concat(SString &amp;T, SString S1, SString S2)</td>\n<td align=\"left\">用T返回由S1和S2联接而成的新串</td>\n<td align=\"left\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//求子串</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">SubString</span><span class=\"params\">(SString *Sub, SString S, <span class=\"type\">int</span> pos, <span class=\"type\">int</span> len)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 参数合法性判断</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pos&lt;<span class=\"number\">1</span> || pos&gt;S.length || len&lt;<span class=\"number\">0</span> || len&gt;S.length-pos+<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">//2. 子串赋值</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=pos; i&lt;pos+len; i++)</span><br><span class=\"line\">        Sub-&gt;ch[i-pos+<span class=\"number\">1</span>]=S.ch[i];</span><br><span class=\"line\">    Sub-&gt;length=len;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//比较</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">StrCompare</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>; i&lt;=S.length &amp;&amp; i&lt;=T.length; i++)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(S.ch[i]!=T.ch[i])</span><br><span class=\"line\">            <span class=\"keyword\">return</span> S.ch[i]-T.ch[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> S.length-T.length;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//定位</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, n=S.length, m=T.length;</span><br><span class=\"line\">    SString sub;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=n-m+<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        SubString(&amp;sub, S, i, m);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(StrCompare(sub, T)!=<span class=\"number\">0</span>)</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4-4-模式匹配\"><a href=\"#4-4-模式匹配\" class=\"headerlink\" title=\"4.4 模式匹配\"></a>4.4 模式匹配</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/6.png\"><br><img src=\"/img/datastruct/4_string/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"4-4-1-朴素模式匹配算法\"><a href=\"#4-4-1-朴素模式匹配算法\" class=\"headerlink\" title=\"4.4.1 朴素模式匹配算法\"></a>4.4.1 朴素模式匹配算法</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//朴素模式匹配算法</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index</span><span class=\"params\">(SString S, SString T)</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, n=S.length, m=T.length;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=n-m+<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j=<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&lt;=m)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(S.ch[i+j<span class=\"number\">-1</span>]==T.ch[j])</span><br><span class=\"line\">                ++j;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j&gt;m)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//定位算法中，子串的长度是固定的，而模式匹配算法中，子串的长度是可变的</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-4-2-KMP模式匹配算法\"><a href=\"#4-4-2-KMP模式匹配算法\" class=\"headerlink\" title=\"4.4.2 KMP模式匹配算法\"></a>4.4.2 KMP模式匹配算法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/7.png\"><br><img src=\"/img/datastruct/4_string/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/8.png\"><br><img src=\"/img/datastruct/4_string/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>1）根据模式求next数组<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/9.png\"><br><img src=\"/img/datastruct/4_string/9.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/11.png\"><br><img src=\"/img/datastruct/4_string/11.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/22.png\"><br><img src=\"/img/datastruct/4_string/22.png\" alt=\"数据结构\"></p>\n<ul>\n<li>算法优化<br><img src=\"/../../../../themes/yilia/source/img/datastruct/4_string/33.png\"><br><img src=\"/img/datastruct/4_string/33.png\" alt=\"数据结构\"></li>\n</ul>\n<p>next[3]&#x3D;1 , next[3]与next[1]相等，所以转到next[1]后也会失配，所以next[3]可以改为next[1]&#x3D;0</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//KMP算法</span></span><br><span class=\"line\"><span class=\"comment\">//求next</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">get_next</span><span class=\"params\">(SString T, <span class=\"type\">int</span> next[])</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 初始化</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    next[<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || T.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">            next[i]=j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=next[j];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求nextval</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">get_nextval</span><span class=\"params\">(SString T, <span class=\"type\">int</span> nextval[])</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//1. 初始化</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">0</span>;</span><br><span class=\"line\">    nextval[<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || T.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(T.ch[i]!=T.ch[j])</span><br><span class=\"line\">                nextval[i]=j;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                nextval[i]=nextval[j];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=nextval[j];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">Index_KMP</span><span class=\"params\">(SString S, SString T, <span class=\"type\">int</span> next[])</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=<span class=\"number\">1</span>, j=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=S.length &amp;&amp; j&lt;=T.length)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j==<span class=\"number\">0</span> || S.ch[i]==T.ch[j])&#123;</span><br><span class=\"line\">            ++i;</span><br><span class=\"line\">            ++j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            j=next[j];<span class=\"comment\">//i不回溯</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(j&gt;T.length)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> i-T.length;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"2.3 双链表","date":"2023-08-04T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n# 2 线性表\n\n\n|单链表|双链表\n|:---:|:---:|\n|无法逆向检索，不太方便|可进可退，存储密度更低\n\n\n\n### 2.4.1 基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/1.png)\n\n- 插入\n- 删除\n- 遍历\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct DNode{\n    int data;\n    struct DNode *prior,*next;\n} DNode, *DLinklist;\n\n//创建一个结点\nDNode* CreateNode(int data){\n    DNode *p;\n    p=(DNode*)malloc(sizeof(DNode));\n    p->data=data;\n    p->prior=NULL;\n    p->next=NULL;\n    return p;\n}\n\n//输出链表\nvoid printlist(DLinklist L){\n    DNode* p=L;\n    for(;p!=NULL;p=p->next)\n        printf(\"%d \",p->data);\n}\n\nint main(){\n    DLinklist L=NULL;\n    //创建一个结点\n    DNode *p=CreateNode(1);\n    //插入\n    InsertNextNode(p,CreateNode(2));\n    InsertNextNode(p->next,CreateNode(3));\n    InsertNextNode(p->next->next,CreateNode(4));\n    InsertNextNode(p->next->next->next,CreateNode(5));\n\n    //输出链表\n    printlist(p);\n    return 0;\n}\n\n//后插\nint InsertNextNode(DNode *p, DNode *s){\n    if(p==NULL||s==NULL)\n        return 0;\n    s->next=p->next;\n    if(p->next!=NULL)\n        p->next->prior=s;\n    s->prior=p;\n    p->next=s;\n    return 1;\n}\n\n//删除\nint DeleteNode(DNode *p){\n    if(p==NULL)\n        return 0;\n    p->prior->next=p->next;\n    p->next->prior=p->prior;\n    free(p);\n    return 1;\n}\n\n```\n\n## 2.5 循环链表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/2.png)\n\n## 2.6 静态链表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/3.png)\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/4.png)\n\n### 2.6.1 代码实现\n- 插入\n- 删除\n\n## 2.7 顺序表vs链表\n\n||顺序表|链表\n|:---:|:---:|:---:|\n|逻辑结构|线性结构|线性结构\n|存储结构|顺序存储|链式存储\n|优点|随机存取，存储密度高|插入和删除\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/5.png)","source":"_posts/datastruct/2_linearlist/3_doublelinklist.md","raw":"---\ntitle: 2.3 双链表\ndate: 2023-08-05 00:00:00\ntags: [数据结构,线性表,双链表]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png)\n![数据结构](/img/datastruct/2_linearlist/1.png)\n\n# 2 线性表\n\n\n|单链表|双链表\n|:---:|:---:|\n|无法逆向检索，不太方便|可进可退，存储密度更低\n\n\n\n### 2.4.1 基本操作\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/1.png)\n\n- 插入\n- 删除\n- 遍历\n```c\n#include<stdio.h>\n#include<stdlib.h>\ntypedef struct DNode{\n    int data;\n    struct DNode *prior,*next;\n} DNode, *DLinklist;\n\n//创建一个结点\nDNode* CreateNode(int data){\n    DNode *p;\n    p=(DNode*)malloc(sizeof(DNode));\n    p->data=data;\n    p->prior=NULL;\n    p->next=NULL;\n    return p;\n}\n\n//输出链表\nvoid printlist(DLinklist L){\n    DNode* p=L;\n    for(;p!=NULL;p=p->next)\n        printf(\"%d \",p->data);\n}\n\nint main(){\n    DLinklist L=NULL;\n    //创建一个结点\n    DNode *p=CreateNode(1);\n    //插入\n    InsertNextNode(p,CreateNode(2));\n    InsertNextNode(p->next,CreateNode(3));\n    InsertNextNode(p->next->next,CreateNode(4));\n    InsertNextNode(p->next->next->next,CreateNode(5));\n\n    //输出链表\n    printlist(p);\n    return 0;\n}\n\n//后插\nint InsertNextNode(DNode *p, DNode *s){\n    if(p==NULL||s==NULL)\n        return 0;\n    s->next=p->next;\n    if(p->next!=NULL)\n        p->next->prior=s;\n    s->prior=p;\n    p->next=s;\n    return 1;\n}\n\n//删除\nint DeleteNode(DNode *p){\n    if(p==NULL)\n        return 0;\n    p->prior->next=p->next;\n    p->next->prior=p->prior;\n    free(p);\n    return 1;\n}\n\n```\n\n## 2.5 循环链表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/2.png)\n\n## 2.6 静态链表\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/3.png)\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/4.png)\n\n### 2.6.1 代码实现\n- 插入\n- 删除\n\n## 2.7 顺序表vs链表\n\n||顺序表|链表\n|:---:|:---:|:---:|\n|逻辑结构|线性结构|线性结构\n|存储结构|顺序存储|链式存储\n|优点|随机存取，存储密度高|插入和删除\n\n![](../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png)\n![数据结构](/img/datastruct/2_linearlist/doublelinklist/5.png)","slug":"datastruct/2_linearlist/3_doublelinklist","published":1,"updated":"2023-10-23T12:03:40.512Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858u001r7svw18abfw5j","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<h1 id=\"2-线性表\"><a href=\"#2-线性表\" class=\"headerlink\" title=\"2 线性表\"></a>2 线性表</h1><table>\n<thead>\n<tr>\n<th align=\"center\">单链表</th>\n<th align=\"center\">双链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">无法逆向检索，不太方便</td>\n<td align=\"center\">可进可退，存储密度更低</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-4-1-基本操作\"><a href=\"#2-4-1-基本操作\" class=\"headerlink\" title=\"2.4.1 基本操作\"></a>2.4.1 基本操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/1.png\" alt=\"数据结构\"></p>\n<ul>\n<li>插入</li>\n<li>删除</li>\n<li>遍历<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">DNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">DNode</span> *<span class=\"title\">prior</span>,*<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; DNode, *DLinklist;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//创建一个结点</span></span><br><span class=\"line\">DNode* <span class=\"title function_\">CreateNode</span><span class=\"params\">(<span class=\"type\">int</span> data)</span>&#123;</span><br><span class=\"line\">    DNode *p;</span><br><span class=\"line\">    p=(DNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(DNode));</span><br><span class=\"line\">    p-&gt;data=data;</span><br><span class=\"line\">    p-&gt;prior=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//输出链表</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">printlist</span><span class=\"params\">(DLinklist L)</span>&#123;</span><br><span class=\"line\">    DNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,p-&gt;data);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    DLinklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//创建一个结点</span></span><br><span class=\"line\">    DNode *p=CreateNode(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"comment\">//插入</span></span><br><span class=\"line\">    InsertNextNode(p,CreateNode(<span class=\"number\">2</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next,CreateNode(<span class=\"number\">3</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next-&gt;next,CreateNode(<span class=\"number\">4</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next-&gt;next-&gt;next,CreateNode(<span class=\"number\">5</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//输出链表</span></span><br><span class=\"line\">    printlist(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//后插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertNextNode</span><span class=\"params\">(DNode *p, DNode *s)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>||s==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;next!=<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        p-&gt;next-&gt;prior=s;</span><br><span class=\"line\">    s-&gt;prior=p;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeleteNode</span><span class=\"params\">(DNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    p-&gt;prior-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next-&gt;prior=p-&gt;prior;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"2-5-循环链表\"><a href=\"#2-5-循环链表\" class=\"headerlink\" title=\"2.5 循环链表\"></a>2.5 循环链表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/2.png\" alt=\"数据结构\"></p>\n<h2 id=\"2-6-静态链表\"><a href=\"#2-6-静态链表\" class=\"headerlink\" title=\"2.6 静态链表\"></a>2.6 静态链表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/3.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/4.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-6-1-代码实现\"><a href=\"#2-6-1-代码实现\" class=\"headerlink\" title=\"2.6.1 代码实现\"></a>2.6.1 代码实现</h3><ul>\n<li>插入</li>\n<li>删除</li>\n</ul>\n<h2 id=\"2-7-顺序表vs链表\"><a href=\"#2-7-顺序表vs链表\" class=\"headerlink\" title=\"2.7 顺序表vs链表\"></a>2.7 顺序表vs链表</h2><table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">顺序表</th>\n<th align=\"center\">链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">逻辑结构</td>\n<td align=\"center\">线性结构</td>\n<td align=\"center\">线性结构</td>\n</tr>\n<tr>\n<td align=\"center\">存储结构</td>\n<td align=\"center\">顺序存储</td>\n<td align=\"center\">链式存储</td>\n</tr>\n<tr>\n<td align=\"center\">优点</td>\n<td align=\"center\">随机存取，存储密度高</td>\n<td align=\"center\">插入和删除</td>\n</tr>\n</tbody></table>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/5.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/1.png\" alt=\"数据结构\"></p>\n<h1 id=\"2-线性表\"><a href=\"#2-线性表\" class=\"headerlink\" title=\"2 线性表\"></a>2 线性表</h1><table>\n<thead>\n<tr>\n<th align=\"center\">单链表</th>\n<th align=\"center\">双链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">无法逆向检索，不太方便</td>\n<td align=\"center\">可进可退，存储密度更低</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-4-1-基本操作\"><a href=\"#2-4-1-基本操作\" class=\"headerlink\" title=\"2.4.1 基本操作\"></a>2.4.1 基本操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/1.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/1.png\" alt=\"数据结构\"></p>\n<ul>\n<li>插入</li>\n<li>删除</li>\n<li>遍历<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">DNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">DNode</span> *<span class=\"title\">prior</span>,*<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125; DNode, *DLinklist;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//创建一个结点</span></span><br><span class=\"line\">DNode* <span class=\"title function_\">CreateNode</span><span class=\"params\">(<span class=\"type\">int</span> data)</span>&#123;</span><br><span class=\"line\">    DNode *p;</span><br><span class=\"line\">    p=(DNode*)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(DNode));</span><br><span class=\"line\">    p-&gt;data=data;</span><br><span class=\"line\">    p-&gt;prior=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//输出链表</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">printlist</span><span class=\"params\">(DLinklist L)</span>&#123;</span><br><span class=\"line\">    DNode* p=L;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;p!=<span class=\"literal\">NULL</span>;p=p-&gt;next)</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,p-&gt;data);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    DLinklist L=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//创建一个结点</span></span><br><span class=\"line\">    DNode *p=CreateNode(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"comment\">//插入</span></span><br><span class=\"line\">    InsertNextNode(p,CreateNode(<span class=\"number\">2</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next,CreateNode(<span class=\"number\">3</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next-&gt;next,CreateNode(<span class=\"number\">4</span>));</span><br><span class=\"line\">    InsertNextNode(p-&gt;next-&gt;next-&gt;next,CreateNode(<span class=\"number\">5</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//输出链表</span></span><br><span class=\"line\">    printlist(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//后插</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">InsertNextNode</span><span class=\"params\">(DNode *p, DNode *s)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>||s==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    s-&gt;next=p-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;next!=<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        p-&gt;next-&gt;prior=s;</span><br><span class=\"line\">    s-&gt;prior=p;</span><br><span class=\"line\">    p-&gt;next=s;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//删除</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">DeleteNode</span><span class=\"params\">(DNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    p-&gt;prior-&gt;next=p-&gt;next;</span><br><span class=\"line\">    p-&gt;next-&gt;prior=p-&gt;prior;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"2-5-循环链表\"><a href=\"#2-5-循环链表\" class=\"headerlink\" title=\"2.5 循环链表\"></a>2.5 循环链表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/2.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/2.png\" alt=\"数据结构\"></p>\n<h2 id=\"2-6-静态链表\"><a href=\"#2-6-静态链表\" class=\"headerlink\" title=\"2.6 静态链表\"></a>2.6 静态链表</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/3.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/3.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/4.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/4.png\" alt=\"数据结构\"></p>\n<h3 id=\"2-6-1-代码实现\"><a href=\"#2-6-1-代码实现\" class=\"headerlink\" title=\"2.6.1 代码实现\"></a>2.6.1 代码实现</h3><ul>\n<li>插入</li>\n<li>删除</li>\n</ul>\n<h2 id=\"2-7-顺序表vs链表\"><a href=\"#2-7-顺序表vs链表\" class=\"headerlink\" title=\"2.7 顺序表vs链表\"></a>2.7 顺序表vs链表</h2><table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">顺序表</th>\n<th align=\"center\">链表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">逻辑结构</td>\n<td align=\"center\">线性结构</td>\n<td align=\"center\">线性结构</td>\n</tr>\n<tr>\n<td align=\"center\">存储结构</td>\n<td align=\"center\">顺序存储</td>\n<td align=\"center\">链式存储</td>\n</tr>\n<tr>\n<td align=\"center\">优点</td>\n<td align=\"center\">随机存取，存储密度高</td>\n<td align=\"center\">插入和删除</td>\n</tr>\n</tbody></table>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/2_linearlist/doublelinklist/5.png\"><br><img src=\"/img/datastruct/2_linearlist/doublelinklist/5.png\" alt=\"数据结构\"></p>"},{"title":"5.2 二叉树","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/1.png)\n![数据结构](/img/datastruct/5_tree/bintree/1.png)\n<!--more-->\n- 二叉树是有序树，有左右之分\n- 二叉树有五种基本形态：空二叉树、只有根结点、只有左子树、只有右子树、左右子树都有\n\n### 5.2.1 特殊二叉树\n|名称|说明|特点|\n|:---:|:---:|:---:|\n|满二叉树|所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上|![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/2.png)|\n|完全二叉树|叶子结点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树|![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/3.png)|\n|二叉排序树|空树 / 左子树上所有结点的值均小于它的根结点的值；右子树上所有结点的值均大于它的根结点的值；左右子树也分别为二叉排序树||\n|平衡二叉树|空树 / 左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一棵平衡二叉树||\n\n### 5.2.2 一些性质\n- 叶子结点比度为2的结点多1个\n- 第i层最多有2<sup>i-1</sup>个结点\n- 高度为h的二叉树至多有2<sup>h</sup>-1个结点\n- 有n个结点的完全二叉树高度为$$\\lceil log_2(n+1)\\rceil 或 \\lfloor log_2n\\rfloor+1$$\n- 若完全二叉树有2k个结点，n<sub>0</sub>=k,n<sub>1</sub>=1,n<sub>2</sub>=k-1\n\n- 若完全二叉树有2k-1个结点，n<sub>0</sub>=k,n<sub>1</sub>=0,n<sub>2</sub>=k-1\n\n### 5.2.3 存储结构\n- 顺序存储\n```c\n#define MaxSize 100\ntypedef struct{\n    int value;\n    int isEmpty;\n}TreeNode;\n\nTreeNode t[MaxSize];\n```\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/4.png)\n![数据结构](/img/datastruct/5_tree/bintree/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/5.png)\n![数据结构](/img/datastruct/5_tree/bintree/5.png)\n\n- 链式存储\n  \n```c\ntypedef struct BiTnode{\n    int data;\n    struct BiTnode *lchild, *rchild;\n}BiTNode,BiTree;\n```\n- n个结点的二叉链表共有n+1个空链域\n\n### 5.2.4 遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/9.png)\n![数据结构](/img/datastruct/5_tree/bintree/9.png)\n\n- 先序遍历\n```c\n//先序遍历\nvoid PreOrder(BiTree T){\n    if(T){\n        visit(T);//操作\n        PreOrder(T->lchild);\n        PreOrder(T->rchild);\n    }\n}\n```\n- 中序遍历\n```c\n//中序遍历\nvoid InOrder(BiTree T){\n    if(T){\n        InOrder(T->lchild);\n        visit(T);//操作\n        InOrder(T->rchild);\n    }\n}\n```\n- 后序遍历\n```c\n//后序遍历\nvoid PostOrder(BiTree T){\n    if(T){\n        PostOrder(T->lchild);\n        PostOrder(T->rchild);\n        vist(T);//操作\n    }\n}\n```\n\n- 求树的深度\n```c\n//求树的深度\nint treeDepth(BiTree T){\n    if(!T)\n        return 0;\n    else{\n        int l=treeDepth(T->lchild);\n        int r=treeDepth(T->rchild);\n        return (l>r)?(l+1):(r+1);\n    }\n}\n```\n\n- 层次遍历\n```c\n//层次遍历\nvoid LevelOrder(BiTree T){\n    BiTree p;\n    BiTree q[MaxSize];\n    int front=0, rear=0;\n    if(T){\n        rear=(rear+1)%MaxSize;\n        q[rear]=T;\n        while(front!=rear){\n            front=(front+1)%MaxSize;\n            p=q[front];\n            visit(p);\n            if(p->lchild){\n                rear=(rear+1)%MaxSize;\n                q[rear]=p->lchild;\n            }\n            if(p->rchild){\n                rear=(rear+1)%MaxSize;\n                q[rear]=p->rchild;\n            }\n        }\n    }\n}\n```\n\n### 5.2.5 练习\n- 求遍历序列\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/6.png)\n![数据结构](/img/datastruct/5_tree/bintree/6.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/7.png)\n![数据结构](/img/datastruct/5_tree/bintree/7.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/8.png)\n![数据结构](/img/datastruct/5_tree/bintree/8.png)\n\n- 根据序列求树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/10.png)\n![数据结构](/img/datastruct/5_tree/bintree/10.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/11.png)\n![数据结构](/img/datastruct/5_tree/bintree/11.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/12.png)\n![数据结构](/img/datastruct/5_tree/bintree/12.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/13.png)\n![数据结构](/img/datastruct/5_tree/bintree/13.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/14.png)\n![数据结构](/img/datastruct/5_tree/bintree/14.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/15.png)\n![数据结构](/img/datastruct/5_tree/bintree/15.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/16.png)\n![数据结构](/img/datastruct/5_tree/bintree/16.png)\n\n### 5.2.6 线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/17.png)\n![数据结构](/img/datastruct/5_tree/bintree/17.png)\n- 存储结构\n```c\n//线索二叉树\ntypedef struct ThreadNode{\n    int data;\n    struct ThreadNode *lchild, *rchild;\n    int ltag, rtag;//左右线索标志\n}ThreadNode, *ThreadTree;\n```\n- 中序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/18.png)\n![数据结构](/img/datastruct/5_tree/bintree/18.png)\n- 先序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/19.png)\n![数据结构](/img/datastruct/5_tree/bintree/19.png)\n- 后序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/20.png)\n![数据结构](/img/datastruct/5_tree/bintree/20.png)\n- 线索化\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/21.png)\n![数据结构](/img/datastruct/5_tree/bintree/21.png)\n```c\n//土办法找到中序前驱\nBiTNode *p=NULL, *pre=NULL,*final=NULL;\nvoid findPre(BiTree T){\n    if(T){\n        findPre(T->lchild);\n        visit(T);\n        findPre(T->rchild);\n    }\n}\nvoid visit(BiTNode* q){\n    if(q==p)\n        final=pre;\n    else\n        pre=q;\n}\n```\n\n```c\n//中序线索化\nThreadNode *pre=NULL;\nvoid InThread(ThreadTree p){\n    if(p){\n        InThread(p->lchild);\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        InThread(p->rchild);\n    }\n}\n//先序线索化\nvoid PreThread(ThreadTree p){\n    if(p){\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        if(p->ltag==0)\n            PreThread(p->lchild);\n        PreThread(p->rchild);\n    }\n}\n//后序线索化\nvoid PostThread(ThreadTree p){\n    if(p){\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        PreThread(p->lchild);\n        PreThread(p->rchild);\n    }\n}\nvoid CreateInThread(ThreadTree T){\n    pre=NULL;\n    if(T){\n        InThread(T);\n        if(!pre->rchild){\n            pre->rtag=1;\n        }\n    }\n}\n```\n\n- 线索二叉树找前驱/后继\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/22.png)\n![数据结构](/img/datastruct/5_tree/bintree/22.png)\n    - 中序，后继\n\n        1）p->rtag==1，则next=p->rchild\n\n        2）p->rtag==0，则\n        ```c\n        //中序线索二叉树找后继\n        ThreadNode *Firstnode(ThreadNode *p){\n            while(p->ltag==0)\n                p=p->lchild;\n            return p;\n        }\n        ThreadNode *Nextnode(ThreadNode *p){\n            if(p->rtag==0)\n                return Firstnode(p->rchild);\n            else\n                return p->rchild;\n        }\n        ```\n    - 中序，前驱\n\n        1）p->ltag==1，则pre=p->lchild\n\n        2）p->ltag==0,pre=左子树的最右下\n\n        ```c\n        //中序线索二叉树找到前驱\n        ThreadNode *Lastnode(ThreadNode *p){\n            while(p->rtag==0)\n                p=p->rchild;\n            return p;\n        }\n        ThreadNode *Prenode(ThreadNode *p){\n            if(p->ltag==0)\n                return Lastnode(p->lchild);\n            else\n                return p->lchild;\n        }\n        //对中序线索二叉树逆向遍历\n        void InOrder(ThreadNode *T){\n            for(ThreadNode *p=Lastnode(T); p!=NULL; p=Prenode(p))\n                visit(p);\n        }\n        ```\n    - 先序，后继\n\n        1）p->rtag==1，则next=p->rchild\n\n        2）p->rtag==0，则next=左孩子（无则右孩子）\n\n    - 先序，前驱\n\n\n        1）p->ltag==1，则prep->lchild\n    \n        2）p->ltag==0\n    \n        - 若能找到p的父，p为左孩子，则pre=父\n    \n        - 若能找到p的父，p为右孩子，左兄弟空，则pre=父\n    \n        - 若能找到p的父，p为右孩子，左兄弟不空，则pre=左子树中最后一个被中序遍历的结点\n    \n    - 后序，前驱\n    \n        1）p->ltag==1，则pre=p->lchild\n    \n        2）p->ltag==0，则pre=右孩子（无则左孩子）\n    \n    - 后序，后继\n\n\n        1）p->rtag==1，则next->rchild\n    \n        2）p->rtag==0\n    \n        - 若能找到p的父，p为右孩子，则next=父\n    \n        - 若能找到p的父，p为左孩子，右兄弟空，则next=父\n    \n        - 若能找到p的父，p为左孩子，右兄弟不空，则next=右子树中第一个被后序遍历的结点\n\n\n\n","source":"_posts/datastruct/5_tree/2_bintree.md","raw":"---\ntitle: 5.2 二叉树\ndate: 2023-08-07 00:00:00\ntags: [数据结构,树,二叉树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/1.png)\n![数据结构](/img/datastruct/5_tree/bintree/1.png)\n<!--more-->\n- 二叉树是有序树，有左右之分\n- 二叉树有五种基本形态：空二叉树、只有根结点、只有左子树、只有右子树、左右子树都有\n\n### 5.2.1 特殊二叉树\n|名称|说明|特点|\n|:---:|:---:|:---:|\n|满二叉树|所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上|![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/2.png)|\n|完全二叉树|叶子结点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树|![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/3.png)|\n|二叉排序树|空树 / 左子树上所有结点的值均小于它的根结点的值；右子树上所有结点的值均大于它的根结点的值；左右子树也分别为二叉排序树||\n|平衡二叉树|空树 / 左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一棵平衡二叉树||\n\n### 5.2.2 一些性质\n- 叶子结点比度为2的结点多1个\n- 第i层最多有2<sup>i-1</sup>个结点\n- 高度为h的二叉树至多有2<sup>h</sup>-1个结点\n- 有n个结点的完全二叉树高度为$$\\lceil log_2(n+1)\\rceil 或 \\lfloor log_2n\\rfloor+1$$\n- 若完全二叉树有2k个结点，n<sub>0</sub>=k,n<sub>1</sub>=1,n<sub>2</sub>=k-1\n\n- 若完全二叉树有2k-1个结点，n<sub>0</sub>=k,n<sub>1</sub>=0,n<sub>2</sub>=k-1\n\n### 5.2.3 存储结构\n- 顺序存储\n```c\n#define MaxSize 100\ntypedef struct{\n    int value;\n    int isEmpty;\n}TreeNode;\n\nTreeNode t[MaxSize];\n```\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/4.png)\n![数据结构](/img/datastruct/5_tree/bintree/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/5.png)\n![数据结构](/img/datastruct/5_tree/bintree/5.png)\n\n- 链式存储\n  \n```c\ntypedef struct BiTnode{\n    int data;\n    struct BiTnode *lchild, *rchild;\n}BiTNode,BiTree;\n```\n- n个结点的二叉链表共有n+1个空链域\n\n### 5.2.4 遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/9.png)\n![数据结构](/img/datastruct/5_tree/bintree/9.png)\n\n- 先序遍历\n```c\n//先序遍历\nvoid PreOrder(BiTree T){\n    if(T){\n        visit(T);//操作\n        PreOrder(T->lchild);\n        PreOrder(T->rchild);\n    }\n}\n```\n- 中序遍历\n```c\n//中序遍历\nvoid InOrder(BiTree T){\n    if(T){\n        InOrder(T->lchild);\n        visit(T);//操作\n        InOrder(T->rchild);\n    }\n}\n```\n- 后序遍历\n```c\n//后序遍历\nvoid PostOrder(BiTree T){\n    if(T){\n        PostOrder(T->lchild);\n        PostOrder(T->rchild);\n        vist(T);//操作\n    }\n}\n```\n\n- 求树的深度\n```c\n//求树的深度\nint treeDepth(BiTree T){\n    if(!T)\n        return 0;\n    else{\n        int l=treeDepth(T->lchild);\n        int r=treeDepth(T->rchild);\n        return (l>r)?(l+1):(r+1);\n    }\n}\n```\n\n- 层次遍历\n```c\n//层次遍历\nvoid LevelOrder(BiTree T){\n    BiTree p;\n    BiTree q[MaxSize];\n    int front=0, rear=0;\n    if(T){\n        rear=(rear+1)%MaxSize;\n        q[rear]=T;\n        while(front!=rear){\n            front=(front+1)%MaxSize;\n            p=q[front];\n            visit(p);\n            if(p->lchild){\n                rear=(rear+1)%MaxSize;\n                q[rear]=p->lchild;\n            }\n            if(p->rchild){\n                rear=(rear+1)%MaxSize;\n                q[rear]=p->rchild;\n            }\n        }\n    }\n}\n```\n\n### 5.2.5 练习\n- 求遍历序列\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/6.png)\n![数据结构](/img/datastruct/5_tree/bintree/6.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/7.png)\n![数据结构](/img/datastruct/5_tree/bintree/7.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/8.png)\n![数据结构](/img/datastruct/5_tree/bintree/8.png)\n\n- 根据序列求树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/10.png)\n![数据结构](/img/datastruct/5_tree/bintree/10.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/11.png)\n![数据结构](/img/datastruct/5_tree/bintree/11.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/12.png)\n![数据结构](/img/datastruct/5_tree/bintree/12.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/13.png)\n![数据结构](/img/datastruct/5_tree/bintree/13.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/14.png)\n![数据结构](/img/datastruct/5_tree/bintree/14.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/15.png)\n![数据结构](/img/datastruct/5_tree/bintree/15.png)\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/16.png)\n![数据结构](/img/datastruct/5_tree/bintree/16.png)\n\n### 5.2.6 线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/17.png)\n![数据结构](/img/datastruct/5_tree/bintree/17.png)\n- 存储结构\n```c\n//线索二叉树\ntypedef struct ThreadNode{\n    int data;\n    struct ThreadNode *lchild, *rchild;\n    int ltag, rtag;//左右线索标志\n}ThreadNode, *ThreadTree;\n```\n- 中序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/18.png)\n![数据结构](/img/datastruct/5_tree/bintree/18.png)\n- 先序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/19.png)\n![数据结构](/img/datastruct/5_tree/bintree/19.png)\n- 后序线索二叉树\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/20.png)\n![数据结构](/img/datastruct/5_tree/bintree/20.png)\n- 线索化\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/21.png)\n![数据结构](/img/datastruct/5_tree/bintree/21.png)\n```c\n//土办法找到中序前驱\nBiTNode *p=NULL, *pre=NULL,*final=NULL;\nvoid findPre(BiTree T){\n    if(T){\n        findPre(T->lchild);\n        visit(T);\n        findPre(T->rchild);\n    }\n}\nvoid visit(BiTNode* q){\n    if(q==p)\n        final=pre;\n    else\n        pre=q;\n}\n```\n\n```c\n//中序线索化\nThreadNode *pre=NULL;\nvoid InThread(ThreadTree p){\n    if(p){\n        InThread(p->lchild);\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        InThread(p->rchild);\n    }\n}\n//先序线索化\nvoid PreThread(ThreadTree p){\n    if(p){\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        if(p->ltag==0)\n            PreThread(p->lchild);\n        PreThread(p->rchild);\n    }\n}\n//后序线索化\nvoid PostThread(ThreadTree p){\n    if(p){\n        if(!p->lchild){\n            p->lchild=pre;\n            p->ltag=1;\n        }\n        if(!pre->rchild){\n            pre->rchild=p;\n            pre->rtag=1;\n        }\n        pre=p;\n        PreThread(p->lchild);\n        PreThread(p->rchild);\n    }\n}\nvoid CreateInThread(ThreadTree T){\n    pre=NULL;\n    if(T){\n        InThread(T);\n        if(!pre->rchild){\n            pre->rtag=1;\n        }\n    }\n}\n```\n\n- 线索二叉树找前驱/后继\n![](../../../../themes/yilia/source/img/datastruct/5_tree/bintree/22.png)\n![数据结构](/img/datastruct/5_tree/bintree/22.png)\n    - 中序，后继\n\n        1）p->rtag==1，则next=p->rchild\n\n        2）p->rtag==0，则\n        ```c\n        //中序线索二叉树找后继\n        ThreadNode *Firstnode(ThreadNode *p){\n            while(p->ltag==0)\n                p=p->lchild;\n            return p;\n        }\n        ThreadNode *Nextnode(ThreadNode *p){\n            if(p->rtag==0)\n                return Firstnode(p->rchild);\n            else\n                return p->rchild;\n        }\n        ```\n    - 中序，前驱\n\n        1）p->ltag==1，则pre=p->lchild\n\n        2）p->ltag==0,pre=左子树的最右下\n\n        ```c\n        //中序线索二叉树找到前驱\n        ThreadNode *Lastnode(ThreadNode *p){\n            while(p->rtag==0)\n                p=p->rchild;\n            return p;\n        }\n        ThreadNode *Prenode(ThreadNode *p){\n            if(p->ltag==0)\n                return Lastnode(p->lchild);\n            else\n                return p->lchild;\n        }\n        //对中序线索二叉树逆向遍历\n        void InOrder(ThreadNode *T){\n            for(ThreadNode *p=Lastnode(T); p!=NULL; p=Prenode(p))\n                visit(p);\n        }\n        ```\n    - 先序，后继\n\n        1）p->rtag==1，则next=p->rchild\n\n        2）p->rtag==0，则next=左孩子（无则右孩子）\n\n    - 先序，前驱\n\n\n        1）p->ltag==1，则prep->lchild\n    \n        2）p->ltag==0\n    \n        - 若能找到p的父，p为左孩子，则pre=父\n    \n        - 若能找到p的父，p为右孩子，左兄弟空，则pre=父\n    \n        - 若能找到p的父，p为右孩子，左兄弟不空，则pre=左子树中最后一个被中序遍历的结点\n    \n    - 后序，前驱\n    \n        1）p->ltag==1，则pre=p->lchild\n    \n        2）p->ltag==0，则pre=右孩子（无则左孩子）\n    \n    - 后序，后继\n\n\n        1）p->rtag==1，则next->rchild\n    \n        2）p->rtag==0\n    \n        - 若能找到p的父，p为右孩子，则next=父\n    \n        - 若能找到p的父，p为左孩子，右兄弟空，则next=父\n    \n        - 若能找到p的父，p为左孩子，右兄弟不空，则next=右子树中第一个被后序遍历的结点\n\n\n\n","slug":"datastruct/5_tree/2_bintree","published":1,"updated":"2023-10-23T12:16:20.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858v001t7svw46o68o8s","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/1.png\"><br><img src=\"/img/datastruct/5_tree/bintree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li>二叉树是有序树，有左右之分</li>\n<li>二叉树有五种基本形态：空二叉树、只有根结点、只有左子树、只有右子树、左右子树都有</li>\n</ul>\n<h3 id=\"5-2-1-特殊二叉树\"><a href=\"#5-2-1-特殊二叉树\" class=\"headerlink\" title=\"5.2.1 特殊二叉树\"></a>5.2.1 特殊二叉树</h3><table>\n<thead>\n<tr>\n<th align=\"center\">名称</th>\n<th align=\"center\">说明</th>\n<th align=\"center\">特点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">满二叉树</td>\n<td align=\"center\">所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/2.png\"></td>\n</tr>\n<tr>\n<td align=\"center\">完全二叉树</td>\n<td align=\"center\">叶子结点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/3.png\"></td>\n</tr>\n<tr>\n<td align=\"center\">二叉排序树</td>\n<td align=\"center\">空树 &#x2F; 左子树上所有结点的值均小于它的根结点的值；右子树上所有结点的值均大于它的根结点的值；左右子树也分别为二叉排序树</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">平衡二叉树</td>\n<td align=\"center\">空树 &#x2F; 左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一棵平衡二叉树</td>\n<td align=\"center\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"5-2-2-一些性质\"><a href=\"#5-2-2-一些性质\" class=\"headerlink\" title=\"5.2.2 一些性质\"></a>5.2.2 一些性质</h3><ul>\n<li><p>叶子结点比度为2的结点多1个</p>\n</li>\n<li><p>第i层最多有2<sup>i-1</sup>个结点</p>\n</li>\n<li><p>高度为h的二叉树至多有2<sup>h</sup>-1个结点</p>\n</li>\n<li><p>有n个结点的完全二叉树高度为$$\\lceil log_2(n+1)\\rceil 或 \\lfloor log_2n\\rfloor+1$$</p>\n</li>\n<li><p>若完全二叉树有2k个结点，n<sub>0</sub>&#x3D;k,n<sub>1</sub>&#x3D;1,n<sub>2</sub>&#x3D;k-1</p>\n</li>\n<li><p>若完全二叉树有2k-1个结点，n<sub>0</sub>&#x3D;k,n<sub>1</sub>&#x3D;0,n<sub>2</sub>&#x3D;k-1</p>\n</li>\n</ul>\n<h3 id=\"5-2-3-存储结构\"><a href=\"#5-2-3-存储结构\" class=\"headerlink\" title=\"5.2.3 存储结构\"></a>5.2.3 存储结构</h3><ul>\n<li>顺序存储<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 100</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> value;</span><br><span class=\"line\">    <span class=\"type\">int</span> isEmpty;</span><br><span class=\"line\">&#125;TreeNode;</span><br><span class=\"line\"></span><br><span class=\"line\">TreeNode t[MaxSize];</span><br></pre></td></tr></table></figure>\n<img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/4.png\"><br><img src=\"/img/datastruct/5_tree/bintree/4.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/5.png\"><br><img src=\"/img/datastruct/5_tree/bintree/5.png\" alt=\"数据结构\"></p>\n<ul>\n<li>链式存储</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTnode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTnode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">&#125;BiTNode,BiTree;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>n个结点的二叉链表共有n+1个空链域</li>\n</ul>\n<h3 id=\"5-2-4-遍历\"><a href=\"#5-2-4-遍历\" class=\"headerlink\" title=\"5.2.4 遍历\"></a>5.2.4 遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/9.png\"><br><img src=\"/img/datastruct/5_tree/bintree/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>先序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//先序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PreOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        visit(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">        PreOrder(T-&gt;lchild);</span><br><span class=\"line\">        PreOrder(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>中序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        InOrder(T-&gt;lchild);</span><br><span class=\"line\">        visit(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">        InOrder(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>后序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//后序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PostOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        PostOrder(T-&gt;lchild);</span><br><span class=\"line\">        PostOrder(T-&gt;rchild);</span><br><span class=\"line\">        vist(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>求树的深度</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//求树的深度</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">treeDepth</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!T)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> l=treeDepth(T-&gt;lchild);</span><br><span class=\"line\">        <span class=\"type\">int</span> r=treeDepth(T-&gt;rchild);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (l&gt;r)?(l+<span class=\"number\">1</span>):(r+<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>层次遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//层次遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">LevelOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    BiTree p;</span><br><span class=\"line\">    BiTree q[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> front=<span class=\"number\">0</span>, rear=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">        q[rear]=T;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(front!=rear)&#123;</span><br><span class=\"line\">            front=(front+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">            p=q[front];</span><br><span class=\"line\">            visit(p);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(p-&gt;lchild)&#123;</span><br><span class=\"line\">                rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">                q[rear]=p-&gt;lchild;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(p-&gt;rchild)&#123;</span><br><span class=\"line\">                rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">                q[rear]=p-&gt;rchild;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-2-5-练习\"><a href=\"#5-2-5-练习\" class=\"headerlink\" title=\"5.2.5 练习\"></a>5.2.5 练习</h3><ul>\n<li><p>求遍历序列<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/6.png\"><br><img src=\"/img/datastruct/5_tree/bintree/6.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/7.png\"><br><img src=\"/img/datastruct/5_tree/bintree/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/8.png\"><br><img src=\"/img/datastruct/5_tree/bintree/8.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>根据序列求树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/10.png\"><br><img src=\"/img/datastruct/5_tree/bintree/10.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/11.png\"><br><img src=\"/img/datastruct/5_tree/bintree/11.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/12.png\"><br><img src=\"/img/datastruct/5_tree/bintree/12.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/13.png\"><br><img src=\"/img/datastruct/5_tree/bintree/13.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/14.png\"><br><img src=\"/img/datastruct/5_tree/bintree/14.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/15.png\"><br><img src=\"/img/datastruct/5_tree/bintree/15.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/16.png\"><br><img src=\"/img/datastruct/5_tree/bintree/16.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<h3 id=\"5-2-6-线索二叉树\"><a href=\"#5-2-6-线索二叉树\" class=\"headerlink\" title=\"5.2.6 线索二叉树\"></a>5.2.6 线索二叉树</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/17.png\"><br><img src=\"/img/datastruct/5_tree/bintree/17.png\" alt=\"数据结构\"></p>\n<ul>\n<li>存储结构<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//线索二叉树</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ThreadNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ThreadNode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> ltag, rtag;<span class=\"comment\">//左右线索标志</span></span><br><span class=\"line\">&#125;ThreadNode, *ThreadTree;</span><br></pre></td></tr></table></figure></li>\n<li>中序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/18.png\"><br><img src=\"/img/datastruct/5_tree/bintree/18.png\" alt=\"数据结构\"></li>\n<li>先序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/19.png\"><br><img src=\"/img/datastruct/5_tree/bintree/19.png\" alt=\"数据结构\"></li>\n<li>后序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/20.png\"><br><img src=\"/img/datastruct/5_tree/bintree/20.png\" alt=\"数据结构\"></li>\n<li>线索化<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/21.png\"><br><img src=\"/img/datastruct/5_tree/bintree/21.png\" alt=\"数据结构\"><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//土办法找到中序前驱</span></span><br><span class=\"line\">BiTNode *p=<span class=\"literal\">NULL</span>, *pre=<span class=\"literal\">NULL</span>,*final=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">findPre</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        findPre(T-&gt;lchild);</span><br><span class=\"line\">        visit(T);</span><br><span class=\"line\">        findPre(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">visit</span><span class=\"params\">(BiTNode* q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q==p)</span><br><span class=\"line\">        final=pre;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        pre=q;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索化</span></span><br><span class=\"line\">ThreadNode *pre=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        InThread(p-&gt;lchild);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        InThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//先序线索化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PreThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">            PreThread(p-&gt;lchild);</span><br><span class=\"line\">        PreThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//后序线索化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PostThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        PreThread(p-&gt;lchild);</span><br><span class=\"line\">        PreThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">CreateInThread</span><span class=\"params\">(ThreadTree T)</span>&#123;</span><br><span class=\"line\">    pre=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        InThread(T);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>线索二叉树找前驱&#x2F;后继<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/22.png\"><br><img src=\"/img/datastruct/5_tree/bintree/22.png\" alt=\"数据结构\"><ul>\n<li><p>中序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next&#x3D;p-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0，则</p>\n  <figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索二叉树找后继</span></span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Firstnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        p=p-&gt;lchild;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Nextnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;rtag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Firstnode(p-&gt;rchild);</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> p-&gt;rchild;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>中序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则pre&#x3D;p-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0,pre&#x3D;左子树的最右下</p>\n  <figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索二叉树找到前驱</span></span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Lastnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p-&gt;rtag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        p=p-&gt;rchild;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Prenode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Lastnode(p-&gt;lchild);</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> p-&gt;lchild;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//对中序线索二叉树逆向遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InOrder</span><span class=\"params\">(ThreadNode *T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(ThreadNode *p=Lastnode(T); p!=<span class=\"literal\">NULL</span>; p=Prenode(p))</span><br><span class=\"line\">        visit(p);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>先序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next&#x3D;p-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0，则next&#x3D;左孩子（无则右孩子）</p>\n</li>\n<li><p>先序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则prep-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0</p>\n<ul>\n<li><p>若能找到p的父，p为左孩子，则pre&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为右孩子，左兄弟空，则pre&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为右孩子，左兄弟不空，则pre&#x3D;左子树中最后一个被中序遍历的结点</p>\n</li>\n</ul>\n</li>\n<li><p>后序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则pre&#x3D;p-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0，则pre&#x3D;右孩子（无则左孩子）</p>\n</li>\n<li><p>后序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0</p>\n<ul>\n<li><p>若能找到p的父，p为右孩子，则next&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为左孩子，右兄弟空，则next&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为左孩子，右兄弟不空，则next&#x3D;右子树中第一个被后序遍历的结点</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/1.png\"><br><img src=\"/img/datastruct/5_tree/bintree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li>二叉树是有序树，有左右之分</li>\n<li>二叉树有五种基本形态：空二叉树、只有根结点、只有左子树、只有右子树、左右子树都有</li>\n</ul>\n<h3 id=\"5-2-1-特殊二叉树\"><a href=\"#5-2-1-特殊二叉树\" class=\"headerlink\" title=\"5.2.1 特殊二叉树\"></a>5.2.1 特殊二叉树</h3><table>\n<thead>\n<tr>\n<th align=\"center\">名称</th>\n<th align=\"center\">说明</th>\n<th align=\"center\">特点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">满二叉树</td>\n<td align=\"center\">所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/2.png\"></td>\n</tr>\n<tr>\n<td align=\"center\">完全二叉树</td>\n<td align=\"center\">叶子结点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树</td>\n<td align=\"center\"><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/3.png\"></td>\n</tr>\n<tr>\n<td align=\"center\">二叉排序树</td>\n<td align=\"center\">空树 &#x2F; 左子树上所有结点的值均小于它的根结点的值；右子树上所有结点的值均大于它的根结点的值；左右子树也分别为二叉排序树</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">平衡二叉树</td>\n<td align=\"center\">空树 &#x2F; 左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一棵平衡二叉树</td>\n<td align=\"center\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"5-2-2-一些性质\"><a href=\"#5-2-2-一些性质\" class=\"headerlink\" title=\"5.2.2 一些性质\"></a>5.2.2 一些性质</h3><ul>\n<li><p>叶子结点比度为2的结点多1个</p>\n</li>\n<li><p>第i层最多有2<sup>i-1</sup>个结点</p>\n</li>\n<li><p>高度为h的二叉树至多有2<sup>h</sup>-1个结点</p>\n</li>\n<li><p>有n个结点的完全二叉树高度为$$\\lceil log_2(n+1)\\rceil 或 \\lfloor log_2n\\rfloor+1$$</p>\n</li>\n<li><p>若完全二叉树有2k个结点，n<sub>0</sub>&#x3D;k,n<sub>1</sub>&#x3D;1,n<sub>2</sub>&#x3D;k-1</p>\n</li>\n<li><p>若完全二叉树有2k-1个结点，n<sub>0</sub>&#x3D;k,n<sub>1</sub>&#x3D;0,n<sub>2</sub>&#x3D;k-1</p>\n</li>\n</ul>\n<h3 id=\"5-2-3-存储结构\"><a href=\"#5-2-3-存储结构\" class=\"headerlink\" title=\"5.2.3 存储结构\"></a>5.2.3 存储结构</h3><ul>\n<li>顺序存储<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> MaxSize 100</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> value;</span><br><span class=\"line\">    <span class=\"type\">int</span> isEmpty;</span><br><span class=\"line\">&#125;TreeNode;</span><br><span class=\"line\"></span><br><span class=\"line\">TreeNode t[MaxSize];</span><br></pre></td></tr></table></figure>\n<img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/4.png\"><br><img src=\"/img/datastruct/5_tree/bintree/4.png\" alt=\"数据结构\"></li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/5.png\"><br><img src=\"/img/datastruct/5_tree/bintree/5.png\" alt=\"数据结构\"></p>\n<ul>\n<li>链式存储</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTnode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTnode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">&#125;BiTNode,BiTree;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>n个结点的二叉链表共有n+1个空链域</li>\n</ul>\n<h3 id=\"5-2-4-遍历\"><a href=\"#5-2-4-遍历\" class=\"headerlink\" title=\"5.2.4 遍历\"></a>5.2.4 遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/9.png\"><br><img src=\"/img/datastruct/5_tree/bintree/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>先序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//先序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PreOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        visit(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">        PreOrder(T-&gt;lchild);</span><br><span class=\"line\">        PreOrder(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>中序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        InOrder(T-&gt;lchild);</span><br><span class=\"line\">        visit(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">        InOrder(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>后序遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//后序遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PostOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        PostOrder(T-&gt;lchild);</span><br><span class=\"line\">        PostOrder(T-&gt;rchild);</span><br><span class=\"line\">        vist(T);<span class=\"comment\">//操作</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>求树的深度</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//求树的深度</span></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">treeDepth</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!T)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> l=treeDepth(T-&gt;lchild);</span><br><span class=\"line\">        <span class=\"type\">int</span> r=treeDepth(T-&gt;rchild);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (l&gt;r)?(l+<span class=\"number\">1</span>):(r+<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>层次遍历</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//层次遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">LevelOrder</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    BiTree p;</span><br><span class=\"line\">    BiTree q[MaxSize];</span><br><span class=\"line\">    <span class=\"type\">int</span> front=<span class=\"number\">0</span>, rear=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">        q[rear]=T;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(front!=rear)&#123;</span><br><span class=\"line\">            front=(front+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">            p=q[front];</span><br><span class=\"line\">            visit(p);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(p-&gt;lchild)&#123;</span><br><span class=\"line\">                rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">                q[rear]=p-&gt;lchild;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(p-&gt;rchild)&#123;</span><br><span class=\"line\">                rear=(rear+<span class=\"number\">1</span>)%MaxSize;</span><br><span class=\"line\">                q[rear]=p-&gt;rchild;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-2-5-练习\"><a href=\"#5-2-5-练习\" class=\"headerlink\" title=\"5.2.5 练习\"></a>5.2.5 练习</h3><ul>\n<li><p>求遍历序列<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/6.png\"><br><img src=\"/img/datastruct/5_tree/bintree/6.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/7.png\"><br><img src=\"/img/datastruct/5_tree/bintree/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/8.png\"><br><img src=\"/img/datastruct/5_tree/bintree/8.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>根据序列求树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/10.png\"><br><img src=\"/img/datastruct/5_tree/bintree/10.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/11.png\"><br><img src=\"/img/datastruct/5_tree/bintree/11.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/12.png\"><br><img src=\"/img/datastruct/5_tree/bintree/12.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/13.png\"><br><img src=\"/img/datastruct/5_tree/bintree/13.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/14.png\"><br><img src=\"/img/datastruct/5_tree/bintree/14.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/15.png\"><br><img src=\"/img/datastruct/5_tree/bintree/15.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/16.png\"><br><img src=\"/img/datastruct/5_tree/bintree/16.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n<h3 id=\"5-2-6-线索二叉树\"><a href=\"#5-2-6-线索二叉树\" class=\"headerlink\" title=\"5.2.6 线索二叉树\"></a>5.2.6 线索二叉树</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/17.png\"><br><img src=\"/img/datastruct/5_tree/bintree/17.png\" alt=\"数据结构\"></p>\n<ul>\n<li>存储结构<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//线索二叉树</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ThreadNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ThreadNode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> ltag, rtag;<span class=\"comment\">//左右线索标志</span></span><br><span class=\"line\">&#125;ThreadNode, *ThreadTree;</span><br></pre></td></tr></table></figure></li>\n<li>中序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/18.png\"><br><img src=\"/img/datastruct/5_tree/bintree/18.png\" alt=\"数据结构\"></li>\n<li>先序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/19.png\"><br><img src=\"/img/datastruct/5_tree/bintree/19.png\" alt=\"数据结构\"></li>\n<li>后序线索二叉树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/20.png\"><br><img src=\"/img/datastruct/5_tree/bintree/20.png\" alt=\"数据结构\"></li>\n<li>线索化<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/21.png\"><br><img src=\"/img/datastruct/5_tree/bintree/21.png\" alt=\"数据结构\"><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//土办法找到中序前驱</span></span><br><span class=\"line\">BiTNode *p=<span class=\"literal\">NULL</span>, *pre=<span class=\"literal\">NULL</span>,*final=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">findPre</span><span class=\"params\">(BiTree T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        findPre(T-&gt;lchild);</span><br><span class=\"line\">        visit(T);</span><br><span class=\"line\">        findPre(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">visit</span><span class=\"params\">(BiTNode* q)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q==p)</span><br><span class=\"line\">        final=pre;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        pre=q;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索化</span></span><br><span class=\"line\">ThreadNode *pre=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        InThread(p-&gt;lchild);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        InThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//先序线索化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PreThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">            PreThread(p-&gt;lchild);</span><br><span class=\"line\">        PreThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//后序线索化</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">PostThread</span><span class=\"params\">(ThreadTree p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!p-&gt;lchild)&#123;</span><br><span class=\"line\">            p-&gt;lchild=pre;</span><br><span class=\"line\">            p-&gt;ltag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rchild=p;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre=p;</span><br><span class=\"line\">        PreThread(p-&gt;lchild);</span><br><span class=\"line\">        PreThread(p-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">CreateInThread</span><span class=\"params\">(ThreadTree T)</span>&#123;</span><br><span class=\"line\">    pre=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)&#123;</span><br><span class=\"line\">        InThread(T);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!pre-&gt;rchild)&#123;</span><br><span class=\"line\">            pre-&gt;rtag=<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>线索二叉树找前驱&#x2F;后继<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/bintree/22.png\"><br><img src=\"/img/datastruct/5_tree/bintree/22.png\" alt=\"数据结构\"><ul>\n<li><p>中序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next&#x3D;p-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0，则</p>\n  <figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索二叉树找后继</span></span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Firstnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        p=p-&gt;lchild;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Nextnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;rtag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Firstnode(p-&gt;rchild);</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> p-&gt;rchild;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>中序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则pre&#x3D;p-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0,pre&#x3D;左子树的最右下</p>\n  <figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//中序线索二叉树找到前驱</span></span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Lastnode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(p-&gt;rtag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        p=p-&gt;rchild;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">ThreadNode *<span class=\"title function_\">Prenode</span><span class=\"params\">(ThreadNode *p)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(p-&gt;ltag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Lastnode(p-&gt;lchild);</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> p-&gt;lchild;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//对中序线索二叉树逆向遍历</span></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">InOrder</span><span class=\"params\">(ThreadNode *T)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(ThreadNode *p=Lastnode(T); p!=<span class=\"literal\">NULL</span>; p=Prenode(p))</span><br><span class=\"line\">        visit(p);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>先序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next&#x3D;p-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0，则next&#x3D;左孩子（无则右孩子）</p>\n</li>\n<li><p>先序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则prep-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0</p>\n<ul>\n<li><p>若能找到p的父，p为左孩子，则pre&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为右孩子，左兄弟空，则pre&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为右孩子，左兄弟不空，则pre&#x3D;左子树中最后一个被中序遍历的结点</p>\n</li>\n</ul>\n</li>\n<li><p>后序，前驱</p>\n<p>  1）p-&gt;ltag&#x3D;&#x3D;1，则pre&#x3D;p-&gt;lchild</p>\n<p>  2）p-&gt;ltag&#x3D;&#x3D;0，则pre&#x3D;右孩子（无则左孩子）</p>\n</li>\n<li><p>后序，后继</p>\n<p>  1）p-&gt;rtag&#x3D;&#x3D;1，则next-&gt;rchild</p>\n<p>  2）p-&gt;rtag&#x3D;&#x3D;0</p>\n<ul>\n<li><p>若能找到p的父，p为右孩子，则next&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为左孩子，右兄弟空，则next&#x3D;父</p>\n</li>\n<li><p>若能找到p的父，p为左孩子，右兄弟不空，则next&#x3D;右子树中第一个被后序遍历的结点</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>"},{"title":"5.3 树的存储结构","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/1.png)\n![数据结构](/img/datastruct/5_tree/treesave/1.png)\n<!--more-->\n\n### 5.3.1 双亲表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/2.png)\n![数据结构](/img/datastruct/5_tree/treesave/2.png)\n- 查双亲方便\n- 空数据导致遍历慢\n- 查孩子只能从头遍历\n\n### 5.3.2 孩子表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/3.png)\n![数据结构](/img/datastruct/5_tree/treesave/3.png)\n\n### 5.3.3 孩子兄弟表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/4.png)\n![数据结构](/img/datastruct/5_tree/treesave/4.png)\n\n## 5.3.4 树、森林的遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/5.png)\n![数据结构](/img/datastruct/5_tree/treesave/5.png)\n\n### 5.3.5 树的先根遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/6.png)\n![数据结构](/img/datastruct/5_tree/treesave/6.png)\n\n### 5.3.6 树的后根遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/7.png)\n![数据结构](/img/datastruct/5_tree/treesave/7.png)\n\n### 5.3.7 树的层次遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/8.png)\n![数据结构](/img/datastruct/5_tree/treesave/8.png)\n\n|树|森林|二叉树\n|:---|:---|:---|\n|先根遍历|先根遍历|先序遍历|\n|后根遍历|中序遍历|中序遍历|","source":"_posts/datastruct/5_tree/3_treesave.md","raw":"---\ntitle: 5.3 树的存储结构\ndate: 2023-08-07 00:00:00\ntags: [数据结构,树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/1.png)\n![数据结构](/img/datastruct/5_tree/treesave/1.png)\n<!--more-->\n\n### 5.3.1 双亲表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/2.png)\n![数据结构](/img/datastruct/5_tree/treesave/2.png)\n- 查双亲方便\n- 空数据导致遍历慢\n- 查孩子只能从头遍历\n\n### 5.3.2 孩子表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/3.png)\n![数据结构](/img/datastruct/5_tree/treesave/3.png)\n\n### 5.3.3 孩子兄弟表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/4.png)\n![数据结构](/img/datastruct/5_tree/treesave/4.png)\n\n## 5.3.4 树、森林的遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/5.png)\n![数据结构](/img/datastruct/5_tree/treesave/5.png)\n\n### 5.3.5 树的先根遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/6.png)\n![数据结构](/img/datastruct/5_tree/treesave/6.png)\n\n### 5.3.6 树的后根遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/7.png)\n![数据结构](/img/datastruct/5_tree/treesave/7.png)\n\n### 5.3.7 树的层次遍历\n![](../../../../themes/yilia/source/img/datastruct/5_tree/treesave/8.png)\n![数据结构](/img/datastruct/5_tree/treesave/8.png)\n\n|树|森林|二叉树\n|:---|:---|:---|\n|先根遍历|先根遍历|先序遍历|\n|后根遍历|中序遍历|中序遍历|","slug":"datastruct/5_tree/3_treesave","published":1,"updated":"2023-10-23T12:20:08.035Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858v001y7svwc62p6b4u","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/1.png\"><br><img src=\"/img/datastruct/5_tree/treesave/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"5-3-1-双亲表示法\"><a href=\"#5-3-1-双亲表示法\" class=\"headerlink\" title=\"5.3.1 双亲表示法\"></a>5.3.1 双亲表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/2.png\"><br><img src=\"/img/datastruct/5_tree/treesave/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>查双亲方便</li>\n<li>空数据导致遍历慢</li>\n<li>查孩子只能从头遍历</li>\n</ul>\n<h3 id=\"5-3-2-孩子表示法\"><a href=\"#5-3-2-孩子表示法\" class=\"headerlink\" title=\"5.3.2 孩子表示法\"></a>5.3.2 孩子表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/3.png\"><br><img src=\"/img/datastruct/5_tree/treesave/3.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-3-孩子兄弟表示法\"><a href=\"#5-3-3-孩子兄弟表示法\" class=\"headerlink\" title=\"5.3.3 孩子兄弟表示法\"></a>5.3.3 孩子兄弟表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/4.png\"><br><img src=\"/img/datastruct/5_tree/treesave/4.png\" alt=\"数据结构\"></p>\n<h2 id=\"5-3-4-树、森林的遍历\"><a href=\"#5-3-4-树、森林的遍历\" class=\"headerlink\" title=\"5.3.4 树、森林的遍历\"></a>5.3.4 树、森林的遍历</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/5.png\"><br><img src=\"/img/datastruct/5_tree/treesave/5.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-5-树的先根遍历\"><a href=\"#5-3-5-树的先根遍历\" class=\"headerlink\" title=\"5.3.5 树的先根遍历\"></a>5.3.5 树的先根遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/6.png\"><br><img src=\"/img/datastruct/5_tree/treesave/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-6-树的后根遍历\"><a href=\"#5-3-6-树的后根遍历\" class=\"headerlink\" title=\"5.3.6 树的后根遍历\"></a>5.3.6 树的后根遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/7.png\"><br><img src=\"/img/datastruct/5_tree/treesave/7.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-7-树的层次遍历\"><a href=\"#5-3-7-树的层次遍历\" class=\"headerlink\" title=\"5.3.7 树的层次遍历\"></a>5.3.7 树的层次遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/8.png\"><br><img src=\"/img/datastruct/5_tree/treesave/8.png\" alt=\"数据结构\"></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">树</th>\n<th align=\"left\">森林</th>\n<th align=\"left\">二叉树</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">先根遍历</td>\n<td align=\"left\">先根遍历</td>\n<td align=\"left\">先序遍历</td>\n</tr>\n<tr>\n<td align=\"left\">后根遍历</td>\n<td align=\"left\">中序遍历</td>\n<td align=\"left\">中序遍历</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/1.png\"><br><img src=\"/img/datastruct/5_tree/treesave/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"5-3-1-双亲表示法\"><a href=\"#5-3-1-双亲表示法\" class=\"headerlink\" title=\"5.3.1 双亲表示法\"></a>5.3.1 双亲表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/2.png\"><br><img src=\"/img/datastruct/5_tree/treesave/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>查双亲方便</li>\n<li>空数据导致遍历慢</li>\n<li>查孩子只能从头遍历</li>\n</ul>\n<h3 id=\"5-3-2-孩子表示法\"><a href=\"#5-3-2-孩子表示法\" class=\"headerlink\" title=\"5.3.2 孩子表示法\"></a>5.3.2 孩子表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/3.png\"><br><img src=\"/img/datastruct/5_tree/treesave/3.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-3-孩子兄弟表示法\"><a href=\"#5-3-3-孩子兄弟表示法\" class=\"headerlink\" title=\"5.3.3 孩子兄弟表示法\"></a>5.3.3 孩子兄弟表示法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/4.png\"><br><img src=\"/img/datastruct/5_tree/treesave/4.png\" alt=\"数据结构\"></p>\n<h2 id=\"5-3-4-树、森林的遍历\"><a href=\"#5-3-4-树、森林的遍历\" class=\"headerlink\" title=\"5.3.4 树、森林的遍历\"></a>5.3.4 树、森林的遍历</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/5.png\"><br><img src=\"/img/datastruct/5_tree/treesave/5.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-5-树的先根遍历\"><a href=\"#5-3-5-树的先根遍历\" class=\"headerlink\" title=\"5.3.5 树的先根遍历\"></a>5.3.5 树的先根遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/6.png\"><br><img src=\"/img/datastruct/5_tree/treesave/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-6-树的后根遍历\"><a href=\"#5-3-6-树的后根遍历\" class=\"headerlink\" title=\"5.3.6 树的后根遍历\"></a>5.3.6 树的后根遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/7.png\"><br><img src=\"/img/datastruct/5_tree/treesave/7.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-3-7-树的层次遍历\"><a href=\"#5-3-7-树的层次遍历\" class=\"headerlink\" title=\"5.3.7 树的层次遍历\"></a>5.3.7 树的层次遍历</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/treesave/8.png\"><br><img src=\"/img/datastruct/5_tree/treesave/8.png\" alt=\"数据结构\"></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">树</th>\n<th align=\"left\">森林</th>\n<th align=\"left\">二叉树</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">先根遍历</td>\n<td align=\"left\">先根遍历</td>\n<td align=\"left\">先序遍历</td>\n</tr>\n<tr>\n<td align=\"left\">后根遍历</td>\n<td align=\"left\">中序遍历</td>\n<td align=\"left\">中序遍历</td>\n</tr>\n</tbody></table>"},{"title":"5.1 树","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png)\n![数据结构](/img/datastruct/5_tree/tree/1.png)\n<!--more-->\n\n## 5.1.1 一些性质\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/3.png)\n![数据结构](/img/datastruct/5_tree/tree/3.png)\n- 根在第0层\n- 节点数=总度数+1\n- 结点的度：结点拥有的子树的个数\n- m叉树中可以没有m个子树，但是不能超过m个子树\n- 度为m的树，第i层最多有$$m^{i-1}$$个结点\n- 高度为h的m叉树，最多有$$\\frac{m^h-1}{m-1}$$个结点\n- 高度为h的m叉树，最少有h个结点\n- 高度为h，度为m的树，最多有$$\\frac{m^{h+1}-1}{m-1}$$个结点，最少有h+m-1个结点\n- n个结点的m叉树的最小高度为：$$\\lceil log_m(n(m-1)+1)\\rceil$$\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png)\n![数据结构](/img/datastruct/5_tree/tree/1.png)","source":"_posts/datastruct/5_tree/1_tree.md","raw":"---\ntitle: 5.1 树\ndate: 2023-08-07 00:00:00\ntags: [数据结构,树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png)\n![数据结构](/img/datastruct/5_tree/tree/1.png)\n<!--more-->\n\n## 5.1.1 一些性质\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/3.png)\n![数据结构](/img/datastruct/5_tree/tree/3.png)\n- 根在第0层\n- 节点数=总度数+1\n- 结点的度：结点拥有的子树的个数\n- m叉树中可以没有m个子树，但是不能超过m个子树\n- 度为m的树，第i层最多有$$m^{i-1}$$个结点\n- 高度为h的m叉树，最多有$$\\frac{m^h-1}{m-1}$$个结点\n- 高度为h的m叉树，最少有h个结点\n- 高度为h，度为m的树，最多有$$\\frac{m^{h+1}-1}{m-1}$$个结点，最少有h+m-1个结点\n- n个结点的m叉树的最小高度为：$$\\lceil log_m(n(m-1)+1)\\rceil$$\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png)\n![数据结构](/img/datastruct/5_tree/tree/1.png)","slug":"datastruct/5_tree/1_tree","published":1,"updated":"2023-10-23T12:15:55.713Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858w00207svwdai5axd1","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png\"><br><img src=\"/img/datastruct/5_tree/tree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h2 id=\"5-1-1-一些性质\"><a href=\"#5-1-1-一些性质\" class=\"headerlink\" title=\"5.1.1 一些性质\"></a>5.1.1 一些性质</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/3.png\"><br><img src=\"/img/datastruct/5_tree/tree/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>根在第0层</li>\n<li>节点数&#x3D;总度数+1</li>\n<li>结点的度：结点拥有的子树的个数</li>\n<li>m叉树中可以没有m个子树，但是不能超过m个子树</li>\n<li>度为m的树，第i层最多有$$m^{i-1}$$个结点</li>\n<li>高度为h的m叉树，最多有$$\\frac{m^h-1}{m-1}$$个结点</li>\n<li>高度为h的m叉树，最少有h个结点</li>\n<li>高度为h，度为m的树，最多有$$\\frac{m^{h+1}-1}{m-1}$$个结点，最少有h+m-1个结点</li>\n<li>n个结点的m叉树的最小高度为：$$\\lceil log_m(n(m-1)+1)\\rceil$$</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png\"><br><img src=\"/img/datastruct/5_tree/tree/1.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png\"><br><img src=\"/img/datastruct/5_tree/tree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h2 id=\"5-1-1-一些性质\"><a href=\"#5-1-1-一些性质\" class=\"headerlink\" title=\"5.1.1 一些性质\"></a>5.1.1 一些性质</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/3.png\"><br><img src=\"/img/datastruct/5_tree/tree/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>根在第0层</li>\n<li>节点数&#x3D;总度数+1</li>\n<li>结点的度：结点拥有的子树的个数</li>\n<li>m叉树中可以没有m个子树，但是不能超过m个子树</li>\n<li>度为m的树，第i层最多有$$m^{i-1}$$个结点</li>\n<li>高度为h的m叉树，最多有$$\\frac{m^h-1}{m-1}$$个结点</li>\n<li>高度为h的m叉树，最少有h个结点</li>\n<li>高度为h，度为m的树，最多有$$\\frac{m^{h+1}-1}{m-1}$$个结点，最少有h+m-1个结点</li>\n<li>n个结点的m叉树的最小高度为：$$\\lceil log_m(n(m-1)+1)\\rceil$$</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/tree/1.png\"><br><img src=\"/img/datastruct/5_tree/tree/1.png\" alt=\"数据结构\"></p>"},{"title":"5.4 哈夫曼树","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/1.png)\n<!--more-->\n\n### 5.4.1 带权路径长度\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/2.png)\n\n### 5.4.2 定义\n- n个带权叶子结点构成的带权路径最小的二叉树，也称为最优二叉树\n\n### 5.4.3 构造算法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/3.png)\n\n### 5.4.4 哈夫曼编码\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/4.png)\n\n- 前缀码","source":"_posts/datastruct/5_tree/4_Hafmantree.md","raw":"---\ntitle: 5.4 哈夫曼树\ndate: 2023-08-07 00:00:00\ntags: [数据结构,树,哈夫曼树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/1.png)\n<!--more-->\n\n### 5.4.1 带权路径长度\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/2.png)\n\n### 5.4.2 定义\n- n个带权叶子结点构成的带权路径最小的二叉树，也称为最优二叉树\n\n### 5.4.3 构造算法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/3.png)\n\n### 5.4.4 哈夫曼编码\n![](../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png)\n![数据结构](/img/datastruct/5_tree/hafmantree/4.png)\n\n- 前缀码","slug":"datastruct/5_tree/4_Hafmantree","published":1,"updated":"2023-10-23T12:21:19.991Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858w00237svw3jg14gqt","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"5-4-1-带权路径长度\"><a href=\"#5-4-1-带权路径长度\" class=\"headerlink\" title=\"5.4.1 带权路径长度\"></a>5.4.1 带权路径长度</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-4-2-定义\"><a href=\"#5-4-2-定义\" class=\"headerlink\" title=\"5.4.2 定义\"></a>5.4.2 定义</h3><ul>\n<li>n个带权叶子结点构成的带权路径最小的二叉树，也称为最优二叉树</li>\n</ul>\n<h3 id=\"5-4-3-构造算法\"><a href=\"#5-4-3-构造算法\" class=\"headerlink\" title=\"5.4.3 构造算法\"></a>5.4.3 构造算法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/3.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-4-4-哈夫曼编码\"><a href=\"#5-4-4-哈夫曼编码\" class=\"headerlink\" title=\"5.4.4 哈夫曼编码\"></a>5.4.4 哈夫曼编码</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>前缀码</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/1.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"5-4-1-带权路径长度\"><a href=\"#5-4-1-带权路径长度\" class=\"headerlink\" title=\"5.4.1 带权路径长度\"></a>5.4.1 带权路径长度</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/2.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-4-2-定义\"><a href=\"#5-4-2-定义\" class=\"headerlink\" title=\"5.4.2 定义\"></a>5.4.2 定义</h3><ul>\n<li>n个带权叶子结点构成的带权路径最小的二叉树，也称为最优二叉树</li>\n</ul>\n<h3 id=\"5-4-3-构造算法\"><a href=\"#5-4-3-构造算法\" class=\"headerlink\" title=\"5.4.3 构造算法\"></a>5.4.3 构造算法</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/3.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/3.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-4-4-哈夫曼编码\"><a href=\"#5-4-4-哈夫曼编码\" class=\"headerlink\" title=\"5.4.4 哈夫曼编码\"></a>5.4.4 哈夫曼编码</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/hafmantree/4.png\"><br><img src=\"/img/datastruct/5_tree/hafmantree/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>前缀码</li>\n</ul>"},{"title":"5.5 并查集","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/1.png)\n![数据结构](/img/datastruct/5_tree/set/1.png)\n### 5.5.1 存储结构\n\n- 双亲表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/2.png)\n![数据结构](/img/datastruct/5_tree/set/2.png)\n\n\n### 5.5.2 操作\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/3.png)\n![数据结构](/img/datastruct/5_tree/set/3.png)\n- 时间复杂度\n\n|操作|最坏时间复杂度|\n|:---|:---|\n|Find(x)|O(n)|\n|Union(x,y)|O(1)|\n- 优化union操作\n    ![](../../../../themes/yilia/source/img/datastruct/5_tree/set/4.png)\n    ![数据结构](/img/datastruct/5_tree/set/4.png)\n\n    - 树高不超过$$\\lfloor log_2n \\rfloor+1$$\n    - find时间复杂度为$$O( log_2n)$$\n- 优化find操作\n\n    ![](../../../../themes/yilia/source/img/datastruct/5_tree/set/5.png)\n    ![数据结构](/img/datastruct/5_tree/set/5.png)\n\n    - 每次查找时，将路径上的结点都放到根下面\n\n\n​        ","source":"_posts/datastruct/5_tree/5_set.md","raw":"---\ntitle: 5.5 并查集\ndate: 2023-08-07 00:00:00\ntags: [数据结构,并查集]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/1.png)\n![数据结构](/img/datastruct/5_tree/set/1.png)\n### 5.5.1 存储结构\n\n- 双亲表示法\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/2.png)\n![数据结构](/img/datastruct/5_tree/set/2.png)\n\n\n### 5.5.2 操作\n![](../../../../themes/yilia/source/img/datastruct/5_tree/set/3.png)\n![数据结构](/img/datastruct/5_tree/set/3.png)\n- 时间复杂度\n\n|操作|最坏时间复杂度|\n|:---|:---|\n|Find(x)|O(n)|\n|Union(x,y)|O(1)|\n- 优化union操作\n    ![](../../../../themes/yilia/source/img/datastruct/5_tree/set/4.png)\n    ![数据结构](/img/datastruct/5_tree/set/4.png)\n\n    - 树高不超过$$\\lfloor log_2n \\rfloor+1$$\n    - find时间复杂度为$$O( log_2n)$$\n- 优化find操作\n\n    ![](../../../../themes/yilia/source/img/datastruct/5_tree/set/5.png)\n    ![数据结构](/img/datastruct/5_tree/set/5.png)\n\n    - 每次查找时，将路径上的结点都放到根下面\n\n\n​        ","slug":"datastruct/5_tree/5_set","published":1,"updated":"2023-10-23T12:23:20.125Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858x00267svw4zvzc4ph","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/1.png\"><br><img src=\"/img/datastruct/5_tree/set/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-5-1-存储结构\"><a href=\"#5-5-1-存储结构\" class=\"headerlink\" title=\"5.5.1 存储结构\"></a>5.5.1 存储结构</h3><ul>\n<li>双亲表示法<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/2.png\"><br><img src=\"/img/datastruct/5_tree/set/2.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"5-5-2-操作\"><a href=\"#5-5-2-操作\" class=\"headerlink\" title=\"5.5.2 操作\"></a>5.5.2 操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/3.png\"><br><img src=\"/img/datastruct/5_tree/set/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">操作</th>\n<th align=\"left\">最坏时间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Find(x)</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">Union(x,y)</td>\n<td align=\"left\">O(1)</td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>优化union操作<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/4.png\"><br>  <img src=\"/img/datastruct/5_tree/set/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>树高不超过$$\\lfloor log_2n \\rfloor+1$$</li>\n<li>find时间复杂度为$$O( log_2n)$$</li>\n</ul>\n</li>\n<li><p>优化find操作</p>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/5.png\"><br>  <img src=\"/img/datastruct/5_tree/set/5.png\" alt=\"数据结构\"></p>\n<ul>\n<li>每次查找时，将路径上的结点都放到根下面</li>\n</ul>\n</li>\n</ul>\n<p>​        </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/1.png\"><br><img src=\"/img/datastruct/5_tree/set/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"5-5-1-存储结构\"><a href=\"#5-5-1-存储结构\" class=\"headerlink\" title=\"5.5.1 存储结构\"></a>5.5.1 存储结构</h3><ul>\n<li>双亲表示法<br><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/2.png\"><br><img src=\"/img/datastruct/5_tree/set/2.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"5-5-2-操作\"><a href=\"#5-5-2-操作\" class=\"headerlink\" title=\"5.5.2 操作\"></a>5.5.2 操作</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/3.png\"><br><img src=\"/img/datastruct/5_tree/set/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">操作</th>\n<th align=\"left\">最坏时间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Find(x)</td>\n<td align=\"left\">O(n)</td>\n</tr>\n<tr>\n<td align=\"left\">Union(x,y)</td>\n<td align=\"left\">O(1)</td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>优化union操作<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/4.png\"><br>  <img src=\"/img/datastruct/5_tree/set/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>树高不超过$$\\lfloor log_2n \\rfloor+1$$</li>\n<li>find时间复杂度为$$O( log_2n)$$</li>\n</ul>\n</li>\n<li><p>优化find操作</p>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/5_tree/set/5.png\"><br>  <img src=\"/img/datastruct/5_tree/set/5.png\" alt=\"数据结构\"></p>\n<ul>\n<li>每次查找时，将路径上的结点都放到根下面</li>\n</ul>\n</li>\n</ul>\n<p>​        </p>"},{"title":"7.1 顺序查找","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n### \n\n## 7.1-1 概念\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/1.png)\n![数据结构](/img/datastruct/7_search/search/1.png)\n<!--more-->\n- 平均查找长度：$$ASL=\\sum_{i=1}^n p_i c_i$$\n\n## 7.1-2 顺序查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/2.png)\n![数据结构](/img/datastruct/7_search/search/2.png)\n\n## 7.1-3 折半查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/3.png)\n![数据结构](/img/datastruct/7_search/search/3.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/4.png)\n![数据结构](/img/datastruct/7_search/search/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/5.png)\n![数据结构](/img/datastruct/7_search/search/5.png)\n\n## 7.1-4 分块查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/6.png)\n![数据结构](/img/datastruct/7_search/search/6.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/7.png)\n![数据结构](/img/datastruct/7_search/search/7.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/8.png)\n![数据结构](/img/datastruct/7_search/search/8.png)","source":"_posts/datastruct/7_search/1_search.md","raw":"---\ntitle: 7.1 顺序查找\ndate: 2023-08-07 00:00:00\ntags: [数据结构,查找]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n### \n\n## 7.1-1 概念\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/1.png)\n![数据结构](/img/datastruct/7_search/search/1.png)\n<!--more-->\n- 平均查找长度：$$ASL=\\sum_{i=1}^n p_i c_i$$\n\n## 7.1-2 顺序查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/2.png)\n![数据结构](/img/datastruct/7_search/search/2.png)\n\n## 7.1-3 折半查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/3.png)\n![数据结构](/img/datastruct/7_search/search/3.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/4.png)\n![数据结构](/img/datastruct/7_search/search/4.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/5.png)\n![数据结构](/img/datastruct/7_search/search/5.png)\n\n## 7.1-4 分块查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/6.png)\n![数据结构](/img/datastruct/7_search/search/6.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/7.png)\n![数据结构](/img/datastruct/7_search/search/7.png)\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/search/8.png)\n![数据结构](/img/datastruct/7_search/search/8.png)","slug":"datastruct/7_search/1_search","published":1,"updated":"2023-10-23T12:50:18.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858y00287svwgftx5tbp","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"7-1-1-概念\"><a href=\"#7-1-1-概念\" class=\"headerlink\" title=\"7.1-1 概念\"></a>7.1-1 概念</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/1.png\"><br><img src=\"/img/datastruct/7_search/search/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li>平均查找长度：$$ASL&#x3D;\\sum_{i&#x3D;1}^n p_i c_i$$</li>\n</ul>\n<h2 id=\"7-1-2-顺序查找\"><a href=\"#7-1-2-顺序查找\" class=\"headerlink\" title=\"7.1-2 顺序查找\"></a>7.1-2 顺序查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/2.png\"><br><img src=\"/img/datastruct/7_search/search/2.png\" alt=\"数据结构\"></p>\n<h2 id=\"7-1-3-折半查找\"><a href=\"#7-1-3-折半查找\" class=\"headerlink\" title=\"7.1-3 折半查找\"></a>7.1-3 折半查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/3.png\"><br><img src=\"/img/datastruct/7_search/search/3.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/4.png\"><br><img src=\"/img/datastruct/7_search/search/4.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/5.png\"><br><img src=\"/img/datastruct/7_search/search/5.png\" alt=\"数据结构\"></p>\n<h2 id=\"7-1-4-分块查找\"><a href=\"#7-1-4-分块查找\" class=\"headerlink\" title=\"7.1-4 分块查找\"></a>7.1-4 分块查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/6.png\"><br><img src=\"/img/datastruct/7_search/search/6.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/7.png\"><br><img src=\"/img/datastruct/7_search/search/7.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/8.png\"><br><img src=\"/img/datastruct/7_search/search/8.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"7-1-1-概念\"><a href=\"#7-1-1-概念\" class=\"headerlink\" title=\"7.1-1 概念\"></a>7.1-1 概念</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/1.png\"><br><img src=\"/img/datastruct/7_search/search/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li>平均查找长度：$$ASL&#x3D;\\sum_{i&#x3D;1}^n p_i c_i$$</li>\n</ul>\n<h2 id=\"7-1-2-顺序查找\"><a href=\"#7-1-2-顺序查找\" class=\"headerlink\" title=\"7.1-2 顺序查找\"></a>7.1-2 顺序查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/2.png\"><br><img src=\"/img/datastruct/7_search/search/2.png\" alt=\"数据结构\"></p>\n<h2 id=\"7-1-3-折半查找\"><a href=\"#7-1-3-折半查找\" class=\"headerlink\" title=\"7.1-3 折半查找\"></a>7.1-3 折半查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/3.png\"><br><img src=\"/img/datastruct/7_search/search/3.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/4.png\"><br><img src=\"/img/datastruct/7_search/search/4.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/5.png\"><br><img src=\"/img/datastruct/7_search/search/5.png\" alt=\"数据结构\"></p>\n<h2 id=\"7-1-4-分块查找\"><a href=\"#7-1-4-分块查找\" class=\"headerlink\" title=\"7.1-4 分块查找\"></a>7.1-4 分块查找</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/6.png\"><br><img src=\"/img/datastruct/7_search/search/6.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/7.png\"><br><img src=\"/img/datastruct/7_search/search/7.png\" alt=\"数据结构\"></p>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/search/8.png\"><br><img src=\"/img/datastruct/7_search/search/8.png\" alt=\"数据结构\"></p>"},{"title":"7.2 二叉排序树","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n### \n\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/1.png)\n![数据结构](/img/datastruct/7_search/BST/1.png)\n<!--more-->\n- 左<根<右\n- 中序遍历：升序排列\n- 操作\n    - 查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/2.png)\n![数据结构](/img/datastruct/7_search/BST/2.png)\n    - 插入\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/3.png)\n![数据结构](/img/datastruct/7_search/BST/3.png)\n    - 构造\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/4.png)\n![数据结构](/img/datastruct/7_search/BST/4.png)\n    - 删除z\n        - z是叶子\n\n            删\n        - z只有一颗左子树/右子树\n\n            删，子树代替\n        - z有两棵子树\n\n            用前驱（左子树最右下）/后继（右子树最左下）代替，删除前驱/后继\n- 查找效率分析\n\n    - 最好：O(log<sub>2</sub>n)\n    - 最坏：O(n)\n","source":"_posts/datastruct/7_search/2_BST.md","raw":"---\ntitle: 7.2 二叉排序树\ndate: 2023-08-07 00:00:00\ntags: [数据结构,查找,二叉排序树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n### \n\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/1.png)\n![数据结构](/img/datastruct/7_search/BST/1.png)\n<!--more-->\n- 左<根<右\n- 中序遍历：升序排列\n- 操作\n    - 查找\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/2.png)\n![数据结构](/img/datastruct/7_search/BST/2.png)\n    - 插入\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/3.png)\n![数据结构](/img/datastruct/7_search/BST/3.png)\n    - 构造\n![](../../../../themes/yilia/source/img/datastruct/7_search/BST/4.png)\n![数据结构](/img/datastruct/7_search/BST/4.png)\n    - 删除z\n        - z是叶子\n\n            删\n        - z只有一颗左子树/右子树\n\n            删，子树代替\n        - z有两棵子树\n\n            用前驱（左子树最右下）/后继（右子树最左下）代替，删除前驱/后继\n- 查找效率分析\n\n    - 最好：O(log<sub>2</sub>n)\n    - 最坏：O(n)\n","slug":"datastruct/7_search/2_BST","published":1,"updated":"2023-10-23T12:53:49.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858y002c7svwe42s6xfp","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/1.png\"><br><img src=\"/img/datastruct/7_search/BST/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li><p>左&lt;根&lt;右</p>\n</li>\n<li><p>中序遍历：升序排列</p>\n</li>\n<li><p>操作</p>\n<ul>\n<li>查找<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/2.png\"><br><img src=\"/img/datastruct/7_search/BST/2.png\" alt=\"数据结构\"></li>\n<li>插入<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/3.png\"><br><img src=\"/img/datastruct/7_search/BST/3.png\" alt=\"数据结构\"></li>\n<li>构造<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/4.png\"><br><img src=\"/img/datastruct/7_search/BST/4.png\" alt=\"数据结构\"></li>\n<li>删除z<ul>\n<li><p>z是叶子</p>\n<p>  删</p>\n</li>\n<li><p>z只有一颗左子树&#x2F;右子树</p>\n<p>  删，子树代替</p>\n</li>\n<li><p>z有两棵子树</p>\n<p>  用前驱（左子树最右下）&#x2F;后继（右子树最左下）代替，删除前驱&#x2F;后继</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>查找效率分析</p>\n<ul>\n<li>最好：O(log<sub>2</sub>n)</li>\n<li>最坏：O(n)</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/1.png\"><br><img src=\"/img/datastruct/7_search/BST/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<ul>\n<li><p>左&lt;根&lt;右</p>\n</li>\n<li><p>中序遍历：升序排列</p>\n</li>\n<li><p>操作</p>\n<ul>\n<li>查找<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/2.png\"><br><img src=\"/img/datastruct/7_search/BST/2.png\" alt=\"数据结构\"></li>\n<li>插入<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/3.png\"><br><img src=\"/img/datastruct/7_search/BST/3.png\" alt=\"数据结构\"></li>\n<li>构造<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/BST/4.png\"><br><img src=\"/img/datastruct/7_search/BST/4.png\" alt=\"数据结构\"></li>\n<li>删除z<ul>\n<li><p>z是叶子</p>\n<p>  删</p>\n</li>\n<li><p>z只有一颗左子树&#x2F;右子树</p>\n<p>  删，子树代替</p>\n</li>\n<li><p>z有两棵子树</p>\n<p>  用前驱（左子树最右下）&#x2F;后继（右子树最左下）代替，删除前驱&#x2F;后继</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>查找效率分析</p>\n<ul>\n<li>最好：O(log<sub>2</sub>n)</li>\n<li>最坏：O(n)</li>\n</ul>\n</li>\n</ul>"},{"title":"7.3 平衡二叉树","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/1.png)\n![数据结构](/img/datastruct/7_search/AVL/1.png)\n<!--more-->\n\n### 7.3-1 定义\n- 左右子树高度差不超过1的二叉排序树，简称AVL树\n\n### 7.3-2 操作\n- 插入\n    - 1） 插入二叉排序树\n    - 2）调整最小不平衡子树A\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/6.png)\n        ![数据结构](/img/datastruct/7_search/AVL/6.png)\n\n        - LL型：在A的左孩子的左子树插入\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/2.png)\n        ![数据结构](/img/datastruct/7_search/AVL/2.png)\n\n        - RR型：在A的右孩子的右子树插入\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/3.png)\n        ![数据结构](/img/datastruct/7_search/AVL/3.png)\n\n        - LR型：在A的左孩子的右子树插入\n        \n    \n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/4.png)\n        ![数据结构](/img/datastruct/7_search/AVL/4.png)\n\n        - RL型：在A的右孩子的左子树插入\n        \n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/5.png)\n        ![数据结构](/img/datastruct/7_search/AVL/5.png)\n\n- 删除\n![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/7.png)\n![数据结构](/img/datastruct/7_search/AVL/7.png)","source":"_posts/datastruct/7_search/3_AVL.md","raw":"---\ntitle: 7.3 平衡二叉树\ntags: [数据结构,查找,平衡二叉树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/1.png)\n![数据结构](/img/datastruct/7_search/AVL/1.png)\n<!--more-->\n\n### 7.3-1 定义\n- 左右子树高度差不超过1的二叉排序树，简称AVL树\n\n### 7.3-2 操作\n- 插入\n    - 1） 插入二叉排序树\n    - 2）调整最小不平衡子树A\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/6.png)\n        ![数据结构](/img/datastruct/7_search/AVL/6.png)\n\n        - LL型：在A的左孩子的左子树插入\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/2.png)\n        ![数据结构](/img/datastruct/7_search/AVL/2.png)\n\n        - RR型：在A的右孩子的右子树插入\n\n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/3.png)\n        ![数据结构](/img/datastruct/7_search/AVL/3.png)\n\n        - LR型：在A的左孩子的右子树插入\n        \n    \n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/4.png)\n        ![数据结构](/img/datastruct/7_search/AVL/4.png)\n\n        - RL型：在A的右孩子的左子树插入\n        \n        ![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/5.png)\n        ![数据结构](/img/datastruct/7_search/AVL/5.png)\n\n- 删除\n![](../../../../themes/yilia/source/img/datastruct/7_search/AVL/7.png)\n![数据结构](/img/datastruct/7_search/AVL/7.png)","slug":"datastruct/7_search/3_AVL","published":1,"date":"2023-08-26T07:15:22.626Z","updated":"2023-10-23T13:02:02.520Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19858z002e7svw34dx4x8j","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/1.png\"><br><img src=\"/img/datastruct/7_search/AVL/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"7-3-1-定义\"><a href=\"#7-3-1-定义\" class=\"headerlink\" title=\"7.3-1 定义\"></a>7.3-1 定义</h3><ul>\n<li>左右子树高度差不超过1的二叉排序树，简称AVL树</li>\n</ul>\n<h3 id=\"7-3-2-操作\"><a href=\"#7-3-2-操作\" class=\"headerlink\" title=\"7.3-2 操作\"></a>7.3-2 操作</h3><ul>\n<li><p>插入</p>\n<ul>\n<li><p>1） 插入二叉排序树</p>\n</li>\n<li><p>2）调整最小不平衡子树A</p>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/6.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>LL型：在A的左孩子的左子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/2.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>RR型：在A的右孩子的右子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/3.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>LR型：在A的左孩子的右子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/4.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>RL型：在A的右孩子的左子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/5.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/5.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n</li>\n<li><p>删除<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/7.png\"><br><img src=\"/img/datastruct/7_search/AVL/7.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/1.png\"><br><img src=\"/img/datastruct/7_search/AVL/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"7-3-1-定义\"><a href=\"#7-3-1-定义\" class=\"headerlink\" title=\"7.3-1 定义\"></a>7.3-1 定义</h3><ul>\n<li>左右子树高度差不超过1的二叉排序树，简称AVL树</li>\n</ul>\n<h3 id=\"7-3-2-操作\"><a href=\"#7-3-2-操作\" class=\"headerlink\" title=\"7.3-2 操作\"></a>7.3-2 操作</h3><ul>\n<li><p>插入</p>\n<ul>\n<li><p>1） 插入二叉排序树</p>\n</li>\n<li><p>2）调整最小不平衡子树A</p>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/6.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/6.png\" alt=\"数据结构\"></p>\n<ul>\n<li>LL型：在A的左孩子的左子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/2.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/2.png\" alt=\"数据结构\"></p>\n<ul>\n<li>RR型：在A的右孩子的右子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/3.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>LR型：在A的左孩子的右子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/4.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li>RL型：在A的右孩子的左子树插入</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/5.png\"><br>  <img src=\"/img/datastruct/7_search/AVL/5.png\" alt=\"数据结构\"></p>\n</li>\n</ul>\n</li>\n<li><p>删除<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/AVL/7.png\"><br><img src=\"/img/datastruct/7_search/AVL/7.png\" alt=\"数据结构\"></p>\n</li>\n</ul>"},{"title":"7.4 红黑树","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n## 9.7 红黑树\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/1.png)\n![数据结构](/img/datastruct/7_search/red/1.png)\n<!--more-->\n\n### 7.4-1 为什么要有红黑树\n- 平衡二叉树插入/删除操作效率低，因为调整次数多\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/2.png)\n![数据结构](/img/datastruct/7_search/red/2.png)\n\n### 7.4-2 定义\n- 二叉排序树\n- 左根右\n- 根叶黑\n- 不红红\n- 黑路同\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/3.png)\n![数据结构](/img/datastruct/7_search/red/3.png)\n\n### 7.4-3 性质\n- 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长\n- 有n个结点的红黑树的高度至多为2log<sub>2</sub>(n+1)\n- 若根节点黑高为h，则红黑树的高度至多为2h\n\n### 7.4-4 操作\n- 查找\n- 插入\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/4.png)\n![数据结构](/img/datastruct/7_search/red/4.png)\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/5.png)\n![数据结构](/img/datastruct/7_search/red/5.png)\n- 删除\n","source":"_posts/datastruct/7_search/4_redblacktree.md","raw":"---\ntitle: 7.4 红黑树\ntags: [数据结构]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n## 9.7 红黑树\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/1.png)\n![数据结构](/img/datastruct/7_search/red/1.png)\n<!--more-->\n\n### 7.4-1 为什么要有红黑树\n- 平衡二叉树插入/删除操作效率低，因为调整次数多\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/2.png)\n![数据结构](/img/datastruct/7_search/red/2.png)\n\n### 7.4-2 定义\n- 二叉排序树\n- 左根右\n- 根叶黑\n- 不红红\n- 黑路同\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/3.png)\n![数据结构](/img/datastruct/7_search/red/3.png)\n\n### 7.4-3 性质\n- 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长\n- 有n个结点的红黑树的高度至多为2log<sub>2</sub>(n+1)\n- 若根节点黑高为h，则红黑树的高度至多为2h\n\n### 7.4-4 操作\n- 查找\n- 插入\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/4.png)\n![数据结构](/img/datastruct/7_search/red/4.png)\n![](../../../../themes/yilia/source/img/datastruct/7_search/red/5.png)\n![数据结构](/img/datastruct/7_search/red/5.png)\n- 删除\n","slug":"datastruct/7_search/4_redblacktree","published":1,"date":"2023-08-26T07:46:09.411Z","updated":"2023-10-23T13:02:27.149Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198590002i7svwbmdj8uh3","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h2 id=\"9-7-红黑树\"><a href=\"#9-7-红黑树\" class=\"headerlink\" title=\"9.7 红黑树\"></a>9.7 红黑树</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/1.png\"><br><img src=\"/img/datastruct/7_search/red/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"7-4-1-为什么要有红黑树\"><a href=\"#7-4-1-为什么要有红黑树\" class=\"headerlink\" title=\"7.4-1 为什么要有红黑树\"></a>7.4-1 为什么要有红黑树</h3><ul>\n<li>平衡二叉树插入&#x2F;删除操作效率低，因为调整次数多<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/2.png\"><br><img src=\"/img/datastruct/7_search/red/2.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"7-4-2-定义\"><a href=\"#7-4-2-定义\" class=\"headerlink\" title=\"7.4-2 定义\"></a>7.4-2 定义</h3><ul>\n<li>二叉排序树</li>\n<li>左根右</li>\n<li>根叶黑</li>\n<li>不红红</li>\n<li>黑路同<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/3.png\"><br><img src=\"/img/datastruct/7_search/red/3.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"7-4-3-性质\"><a href=\"#7-4-3-性质\" class=\"headerlink\" title=\"7.4-3 性质\"></a>7.4-3 性质</h3><ul>\n<li>从根到叶子的最长的可能路径不多于最短的可能路径的两倍长</li>\n<li>有n个结点的红黑树的高度至多为2log<sub>2</sub>(n+1)</li>\n<li>若根节点黑高为h，则红黑树的高度至多为2h</li>\n</ul>\n<h3 id=\"7-4-4-操作\"><a href=\"#7-4-4-操作\" class=\"headerlink\" title=\"7.4-4 操作\"></a>7.4-4 操作</h3><ul>\n<li>查找</li>\n<li>插入<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/4.png\"><br><img src=\"/img/datastruct/7_search/red/4.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/5.png\"><br><img src=\"/img/datastruct/7_search/red/5.png\" alt=\"数据结构\"></li>\n<li>删除</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h2 id=\"9-7-红黑树\"><a href=\"#9-7-红黑树\" class=\"headerlink\" title=\"9.7 红黑树\"></a>9.7 红黑树</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/1.png\"><br><img src=\"/img/datastruct/7_search/red/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n\n<h3 id=\"7-4-1-为什么要有红黑树\"><a href=\"#7-4-1-为什么要有红黑树\" class=\"headerlink\" title=\"7.4-1 为什么要有红黑树\"></a>7.4-1 为什么要有红黑树</h3><ul>\n<li>平衡二叉树插入&#x2F;删除操作效率低，因为调整次数多<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/2.png\"><br><img src=\"/img/datastruct/7_search/red/2.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"7-4-2-定义\"><a href=\"#7-4-2-定义\" class=\"headerlink\" title=\"7.4-2 定义\"></a>7.4-2 定义</h3><ul>\n<li>二叉排序树</li>\n<li>左根右</li>\n<li>根叶黑</li>\n<li>不红红</li>\n<li>黑路同<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/3.png\"><br><img src=\"/img/datastruct/7_search/red/3.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"7-4-3-性质\"><a href=\"#7-4-3-性质\" class=\"headerlink\" title=\"7.4-3 性质\"></a>7.4-3 性质</h3><ul>\n<li>从根到叶子的最长的可能路径不多于最短的可能路径的两倍长</li>\n<li>有n个结点的红黑树的高度至多为2log<sub>2</sub>(n+1)</li>\n<li>若根节点黑高为h，则红黑树的高度至多为2h</li>\n</ul>\n<h3 id=\"7-4-4-操作\"><a href=\"#7-4-4-操作\" class=\"headerlink\" title=\"7.4-4 操作\"></a>7.4-4 操作</h3><ul>\n<li>查找</li>\n<li>插入<br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/4.png\"><br><img src=\"/img/datastruct/7_search/red/4.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/red/5.png\"><br><img src=\"/img/datastruct/7_search/red/5.png\" alt=\"数据结构\"></li>\n<li>删除</li>\n</ul>"},{"title":"7.5 B树","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/B/1.png)\n![数据结构](/img/datastruct/7_search/B/1.png)\n\n\n","source":"_posts/datastruct/7_search/5_Btree.md","raw":"---\ntitle: 7.5 B树\ntags: [数据结构,查找,B树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/7_search/B/1.png)\n![数据结构](/img/datastruct/7_search/B/1.png)\n\n\n","slug":"datastruct/7_search/5_Btree","published":1,"date":"2023-08-26T08:50:40.799Z","updated":"2023-10-23T13:05:28.937Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198590002k7svw9qcp94qn","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/B/1.png\"><br><img src=\"/img/datastruct/7_search/B/1.png\" alt=\"数据结构\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/7_search/B/1.png\"><br><img src=\"/img/datastruct/7_search/B/1.png\" alt=\"数据结构\"></p>"},{"title":"6.1 图","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/1.png)\n![数据结构](/img/datastruct/6_graph/graph/1.png)\n\n\n## 6.1-1 定义\n- 由顶点的有穷非空集合和顶点之间边的集合组成\n- 通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。\n- 线性表可以空，树可以空，图不可以\n\n\n## 6.1-2 一些概念\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/2.png)\n![数据结构](/img/datastruct/6_graph/graph/2.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/3.png)\n![数据结构](/img/datastruct/6_graph/graph/3.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/4.png)\n![数据结构](/img/datastruct/6_graph/graph/4.png)\n- 生成子图要包含所有顶点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/5.png)\n![数据结构](/img/datastruct/6_graph/graph/5.png)\n- 强连通分量：有向图中\n\n- 连通图的生成树：连通图的极小连通子图\n\n## 6.1-3 图的存储\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/6.png)\n![数据结构](/img/datastruct/6_graph/graph/6.png)\n### 6.1-3.1 邻接矩阵\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/7.png)\n![数据结构](/img/datastruct/6_graph/graph/7.png)\n- 出度：一行中非0元素的个数\n- 入度：一列中非0元素的个数\n- 空间复杂度：O(|v|<sup>2</sup>)\n- 无向图->对称->矩阵压缩\n- 设邻接矩阵A只含0、1，则A<sup>k</sup>中非零元素表示从i到j的长度为k的路径数\n\n### 6.1-3.2 邻接表\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/8.png)\n![数据结构](/img/datastruct/6_graph/graph/8.png)\n- 空间复杂度：O(|v|+|e|)\n\n### 6.1-3.3 十字链表（有向图）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/9.png)\n![数据结构](/img/datastruct/6_graph/graph/9.png)\n- 空间复杂度：O(|v|+|e|)\n- 如何找到指定顶点的所有出边：沿着绿色的箭头找\n- 如何找到指定顶点的所有入边：沿着橙色的箭头找\n\n### 6.1-3.4 邻接多重表（无向图）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/10.png)\n![数据结构](/img/datastruct/6_graph/graph/10.png)\n- 空间复杂度：O(|v|+|e|)\n- 删除边、顶点很方便\n\n\n## 6.1-4 基本操作\n|函数|功能|\n|:---|:---|\n|Adjacent(G,x,y)|判断是否有从x到y的边，无向图只需判断一次|\n|Neighbors(G,x)|返回与x邻接的顶点|\n|InsertVertex(G,x)|插入顶点|\n|DeleteVertex(G,x)|删除顶点|\n|AddEdge(G,x,y)|插入边|\n|RemoveEdge(G,x,y)|删除边|\n|FirstNeighbor(G,x)|返回x的第一个邻接点|\n|NextNeighbor(G,x,y)|返回x相对于y的下一个邻接点|\n|Get_edge_value(G,x,y)|返回边(x,y)的权值|\n|Set_edge_value(G,x,y,v)|设置边(x,y)的权值为v|\n\n|有向图|无向图|\n|:---|:---|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/11.png)![数据结构](/img/datastruct/6_graph/graph/11.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/12.png)![数据结构](/img/datastruct/6_graph/graph/12.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/13.png)![数据结构](/img/datastruct/6_graph/graph/13.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/14.png)![数据结构](/img/datastruct/6_graph/graph/14.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png)![数据结构](/img/datastruct/6_graph/graph/15.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png)![数据结构](/img/datastruct/6_graph/graph/15.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/16.png)![数据结构](/img/datastruct/6_graph/graph/16.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/17.png)![数据结构](/img/datastruct/6_graph/graph/17.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png)![数据结构](/img/datastruct/6_graph/graph/18.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png)![数据结构](/img/datastruct/6_graph/graph/18.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png)![数据结构](/img/datastruct/6_graph/graph/19.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png)![数据结构](/img/datastruct/6_graph/graph/19.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png)![数据结构](/img/datastruct/6_graph/graph/20.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png)![数据结构](/img/datastruct/6_graph/graph/20.png)|\n\n### 6.1-4.1 图的遍历\n- 广度优先遍历（BFS）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/21.png)\n![数据结构](/img/datastruct/6_graph/graph/21.png)\n\n    - 找到所有与v相邻的顶点：FirstNeighbor(G,v)，NextNeighbor(G,v,w)\n    - 标记哪个顶点已经访问过：visited[]\n    - 用队列保存已经访问过的顶点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/22.png)\n![数据结构](/img/datastruct/6_graph/graph/22.png)\n    - 如果图是非连通的，需要对每个连通分量进行BFS\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/23.png)\n![数据结构](/img/datastruct/6_graph/graph/23.png)\n    - 广度优先生成树\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/24.png)\n![数据结构](/img/datastruct/6_graph/graph/24.png)\n    - 广度优先生成森林\n- 深度优先遍历（DFS）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/25.png)\n![数据结构](/img/datastruct/6_graph/graph/25.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/26.png)\n![数据结构](/img/datastruct/6_graph/graph/26.png)\n    - 深度优先生成树\n    - 深度优先生成森林\n","source":"_posts/datastruct/6_graph/1_graph.md","raw":"---\ntitle: 6.1 图\ndate: 2023-08-07 00:00:00\ntags: [数据结构,图]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/1.png)\n![数据结构](/img/datastruct/6_graph/graph/1.png)\n\n\n## 6.1-1 定义\n- 由顶点的有穷非空集合和顶点之间边的集合组成\n- 通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。\n- 线性表可以空，树可以空，图不可以\n\n\n## 6.1-2 一些概念\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/2.png)\n![数据结构](/img/datastruct/6_graph/graph/2.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/3.png)\n![数据结构](/img/datastruct/6_graph/graph/3.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/4.png)\n![数据结构](/img/datastruct/6_graph/graph/4.png)\n- 生成子图要包含所有顶点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/5.png)\n![数据结构](/img/datastruct/6_graph/graph/5.png)\n- 强连通分量：有向图中\n\n- 连通图的生成树：连通图的极小连通子图\n\n## 6.1-3 图的存储\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/6.png)\n![数据结构](/img/datastruct/6_graph/graph/6.png)\n### 6.1-3.1 邻接矩阵\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/7.png)\n![数据结构](/img/datastruct/6_graph/graph/7.png)\n- 出度：一行中非0元素的个数\n- 入度：一列中非0元素的个数\n- 空间复杂度：O(|v|<sup>2</sup>)\n- 无向图->对称->矩阵压缩\n- 设邻接矩阵A只含0、1，则A<sup>k</sup>中非零元素表示从i到j的长度为k的路径数\n\n### 6.1-3.2 邻接表\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/8.png)\n![数据结构](/img/datastruct/6_graph/graph/8.png)\n- 空间复杂度：O(|v|+|e|)\n\n### 6.1-3.3 十字链表（有向图）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/9.png)\n![数据结构](/img/datastruct/6_graph/graph/9.png)\n- 空间复杂度：O(|v|+|e|)\n- 如何找到指定顶点的所有出边：沿着绿色的箭头找\n- 如何找到指定顶点的所有入边：沿着橙色的箭头找\n\n### 6.1-3.4 邻接多重表（无向图）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/10.png)\n![数据结构](/img/datastruct/6_graph/graph/10.png)\n- 空间复杂度：O(|v|+|e|)\n- 删除边、顶点很方便\n\n\n## 6.1-4 基本操作\n|函数|功能|\n|:---|:---|\n|Adjacent(G,x,y)|判断是否有从x到y的边，无向图只需判断一次|\n|Neighbors(G,x)|返回与x邻接的顶点|\n|InsertVertex(G,x)|插入顶点|\n|DeleteVertex(G,x)|删除顶点|\n|AddEdge(G,x,y)|插入边|\n|RemoveEdge(G,x,y)|删除边|\n|FirstNeighbor(G,x)|返回x的第一个邻接点|\n|NextNeighbor(G,x,y)|返回x相对于y的下一个邻接点|\n|Get_edge_value(G,x,y)|返回边(x,y)的权值|\n|Set_edge_value(G,x,y,v)|设置边(x,y)的权值为v|\n\n|有向图|无向图|\n|:---|:---|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/11.png)![数据结构](/img/datastruct/6_graph/graph/11.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/12.png)![数据结构](/img/datastruct/6_graph/graph/12.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/13.png)![数据结构](/img/datastruct/6_graph/graph/13.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/14.png)![数据结构](/img/datastruct/6_graph/graph/14.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png)![数据结构](/img/datastruct/6_graph/graph/15.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png)![数据结构](/img/datastruct/6_graph/graph/15.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/16.png)![数据结构](/img/datastruct/6_graph/graph/16.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/17.png)![数据结构](/img/datastruct/6_graph/graph/17.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png)![数据结构](/img/datastruct/6_graph/graph/18.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png)![数据结构](/img/datastruct/6_graph/graph/18.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png)![数据结构](/img/datastruct/6_graph/graph/19.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png)![数据结构](/img/datastruct/6_graph/graph/19.png)|\n|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png)![数据结构](/img/datastruct/6_graph/graph/20.png)|![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png)![数据结构](/img/datastruct/6_graph/graph/20.png)|\n\n### 6.1-4.1 图的遍历\n- 广度优先遍历（BFS）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/21.png)\n![数据结构](/img/datastruct/6_graph/graph/21.png)\n\n    - 找到所有与v相邻的顶点：FirstNeighbor(G,v)，NextNeighbor(G,v,w)\n    - 标记哪个顶点已经访问过：visited[]\n    - 用队列保存已经访问过的顶点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/22.png)\n![数据结构](/img/datastruct/6_graph/graph/22.png)\n    - 如果图是非连通的，需要对每个连通分量进行BFS\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/23.png)\n![数据结构](/img/datastruct/6_graph/graph/23.png)\n    - 广度优先生成树\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/24.png)\n![数据结构](/img/datastruct/6_graph/graph/24.png)\n    - 广度优先生成森林\n- 深度优先遍历（DFS）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/25.png)\n![数据结构](/img/datastruct/6_graph/graph/25.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/graph/26.png)\n![数据结构](/img/datastruct/6_graph/graph/26.png)\n    - 深度优先生成树\n    - 深度优先生成森林\n","slug":"datastruct/6_graph/1_graph","published":1,"updated":"2023-10-23T12:26:47.885Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198591002n7svw3f22ckr2","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/1.png\"><br><img src=\"/img/datastruct/6_graph/graph/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"6-1-1-定义\"><a href=\"#6-1-1-定义\" class=\"headerlink\" title=\"6.1-1 定义\"></a>6.1-1 定义</h2><ul>\n<li>由顶点的有穷非空集合和顶点之间边的集合组成</li>\n<li>通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。</li>\n<li>线性表可以空，树可以空，图不可以</li>\n</ul>\n<h2 id=\"6-1-2-一些概念\"><a href=\"#6-1-2-一些概念\" class=\"headerlink\" title=\"6.1-2 一些概念\"></a>6.1-2 一些概念</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/2.png\"><br><img src=\"/img/datastruct/6_graph/graph/2.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/3.png\"><br><img src=\"/img/datastruct/6_graph/graph/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/4.png\"><br><img src=\"/img/datastruct/6_graph/graph/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>生成子图要包含所有顶点<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/5.png\"><br><img src=\"/img/datastruct/6_graph/graph/5.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>强连通分量：有向图中</p>\n</li>\n<li><p>连通图的生成树：连通图的极小连通子图</p>\n</li>\n</ul>\n<h2 id=\"6-1-3-图的存储\"><a href=\"#6-1-3-图的存储\" class=\"headerlink\" title=\"6.1-3 图的存储\"></a>6.1-3 图的存储</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/6.png\"><br><img src=\"/img/datastruct/6_graph/graph/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-1-3-1-邻接矩阵\"><a href=\"#6-1-3-1-邻接矩阵\" class=\"headerlink\" title=\"6.1-3.1 邻接矩阵\"></a>6.1-3.1 邻接矩阵</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/7.png\"><br><img src=\"/img/datastruct/6_graph/graph/7.png\" alt=\"数据结构\"></p>\n<ul>\n<li>出度：一行中非0元素的个数</li>\n<li>入度：一列中非0元素的个数</li>\n<li>空间复杂度：O(|v|<sup>2</sup>)</li>\n<li>无向图-&gt;对称-&gt;矩阵压缩</li>\n<li>设邻接矩阵A只含0、1，则A<sup>k</sup>中非零元素表示从i到j的长度为k的路径数</li>\n</ul>\n<h3 id=\"6-1-3-2-邻接表\"><a href=\"#6-1-3-2-邻接表\" class=\"headerlink\" title=\"6.1-3.2 邻接表\"></a>6.1-3.2 邻接表</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/8.png\"><br><img src=\"/img/datastruct/6_graph/graph/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n</ul>\n<h3 id=\"6-1-3-3-十字链表（有向图）\"><a href=\"#6-1-3-3-十字链表（有向图）\" class=\"headerlink\" title=\"6.1-3.3 十字链表（有向图）\"></a>6.1-3.3 十字链表（有向图）</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/9.png\"><br><img src=\"/img/datastruct/6_graph/graph/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n<li>如何找到指定顶点的所有出边：沿着绿色的箭头找</li>\n<li>如何找到指定顶点的所有入边：沿着橙色的箭头找</li>\n</ul>\n<h3 id=\"6-1-3-4-邻接多重表（无向图）\"><a href=\"#6-1-3-4-邻接多重表（无向图）\" class=\"headerlink\" title=\"6.1-3.4 邻接多重表（无向图）\"></a>6.1-3.4 邻接多重表（无向图）</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/10.png\"><br><img src=\"/img/datastruct/6_graph/graph/10.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n<li>删除边、顶点很方便</li>\n</ul>\n<h2 id=\"6-1-4-基本操作\"><a href=\"#6-1-4-基本操作\" class=\"headerlink\" title=\"6.1-4 基本操作\"></a>6.1-4 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"left\">函数</th>\n<th align=\"left\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Adjacent(G,x,y)</td>\n<td align=\"left\">判断是否有从x到y的边，无向图只需判断一次</td>\n</tr>\n<tr>\n<td align=\"left\">Neighbors(G,x)</td>\n<td align=\"left\">返回与x邻接的顶点</td>\n</tr>\n<tr>\n<td align=\"left\">InsertVertex(G,x)</td>\n<td align=\"left\">插入顶点</td>\n</tr>\n<tr>\n<td align=\"left\">DeleteVertex(G,x)</td>\n<td align=\"left\">删除顶点</td>\n</tr>\n<tr>\n<td align=\"left\">AddEdge(G,x,y)</td>\n<td align=\"left\">插入边</td>\n</tr>\n<tr>\n<td align=\"left\">RemoveEdge(G,x,y)</td>\n<td align=\"left\">删除边</td>\n</tr>\n<tr>\n<td align=\"left\">FirstNeighbor(G,x)</td>\n<td align=\"left\">返回x的第一个邻接点</td>\n</tr>\n<tr>\n<td align=\"left\">NextNeighbor(G,x,y)</td>\n<td align=\"left\">返回x相对于y的下一个邻接点</td>\n</tr>\n<tr>\n<td align=\"left\">Get_edge_value(G,x,y)</td>\n<td align=\"left\">返回边(x,y)的权值</td>\n</tr>\n<tr>\n<td align=\"left\">Set_edge_value(G,x,y,v)</td>\n<td align=\"left\">设置边(x,y)的权值为v</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">有向图</th>\n<th align=\"left\">无向图</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/11.png\"><img src=\"/img/datastruct/6_graph/graph/11.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/12.png\"><img src=\"/img/datastruct/6_graph/graph/12.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/13.png\"><img src=\"/img/datastruct/6_graph/graph/13.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/14.png\"><img src=\"/img/datastruct/6_graph/graph/14.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png\"><img src=\"/img/datastruct/6_graph/graph/15.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png\"><img src=\"/img/datastruct/6_graph/graph/15.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/16.png\"><img src=\"/img/datastruct/6_graph/graph/16.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/17.png\"><img src=\"/img/datastruct/6_graph/graph/17.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png\"><img src=\"/img/datastruct/6_graph/graph/18.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png\"><img src=\"/img/datastruct/6_graph/graph/18.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png\"><img src=\"/img/datastruct/6_graph/graph/19.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png\"><img src=\"/img/datastruct/6_graph/graph/19.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png\"><img src=\"/img/datastruct/6_graph/graph/20.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png\"><img src=\"/img/datastruct/6_graph/graph/20.png\" alt=\"数据结构\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"6-1-4-1-图的遍历\"><a href=\"#6-1-4-1-图的遍历\" class=\"headerlink\" title=\"6.1-4.1 图的遍历\"></a>6.1-4.1 图的遍历</h3><ul>\n<li><p>广度优先遍历（BFS）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/21.png\"><br><img src=\"/img/datastruct/6_graph/graph/21.png\" alt=\"数据结构\"></p>\n<ul>\n<li>找到所有与v相邻的顶点：FirstNeighbor(G,v)，NextNeighbor(G,v,w)</li>\n<li>标记哪个顶点已经访问过：visited[]</li>\n<li>用队列保存已经访问过的顶点</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/22.png\"><br><img src=\"/img/datastruct/6_graph/graph/22.png\" alt=\"数据结构\"><br>    - 如果图是非连通的，需要对每个连通分量进行BFS<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/23.png\"><br><img src=\"/img/datastruct/6_graph/graph/23.png\" alt=\"数据结构\"><br>    - 广度优先生成树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/24.png\"><br><img src=\"/img/datastruct/6_graph/graph/24.png\" alt=\"数据结构\"><br>    - 广度优先生成森林</p>\n<ul>\n<li>深度优先遍历（DFS）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/25.png\"><br><img src=\"/img/datastruct/6_graph/graph/25.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/26.png\"><br><img src=\"/img/datastruct/6_graph/graph/26.png\" alt=\"数据结构\"><ul>\n<li>深度优先生成树</li>\n<li>深度优先生成森林</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/1.png\"><br><img src=\"/img/datastruct/6_graph/graph/1.png\" alt=\"数据结构\"></p>\n<h2 id=\"6-1-1-定义\"><a href=\"#6-1-1-定义\" class=\"headerlink\" title=\"6.1-1 定义\"></a>6.1-1 定义</h2><ul>\n<li>由顶点的有穷非空集合和顶点之间边的集合组成</li>\n<li>通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。</li>\n<li>线性表可以空，树可以空，图不可以</li>\n</ul>\n<h2 id=\"6-1-2-一些概念\"><a href=\"#6-1-2-一些概念\" class=\"headerlink\" title=\"6.1-2 一些概念\"></a>6.1-2 一些概念</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/2.png\"><br><img src=\"/img/datastruct/6_graph/graph/2.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/3.png\"><br><img src=\"/img/datastruct/6_graph/graph/3.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/4.png\"><br><img src=\"/img/datastruct/6_graph/graph/4.png\" alt=\"数据结构\"></p>\n<ul>\n<li><p>生成子图要包含所有顶点<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/5.png\"><br><img src=\"/img/datastruct/6_graph/graph/5.png\" alt=\"数据结构\"></p>\n</li>\n<li><p>强连通分量：有向图中</p>\n</li>\n<li><p>连通图的生成树：连通图的极小连通子图</p>\n</li>\n</ul>\n<h2 id=\"6-1-3-图的存储\"><a href=\"#6-1-3-图的存储\" class=\"headerlink\" title=\"6.1-3 图的存储\"></a>6.1-3 图的存储</h2><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/6.png\"><br><img src=\"/img/datastruct/6_graph/graph/6.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-1-3-1-邻接矩阵\"><a href=\"#6-1-3-1-邻接矩阵\" class=\"headerlink\" title=\"6.1-3.1 邻接矩阵\"></a>6.1-3.1 邻接矩阵</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/7.png\"><br><img src=\"/img/datastruct/6_graph/graph/7.png\" alt=\"数据结构\"></p>\n<ul>\n<li>出度：一行中非0元素的个数</li>\n<li>入度：一列中非0元素的个数</li>\n<li>空间复杂度：O(|v|<sup>2</sup>)</li>\n<li>无向图-&gt;对称-&gt;矩阵压缩</li>\n<li>设邻接矩阵A只含0、1，则A<sup>k</sup>中非零元素表示从i到j的长度为k的路径数</li>\n</ul>\n<h3 id=\"6-1-3-2-邻接表\"><a href=\"#6-1-3-2-邻接表\" class=\"headerlink\" title=\"6.1-3.2 邻接表\"></a>6.1-3.2 邻接表</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/8.png\"><br><img src=\"/img/datastruct/6_graph/graph/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n</ul>\n<h3 id=\"6-1-3-3-十字链表（有向图）\"><a href=\"#6-1-3-3-十字链表（有向图）\" class=\"headerlink\" title=\"6.1-3.3 十字链表（有向图）\"></a>6.1-3.3 十字链表（有向图）</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/9.png\"><br><img src=\"/img/datastruct/6_graph/graph/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n<li>如何找到指定顶点的所有出边：沿着绿色的箭头找</li>\n<li>如何找到指定顶点的所有入边：沿着橙色的箭头找</li>\n</ul>\n<h3 id=\"6-1-3-4-邻接多重表（无向图）\"><a href=\"#6-1-3-4-邻接多重表（无向图）\" class=\"headerlink\" title=\"6.1-3.4 邻接多重表（无向图）\"></a>6.1-3.4 邻接多重表（无向图）</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/10.png\"><br><img src=\"/img/datastruct/6_graph/graph/10.png\" alt=\"数据结构\"></p>\n<ul>\n<li>空间复杂度：O(|v|+|e|)</li>\n<li>删除边、顶点很方便</li>\n</ul>\n<h2 id=\"6-1-4-基本操作\"><a href=\"#6-1-4-基本操作\" class=\"headerlink\" title=\"6.1-4 基本操作\"></a>6.1-4 基本操作</h2><table>\n<thead>\n<tr>\n<th align=\"left\">函数</th>\n<th align=\"left\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Adjacent(G,x,y)</td>\n<td align=\"left\">判断是否有从x到y的边，无向图只需判断一次</td>\n</tr>\n<tr>\n<td align=\"left\">Neighbors(G,x)</td>\n<td align=\"left\">返回与x邻接的顶点</td>\n</tr>\n<tr>\n<td align=\"left\">InsertVertex(G,x)</td>\n<td align=\"left\">插入顶点</td>\n</tr>\n<tr>\n<td align=\"left\">DeleteVertex(G,x)</td>\n<td align=\"left\">删除顶点</td>\n</tr>\n<tr>\n<td align=\"left\">AddEdge(G,x,y)</td>\n<td align=\"left\">插入边</td>\n</tr>\n<tr>\n<td align=\"left\">RemoveEdge(G,x,y)</td>\n<td align=\"left\">删除边</td>\n</tr>\n<tr>\n<td align=\"left\">FirstNeighbor(G,x)</td>\n<td align=\"left\">返回x的第一个邻接点</td>\n</tr>\n<tr>\n<td align=\"left\">NextNeighbor(G,x,y)</td>\n<td align=\"left\">返回x相对于y的下一个邻接点</td>\n</tr>\n<tr>\n<td align=\"left\">Get_edge_value(G,x,y)</td>\n<td align=\"left\">返回边(x,y)的权值</td>\n</tr>\n<tr>\n<td align=\"left\">Set_edge_value(G,x,y,v)</td>\n<td align=\"left\">设置边(x,y)的权值为v</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">有向图</th>\n<th align=\"left\">无向图</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/11.png\"><img src=\"/img/datastruct/6_graph/graph/11.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/12.png\"><img src=\"/img/datastruct/6_graph/graph/12.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/13.png\"><img src=\"/img/datastruct/6_graph/graph/13.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/14.png\"><img src=\"/img/datastruct/6_graph/graph/14.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png\"><img src=\"/img/datastruct/6_graph/graph/15.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/15.png\"><img src=\"/img/datastruct/6_graph/graph/15.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/16.png\"><img src=\"/img/datastruct/6_graph/graph/16.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/17.png\"><img src=\"/img/datastruct/6_graph/graph/17.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png\"><img src=\"/img/datastruct/6_graph/graph/18.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/18.png\"><img src=\"/img/datastruct/6_graph/graph/18.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png\"><img src=\"/img/datastruct/6_graph/graph/19.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/19.png\"><img src=\"/img/datastruct/6_graph/graph/19.png\" alt=\"数据结构\"></td>\n</tr>\n<tr>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png\"><img src=\"/img/datastruct/6_graph/graph/20.png\" alt=\"数据结构\"></td>\n<td align=\"left\"><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/20.png\"><img src=\"/img/datastruct/6_graph/graph/20.png\" alt=\"数据结构\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"6-1-4-1-图的遍历\"><a href=\"#6-1-4-1-图的遍历\" class=\"headerlink\" title=\"6.1-4.1 图的遍历\"></a>6.1-4.1 图的遍历</h3><ul>\n<li><p>广度优先遍历（BFS）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/21.png\"><br><img src=\"/img/datastruct/6_graph/graph/21.png\" alt=\"数据结构\"></p>\n<ul>\n<li>找到所有与v相邻的顶点：FirstNeighbor(G,v)，NextNeighbor(G,v,w)</li>\n<li>标记哪个顶点已经访问过：visited[]</li>\n<li>用队列保存已经访问过的顶点</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/22.png\"><br><img src=\"/img/datastruct/6_graph/graph/22.png\" alt=\"数据结构\"><br>    - 如果图是非连通的，需要对每个连通分量进行BFS<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/23.png\"><br><img src=\"/img/datastruct/6_graph/graph/23.png\" alt=\"数据结构\"><br>    - 广度优先生成树<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/24.png\"><br><img src=\"/img/datastruct/6_graph/graph/24.png\" alt=\"数据结构\"><br>    - 广度优先生成森林</p>\n<ul>\n<li>深度优先遍历（DFS）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/25.png\"><br><img src=\"/img/datastruct/6_graph/graph/25.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/graph/26.png\"><br><img src=\"/img/datastruct/6_graph/graph/26.png\" alt=\"数据结构\"><ul>\n<li>深度优先生成树</li>\n<li>深度优先生成森林</li>\n</ul>\n</li>\n</ul>"},{"title":"6.3 最短路径","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n### \n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png)\n![数据结构](/img/datastruct/6_graph/shortestpath/1.png)\n<!--more-->\n### 6.3-1 单源最短路径\n- ##### 1） BFS算法(无权)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/2.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/3.png)\n\n- ##### 2）Dijkstra(带权)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/4.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/5.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/6.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/7.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/8.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/9.png)\n    - 时间复杂度：O(|V|<sup>2</sup>)\n    - 不可用于有负权边的图\n\n### 6.3-2 各顶点间最短路径\n- ##### 1）Floyd算法\n    - 动态规划思想：\n\n        - 1）允许在v0中转，求最短路径\n        - 2）允许在v0、v1中转，求最短路径\n        - 3）允许在v0、v1、v2中转，求最短路径\n        - ...\n    \n\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/10.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/11.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/12.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/13.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/14.png)\n    - 时间复杂度：O(|V|<sup>3</sup>)\n    - 不能解决负权回路的问题","source":"_posts/datastruct/6_graph/3_shortestpath.md","raw":"---\ntitle: 6.3 最短路径\ndate: 2023-08-07 00:00:00\ntags: [数据结构,图,最短路径]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n### \n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png)\n![数据结构](/img/datastruct/6_graph/shortestpath/1.png)\n<!--more-->\n### 6.3-1 单源最短路径\n- ##### 1） BFS算法(无权)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/2.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/3.png)\n\n- ##### 2）Dijkstra(带权)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/4.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/5.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/6.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/7.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/8.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/9.png)\n    - 时间复杂度：O(|V|<sup>2</sup>)\n    - 不可用于有负权边的图\n\n### 6.3-2 各顶点间最短路径\n- ##### 1）Floyd算法\n    - 动态规划思想：\n\n        - 1）允许在v0中转，求最短路径\n        - 2）允许在v0、v1中转，求最短路径\n        - 3）允许在v0、v1、v2中转，求最短路径\n        - ...\n    \n\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/10.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/11.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/12.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/13.png)\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png)\n    ![数据结构](/img/datastruct/6_graph/shortestpath/14.png)\n    - 时间复杂度：O(|V|<sup>3</sup>)\n    - 不能解决负权回路的问题","slug":"datastruct/6_graph/3_shortestpath","published":1,"updated":"2023-10-23T12:30:27.797Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198591002o7svw4y0w7q7b","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png\"><br><img src=\"/img/datastruct/6_graph/shortestpath/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<h3 id=\"6-3-1-单源最短路径\"><a href=\"#6-3-1-单源最短路径\" class=\"headerlink\" title=\"6.3-1 单源最短路径\"></a>6.3-1 单源最短路径</h3><ul>\n<li><h5 id=\"1）-BFS算法-无权\"><a href=\"#1）-BFS算法-无权\" class=\"headerlink\" title=\"1） BFS算法(无权)\"></a>1） BFS算法(无权)</h5><p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/2.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/3.png\" alt=\"数据结构\"></p>\n</li>\n<li><h5 id=\"2）Dijkstra-带权\"><a href=\"#2）Dijkstra-带权\" class=\"headerlink\" title=\"2）Dijkstra(带权)\"></a>2）Dijkstra(带权)</h5><p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/4.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/5.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/6.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/7.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/8.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度：O(|V|<sup>2</sup>)</li>\n<li>不可用于有负权边的图</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-3-2-各顶点间最短路径\"><a href=\"#6-3-2-各顶点间最短路径\" class=\"headerlink\" title=\"6.3-2 各顶点间最短路径\"></a>6.3-2 各顶点间最短路径</h3><ul>\n<li><h5 id=\"1）Floyd算法\"><a href=\"#1）Floyd算法\" class=\"headerlink\" title=\"1）Floyd算法\"></a>1）Floyd算法</h5><ul>\n<li><p>动态规划思想：</p>\n<ul>\n<li>1）允许在v0中转，求最短路径</li>\n<li>2）允许在v0、v1中转，求最短路径</li>\n<li>3）允许在v0、v1、v2中转，求最短路径</li>\n<li>…</li>\n</ul>\n</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/10.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/11.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/12.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/13.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/14.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度：O(|V|<sup>3</sup>)</li>\n<li>不能解决负权回路的问题</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/1.png\"><br><img src=\"/img/datastruct/6_graph/shortestpath/1.png\" alt=\"数据结构\"></p>\n<!--more-->\n<h3 id=\"6-3-1-单源最短路径\"><a href=\"#6-3-1-单源最短路径\" class=\"headerlink\" title=\"6.3-1 单源最短路径\"></a>6.3-1 单源最短路径</h3><ul>\n<li><h5 id=\"1）-BFS算法-无权\"><a href=\"#1）-BFS算法-无权\" class=\"headerlink\" title=\"1） BFS算法(无权)\"></a>1） BFS算法(无权)</h5><p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/2.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/2.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/3.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/3.png\" alt=\"数据结构\"></p>\n</li>\n<li><h5 id=\"2）Dijkstra-带权\"><a href=\"#2）Dijkstra-带权\" class=\"headerlink\" title=\"2）Dijkstra(带权)\"></a>2）Dijkstra(带权)</h5><p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/4.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/4.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/5.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/5.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/6.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/6.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/7.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/7.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/8.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/8.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/9.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/9.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度：O(|V|<sup>2</sup>)</li>\n<li>不可用于有负权边的图</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-3-2-各顶点间最短路径\"><a href=\"#6-3-2-各顶点间最短路径\" class=\"headerlink\" title=\"6.3-2 各顶点间最短路径\"></a>6.3-2 各顶点间最短路径</h3><ul>\n<li><h5 id=\"1）Floyd算法\"><a href=\"#1）Floyd算法\" class=\"headerlink\" title=\"1）Floyd算法\"></a>1）Floyd算法</h5><ul>\n<li><p>动态规划思想：</p>\n<ul>\n<li>1）允许在v0中转，求最短路径</li>\n<li>2）允许在v0、v1中转，求最短路径</li>\n<li>3）允许在v0、v1、v2中转，求最短路径</li>\n<li>…</li>\n</ul>\n</li>\n</ul>\n<p>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/10.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/10.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/11.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/11.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/12.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/12.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/13.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/13.png\" alt=\"数据结构\"><br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/shortestpath/14.png\"><br>  <img src=\"/img/datastruct/6_graph/shortestpath/14.png\" alt=\"数据结构\"></p>\n<ul>\n<li>时间复杂度：O(|V|<sup>3</sup>)</li>\n<li>不能解决负权回路的问题</li>\n</ul>\n</li>\n</ul>"},{"title":"6.4 有向无环图","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n### \n\n<!--more-->\n### 6.4-1 DAG描述表达式\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/1.png)\n![数据结构](/img/datastruct/6_graph/DAG/1.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/2.png)\n![数据结构](/img/datastruct/6_graph/DAG/2.png)\n### 6.4-2 拓扑排序\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/3.png)\n![数据结构](/img/datastruct/6_graph/DAG/3.png)\n- AOV网（Activity On Vertex Network）：顶点表示活动，弧表示活动之间的优先关系\n- 实现：\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/4.png)\n![数据结构](/img/datastruct/6_graph/DAG/4.png)\n- 时间复杂度：\n    - 邻接表：O(|V|+|E|)\n    - 邻接矩阵：O(|V|<sup>2</sup>)\n- 逆拓扑排序\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/5.png)\n![数据结构](/img/datastruct/6_graph/DAG/5.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/6.png)\n![数据结构](/img/datastruct/6_graph/DAG/6.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/7.png)\n![数据结构](/img/datastruct/6_graph/DAG/7.png)\n\n### 6.4-3 关键路径\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/8.png)\n![数据结构](/img/datastruct/6_graph/DAG/8.png)\n- AOE网（Activity On Edge Network）：弧表示活动，顶点表示事件\n    - 只有某顶点代表的时间发生后，该顶点出发的弧上的活动才能开始\n    - 只有在进入某顶点的所有弧上的活动都完成后，该顶点代表的事件才能发生\n- 关键路径：从源点到汇点的最长路径\n- 关键活动：关键路径上的活动\n- 事件V<sub>k</sub>的最早发生时间ve(k)：决定了所有从V<sub>k</sub>出发的活动的最早开始时间\n- 活动a<sub>i</sub>的最早开始时间e(i)：决定了该活动弧的起点所表示的事件的最早发生时间\n- 事件V<sub>k</sub>的最迟发生时间vl(k)：在不推迟整个工程完成时间的前提下，该事件必须发生的最迟时间\n- 活动a<sub>i</sub>的最迟开始时间l(i)：该活动弧的终点所表示的事件的最迟发生时间与该活动所需的时间之差\n- 求关键路径\n    - 1）正大\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/9.png)\n![数据结构](/img/datastruct/6_graph/DAG/9.png)\n    - 2）反小\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/10.png)\n![数据结构](/img/datastruct/6_graph/DAG/10.png)\n    - 3）=起点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/11.png)\n![数据结构](/img/datastruct/6_graph/DAG/11.png)\n    - 4）=终点-\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/12.png)\n![数据结构](/img/datastruct/6_graph/DAG/12.png)\n    - 5）相减\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/13.png)\n![数据结构](/img/datastruct/6_graph/DAG/13.png)\n","source":"_posts/datastruct/6_graph/4_DAG.md","raw":"---\ntitle: 6.4 有向无环图\ndate: 2023-08-07 00:00:00\ntags: [数据结构,图]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n### \n\n<!--more-->\n### 6.4-1 DAG描述表达式\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/1.png)\n![数据结构](/img/datastruct/6_graph/DAG/1.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/2.png)\n![数据结构](/img/datastruct/6_graph/DAG/2.png)\n### 6.4-2 拓扑排序\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/3.png)\n![数据结构](/img/datastruct/6_graph/DAG/3.png)\n- AOV网（Activity On Vertex Network）：顶点表示活动，弧表示活动之间的优先关系\n- 实现：\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/4.png)\n![数据结构](/img/datastruct/6_graph/DAG/4.png)\n- 时间复杂度：\n    - 邻接表：O(|V|+|E|)\n    - 邻接矩阵：O(|V|<sup>2</sup>)\n- 逆拓扑排序\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/5.png)\n![数据结构](/img/datastruct/6_graph/DAG/5.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/6.png)\n![数据结构](/img/datastruct/6_graph/DAG/6.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/7.png)\n![数据结构](/img/datastruct/6_graph/DAG/7.png)\n\n### 6.4-3 关键路径\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/8.png)\n![数据结构](/img/datastruct/6_graph/DAG/8.png)\n- AOE网（Activity On Edge Network）：弧表示活动，顶点表示事件\n    - 只有某顶点代表的时间发生后，该顶点出发的弧上的活动才能开始\n    - 只有在进入某顶点的所有弧上的活动都完成后，该顶点代表的事件才能发生\n- 关键路径：从源点到汇点的最长路径\n- 关键活动：关键路径上的活动\n- 事件V<sub>k</sub>的最早发生时间ve(k)：决定了所有从V<sub>k</sub>出发的活动的最早开始时间\n- 活动a<sub>i</sub>的最早开始时间e(i)：决定了该活动弧的起点所表示的事件的最早发生时间\n- 事件V<sub>k</sub>的最迟发生时间vl(k)：在不推迟整个工程完成时间的前提下，该事件必须发生的最迟时间\n- 活动a<sub>i</sub>的最迟开始时间l(i)：该活动弧的终点所表示的事件的最迟发生时间与该活动所需的时间之差\n- 求关键路径\n    - 1）正大\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/9.png)\n![数据结构](/img/datastruct/6_graph/DAG/9.png)\n    - 2）反小\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/10.png)\n![数据结构](/img/datastruct/6_graph/DAG/10.png)\n    - 3）=起点\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/11.png)\n![数据结构](/img/datastruct/6_graph/DAG/11.png)\n    - 4）=终点-\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/12.png)\n![数据结构](/img/datastruct/6_graph/DAG/12.png)\n    - 5）相减\n![](../../../../themes/yilia/source/img/datastruct/6_graph/DAG/13.png)\n![数据结构](/img/datastruct/6_graph/DAG/13.png)\n","slug":"datastruct/6_graph/4_DAG","published":1,"updated":"2023-10-23T12:34:36.586Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198592002s7svw8mtre56y","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><!--more-->\n<h3 id=\"6-4-1-DAG描述表达式\"><a href=\"#6-4-1-DAG描述表达式\" class=\"headerlink\" title=\"6.4-1 DAG描述表达式\"></a>6.4-1 DAG描述表达式</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/1.png\"><br><img src=\"/img/datastruct/6_graph/DAG/1.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/2.png\"><br><img src=\"/img/datastruct/6_graph/DAG/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-4-2-拓扑排序\"><a href=\"#6-4-2-拓扑排序\" class=\"headerlink\" title=\"6.4-2 拓扑排序\"></a>6.4-2 拓扑排序</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/3.png\"><br><img src=\"/img/datastruct/6_graph/DAG/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>AOV网（Activity On Vertex Network）：顶点表示活动，弧表示活动之间的优先关系</li>\n<li>实现：<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/4.png\"><br><img src=\"/img/datastruct/6_graph/DAG/4.png\" alt=\"数据结构\"></li>\n<li>时间复杂度：<ul>\n<li>邻接表：O(|V|+|E|)</li>\n<li>邻接矩阵：O(|V|<sup>2</sup>)</li>\n</ul>\n</li>\n<li>逆拓扑排序<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/5.png\"><br><img src=\"/img/datastruct/6_graph/DAG/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/6.png\"><br><img src=\"/img/datastruct/6_graph/DAG/6.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/7.png\"><br><img src=\"/img/datastruct/6_graph/DAG/7.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"6-4-3-关键路径\"><a href=\"#6-4-3-关键路径\" class=\"headerlink\" title=\"6.4-3 关键路径\"></a>6.4-3 关键路径</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/8.png\"><br><img src=\"/img/datastruct/6_graph/DAG/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>AOE网（Activity On Edge Network）：弧表示活动，顶点表示事件<ul>\n<li>只有某顶点代表的时间发生后，该顶点出发的弧上的活动才能开始</li>\n<li>只有在进入某顶点的所有弧上的活动都完成后，该顶点代表的事件才能发生</li>\n</ul>\n</li>\n<li>关键路径：从源点到汇点的最长路径</li>\n<li>关键活动：关键路径上的活动</li>\n<li>事件V<sub>k</sub>的最早发生时间ve(k)：决定了所有从V<sub>k</sub>出发的活动的最早开始时间</li>\n<li>活动a<sub>i</sub>的最早开始时间e(i)：决定了该活动弧的起点所表示的事件的最早发生时间</li>\n<li>事件V<sub>k</sub>的最迟发生时间vl(k)：在不推迟整个工程完成时间的前提下，该事件必须发生的最迟时间</li>\n<li>活动a<sub>i</sub>的最迟开始时间l(i)：该活动弧的终点所表示的事件的最迟发生时间与该活动所需的时间之差</li>\n<li>求关键路径<ul>\n<li>1）正大<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/9.png\"><br><img src=\"/img/datastruct/6_graph/DAG/9.png\" alt=\"数据结构\"></li>\n<li>2）反小<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/10.png\"><br><img src=\"/img/datastruct/6_graph/DAG/10.png\" alt=\"数据结构\"></li>\n<li>3）&#x3D;起点<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/11.png\"><br><img src=\"/img/datastruct/6_graph/DAG/11.png\" alt=\"数据结构\"></li>\n<li>4）&#x3D;终点-<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/12.png\"><br><img src=\"/img/datastruct/6_graph/DAG/12.png\" alt=\"数据结构\"></li>\n<li>5）相减<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/13.png\"><br><img src=\"/img/datastruct/6_graph/DAG/13.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><!--more-->\n<h3 id=\"6-4-1-DAG描述表达式\"><a href=\"#6-4-1-DAG描述表达式\" class=\"headerlink\" title=\"6.4-1 DAG描述表达式\"></a>6.4-1 DAG描述表达式</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/1.png\"><br><img src=\"/img/datastruct/6_graph/DAG/1.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/2.png\"><br><img src=\"/img/datastruct/6_graph/DAG/2.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-4-2-拓扑排序\"><a href=\"#6-4-2-拓扑排序\" class=\"headerlink\" title=\"6.4-2 拓扑排序\"></a>6.4-2 拓扑排序</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/3.png\"><br><img src=\"/img/datastruct/6_graph/DAG/3.png\" alt=\"数据结构\"></p>\n<ul>\n<li>AOV网（Activity On Vertex Network）：顶点表示活动，弧表示活动之间的优先关系</li>\n<li>实现：<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/4.png\"><br><img src=\"/img/datastruct/6_graph/DAG/4.png\" alt=\"数据结构\"></li>\n<li>时间复杂度：<ul>\n<li>邻接表：O(|V|+|E|)</li>\n<li>邻接矩阵：O(|V|<sup>2</sup>)</li>\n</ul>\n</li>\n<li>逆拓扑排序<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/5.png\"><br><img src=\"/img/datastruct/6_graph/DAG/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/6.png\"><br><img src=\"/img/datastruct/6_graph/DAG/6.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/7.png\"><br><img src=\"/img/datastruct/6_graph/DAG/7.png\" alt=\"数据结构\"></li>\n</ul>\n<h3 id=\"6-4-3-关键路径\"><a href=\"#6-4-3-关键路径\" class=\"headerlink\" title=\"6.4-3 关键路径\"></a>6.4-3 关键路径</h3><p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/8.png\"><br><img src=\"/img/datastruct/6_graph/DAG/8.png\" alt=\"数据结构\"></p>\n<ul>\n<li>AOE网（Activity On Edge Network）：弧表示活动，顶点表示事件<ul>\n<li>只有某顶点代表的时间发生后，该顶点出发的弧上的活动才能开始</li>\n<li>只有在进入某顶点的所有弧上的活动都完成后，该顶点代表的事件才能发生</li>\n</ul>\n</li>\n<li>关键路径：从源点到汇点的最长路径</li>\n<li>关键活动：关键路径上的活动</li>\n<li>事件V<sub>k</sub>的最早发生时间ve(k)：决定了所有从V<sub>k</sub>出发的活动的最早开始时间</li>\n<li>活动a<sub>i</sub>的最早开始时间e(i)：决定了该活动弧的起点所表示的事件的最早发生时间</li>\n<li>事件V<sub>k</sub>的最迟发生时间vl(k)：在不推迟整个工程完成时间的前提下，该事件必须发生的最迟时间</li>\n<li>活动a<sub>i</sub>的最迟开始时间l(i)：该活动弧的终点所表示的事件的最迟发生时间与该活动所需的时间之差</li>\n<li>求关键路径<ul>\n<li>1）正大<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/9.png\"><br><img src=\"/img/datastruct/6_graph/DAG/9.png\" alt=\"数据结构\"></li>\n<li>2）反小<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/10.png\"><br><img src=\"/img/datastruct/6_graph/DAG/10.png\" alt=\"数据结构\"></li>\n<li>3）&#x3D;起点<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/11.png\"><br><img src=\"/img/datastruct/6_graph/DAG/11.png\" alt=\"数据结构\"></li>\n<li>4）&#x3D;终点-<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/12.png\"><br><img src=\"/img/datastruct/6_graph/DAG/12.png\" alt=\"数据结构\"></li>\n<li>5）相减<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/DAG/13.png\"><br><img src=\"/img/datastruct/6_graph/DAG/13.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>"},{"title":"6.2 最小生成树","date":"2023-08-06T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/1.png)\n![数据结构](/img/datastruct/6_graph/generatetree/1.png)\n\n\n### 6.2-1 定义\n- T是连通网的生成树，T中所有边的代价之和称为生成树的代价，代价最小的生成树称为最小生成树\n- 最小生成树不唯一\n- 生成树的边数=顶点数-1\n- 只有连通网才有最小生成树\n\n### 6.2-2 Prim算法\n- 从某个顶点出发，选择代价最小的边，然后再选择与之相连的代价最小的边，直到所有顶点都被选中（看顶点）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/2.png)\n![数据结构](/img/datastruct/6_graph/generatetree/2.png)\n    - 过程\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/4.png)\n![数据结构](/img/datastruct/6_graph/generatetree/4.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/5.png)\n![数据结构](/img/datastruct/6_graph/generatetree/5.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/6.png)\n![数据结构](/img/datastruct/6_graph/generatetree/6.png)\n\n### 6.2-3 Kruskal算法\n- 从代价最小的边开始，依次选择代价更小的边，直到所有顶点都被选中（看边）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/3.png)\n![数据结构](/img/datastruct/6_graph/generatetree/3.png)\n    - 过程\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/10.png)\n![数据结构](/img/datastruct/6_graph/generatetree/10.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/7.png)\n![数据结构](/img/datastruct/6_graph/generatetree/7.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/8.png)\n![数据结构](/img/datastruct/6_graph/generatetree/8.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/9.png)\n![数据结构](/img/datastruct/6_graph/generatetree/9.png)\n","source":"_posts/datastruct/6_graph/2_generatetree.md","raw":"---\ntitle: 6.2 最小生成树\ndate: 2023-08-07 00:00:00\ntags: [数据结构,图,最小生成树]\ncategories: [数据结构]\ncomment: false\ntoc: true\n---\n#\n<!--more-->\n\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/1.png)\n![数据结构](/img/datastruct/6_graph/generatetree/1.png)\n\n\n### 6.2-1 定义\n- T是连通网的生成树，T中所有边的代价之和称为生成树的代价，代价最小的生成树称为最小生成树\n- 最小生成树不唯一\n- 生成树的边数=顶点数-1\n- 只有连通网才有最小生成树\n\n### 6.2-2 Prim算法\n- 从某个顶点出发，选择代价最小的边，然后再选择与之相连的代价最小的边，直到所有顶点都被选中（看顶点）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/2.png)\n![数据结构](/img/datastruct/6_graph/generatetree/2.png)\n    - 过程\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/4.png)\n![数据结构](/img/datastruct/6_graph/generatetree/4.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/5.png)\n![数据结构](/img/datastruct/6_graph/generatetree/5.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/6.png)\n![数据结构](/img/datastruct/6_graph/generatetree/6.png)\n\n### 6.2-3 Kruskal算法\n- 从代价最小的边开始，依次选择代价更小的边，直到所有顶点都被选中（看边）\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/3.png)\n![数据结构](/img/datastruct/6_graph/generatetree/3.png)\n    - 过程\n    ![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/10.png)\n![数据结构](/img/datastruct/6_graph/generatetree/10.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/7.png)\n![数据结构](/img/datastruct/6_graph/generatetree/7.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/8.png)\n![数据结构](/img/datastruct/6_graph/generatetree/8.png)\n![](../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/9.png)\n![数据结构](/img/datastruct/6_graph/generatetree/9.png)\n","slug":"datastruct/6_graph/2_generatetree","published":1,"updated":"2023-10-23T12:30:35.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198593002w7svwhs8d44d6","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/1.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-2-1-定义\"><a href=\"#6-2-1-定义\" class=\"headerlink\" title=\"6.2-1 定义\"></a>6.2-1 定义</h3><ul>\n<li>T是连通网的生成树，T中所有边的代价之和称为生成树的代价，代价最小的生成树称为最小生成树</li>\n<li>最小生成树不唯一</li>\n<li>生成树的边数&#x3D;顶点数-1</li>\n<li>只有连通网才有最小生成树</li>\n</ul>\n<h3 id=\"6-2-2-Prim算法\"><a href=\"#6-2-2-Prim算法\" class=\"headerlink\" title=\"6.2-2 Prim算法\"></a>6.2-2 Prim算法</h3><ul>\n<li>从某个顶点出发，选择代价最小的边，然后再选择与之相连的代价最小的边，直到所有顶点都被选中（看顶点）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/2.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/2.png\" alt=\"数据结构\"><ul>\n<li>过程<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/4.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/4.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/5.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/6.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/6.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-2-3-Kruskal算法\"><a href=\"#6-2-3-Kruskal算法\" class=\"headerlink\" title=\"6.2-3 Kruskal算法\"></a>6.2-3 Kruskal算法</h3><ul>\n<li>从代价最小的边开始，依次选择代价更小的边，直到所有顶点都被选中（看边）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/3.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/3.png\" alt=\"数据结构\"><ul>\n<li>过程<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/10.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/10.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/7.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/8.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/8.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/9.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/9.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<p><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/1.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/1.png\" alt=\"数据结构\"></p>\n<h3 id=\"6-2-1-定义\"><a href=\"#6-2-1-定义\" class=\"headerlink\" title=\"6.2-1 定义\"></a>6.2-1 定义</h3><ul>\n<li>T是连通网的生成树，T中所有边的代价之和称为生成树的代价，代价最小的生成树称为最小生成树</li>\n<li>最小生成树不唯一</li>\n<li>生成树的边数&#x3D;顶点数-1</li>\n<li>只有连通网才有最小生成树</li>\n</ul>\n<h3 id=\"6-2-2-Prim算法\"><a href=\"#6-2-2-Prim算法\" class=\"headerlink\" title=\"6.2-2 Prim算法\"></a>6.2-2 Prim算法</h3><ul>\n<li>从某个顶点出发，选择代价最小的边，然后再选择与之相连的代价最小的边，直到所有顶点都被选中（看顶点）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/2.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/2.png\" alt=\"数据结构\"><ul>\n<li>过程<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/4.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/4.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/5.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/5.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/6.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/6.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-2-3-Kruskal算法\"><a href=\"#6-2-3-Kruskal算法\" class=\"headerlink\" title=\"6.2-3 Kruskal算法\"></a>6.2-3 Kruskal算法</h3><ul>\n<li>从代价最小的边开始，依次选择代价更小的边，直到所有顶点都被选中（看边）<br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/3.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/3.png\" alt=\"数据结构\"><ul>\n<li>过程<br>  <img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/10.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/10.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/7.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/7.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/8.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/8.png\" alt=\"数据结构\"><br><img src=\"/../../../../themes/yilia/source/img/datastruct/6_graph/generatetree/9.png\"><br><img src=\"/img/datastruct/6_graph/generatetree/9.png\" alt=\"数据结构\"></li>\n</ul>\n</li>\n</ul>"},{"title":"CDM论文讲解","date":"2024-01-25T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n- 论文标题：[Cascaded diffusion models for high fidelity image generation](https://dl.acm.org/doi/abs/10.5555/3586589.3586636)\n\n- 来源：  JMLR 2022  \n- 贡献：\n  - Cascaded Diffusion Models(CDM)产生的高保真样本在FID评分和分类准确性评分方面优于BigGAN-deep和VQ-VAE-2。\n  - 为超分辨率模型引入了条件增强，并发现它对实现高样本保真度至关重要。\n\n\n\n# 1. 方法\n\n- 整体思想： Classifier Diffusion Models + SR3 + Tricks的串联模型，应用多个不同分辨率的扩散模型实现超分效果。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\1.png)\n![](img/deeplearning/paper/SR/CDM/1.png)\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\2.png)\n![](img/deeplearning/paper/SR/CDM/2.png)\n- SR3中也提到可以用级联的SR3做生成，本文在此基础上提出条件增强以提高生成质量\n\n# 1.1 条件增强\n\n- 截断条件采样：逆向过程中的中间图片Xt输入下一个超分模型（而不是XT，即逆向过程只做一部分）\n- 非截断条件增强：生成XT之后再施加高斯噪声后输入下一个模型\n\n\n\n# 2. 实验\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\3.png)\n\n![](img/deeplearning/paper/SR/CDM/3.png)\n\n- 效果比直接级联SR3好","source":"_posts/deeplearning/paper/SR/CDM.md","raw":"---\ntitle: CDM论文讲解\ndate: 2024-01-26 00:00:00\ntags: [深度学习,论文,超分]\ncategories: [深度学习]\ncomment: true\ntoc: true\n\n---\n\n#\n<!--more-->\n\n- 论文标题：[Cascaded diffusion models for high fidelity image generation](https://dl.acm.org/doi/abs/10.5555/3586589.3586636)\n\n- 来源：  JMLR 2022  \n- 贡献：\n  - Cascaded Diffusion Models(CDM)产生的高保真样本在FID评分和分类准确性评分方面优于BigGAN-deep和VQ-VAE-2。\n  - 为超分辨率模型引入了条件增强，并发现它对实现高样本保真度至关重要。\n\n\n\n# 1. 方法\n\n- 整体思想： Classifier Diffusion Models + SR3 + Tricks的串联模型，应用多个不同分辨率的扩散模型实现超分效果。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\1.png)\n![](img/deeplearning/paper/SR/CDM/1.png)\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\2.png)\n![](img/deeplearning/paper/SR/CDM/2.png)\n- SR3中也提到可以用级联的SR3做生成，本文在此基础上提出条件增强以提高生成质量\n\n# 1.1 条件增强\n\n- 截断条件采样：逆向过程中的中间图片Xt输入下一个超分模型（而不是XT，即逆向过程只做一部分）\n- 非截断条件增强：生成XT之后再施加高斯噪声后输入下一个模型\n\n\n\n# 2. 实验\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\3.png)\n\n![](img/deeplearning/paper/SR/CDM/3.png)\n\n- 效果比直接级联SR3好","slug":"deeplearning/paper/SR/CDM","published":1,"updated":"2024-01-30T15:36:04.579Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198594002z7svw8g4v3cm8","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>论文标题：<a href=\"https://dl.acm.org/doi/abs/10.5555/3586589.3586636\">Cascaded diffusion models for high fidelity image generation</a></p>\n</li>\n<li><p>来源：  JMLR 2022  </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>Cascaded Diffusion Models(CDM)产生的高保真样本在FID评分和分类准确性评分方面优于BigGAN-deep和VQ-VAE-2。</li>\n<li>为超分辨率模型引入了条件增强，并发现它对实现高样本保真度至关重要。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-方法\"><a href=\"#1-方法\" class=\"headerlink\" title=\"1. 方法\"></a>1. 方法</h1><ul>\n<li>整体思想： Classifier Diffusion Models + SR3 + Tricks的串联模型，应用多个不同分辨率的扩散模型实现超分效果。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\1.png\"><br><img src=\"/img/deeplearning/paper/SR/CDM/1.png\"><br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\2.png\"><br><img src=\"/img/deeplearning/paper/SR/CDM/2.png\"></p>\n<ul>\n<li>SR3中也提到可以用级联的SR3做生成，本文在此基础上提出条件增强以提高生成质量</li>\n</ul>\n<h1 id=\"1-1-条件增强\"><a href=\"#1-1-条件增强\" class=\"headerlink\" title=\"1.1 条件增强\"></a>1.1 条件增强</h1><ul>\n<li>截断条件采样：逆向过程中的中间图片Xt输入下一个超分模型（而不是XT，即逆向过程只做一部分）</li>\n<li>非截断条件增强：生成XT之后再施加高斯噪声后输入下一个模型</li>\n</ul>\n<h1 id=\"2-实验\"><a href=\"#2-实验\" class=\"headerlink\" title=\"2. 实验\"></a>2. 实验</h1><p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\3.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/CDM/3.png\"></p>\n<ul>\n<li>效果比直接级联SR3好</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>论文标题：<a href=\"https://dl.acm.org/doi/abs/10.5555/3586589.3586636\">Cascaded diffusion models for high fidelity image generation</a></p>\n</li>\n<li><p>来源：  JMLR 2022  </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>Cascaded Diffusion Models(CDM)产生的高保真样本在FID评分和分类准确性评分方面优于BigGAN-deep和VQ-VAE-2。</li>\n<li>为超分辨率模型引入了条件增强，并发现它对实现高样本保真度至关重要。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-方法\"><a href=\"#1-方法\" class=\"headerlink\" title=\"1. 方法\"></a>1. 方法</h1><ul>\n<li>整体思想： Classifier Diffusion Models + SR3 + Tricks的串联模型，应用多个不同分辨率的扩散模型实现超分效果。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\1.png\"><br><img src=\"/img/deeplearning/paper/SR/CDM/1.png\"><br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\2.png\"><br><img src=\"/img/deeplearning/paper/SR/CDM/2.png\"></p>\n<ul>\n<li>SR3中也提到可以用级联的SR3做生成，本文在此基础上提出条件增强以提高生成质量</li>\n</ul>\n<h1 id=\"1-1-条件增强\"><a href=\"#1-1-条件增强\" class=\"headerlink\" title=\"1.1 条件增强\"></a>1.1 条件增强</h1><ul>\n<li>截断条件采样：逆向过程中的中间图片Xt输入下一个超分模型（而不是XT，即逆向过程只做一部分）</li>\n<li>非截断条件增强：生成XT之后再施加高斯噪声后输入下一个模型</li>\n</ul>\n<h1 id=\"2-实验\"><a href=\"#2-实验\" class=\"headerlink\" title=\"2. 实验\"></a>2. 实验</h1><p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\CDM\\3.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/CDM/3.png\"></p>\n<ul>\n<li>效果比直接级联SR3好</li>\n</ul>"},{"title":"Resshift论文讲解","date":"2024-01-26T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n- 论文标题：[Resshift: Efficient diffusion model for image super-resolution by residual shifting](https://arxiv.org/abs/2307.12348)\n\n- 来源：NeurIPS. 2023 \n- 贡献：\n  - 提出了一种残差移动方法，加快了扩散模型推理速度，同时保留高性能。\n  - 提出一个噪声设计方案，能够有效控制扩散过程中的噪声强度和转换速度，也可有效控制保真度-真实性之间的权衡。  \n\n# 1. 问题\n\n- 基于diffusion的超分辨率采样速度慢，现有的加速采样技术不可避免地会在一定程度上牺牲性能，导致超分结果过于模糊。\n\n\n\n# 2. 方法\n\n","source":"_posts/deeplearning/paper/SR/Resshift.md","raw":"---\ntitle: Resshift论文讲解\ndate: 2024-01-27 00:00:00\ntags: [深度学习,论文,超分]\ncategories: [深度学习]\ncomment: true\ntoc: true\n\n\n\n---\n\n#\n<!--more-->\n\n- 论文标题：[Resshift: Efficient diffusion model for image super-resolution by residual shifting](https://arxiv.org/abs/2307.12348)\n\n- 来源：NeurIPS. 2023 \n- 贡献：\n  - 提出了一种残差移动方法，加快了扩散模型推理速度，同时保留高性能。\n  - 提出一个噪声设计方案，能够有效控制扩散过程中的噪声强度和转换速度，也可有效控制保真度-真实性之间的权衡。  \n\n# 1. 问题\n\n- 基于diffusion的超分辨率采样速度慢，现有的加速采样技术不可避免地会在一定程度上牺牲性能，导致超分结果过于模糊。\n\n\n\n# 2. 方法\n\n","slug":"deeplearning/paper/SR/Resshift","published":1,"updated":"2024-01-30T15:36:10.587Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859500337svw2fvh2hie","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>论文标题：<a href=\"https://arxiv.org/abs/2307.12348\">Resshift: Efficient diffusion model for image super-resolution by residual shifting</a></p>\n</li>\n<li><p>来源：NeurIPS. 2023 </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>提出了一种残差移动方法，加快了扩散模型推理速度，同时保留高性能。</li>\n<li>提出一个噪声设计方案，能够有效控制扩散过程中的噪声强度和转换速度，也可有效控制保真度-真实性之间的权衡。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><ul>\n<li>基于diffusion的超分辨率采样速度慢，现有的加速采样技术不可避免地会在一定程度上牺牲性能，导致超分结果过于模糊。</li>\n</ul>\n<h1 id=\"2-方法\"><a href=\"#2-方法\" class=\"headerlink\" title=\"2. 方法\"></a>2. 方法</h1>","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>论文标题：<a href=\"https://arxiv.org/abs/2307.12348\">Resshift: Efficient diffusion model for image super-resolution by residual shifting</a></p>\n</li>\n<li><p>来源：NeurIPS. 2023 </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>提出了一种残差移动方法，加快了扩散模型推理速度，同时保留高性能。</li>\n<li>提出一个噪声设计方案，能够有效控制扩散过程中的噪声强度和转换速度，也可有效控制保真度-真实性之间的权衡。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><ul>\n<li>基于diffusion的超分辨率采样速度慢，现有的加速采样技术不可避免地会在一定程度上牺牲性能，导致超分结果过于模糊。</li>\n</ul>\n<h1 id=\"2-方法\"><a href=\"#2-方法\" class=\"headerlink\" title=\"2. 方法\"></a>2. 方法</h1>"},{"title":"HAT论文讲解","date":"2024-01-24T16:00:00.000Z","comment":false,"toc":true,"_content":"\n#\n<!--more-->\n\n- 论文标题：[Activating more pixels in image super-resolution transformer](https://scholar.google.com/scholar?cluster=4970683343699562565&hl=en&as_sdt=2005&sciodt=0,5)\n\n- 来源：CVPR  2023\n- 贡献：\n  -  在结构上，本文设计的HAT结合了通道注意力与自注意力，在以往Transformer结构的基础上进一步提升了模型利用输入信息的范围。同时设计了一个重叠交叉注意力模块，对Swin结构利用跨窗口信息的能力进行了有效增强。 \n  -  在预训练策略上，本文提出的在相同任务上做预训练的方法，使得模型的性能进一步增强。 \n  -  HAT大幅超越了当前超分方法的性能，这表明该任务或许远没有达到上限，可能依然还有很大的探索空间。 \n  \n  \n\n# 1. 问题\n\n \t本文首先对不同方法的LAM 结果进行了对比。LAM是一种为SR任务设计的归因方法，它能够显示模型在进行超分辨率重建的过程中哪些像素起到了作用。 \n\n​\t 如下图所示，LAM图中红色标记点表示：模型在重建左上图红框标记块时，对重建结果会产生影响的像素（LAM结果下面的值为DI值，它可以定量地反映被利用像素的范围。DI值越大，表示重建时利用的像素范围越大）。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\1.png)\n\n![](img/deeplearning/paper/SR/HAT/1.png)\n\n​\t 一般来说，被利用像素的范围越大，重建的效果往往越好，该结论在对比基于CNN的方法EDSR与RCAN时可以得到明显体现。然而，当对比RCAN与基于Transformer的SwinIR方法时，却出现了结论相反的现象： SwinIR取得了更高的PSNR/SSIM，但相比RCAN并没有使用更大范围的像素信息，并且由于其有限的信息使用范围，在蓝色框区域恢复出了错误的纹理。这与以往普遍认为Transformer结构是通过更好地利用long-range信息来取得性能优势的直觉是相悖的。 \n\n​\t这些现象说明：\n\n- SwinIR结构拥有更强的局部表征能力，能够使用更少的信息来达到更高的性能；\n- SwinIR依然有较大提升空间，如果更多的像素能够被利用，那么应该会取得更大的性能提升。\n\n​\t除此之外，本文发现在SwinIR网络前几层产生的中间特征会出现明显的块状效应。这是由于模型在计算自注意力时的窗口划分导致的，因此本文认为现有结构进行跨窗口信息交互的方式也应该被改进。\n\n\n\n# 2. 解决方案\n\n## 2.1  **网络结构设计** \n\n​\tHAT的整体架构采用了与SwinIR相似的Residual in Residual结构，如下图3所示。主要的不同之处在于混合注意力模块（Hybrid Attention Block， HAB）与重叠的交叉注意力模块（Overlapping Cross-Attention Block， OCAB）的设计。\n\n​\t其中对于HAB，本文采用了并联的方式来结合通道注意力和自注意力。通道注意力能够利用全局信息；自注意力具有强大的表征能力。HAB模块的目的在于能够同时结合这两者的优势。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\2.png)\n\n ![](img/deeplearning/paper/SR/HAT/2.png) \n\n​\t对于OCAB的设计，本文使用了一种重叠的窗口划分机制，如下图所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\3.png)\n\n ![](img/deeplearning/paper/SR/HAT/3.png) \n\n​\t相对于原始基于窗口的self-attention中Q、K和V来自于同一个窗口特征，OCA中的K/V来自更大的窗口特征，这允许attention能够被跨窗口地计算，以增强相邻窗口间信息的交互。\n\n\n\n## 2.2  **预训练策略** \n\n​\t本文提出了一种直接使用相同的任务，但是使用更大的数据集（比如ImageNet）进行预训练的策略。\n\n​\t相比于之前用于超分任务的预训练方案，该策略更简单，但却能带来更多的性能增益。\n\n\n\n# 3. 实验\n\n## 3.1 更大的窗口尺寸\n\n-  通过对于不同窗口尺寸的定量和定性比较，可以看到16窗口尺寸有明显提升，HAT使用窗口尺寸16作为默认设置。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\4.png)\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\5.png)\n\n ![](img/deeplearning/paper/SR/HAT/4.png) \n ![](img/deeplearning/paper/SR/HAT/5.png) \n\n\n\n## 3.2 消融实验\n\n- 本文提供了消融实验来验证CAB和OCAB的影响，定量和定性分析结果如下表2和图6所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\6.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\7.png)![](img/deeplearning/paper/SR/HAT/6.png) \n![](img/deeplearning/paper/SR/HAT/7.png) \n\n- 可以看到文中所提的两个模块在定量指标上均带来了不小的提升，在LAM和视觉效果上相对于Baseline也具有明显改善。\n\n\n\n## 3.3 主实验结果\n\n- 在基准数据集上进行定量对比实验的结果如下表所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\8.png)\n![](img/deeplearning/paper/SR/HAT/8.png) \n\n​\t从定量指标上看，没有使用ImageNet预训练策略的HAT的性能已经明显超越SwinIR，甚至在很多情况下超越了经过ImageNet预训练的EDT。\n\n​\t使用了ImageNet预训练的HAT则更是大幅超越了SwinIR与EDT的性能，在2倍超分的Urban100数据集上，超越SwinIR 1dB。\n\n​\t更大容量的模型HAT-L带来了更大的性能提升，最高在2倍超分的Urban100数据集上超越SwinIR达1.28dB，超越EDT达0.85dB。\n\n-  视觉效果对比如下图所示。可以看出HAT能够恢复更多更清晰的细节，由于对于重复纹理较多的情况，HAT具有显著优势。在文字的恢复上，HAT相比其他方法也能够恢复出更清晰的文字边缘。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\9.png)\n![](img/deeplearning/paper/SR/HAT/8.png) \n\n\n\n## 3.4 **预训练策略对比** \n\n​\t 本文对于不同的预训练策略进行了对比，如下表所示。相对于EDT 提出使用相关任务进行预训练的策略，本文提出的使用相同任务进行预训练的策略无论是在预训练阶段还是微调后的结果，性能都要更优。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\11.png)\n![](img/deeplearning/paper/SR/HAT/11.png) \n\n\n\n\n【转自：https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&menu=1】\n\n","source":"_posts/deeplearning/paper/SR/HAT.md","raw":"---\ntitle: HAT论文讲解\ndate: 2024-01-25 00:00:00\ntags: [深度学习,论文,超分]\ncategories: [深度学习]\ncomment: false\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n- 论文标题：[Activating more pixels in image super-resolution transformer](https://scholar.google.com/scholar?cluster=4970683343699562565&hl=en&as_sdt=2005&sciodt=0,5)\n\n- 来源：CVPR  2023\n- 贡献：\n  -  在结构上，本文设计的HAT结合了通道注意力与自注意力，在以往Transformer结构的基础上进一步提升了模型利用输入信息的范围。同时设计了一个重叠交叉注意力模块，对Swin结构利用跨窗口信息的能力进行了有效增强。 \n  -  在预训练策略上，本文提出的在相同任务上做预训练的方法，使得模型的性能进一步增强。 \n  -  HAT大幅超越了当前超分方法的性能，这表明该任务或许远没有达到上限，可能依然还有很大的探索空间。 \n  \n  \n\n# 1. 问题\n\n \t本文首先对不同方法的LAM 结果进行了对比。LAM是一种为SR任务设计的归因方法，它能够显示模型在进行超分辨率重建的过程中哪些像素起到了作用。 \n\n​\t 如下图所示，LAM图中红色标记点表示：模型在重建左上图红框标记块时，对重建结果会产生影响的像素（LAM结果下面的值为DI值，它可以定量地反映被利用像素的范围。DI值越大，表示重建时利用的像素范围越大）。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\1.png)\n\n![](img/deeplearning/paper/SR/HAT/1.png)\n\n​\t 一般来说，被利用像素的范围越大，重建的效果往往越好，该结论在对比基于CNN的方法EDSR与RCAN时可以得到明显体现。然而，当对比RCAN与基于Transformer的SwinIR方法时，却出现了结论相反的现象： SwinIR取得了更高的PSNR/SSIM，但相比RCAN并没有使用更大范围的像素信息，并且由于其有限的信息使用范围，在蓝色框区域恢复出了错误的纹理。这与以往普遍认为Transformer结构是通过更好地利用long-range信息来取得性能优势的直觉是相悖的。 \n\n​\t这些现象说明：\n\n- SwinIR结构拥有更强的局部表征能力，能够使用更少的信息来达到更高的性能；\n- SwinIR依然有较大提升空间，如果更多的像素能够被利用，那么应该会取得更大的性能提升。\n\n​\t除此之外，本文发现在SwinIR网络前几层产生的中间特征会出现明显的块状效应。这是由于模型在计算自注意力时的窗口划分导致的，因此本文认为现有结构进行跨窗口信息交互的方式也应该被改进。\n\n\n\n# 2. 解决方案\n\n## 2.1  **网络结构设计** \n\n​\tHAT的整体架构采用了与SwinIR相似的Residual in Residual结构，如下图3所示。主要的不同之处在于混合注意力模块（Hybrid Attention Block， HAB）与重叠的交叉注意力模块（Overlapping Cross-Attention Block， OCAB）的设计。\n\n​\t其中对于HAB，本文采用了并联的方式来结合通道注意力和自注意力。通道注意力能够利用全局信息；自注意力具有强大的表征能力。HAB模块的目的在于能够同时结合这两者的优势。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\2.png)\n\n ![](img/deeplearning/paper/SR/HAT/2.png) \n\n​\t对于OCAB的设计，本文使用了一种重叠的窗口划分机制，如下图所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\3.png)\n\n ![](img/deeplearning/paper/SR/HAT/3.png) \n\n​\t相对于原始基于窗口的self-attention中Q、K和V来自于同一个窗口特征，OCA中的K/V来自更大的窗口特征，这允许attention能够被跨窗口地计算，以增强相邻窗口间信息的交互。\n\n\n\n## 2.2  **预训练策略** \n\n​\t本文提出了一种直接使用相同的任务，但是使用更大的数据集（比如ImageNet）进行预训练的策略。\n\n​\t相比于之前用于超分任务的预训练方案，该策略更简单，但却能带来更多的性能增益。\n\n\n\n# 3. 实验\n\n## 3.1 更大的窗口尺寸\n\n-  通过对于不同窗口尺寸的定量和定性比较，可以看到16窗口尺寸有明显提升，HAT使用窗口尺寸16作为默认设置。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\4.png)\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\5.png)\n\n ![](img/deeplearning/paper/SR/HAT/4.png) \n ![](img/deeplearning/paper/SR/HAT/5.png) \n\n\n\n## 3.2 消融实验\n\n- 本文提供了消融实验来验证CAB和OCAB的影响，定量和定性分析结果如下表2和图6所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\6.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\7.png)![](img/deeplearning/paper/SR/HAT/6.png) \n![](img/deeplearning/paper/SR/HAT/7.png) \n\n- 可以看到文中所提的两个模块在定量指标上均带来了不小的提升，在LAM和视觉效果上相对于Baseline也具有明显改善。\n\n\n\n## 3.3 主实验结果\n\n- 在基准数据集上进行定量对比实验的结果如下表所示。\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\8.png)\n![](img/deeplearning/paper/SR/HAT/8.png) \n\n​\t从定量指标上看，没有使用ImageNet预训练策略的HAT的性能已经明显超越SwinIR，甚至在很多情况下超越了经过ImageNet预训练的EDT。\n\n​\t使用了ImageNet预训练的HAT则更是大幅超越了SwinIR与EDT的性能，在2倍超分的Urban100数据集上，超越SwinIR 1dB。\n\n​\t更大容量的模型HAT-L带来了更大的性能提升，最高在2倍超分的Urban100数据集上超越SwinIR达1.28dB，超越EDT达0.85dB。\n\n-  视觉效果对比如下图所示。可以看出HAT能够恢复更多更清晰的细节，由于对于重复纹理较多的情况，HAT具有显著优势。在文字的恢复上，HAT相比其他方法也能够恢复出更清晰的文字边缘。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\9.png)\n![](img/deeplearning/paper/SR/HAT/8.png) \n\n\n\n## 3.4 **预训练策略对比** \n\n​\t 本文对于不同的预训练策略进行了对比，如下表所示。相对于EDT 提出使用相关任务进行预训练的策略，本文提出的使用相同任务进行预训练的策略无论是在预训练阶段还是微调后的结果，性能都要更优。 \n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\11.png)\n![](img/deeplearning/paper/SR/HAT/11.png) \n\n\n\n\n【转自：https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&menu=1】\n\n","slug":"deeplearning/paper/SR/HAT","published":1,"updated":"2024-01-26T11:15:23.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859500367svwdjqlc04r","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>论文标题：<a href=\"https://scholar.google.com/scholar?cluster=4970683343699562565&hl=en&as_sdt=2005&sciodt=0,5\">Activating more pixels in image super-resolution transformer</a></p>\n</li>\n<li><p>来源：CVPR  2023</p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>在结构上，本文设计的HAT结合了通道注意力与自注意力，在以往Transformer结构的基础上进一步提升了模型利用输入信息的范围。同时设计了一个重叠交叉注意力模块，对Swin结构利用跨窗口信息的能力进行了有效增强。 </li>\n<li>在预训练策略上，本文提出的在相同任务上做预训练的方法，使得模型的性能进一步增强。 </li>\n<li>HAT大幅超越了当前超分方法的性能，这表明该任务或许远没有达到上限，可能依然还有很大的探索空间。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><pre><code> 本文首先对不同方法的LAM 结果进行了对比。LAM是一种为SR任务设计的归因方法，它能够显示模型在进行超分辨率重建的过程中哪些像素起到了作用。 \n</code></pre>\n<p>​\t 如下图所示，LAM图中红色标记点表示：模型在重建左上图红框标记块时，对重建结果会产生影响的像素（LAM结果下面的值为DI值，它可以定量地反映被利用像素的范围。DI值越大，表示重建时利用的像素范围越大）。 </p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\1.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/HAT/1.png\"></p>\n<p>​\t 一般来说，被利用像素的范围越大，重建的效果往往越好，该结论在对比基于CNN的方法EDSR与RCAN时可以得到明显体现。然而，当对比RCAN与基于Transformer的SwinIR方法时，却出现了结论相反的现象： SwinIR取得了更高的PSNR&#x2F;SSIM，但相比RCAN并没有使用更大范围的像素信息，并且由于其有限的信息使用范围，在蓝色框区域恢复出了错误的纹理。这与以往普遍认为Transformer结构是通过更好地利用long-range信息来取得性能优势的直觉是相悖的。 </p>\n<p>​\t这些现象说明：</p>\n<ul>\n<li>SwinIR结构拥有更强的局部表征能力，能够使用更少的信息来达到更高的性能；</li>\n<li>SwinIR依然有较大提升空间，如果更多的像素能够被利用，那么应该会取得更大的性能提升。</li>\n</ul>\n<p>​\t除此之外，本文发现在SwinIR网络前几层产生的中间特征会出现明显的块状效应。这是由于模型在计算自注意力时的窗口划分导致的，因此本文认为现有结构进行跨窗口信息交互的方式也应该被改进。</p>\n<h1 id=\"2-解决方案\"><a href=\"#2-解决方案\" class=\"headerlink\" title=\"2. 解决方案\"></a>2. 解决方案</h1><h2 id=\"2-1-网络结构设计\"><a href=\"#2-1-网络结构设计\" class=\"headerlink\" title=\"2.1  网络结构设计\"></a>2.1  <strong>网络结构设计</strong></h2><p>​\tHAT的整体架构采用了与SwinIR相似的Residual in Residual结构，如下图3所示。主要的不同之处在于混合注意力模块（Hybrid Attention Block， HAB）与重叠的交叉注意力模块（Overlapping Cross-Attention Block， OCAB）的设计。</p>\n<p>​\t其中对于HAB，本文采用了并联的方式来结合通道注意力和自注意力。通道注意力能够利用全局信息；自注意力具有强大的表征能力。HAB模块的目的在于能够同时结合这两者的优势。</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\2.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/2.png\"> </p>\n<p>​\t对于OCAB的设计，本文使用了一种重叠的窗口划分机制，如下图所示。</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\3.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/3.png\"> </p>\n<p>​\t相对于原始基于窗口的self-attention中Q、K和V来自于同一个窗口特征，OCA中的K&#x2F;V来自更大的窗口特征，这允许attention能够被跨窗口地计算，以增强相邻窗口间信息的交互。</p>\n<h2 id=\"2-2-预训练策略\"><a href=\"#2-2-预训练策略\" class=\"headerlink\" title=\"2.2  预训练策略\"></a>2.2  <strong>预训练策略</strong></h2><p>​\t本文提出了一种直接使用相同的任务，但是使用更大的数据集（比如ImageNet）进行预训练的策略。</p>\n<p>​\t相比于之前用于超分任务的预训练方案，该策略更简单，但却能带来更多的性能增益。</p>\n<h1 id=\"3-实验\"><a href=\"#3-实验\" class=\"headerlink\" title=\"3. 实验\"></a>3. 实验</h1><h2 id=\"3-1-更大的窗口尺寸\"><a href=\"#3-1-更大的窗口尺寸\" class=\"headerlink\" title=\"3.1 更大的窗口尺寸\"></a>3.1 更大的窗口尺寸</h2><ul>\n<li>通过对于不同窗口尺寸的定量和定性比较，可以看到16窗口尺寸有明显提升，HAT使用窗口尺寸16作为默认设置。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\4.png\"><br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\5.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/4.png\"><br> <img src=\"/img/deeplearning/paper/SR/HAT/5.png\"> </p>\n<h2 id=\"3-2-消融实验\"><a href=\"#3-2-消融实验\" class=\"headerlink\" title=\"3.2 消融实验\"></a>3.2 消融实验</h2><ul>\n<li>本文提供了消融实验来验证CAB和OCAB的影响，定量和定性分析结果如下表2和图6所示。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\6.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\7.png\"><img src=\"/img/deeplearning/paper/SR/HAT/6.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/7.png\"> </p>\n<ul>\n<li>可以看到文中所提的两个模块在定量指标上均带来了不小的提升，在LAM和视觉效果上相对于Baseline也具有明显改善。</li>\n</ul>\n<h2 id=\"3-3-主实验结果\"><a href=\"#3-3-主实验结果\" class=\"headerlink\" title=\"3.3 主实验结果\"></a>3.3 主实验结果</h2><ul>\n<li>在基准数据集上进行定量对比实验的结果如下表所示。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\8.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/8.png\"> </p>\n<p>​\t从定量指标上看，没有使用ImageNet预训练策略的HAT的性能已经明显超越SwinIR，甚至在很多情况下超越了经过ImageNet预训练的EDT。</p>\n<p>​\t使用了ImageNet预训练的HAT则更是大幅超越了SwinIR与EDT的性能，在2倍超分的Urban100数据集上，超越SwinIR 1dB。</p>\n<p>​\t更大容量的模型HAT-L带来了更大的性能提升，最高在2倍超分的Urban100数据集上超越SwinIR达1.28dB，超越EDT达0.85dB。</p>\n<ul>\n<li>视觉效果对比如下图所示。可以看出HAT能够恢复更多更清晰的细节，由于对于重复纹理较多的情况，HAT具有显著优势。在文字的恢复上，HAT相比其他方法也能够恢复出更清晰的文字边缘。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\9.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/8.png\"> </p>\n<h2 id=\"3-4-预训练策略对比\"><a href=\"#3-4-预训练策略对比\" class=\"headerlink\" title=\"3.4 预训练策略对比\"></a>3.4 <strong>预训练策略对比</strong></h2><p>​\t 本文对于不同的预训练策略进行了对比，如下表所示。相对于EDT 提出使用相关任务进行预训练的策略，本文提出的使用相同任务进行预训练的策略无论是在预训练阶段还是微调后的结果，性能都要更优。 </p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\11.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/11.png\"> </p>\n<p>【转自：<a href=\"https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&menu=1%E3%80%91\">https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&amp;menu=1】</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>论文标题：<a href=\"https://scholar.google.com/scholar?cluster=4970683343699562565&hl=en&as_sdt=2005&sciodt=0,5\">Activating more pixels in image super-resolution transformer</a></p>\n</li>\n<li><p>来源：CVPR  2023</p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>在结构上，本文设计的HAT结合了通道注意力与自注意力，在以往Transformer结构的基础上进一步提升了模型利用输入信息的范围。同时设计了一个重叠交叉注意力模块，对Swin结构利用跨窗口信息的能力进行了有效增强。 </li>\n<li>在预训练策略上，本文提出的在相同任务上做预训练的方法，使得模型的性能进一步增强。 </li>\n<li>HAT大幅超越了当前超分方法的性能，这表明该任务或许远没有达到上限，可能依然还有很大的探索空间。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><pre><code> 本文首先对不同方法的LAM 结果进行了对比。LAM是一种为SR任务设计的归因方法，它能够显示模型在进行超分辨率重建的过程中哪些像素起到了作用。 \n</code></pre>\n<p>​\t 如下图所示，LAM图中红色标记点表示：模型在重建左上图红框标记块时，对重建结果会产生影响的像素（LAM结果下面的值为DI值，它可以定量地反映被利用像素的范围。DI值越大，表示重建时利用的像素范围越大）。 </p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\1.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/HAT/1.png\"></p>\n<p>​\t 一般来说，被利用像素的范围越大，重建的效果往往越好，该结论在对比基于CNN的方法EDSR与RCAN时可以得到明显体现。然而，当对比RCAN与基于Transformer的SwinIR方法时，却出现了结论相反的现象： SwinIR取得了更高的PSNR&#x2F;SSIM，但相比RCAN并没有使用更大范围的像素信息，并且由于其有限的信息使用范围，在蓝色框区域恢复出了错误的纹理。这与以往普遍认为Transformer结构是通过更好地利用long-range信息来取得性能优势的直觉是相悖的。 </p>\n<p>​\t这些现象说明：</p>\n<ul>\n<li>SwinIR结构拥有更强的局部表征能力，能够使用更少的信息来达到更高的性能；</li>\n<li>SwinIR依然有较大提升空间，如果更多的像素能够被利用，那么应该会取得更大的性能提升。</li>\n</ul>\n<p>​\t除此之外，本文发现在SwinIR网络前几层产生的中间特征会出现明显的块状效应。这是由于模型在计算自注意力时的窗口划分导致的，因此本文认为现有结构进行跨窗口信息交互的方式也应该被改进。</p>\n<h1 id=\"2-解决方案\"><a href=\"#2-解决方案\" class=\"headerlink\" title=\"2. 解决方案\"></a>2. 解决方案</h1><h2 id=\"2-1-网络结构设计\"><a href=\"#2-1-网络结构设计\" class=\"headerlink\" title=\"2.1  网络结构设计\"></a>2.1  <strong>网络结构设计</strong></h2><p>​\tHAT的整体架构采用了与SwinIR相似的Residual in Residual结构，如下图3所示。主要的不同之处在于混合注意力模块（Hybrid Attention Block， HAB）与重叠的交叉注意力模块（Overlapping Cross-Attention Block， OCAB）的设计。</p>\n<p>​\t其中对于HAB，本文采用了并联的方式来结合通道注意力和自注意力。通道注意力能够利用全局信息；自注意力具有强大的表征能力。HAB模块的目的在于能够同时结合这两者的优势。</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\2.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/2.png\"> </p>\n<p>​\t对于OCAB的设计，本文使用了一种重叠的窗口划分机制，如下图所示。</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\3.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/3.png\"> </p>\n<p>​\t相对于原始基于窗口的self-attention中Q、K和V来自于同一个窗口特征，OCA中的K&#x2F;V来自更大的窗口特征，这允许attention能够被跨窗口地计算，以增强相邻窗口间信息的交互。</p>\n<h2 id=\"2-2-预训练策略\"><a href=\"#2-2-预训练策略\" class=\"headerlink\" title=\"2.2  预训练策略\"></a>2.2  <strong>预训练策略</strong></h2><p>​\t本文提出了一种直接使用相同的任务，但是使用更大的数据集（比如ImageNet）进行预训练的策略。</p>\n<p>​\t相比于之前用于超分任务的预训练方案，该策略更简单，但却能带来更多的性能增益。</p>\n<h1 id=\"3-实验\"><a href=\"#3-实验\" class=\"headerlink\" title=\"3. 实验\"></a>3. 实验</h1><h2 id=\"3-1-更大的窗口尺寸\"><a href=\"#3-1-更大的窗口尺寸\" class=\"headerlink\" title=\"3.1 更大的窗口尺寸\"></a>3.1 更大的窗口尺寸</h2><ul>\n<li>通过对于不同窗口尺寸的定量和定性比较，可以看到16窗口尺寸有明显提升，HAT使用窗口尺寸16作为默认设置。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\4.png\"><br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\5.png\"></p>\n<p> <img src=\"/img/deeplearning/paper/SR/HAT/4.png\"><br> <img src=\"/img/deeplearning/paper/SR/HAT/5.png\"> </p>\n<h2 id=\"3-2-消融实验\"><a href=\"#3-2-消融实验\" class=\"headerlink\" title=\"3.2 消融实验\"></a>3.2 消融实验</h2><ul>\n<li>本文提供了消融实验来验证CAB和OCAB的影响，定量和定性分析结果如下表2和图6所示。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\6.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\7.png\"><img src=\"/img/deeplearning/paper/SR/HAT/6.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/7.png\"> </p>\n<ul>\n<li>可以看到文中所提的两个模块在定量指标上均带来了不小的提升，在LAM和视觉效果上相对于Baseline也具有明显改善。</li>\n</ul>\n<h2 id=\"3-3-主实验结果\"><a href=\"#3-3-主实验结果\" class=\"headerlink\" title=\"3.3 主实验结果\"></a>3.3 主实验结果</h2><ul>\n<li>在基准数据集上进行定量对比实验的结果如下表所示。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\8.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/8.png\"> </p>\n<p>​\t从定量指标上看，没有使用ImageNet预训练策略的HAT的性能已经明显超越SwinIR，甚至在很多情况下超越了经过ImageNet预训练的EDT。</p>\n<p>​\t使用了ImageNet预训练的HAT则更是大幅超越了SwinIR与EDT的性能，在2倍超分的Urban100数据集上，超越SwinIR 1dB。</p>\n<p>​\t更大容量的模型HAT-L带来了更大的性能提升，最高在2倍超分的Urban100数据集上超越SwinIR达1.28dB，超越EDT达0.85dB。</p>\n<ul>\n<li>视觉效果对比如下图所示。可以看出HAT能够恢复更多更清晰的细节，由于对于重复纹理较多的情况，HAT具有显著优势。在文字的恢复上，HAT相比其他方法也能够恢复出更清晰的文字边缘。</li>\n</ul>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\9.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/8.png\"> </p>\n<h2 id=\"3-4-预训练策略对比\"><a href=\"#3-4-预训练策略对比\" class=\"headerlink\" title=\"3.4 预训练策略对比\"></a>3.4 <strong>预训练策略对比</strong></h2><p>​\t 本文对于不同的预训练策略进行了对比，如下表所示。相对于EDT 提出使用相关任务进行预训练的策略，本文提出的使用相同任务进行预训练的策略无论是在预训练阶段还是微调后的结果，性能都要更优。 </p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\HAT\\11.png\"><br><img src=\"/img/deeplearning/paper/SR/HAT/11.png\"> </p>\n<p>【转自：<a href=\"https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&menu=1%E3%80%91\">https://mmlab.siat.ac.cn/research/1/area?id=r2022052401&amp;menu=1】</a></p>"},{"title":"SRDiff论文讲解","date":"2024-01-26T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n- 论文标题：[Srdiff: Single image super-resolution with diffusion probabilistic models](https://www.sciencedirect.com/science/article/pii/S0925231222000522)\n\n- 来源： Neurocomputing 2022  \n- 贡献：\n  - 首次将diffusion用于图像超分，与SR3不同的是：SR3直接预测HR图像，而SRDiff预测LR和HR图像之间的差值，这使得DM能够专注于残差细节，加快收敛速度，稳定训练。其次，SRDiff将LR通过encoder后作为条件输入Unet。\n\n# 1. 问题\n\n- 以往的方案基于PSNR，GAN，flow，会出现过于平滑，模式崩溃，模型开销大等问题\n\n# 2. 解决方案\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\1.png)\n\n![](img/deeplearning/paper/SR/SRDiff/1.png)\n\n- 将残差图像拿来做扩散\n- 将LR通过encoder后作为条件\n\n# 3. 实验\n\n ![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\2.png) \n\n ![](img/deeplearning/paper/SR/SRDiff/2.png) \n\n ![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\3.png) \n\n ![](img/deeplearning/paper/SR/SRDiff/3.png) ","source":"_posts/deeplearning/paper/SR/SRDiff.md","raw":"---\ntitle: SRDiff论文讲解\ndate: 2024-01-27 00:00:00\ntags: [深度学习,论文,超分]\ncategories: [深度学习]\ncomment: true\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n- 论文标题：[Srdiff: Single image super-resolution with diffusion probabilistic models](https://www.sciencedirect.com/science/article/pii/S0925231222000522)\n\n- 来源： Neurocomputing 2022  \n- 贡献：\n  - 首次将diffusion用于图像超分，与SR3不同的是：SR3直接预测HR图像，而SRDiff预测LR和HR图像之间的差值，这使得DM能够专注于残差细节，加快收敛速度，稳定训练。其次，SRDiff将LR通过encoder后作为条件输入Unet。\n\n# 1. 问题\n\n- 以往的方案基于PSNR，GAN，flow，会出现过于平滑，模式崩溃，模型开销大等问题\n\n# 2. 解决方案\n\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\1.png)\n\n![](img/deeplearning/paper/SR/SRDiff/1.png)\n\n- 将残差图像拿来做扩散\n- 将LR通过encoder后作为条件\n\n# 3. 实验\n\n ![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\2.png) \n\n ![](img/deeplearning/paper/SR/SRDiff/2.png) \n\n ![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\3.png) \n\n ![](img/deeplearning/paper/SR/SRDiff/3.png) ","slug":"deeplearning/paper/SR/SRDiff","published":1,"updated":"2024-01-30T15:36:15.672Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198596003a7svwfjbi5qs4","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>论文标题：<a href=\"https://www.sciencedirect.com/science/article/pii/S0925231222000522\">Srdiff: Single image super-resolution with diffusion probabilistic models</a></p>\n</li>\n<li><p>来源： Neurocomputing 2022  </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>首次将diffusion用于图像超分，与SR3不同的是：SR3直接预测HR图像，而SRDiff预测LR和HR图像之间的差值，这使得DM能够专注于残差细节，加快收敛速度，稳定训练。其次，SRDiff将LR通过encoder后作为条件输入Unet。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><ul>\n<li>以往的方案基于PSNR，GAN，flow，会出现过于平滑，模式崩溃，模型开销大等问题</li>\n</ul>\n<h1 id=\"2-解决方案\"><a href=\"#2-解决方案\" class=\"headerlink\" title=\"2. 解决方案\"></a>2. 解决方案</h1><p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\1.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SRDiff/1.png\"></p>\n<ul>\n<li>将残差图像拿来做扩散</li>\n<li>将LR通过encoder后作为条件</li>\n</ul>\n<h1 id=\"3-实验\"><a href=\"#3-实验\" class=\"headerlink\" title=\"3. 实验\"></a>3. 实验</h1><p> <img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\2.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SRDiff/2.png\"> </p>\n<p> <img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\3.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SRDiff/3.png\"> </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>论文标题：<a href=\"https://www.sciencedirect.com/science/article/pii/S0925231222000522\">Srdiff: Single image super-resolution with diffusion probabilistic models</a></p>\n</li>\n<li><p>来源： Neurocomputing 2022  </p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>首次将diffusion用于图像超分，与SR3不同的是：SR3直接预测HR图像，而SRDiff预测LR和HR图像之间的差值，这使得DM能够专注于残差细节，加快收敛速度，稳定训练。其次，SRDiff将LR通过encoder后作为条件输入Unet。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-问题\"><a href=\"#1-问题\" class=\"headerlink\" title=\"1. 问题\"></a>1. 问题</h1><ul>\n<li>以往的方案基于PSNR，GAN，flow，会出现过于平滑，模式崩溃，模型开销大等问题</li>\n</ul>\n<h1 id=\"2-解决方案\"><a href=\"#2-解决方案\" class=\"headerlink\" title=\"2. 解决方案\"></a>2. 解决方案</h1><p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\1.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SRDiff/1.png\"></p>\n<ul>\n<li>将残差图像拿来做扩散</li>\n<li>将LR通过encoder后作为条件</li>\n</ul>\n<h1 id=\"3-实验\"><a href=\"#3-实验\" class=\"headerlink\" title=\"3. 实验\"></a>3. 实验</h1><p> <img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\2.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SRDiff/2.png\"> </p>\n<p> <img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\paper\\SR\\SRDiff\\3.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SRDiff/3.png\"> </p>"},{"title":"SwinIR论文讲解","date":"2024-01-24T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n- 论文标题：[**Swinir**: Image restoration using swin transformer](https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html)\n\n- 来源：ICCV  2021\n- 贡献：\n  - 提出基于Swin Transformer的图像修复模型：SwinIR\n  - 通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota\n\n# 1. 背景\n\n## 1-1 图像修复\n\n- 从一个劣质图片修复成一个干净的图片，如：超分、降噪、JPEG压缩区块失真![](D:/blog/themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png)\n\n  \n\n![](img/deeplearning/paper/SR/SwinIR/1.png)\n\n\n\n# 2. 相关工作\n\n## 2.1 NLP(Neural Language Processing)\n\n- 可以看成一个翻译任务（Seq2Seq)\n\n- 翻译的难点：一词多义 ->根据上下文的信息\n\n- 常用模型：RNN、LSTM ->全局信息损失\n\n## 2.2 Self-Attention\n\n- Attention($Q$ ,$K$,$V$) = softmax$(\\frac{QK^T}{\\sqrt{d_k}})V$\n\n- 计算一个单词与每一个单词的关系（包括自己）\n\n  ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/2.png)\n\n![](img/deeplearning/paper/SR/SwinIR/2.png)\n\n## 2.3 Multi-head Self-Attention (MSA)\n\n- Ensemble 的self attention，集成多个attention再平均\n\n## 2.4 Transformer on NLP\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/3.png)\n\n![](img/deeplearning/paper/SR/SwinIR/3.png)\n\n- Transformer在NLP领域效果很好，但是在CV上不太好。\n\n## 2.5 Transformer on CV\n\n- 第一篇将Transformer应用到CV的是：ViT\n\n  - Transformer接收的是一个序列 -> 将图片分割成多个patch\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/4.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/4.png)\n\n  - 可用于图片分割、图片分类、物体检测\n\n## 2.6 Swin Transformer\n\n- 虽然ViT效果还算不错，但是仍然无法超过一些主流的卷积网络，主要原因是Transformer一开始是针对NLP的，NLP是一个一维的问题，图片是高维的问题。\n\n- 直接分块然后独立地丢入Transformer后会有一个问题：最后得出的结果会有边界的问题（各个分块相交的地方）\n\n- Swin Transformer的一个模块包括两个层：\n  \n  ​\t![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/5.png)\n  \n  ​\t![](img/deeplearning/paper/SR/SwinIR/5.png)\n  \n  - W-MSA：在原来的小分割patch基础上有一个local的概念，先在local上先做。（可以想象成背景有一个大网格）\n  - SW-MSA：背景表格不动，将图片往左上或右下做一个shift，这样分割出来的local跟第一层的分割效果就不同了，这样可以解决边界问题。\n  \n- 效果非常好，基本可以取代卷积运算\n\n  \n\n# 3 SwinIR\n\n## 3.1 结构\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/6.png)\n\n![](img/deeplearning/paper/SR/SwinIR/6.png)\n\n- 浅层特征提取层 -> 深层特征提取层 -> 重建层\n\n  - Shallow Feature Extraction：用一个3*3卷积获得低频信息（颜色或者纹理等基础特性）\n  - Deep Feature Extraction：由于Swin Transformer原本使用在高阶的图像处理任务上，这里让他应用到低阶的任务上，效果非常好。\n  - Reconstruction：\n    - SR：用sub-pixel做up-sample\n    - Denoising/JPEG：用3*3卷积\n\n  - Loss function:\n    - SR：L1 loss -> $l = || I_{RHQ}-I_{HQ}||_1$\n    - Denoising & JPEG：Charbonnier loss -> $l=\\sqrt{||I_{PHQ}-I_{HQ}||^2 + \\epsilon^2}$\n\n\n\n# 4. 实验\n\n## 4.1 Ablation Studies\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/7.png)\n\n![](img/deeplearning/paper/SR/SwinIR/7.png)\n\n- Super Resolution\n\n  - Classical SR\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/8.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/8.png)\n\n  - Lightweight image SR(轻量的网络架构)\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/9.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/9.png)\n\n  - Real-world image SR\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/10.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/10.png)\n\n- JPEG block removal\n\n  ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/11.png)\n\n  ![](img/deeplearning/paper/SR/SwinIR/11.png)\n\n- Denoising\n\n  - Grayscale image denoising\n\n  - Color image denoising\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/12.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/12.png)\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/13.png) \n\n     ![](img/deeplearning/paper/SR/SwinIR/13.png) \n\n # 5 结论\n\n- 提出基于Swin Transformer的图像修复模型：SwinIR\n- 通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota","source":"_posts/deeplearning/paper/SR/SwinIR.md","raw":"---\ntitle: SwinIR论文讲解\ndate: 2024-01-25 00:00:00\ntags: [深度学习,论文,超分]\ncategories: [深度学习]\ncomment: true\ntoc: true\n\n---\n\n#\n<!--more-->\n\n- 论文标题：[**Swinir**: Image restoration using swin transformer](https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html)\n\n- 来源：ICCV  2021\n- 贡献：\n  - 提出基于Swin Transformer的图像修复模型：SwinIR\n  - 通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota\n\n# 1. 背景\n\n## 1-1 图像修复\n\n- 从一个劣质图片修复成一个干净的图片，如：超分、降噪、JPEG压缩区块失真![](D:/blog/themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png)\n\n  \n\n![](img/deeplearning/paper/SR/SwinIR/1.png)\n\n\n\n# 2. 相关工作\n\n## 2.1 NLP(Neural Language Processing)\n\n- 可以看成一个翻译任务（Seq2Seq)\n\n- 翻译的难点：一词多义 ->根据上下文的信息\n\n- 常用模型：RNN、LSTM ->全局信息损失\n\n## 2.2 Self-Attention\n\n- Attention($Q$ ,$K$,$V$) = softmax$(\\frac{QK^T}{\\sqrt{d_k}})V$\n\n- 计算一个单词与每一个单词的关系（包括自己）\n\n  ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/2.png)\n\n![](img/deeplearning/paper/SR/SwinIR/2.png)\n\n## 2.3 Multi-head Self-Attention (MSA)\n\n- Ensemble 的self attention，集成多个attention再平均\n\n## 2.4 Transformer on NLP\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/3.png)\n\n![](img/deeplearning/paper/SR/SwinIR/3.png)\n\n- Transformer在NLP领域效果很好，但是在CV上不太好。\n\n## 2.5 Transformer on CV\n\n- 第一篇将Transformer应用到CV的是：ViT\n\n  - Transformer接收的是一个序列 -> 将图片分割成多个patch\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/4.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/4.png)\n\n  - 可用于图片分割、图片分类、物体检测\n\n## 2.6 Swin Transformer\n\n- 虽然ViT效果还算不错，但是仍然无法超过一些主流的卷积网络，主要原因是Transformer一开始是针对NLP的，NLP是一个一维的问题，图片是高维的问题。\n\n- 直接分块然后独立地丢入Transformer后会有一个问题：最后得出的结果会有边界的问题（各个分块相交的地方）\n\n- Swin Transformer的一个模块包括两个层：\n  \n  ​\t![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/5.png)\n  \n  ​\t![](img/deeplearning/paper/SR/SwinIR/5.png)\n  \n  - W-MSA：在原来的小分割patch基础上有一个local的概念，先在local上先做。（可以想象成背景有一个大网格）\n  - SW-MSA：背景表格不动，将图片往左上或右下做一个shift，这样分割出来的local跟第一层的分割效果就不同了，这样可以解决边界问题。\n  \n- 效果非常好，基本可以取代卷积运算\n\n  \n\n# 3 SwinIR\n\n## 3.1 结构\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/6.png)\n\n![](img/deeplearning/paper/SR/SwinIR/6.png)\n\n- 浅层特征提取层 -> 深层特征提取层 -> 重建层\n\n  - Shallow Feature Extraction：用一个3*3卷积获得低频信息（颜色或者纹理等基础特性）\n  - Deep Feature Extraction：由于Swin Transformer原本使用在高阶的图像处理任务上，这里让他应用到低阶的任务上，效果非常好。\n  - Reconstruction：\n    - SR：用sub-pixel做up-sample\n    - Denoising/JPEG：用3*3卷积\n\n  - Loss function:\n    - SR：L1 loss -> $l = || I_{RHQ}-I_{HQ}||_1$\n    - Denoising & JPEG：Charbonnier loss -> $l=\\sqrt{||I_{PHQ}-I_{HQ}||^2 + \\epsilon^2}$\n\n\n\n# 4. 实验\n\n## 4.1 Ablation Studies\n\n![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/7.png)\n\n![](img/deeplearning/paper/SR/SwinIR/7.png)\n\n- Super Resolution\n\n  - Classical SR\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/8.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/8.png)\n\n  - Lightweight image SR(轻量的网络架构)\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/9.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/9.png)\n\n  - Real-world image SR\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/10.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/10.png)\n\n- JPEG block removal\n\n  ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/11.png)\n\n  ![](img/deeplearning/paper/SR/SwinIR/11.png)\n\n- Denoising\n\n  - Grayscale image denoising\n\n  - Color image denoising\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/12.png)\n\n    ![](img/deeplearning/paper/SR/SwinIR/12.png)\n\n    ![](D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/13.png) \n\n     ![](img/deeplearning/paper/SR/SwinIR/13.png) \n\n # 5 结论\n\n- 提出基于Swin Transformer的图像修复模型：SwinIR\n- 通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota","slug":"deeplearning/paper/SR/SwinIR","published":1,"updated":"2024-01-30T14:37:18.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198597003d7svwe022ejo4","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<ul>\n<li><p>论文标题：<a href=\"https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html\"><strong>Swinir</strong>: Image restoration using swin transformer</a></p>\n</li>\n<li><p>来源：ICCV  2021</p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>提出基于Swin Transformer的图像修复模型：SwinIR</li>\n<li>通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h1><h2 id=\"1-1-图像修复\"><a href=\"#1-1-图像修复\" class=\"headerlink\" title=\"1-1 图像修复\"></a>1-1 图像修复</h2><ul>\n<li>从一个劣质图片修复成一个干净的图片，如：超分、降噪、JPEG压缩区块失真<img src=\"D:/blog/themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png\"></li>\n</ul>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/1.png\"></p>\n<h1 id=\"2-相关工作\"><a href=\"#2-相关工作\" class=\"headerlink\" title=\"2. 相关工作\"></a>2. 相关工作</h1><h2 id=\"2-1-NLP-Neural-Language-Processing\"><a href=\"#2-1-NLP-Neural-Language-Processing\" class=\"headerlink\" title=\"2.1 NLP(Neural Language Processing)\"></a>2.1 NLP(Neural Language Processing)</h2><ul>\n<li><p>可以看成一个翻译任务（Seq2Seq)</p>\n</li>\n<li><p>翻译的难点：一词多义 -&gt;根据上下文的信息</p>\n</li>\n<li><p>常用模型：RNN、LSTM -&gt;全局信息损失</p>\n</li>\n</ul>\n<h2 id=\"2-2-Self-Attention\"><a href=\"#2-2-Self-Attention\" class=\"headerlink\" title=\"2.2 Self-Attention\"></a>2.2 Self-Attention</h2><ul>\n<li><p>Attention($Q$ ,$K$,$V$) &#x3D; softmax$(\\frac{QK^T}{\\sqrt{d_k}})V$</p>\n</li>\n<li><p>计算一个单词与每一个单词的关系（包括自己）</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/2.png\"></p>\n</li>\n</ul>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/2.png\"></p>\n<h2 id=\"2-3-Multi-head-Self-Attention-MSA\"><a href=\"#2-3-Multi-head-Self-Attention-MSA\" class=\"headerlink\" title=\"2.3 Multi-head Self-Attention (MSA)\"></a>2.3 Multi-head Self-Attention (MSA)</h2><ul>\n<li>Ensemble 的self attention，集成多个attention再平均</li>\n</ul>\n<h2 id=\"2-4-Transformer-on-NLP\"><a href=\"#2-4-Transformer-on-NLP\" class=\"headerlink\" title=\"2.4 Transformer on NLP\"></a>2.4 Transformer on NLP</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/3.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/3.png\"></p>\n<ul>\n<li>Transformer在NLP领域效果很好，但是在CV上不太好。</li>\n</ul>\n<h2 id=\"2-5-Transformer-on-CV\"><a href=\"#2-5-Transformer-on-CV\" class=\"headerlink\" title=\"2.5 Transformer on CV\"></a>2.5 Transformer on CV</h2><ul>\n<li><p>第一篇将Transformer应用到CV的是：ViT</p>\n<ul>\n<li><p>Transformer接收的是一个序列 -&gt; 将图片分割成多个patch</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/4.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/4.png\"></p>\n</li>\n<li><p>可用于图片分割、图片分类、物体检测</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-6-Swin-Transformer\"><a href=\"#2-6-Swin-Transformer\" class=\"headerlink\" title=\"2.6 Swin Transformer\"></a>2.6 Swin Transformer</h2><ul>\n<li><p>虽然ViT效果还算不错，但是仍然无法超过一些主流的卷积网络，主要原因是Transformer一开始是针对NLP的，NLP是一个一维的问题，图片是高维的问题。</p>\n</li>\n<li><p>直接分块然后独立地丢入Transformer后会有一个问题：最后得出的结果会有边界的问题（各个分块相交的地方）</p>\n</li>\n<li><p>Swin Transformer的一个模块包括两个层：</p>\n<p>​\t<img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/5.png\"></p>\n<p>​\t<img src=\"/img/deeplearning/paper/SR/SwinIR/5.png\"></p>\n<ul>\n<li>W-MSA：在原来的小分割patch基础上有一个local的概念，先在local上先做。（可以想象成背景有一个大网格）</li>\n<li>SW-MSA：背景表格不动，将图片往左上或右下做一个shift，这样分割出来的local跟第一层的分割效果就不同了，这样可以解决边界问题。</li>\n</ul>\n</li>\n<li><p>效果非常好，基本可以取代卷积运算</p>\n</li>\n</ul>\n<h1 id=\"3-SwinIR\"><a href=\"#3-SwinIR\" class=\"headerlink\" title=\"3 SwinIR\"></a>3 SwinIR</h1><h2 id=\"3-1-结构\"><a href=\"#3-1-结构\" class=\"headerlink\" title=\"3.1 结构\"></a>3.1 结构</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/6.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/6.png\"></p>\n<ul>\n<li><p>浅层特征提取层 -&gt; 深层特征提取层 -&gt; 重建层</p>\n<ul>\n<li><p>Shallow Feature Extraction：用一个3*3卷积获得低频信息（颜色或者纹理等基础特性）</p>\n</li>\n<li><p>Deep Feature Extraction：由于Swin Transformer原本使用在高阶的图像处理任务上，这里让他应用到低阶的任务上，效果非常好。</p>\n</li>\n<li><p>Reconstruction：</p>\n<ul>\n<li>SR：用sub-pixel做up-sample</li>\n<li>Denoising&#x2F;JPEG：用3*3卷积</li>\n</ul>\n</li>\n<li><p>Loss function:</p>\n<ul>\n<li>SR：L1 loss -&gt; $l &#x3D; || I_{RHQ}-I_{HQ}||_1$</li>\n<li>Denoising &amp; JPEG：Charbonnier loss -&gt; $l&#x3D;\\sqrt{||I_{PHQ}-I_{HQ}||^2 + \\epsilon^2}$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"4-实验\"><a href=\"#4-实验\" class=\"headerlink\" title=\"4. 实验\"></a>4. 实验</h1><h2 id=\"4-1-Ablation-Studies\"><a href=\"#4-1-Ablation-Studies\" class=\"headerlink\" title=\"4.1 Ablation Studies\"></a>4.1 Ablation Studies</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/7.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/7.png\"></p>\n<ul>\n<li><p>Super Resolution</p>\n<ul>\n<li><p>Classical SR</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/8.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/8.png\"></p>\n</li>\n<li><p>Lightweight image SR(轻量的网络架构)</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/9.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/9.png\"></p>\n</li>\n<li><p>Real-world image SR</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/10.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/10.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>JPEG block removal</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/11.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/11.png\"></p>\n</li>\n<li><p>Denoising</p>\n<ul>\n<li><p>Grayscale image denoising</p>\n</li>\n<li><p>Color image denoising</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/12.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/12.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/13.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SwinIR/13.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5-结论\"><a href=\"#5-结论\" class=\"headerlink\" title=\"5 结论\"></a>5 结论</h1><ul>\n<li>提出基于Swin Transformer的图像修复模型：SwinIR</li>\n<li>通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>论文标题：<a href=\"https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html\"><strong>Swinir</strong>: Image restoration using swin transformer</a></p>\n</li>\n<li><p>来源：ICCV  2021</p>\n</li>\n<li><p>贡献：</p>\n<ul>\n<li>提出基于Swin Transformer的图像修复模型：SwinIR</li>\n<li>通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h1><h2 id=\"1-1-图像修复\"><a href=\"#1-1-图像修复\" class=\"headerlink\" title=\"1-1 图像修复\"></a>1-1 图像修复</h2><ul>\n<li>从一个劣质图片修复成一个干净的图片，如：超分、降噪、JPEG压缩区块失真<img src=\"D:/blog/themes/yilia/source/img/deeplearning/paper/SR/SwinIR/1.png\"></li>\n</ul>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/1.png\"></p>\n<h1 id=\"2-相关工作\"><a href=\"#2-相关工作\" class=\"headerlink\" title=\"2. 相关工作\"></a>2. 相关工作</h1><h2 id=\"2-1-NLP-Neural-Language-Processing\"><a href=\"#2-1-NLP-Neural-Language-Processing\" class=\"headerlink\" title=\"2.1 NLP(Neural Language Processing)\"></a>2.1 NLP(Neural Language Processing)</h2><ul>\n<li><p>可以看成一个翻译任务（Seq2Seq)</p>\n</li>\n<li><p>翻译的难点：一词多义 -&gt;根据上下文的信息</p>\n</li>\n<li><p>常用模型：RNN、LSTM -&gt;全局信息损失</p>\n</li>\n</ul>\n<h2 id=\"2-2-Self-Attention\"><a href=\"#2-2-Self-Attention\" class=\"headerlink\" title=\"2.2 Self-Attention\"></a>2.2 Self-Attention</h2><ul>\n<li><p>Attention($Q$ ,$K$,$V$) &#x3D; softmax$(\\frac{QK^T}{\\sqrt{d_k}})V$</p>\n</li>\n<li><p>计算一个单词与每一个单词的关系（包括自己）</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/2.png\"></p>\n</li>\n</ul>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/2.png\"></p>\n<h2 id=\"2-3-Multi-head-Self-Attention-MSA\"><a href=\"#2-3-Multi-head-Self-Attention-MSA\" class=\"headerlink\" title=\"2.3 Multi-head Self-Attention (MSA)\"></a>2.3 Multi-head Self-Attention (MSA)</h2><ul>\n<li>Ensemble 的self attention，集成多个attention再平均</li>\n</ul>\n<h2 id=\"2-4-Transformer-on-NLP\"><a href=\"#2-4-Transformer-on-NLP\" class=\"headerlink\" title=\"2.4 Transformer on NLP\"></a>2.4 Transformer on NLP</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/3.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/3.png\"></p>\n<ul>\n<li>Transformer在NLP领域效果很好，但是在CV上不太好。</li>\n</ul>\n<h2 id=\"2-5-Transformer-on-CV\"><a href=\"#2-5-Transformer-on-CV\" class=\"headerlink\" title=\"2.5 Transformer on CV\"></a>2.5 Transformer on CV</h2><ul>\n<li><p>第一篇将Transformer应用到CV的是：ViT</p>\n<ul>\n<li><p>Transformer接收的是一个序列 -&gt; 将图片分割成多个patch</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/4.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/4.png\"></p>\n</li>\n<li><p>可用于图片分割、图片分类、物体检测</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-6-Swin-Transformer\"><a href=\"#2-6-Swin-Transformer\" class=\"headerlink\" title=\"2.6 Swin Transformer\"></a>2.6 Swin Transformer</h2><ul>\n<li><p>虽然ViT效果还算不错，但是仍然无法超过一些主流的卷积网络，主要原因是Transformer一开始是针对NLP的，NLP是一个一维的问题，图片是高维的问题。</p>\n</li>\n<li><p>直接分块然后独立地丢入Transformer后会有一个问题：最后得出的结果会有边界的问题（各个分块相交的地方）</p>\n</li>\n<li><p>Swin Transformer的一个模块包括两个层：</p>\n<p>​\t<img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/5.png\"></p>\n<p>​\t<img src=\"/img/deeplearning/paper/SR/SwinIR/5.png\"></p>\n<ul>\n<li>W-MSA：在原来的小分割patch基础上有一个local的概念，先在local上先做。（可以想象成背景有一个大网格）</li>\n<li>SW-MSA：背景表格不动，将图片往左上或右下做一个shift，这样分割出来的local跟第一层的分割效果就不同了，这样可以解决边界问题。</li>\n</ul>\n</li>\n<li><p>效果非常好，基本可以取代卷积运算</p>\n</li>\n</ul>\n<h1 id=\"3-SwinIR\"><a href=\"#3-SwinIR\" class=\"headerlink\" title=\"3 SwinIR\"></a>3 SwinIR</h1><h2 id=\"3-1-结构\"><a href=\"#3-1-结构\" class=\"headerlink\" title=\"3.1 结构\"></a>3.1 结构</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/6.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/6.png\"></p>\n<ul>\n<li><p>浅层特征提取层 -&gt; 深层特征提取层 -&gt; 重建层</p>\n<ul>\n<li><p>Shallow Feature Extraction：用一个3*3卷积获得低频信息（颜色或者纹理等基础特性）</p>\n</li>\n<li><p>Deep Feature Extraction：由于Swin Transformer原本使用在高阶的图像处理任务上，这里让他应用到低阶的任务上，效果非常好。</p>\n</li>\n<li><p>Reconstruction：</p>\n<ul>\n<li>SR：用sub-pixel做up-sample</li>\n<li>Denoising&#x2F;JPEG：用3*3卷积</li>\n</ul>\n</li>\n<li><p>Loss function:</p>\n<ul>\n<li>SR：L1 loss -&gt; $l &#x3D; || I_{RHQ}-I_{HQ}||_1$</li>\n<li>Denoising &amp; JPEG：Charbonnier loss -&gt; $l&#x3D;\\sqrt{||I_{PHQ}-I_{HQ}||^2 + \\epsilon^2}$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"4-实验\"><a href=\"#4-实验\" class=\"headerlink\" title=\"4. 实验\"></a>4. 实验</h1><h2 id=\"4-1-Ablation-Studies\"><a href=\"#4-1-Ablation-Studies\" class=\"headerlink\" title=\"4.1 Ablation Studies\"></a>4.1 Ablation Studies</h2><p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/7.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/7.png\"></p>\n<ul>\n<li><p>Super Resolution</p>\n<ul>\n<li><p>Classical SR</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/8.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/8.png\"></p>\n</li>\n<li><p>Lightweight image SR(轻量的网络架构)</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/9.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/9.png\"></p>\n</li>\n<li><p>Real-world image SR</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/10.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/10.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>JPEG block removal</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/11.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/11.png\"></p>\n</li>\n<li><p>Denoising</p>\n<ul>\n<li><p>Grayscale image denoising</p>\n</li>\n<li><p>Color image denoising</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/12.png\"></p>\n<p><img src=\"/img/deeplearning/paper/SR/SwinIR/12.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img/deeplearning/paper/SR/SwinIR/13.png\"> </p>\n<p> <img src=\"/img/deeplearning/paper/SR/SwinIR/13.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5-结论\"><a href=\"#5-结论\" class=\"headerlink\" title=\"5 结论\"></a>5 结论</h1><ul>\n<li>提出基于Swin Transformer的图像修复模型：SwinIR</li>\n<li>通过大量实验表明SwinIR在SR、denoising、JPEG block removal上都是sota</li>\n</ul>"},{"title":"1.1 pytorch数据操作","date":"2023-11-11T06:00:00.000Z","comment":false,"toc":true,"_content":"# \n<!--more-->\n\n\n# 1. pytorch数据操作\n\n- pytorch与tensorflow中的Tensor类似于numpy的ndarray\n- pytorch中的Tensor可以在GPU上运行\n- pytorch中的Tensor可以用于自动求导\n\n\n\n## 1.1 张量\n\n- 创建张量\n\n\n```python\n# 1. 导入torch，不是pytorch\nimport torch\n\n# 2. 创建范围张量\nx=torch.arange(12) # 0-11,默认为int64，可以指定dtype，默认存储在CPU上\ny=torch.arange(12,dtype=torch.float32) # 指定dtype\n\n# 3. 创建全0张量\nzeros=torch.zeros(2,3,4) # 2*3*4的全0张量\n\n# 4. 创建全1张量\nones=torch.ones(2,3,4) # 2*3*4的全1张量\n\n# 5. 创建采样张量\nsample=torch.randn(3,4) #从标准高斯分布中采样\n\n# 6. 列表张量\nlists=torch.tensor([[1,2,3],[4,5,6]])\n\n\nprint(x)\nprint(y)\nprint(zeros)\nprint(ones)\nprint(sample)\nprint(lists)\n\n```\n\n    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n    tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n    tensor([[[0., 0., 0., 0.],\n             [0., 0., 0., 0.],\n             [0., 0., 0., 0.]],\n    \n            [[0., 0., 0., 0.],\n             [0., 0., 0., 0.],\n             [0., 0., 0., 0.]]])\n    tensor([[[1., 1., 1., 1.],\n             [1., 1., 1., 1.],\n             [1., 1., 1., 1.]],\n    \n            [[1., 1., 1., 1.],\n             [1., 1., 1., 1.],\n             [1., 1., 1., 1.]]])\n    tensor([[-0.0847, -0.2406,  0.1735, -1.5543],\n            [-0.2820, -0.6689,  0.0565,  0.4746],\n            [ 0.9841, -1.6116, -0.1587, -1.5121]])\n    tensor([[1, 2, 3],\n            [4, 5, 6]])\n    \n\n- 张量的属性\n\n\n```python\n# 3. 查看张量的形状\nprint('x的规模：',x.shape)\n\n# 4. 查看张量的元素总数\nprint('x中元素个数：',x.numel())\n\n# 5. 改变张量的形状\nx=x.reshape(3,4)\nprint('改变x的形状：',x)\nprint('自动计算的形状：',x.reshape(-1,6)) # -1表示自动计算这个维度\n```\n\n    x的规模： torch.Size([12])\n    x中元素个数： 12\n    改变x的形状： tensor([[ 0,  1,  2,  3],\n            [ 4,  5,  6,  7],\n            [ 8,  9, 10, 11]])\n    自动计算的形状： tensor([[ 0,  1,  2,  3,  4,  5],\n            [ 6,  7,  8,  9, 10, 11]])\n    \n\n## 1.2 运算符\n\n\n```python\nx=torch.arange(4)\n\n# 1. 按元素运算\nprint('按元素加法：',x+x)\nprint('按元素减法：',x-x)\nprint('按元素乘法：',x*x)\nprint('按元素除法：',x/x)\nprint('按元素幂运算：',x**x)\nprint('按元素开方：',x.sqrt())\nprint('求幂运算：',torch.exp(x))\n\n# 2. 矩阵运算\n\n# 3. 合并张量(记得加括号)\nx=torch.zeros(12).reshape(3,4)\ny=torch.ones(12).reshape(3,4)\nprint('沿行合并：',torch.cat((x,y),dim=0)) # 沿行合并\nprint('沿列合并：',torch.cat((x,y),dim=1)) # 沿列合并\n\n# 4. 逻辑运算\nprint(x==y)\n\n# 5. 求和\nprint('求和：',y.sum())\n```\n\n    按元素加法： tensor([0, 2, 4, 6])\n    按元素减法： tensor([0, 0, 0, 0])\n    按元素乘法： tensor([0, 1, 4, 9])\n    按元素除法： tensor([nan, 1., 1., 1.])\n    按元素幂运算： tensor([ 1,  1,  4, 27])\n    按元素开方： tensor([0.0000, 1.0000, 1.4142, 1.7321])\n    求幂运算： tensor([ 1.0000,  2.7183,  7.3891, 20.0855])\n    沿行合并： tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [1., 1., 1., 1.],\n            [1., 1., 1., 1.],\n            [1., 1., 1., 1.]])\n    沿列合并： tensor([[0., 0., 0., 0., 1., 1., 1., 1.],\n            [0., 0., 0., 0., 1., 1., 1., 1.],\n            [0., 0., 0., 0., 1., 1., 1., 1.]])\n    tensor([[False, False, False, False],\n            [False, False, False, False],\n            [False, False, False, False]])\n    求和： tensor(12.)\n    \n\n## 1.3 广播机制\n- 对两个形状不同的张量按元素运算时，可能会触发广播机制：先适当复制元素使这两个张量形状相同后再按元素运算\n\n1. 如果两个张量的维度数不同，可以在较小的张量的形状前面补1，直到两者的维度数相同。\n2. 如果两个张量在某个维度上的大小不同，但其中一个张量在该维度上的大小为1，那么可以通过在该维度上重复扩展该张量，使得两个张量在该维度上的大小相同。\n3. 如果两个张量在某个维度上的大小都不为1，且大小不同，那么会发生形状不匹配，导致无法进行广播\n\n```python\na=torch.arange(3).reshape(3,1)\nb=torch.arange(2).reshape(1,2)\nprint('a:',a)\nprint('b:',b)\nprint('a+b:',a+b) #通常沿着长度为1的维度进行广播\n```\n\n    a: tensor([[0],\n            [1],\n            [2]])\n    b: tensor([[0, 1]])\n    a+b: tensor([[0, 1],\n            [1, 2],\n            [2, 3]])\n    \n\n## 1.4 索引和切片\n\n\n```python\nprint('x:',x)\nprint('x[-1]:',x[-1])\nprint('x[1:3]:',x[1:3]) #选择第2和第3个元素\nx[1,2]=9 # 修改元素\nprint('x[1,2]=9后 x:',x)\nx[0:2,:]=12 # 修改一行\nprint('x[0:2,:]=12后 x:',x)\n```\n\n    x: tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n    x[-1]: tensor([0., 0., 0., 0.])\n    x[1:3]: tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n    x[1,2]=9后 x: tensor([[0., 0., 0., 0.],\n            [0., 0., 9., 0.],\n            [0., 0., 0., 0.]])\n    x[0:2,:]=12后 x: tensor([[12., 12., 12., 12.],\n            [12., 12., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    \n\n## 1.5 节省内存\n\n\n```python\nz=torch.zeros(1)\nbefore=id(z)\nz=z+x #对于这种类似列表的数据结构，加号会导致新的内存分配\nprint('z:',z)\nprint('id(z)==before:',id(z)==before) # False，说明z指向了新的地址\n\nz=torch.zeros(3,4) #使用如下操作可以避免新的内存分配，但是无法广播，所以这里要求x和z的形状一致\nbefore=id(z)\nz+=x # +=不会导致新的内存分配\nz[:]=x+z # 也不会导致新的内存分配\nprint('id(z)==before:',id(z)==before) # True\n```\n\n    z: tensor([[12., 12., 12., 12.],\n            [12., 12., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    id(z)==before: False\n    id(z)==before: True\n    \n\n## 1.6 转换为其他python对象\n- tensor与numpy数组\n\n\n```python\nA=x.numpy() # 将张量转换为numpy数组\nB=torch.tensor(A) # 将numpy数组转换为张量\nprint(A,B,sep='\\n')\n\nA[1,1]=3\nprint(A,B,x,sep='\\n') #A与X共享内存\n```\n\n    [[12. 12. 12. 12.]\n     [12.  3. 12. 12.]\n     [ 0.  0.  0.  0.]]\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    [[12. 12. 12. 12.]\n     [12.  3. 12. 12.]\n     [ 0.  0.  0.  0.]]\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    \n\n- 张量转为python标量\n\n\n```python\na=torch.tensor([1.3])\nprint(a)\n\n#由于pytorch中小数用32位，python中用64位；尝试输出.20f就能发现精确度问题\n#由于舍入（四舍五入到最接近的偶数），1.3在pytorch中表示是1.299多，而在python中是1.300多\nprint(a.item()) #使用item函数\nprint(float(a)) #python内置函数\n```\n\n    tensor([1.3000])\n    1.2999999523162842\n    1.2999999523162842\n    \n","source":"_posts/deeplearning/code/pytorch/1_prepare/1_dataoperation.md","raw":"---\ntitle: 1.1 pytorch数据操作\ndate: 2023-11-11 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: false\ntoc: true\n---\n# \n<!--more-->\n\n\n# 1. pytorch数据操作\n\n- pytorch与tensorflow中的Tensor类似于numpy的ndarray\n- pytorch中的Tensor可以在GPU上运行\n- pytorch中的Tensor可以用于自动求导\n\n\n\n## 1.1 张量\n\n- 创建张量\n\n\n```python\n# 1. 导入torch，不是pytorch\nimport torch\n\n# 2. 创建范围张量\nx=torch.arange(12) # 0-11,默认为int64，可以指定dtype，默认存储在CPU上\ny=torch.arange(12,dtype=torch.float32) # 指定dtype\n\n# 3. 创建全0张量\nzeros=torch.zeros(2,3,4) # 2*3*4的全0张量\n\n# 4. 创建全1张量\nones=torch.ones(2,3,4) # 2*3*4的全1张量\n\n# 5. 创建采样张量\nsample=torch.randn(3,4) #从标准高斯分布中采样\n\n# 6. 列表张量\nlists=torch.tensor([[1,2,3],[4,5,6]])\n\n\nprint(x)\nprint(y)\nprint(zeros)\nprint(ones)\nprint(sample)\nprint(lists)\n\n```\n\n    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n    tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n    tensor([[[0., 0., 0., 0.],\n             [0., 0., 0., 0.],\n             [0., 0., 0., 0.]],\n    \n            [[0., 0., 0., 0.],\n             [0., 0., 0., 0.],\n             [0., 0., 0., 0.]]])\n    tensor([[[1., 1., 1., 1.],\n             [1., 1., 1., 1.],\n             [1., 1., 1., 1.]],\n    \n            [[1., 1., 1., 1.],\n             [1., 1., 1., 1.],\n             [1., 1., 1., 1.]]])\n    tensor([[-0.0847, -0.2406,  0.1735, -1.5543],\n            [-0.2820, -0.6689,  0.0565,  0.4746],\n            [ 0.9841, -1.6116, -0.1587, -1.5121]])\n    tensor([[1, 2, 3],\n            [4, 5, 6]])\n    \n\n- 张量的属性\n\n\n```python\n# 3. 查看张量的形状\nprint('x的规模：',x.shape)\n\n# 4. 查看张量的元素总数\nprint('x中元素个数：',x.numel())\n\n# 5. 改变张量的形状\nx=x.reshape(3,4)\nprint('改变x的形状：',x)\nprint('自动计算的形状：',x.reshape(-1,6)) # -1表示自动计算这个维度\n```\n\n    x的规模： torch.Size([12])\n    x中元素个数： 12\n    改变x的形状： tensor([[ 0,  1,  2,  3],\n            [ 4,  5,  6,  7],\n            [ 8,  9, 10, 11]])\n    自动计算的形状： tensor([[ 0,  1,  2,  3,  4,  5],\n            [ 6,  7,  8,  9, 10, 11]])\n    \n\n## 1.2 运算符\n\n\n```python\nx=torch.arange(4)\n\n# 1. 按元素运算\nprint('按元素加法：',x+x)\nprint('按元素减法：',x-x)\nprint('按元素乘法：',x*x)\nprint('按元素除法：',x/x)\nprint('按元素幂运算：',x**x)\nprint('按元素开方：',x.sqrt())\nprint('求幂运算：',torch.exp(x))\n\n# 2. 矩阵运算\n\n# 3. 合并张量(记得加括号)\nx=torch.zeros(12).reshape(3,4)\ny=torch.ones(12).reshape(3,4)\nprint('沿行合并：',torch.cat((x,y),dim=0)) # 沿行合并\nprint('沿列合并：',torch.cat((x,y),dim=1)) # 沿列合并\n\n# 4. 逻辑运算\nprint(x==y)\n\n# 5. 求和\nprint('求和：',y.sum())\n```\n\n    按元素加法： tensor([0, 2, 4, 6])\n    按元素减法： tensor([0, 0, 0, 0])\n    按元素乘法： tensor([0, 1, 4, 9])\n    按元素除法： tensor([nan, 1., 1., 1.])\n    按元素幂运算： tensor([ 1,  1,  4, 27])\n    按元素开方： tensor([0.0000, 1.0000, 1.4142, 1.7321])\n    求幂运算： tensor([ 1.0000,  2.7183,  7.3891, 20.0855])\n    沿行合并： tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [1., 1., 1., 1.],\n            [1., 1., 1., 1.],\n            [1., 1., 1., 1.]])\n    沿列合并： tensor([[0., 0., 0., 0., 1., 1., 1., 1.],\n            [0., 0., 0., 0., 1., 1., 1., 1.],\n            [0., 0., 0., 0., 1., 1., 1., 1.]])\n    tensor([[False, False, False, False],\n            [False, False, False, False],\n            [False, False, False, False]])\n    求和： tensor(12.)\n    \n\n## 1.3 广播机制\n- 对两个形状不同的张量按元素运算时，可能会触发广播机制：先适当复制元素使这两个张量形状相同后再按元素运算\n\n1. 如果两个张量的维度数不同，可以在较小的张量的形状前面补1，直到两者的维度数相同。\n2. 如果两个张量在某个维度上的大小不同，但其中一个张量在该维度上的大小为1，那么可以通过在该维度上重复扩展该张量，使得两个张量在该维度上的大小相同。\n3. 如果两个张量在某个维度上的大小都不为1，且大小不同，那么会发生形状不匹配，导致无法进行广播\n\n```python\na=torch.arange(3).reshape(3,1)\nb=torch.arange(2).reshape(1,2)\nprint('a:',a)\nprint('b:',b)\nprint('a+b:',a+b) #通常沿着长度为1的维度进行广播\n```\n\n    a: tensor([[0],\n            [1],\n            [2]])\n    b: tensor([[0, 1]])\n    a+b: tensor([[0, 1],\n            [1, 2],\n            [2, 3]])\n    \n\n## 1.4 索引和切片\n\n\n```python\nprint('x:',x)\nprint('x[-1]:',x[-1])\nprint('x[1:3]:',x[1:3]) #选择第2和第3个元素\nx[1,2]=9 # 修改元素\nprint('x[1,2]=9后 x:',x)\nx[0:2,:]=12 # 修改一行\nprint('x[0:2,:]=12后 x:',x)\n```\n\n    x: tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n    x[-1]: tensor([0., 0., 0., 0.])\n    x[1:3]: tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n    x[1,2]=9后 x: tensor([[0., 0., 0., 0.],\n            [0., 0., 9., 0.],\n            [0., 0., 0., 0.]])\n    x[0:2,:]=12后 x: tensor([[12., 12., 12., 12.],\n            [12., 12., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    \n\n## 1.5 节省内存\n\n\n```python\nz=torch.zeros(1)\nbefore=id(z)\nz=z+x #对于这种类似列表的数据结构，加号会导致新的内存分配\nprint('z:',z)\nprint('id(z)==before:',id(z)==before) # False，说明z指向了新的地址\n\nz=torch.zeros(3,4) #使用如下操作可以避免新的内存分配，但是无法广播，所以这里要求x和z的形状一致\nbefore=id(z)\nz+=x # +=不会导致新的内存分配\nz[:]=x+z # 也不会导致新的内存分配\nprint('id(z)==before:',id(z)==before) # True\n```\n\n    z: tensor([[12., 12., 12., 12.],\n            [12., 12., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    id(z)==before: False\n    id(z)==before: True\n    \n\n## 1.6 转换为其他python对象\n- tensor与numpy数组\n\n\n```python\nA=x.numpy() # 将张量转换为numpy数组\nB=torch.tensor(A) # 将numpy数组转换为张量\nprint(A,B,sep='\\n')\n\nA[1,1]=3\nprint(A,B,x,sep='\\n') #A与X共享内存\n```\n\n    [[12. 12. 12. 12.]\n     [12.  3. 12. 12.]\n     [ 0.  0.  0.  0.]]\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    [[12. 12. 12. 12.]\n     [12.  3. 12. 12.]\n     [ 0.  0.  0.  0.]]\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    tensor([[12., 12., 12., 12.],\n            [12.,  3., 12., 12.],\n            [ 0.,  0.,  0.,  0.]])\n    \n\n- 张量转为python标量\n\n\n```python\na=torch.tensor([1.3])\nprint(a)\n\n#由于pytorch中小数用32位，python中用64位；尝试输出.20f就能发现精确度问题\n#由于舍入（四舍五入到最接近的偶数），1.3在pytorch中表示是1.299多，而在python中是1.300多\nprint(a.item()) #使用item函数\nprint(float(a)) #python内置函数\n```\n\n    tensor([1.3000])\n    1.2999999523162842\n    1.2999999523162842\n    \n","slug":"deeplearning/code/pytorch/1_prepare/1_dataoperation","published":1,"updated":"2024-02-03T03:48:29.053Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198597003g7svw406y8gbv","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n<h1 id=\"1-pytorch数据操作\"><a href=\"#1-pytorch数据操作\" class=\"headerlink\" title=\"1. pytorch数据操作\"></a>1. pytorch数据操作</h1><ul>\n<li>pytorch与tensorflow中的Tensor类似于numpy的ndarray</li>\n<li>pytorch中的Tensor可以在GPU上运行</li>\n<li>pytorch中的Tensor可以用于自动求导</li>\n</ul>\n<h2 id=\"1-1-张量\"><a href=\"#1-1-张量\" class=\"headerlink\" title=\"1.1 张量\"></a>1.1 张量</h2><ul>\n<li>创建张量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 导入torch，不是pytorch</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 创建范围张量</span></span><br><span class=\"line\">x=torch.arange(<span class=\"number\">12</span>) <span class=\"comment\"># 0-11,默认为int64，可以指定dtype，默认存储在CPU上</span></span><br><span class=\"line\">y=torch.arange(<span class=\"number\">12</span>,dtype=torch.float32) <span class=\"comment\"># 指定dtype</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 创建全0张量</span></span><br><span class=\"line\">zeros=torch.zeros(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\"># 2*3*4的全0张量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 创建全1张量</span></span><br><span class=\"line\">ones=torch.ones(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\"># 2*3*4的全1张量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 创建采样张量</span></span><br><span class=\"line\">sample=torch.randn(<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\">#从标准高斯分布中采样</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 6. 列表张量</span></span><br><span class=\"line\">lists=torch.tensor([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(zeros)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(ones)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(sample)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(lists)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\ntensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\ntensor([[[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]])\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor([[-0.0847, -0.2406,  0.1735, -1.5543],\n        [-0.2820, -0.6689,  0.0565,  0.4746],\n        [ 0.9841, -1.6116, -0.1587, -1.5121]])\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n</code></pre>\n<ul>\n<li>张量的属性</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 3. 查看张量的形状</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x的规模：&#x27;</span>,x.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 查看张量的元素总数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x中元素个数：&#x27;</span>,x.numel())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 改变张量的形状</span></span><br><span class=\"line\">x=x.reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;改变x的形状：&#x27;</span>,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;自动计算的形状：&#x27;</span>,x.reshape(-<span class=\"number\">1</span>,<span class=\"number\">6</span>)) <span class=\"comment\"># -1表示自动计算这个维度</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>x的规模： torch.Size([12])\nx中元素个数： 12\n改变x的形状： tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])\n自动计算的形状： tensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\n</code></pre>\n<h2 id=\"1-2-运算符\"><a href=\"#1-2-运算符\" class=\"headerlink\" title=\"1.2 运算符\"></a>1.2 运算符</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 按元素运算</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素加法：&#x27;</span>,x+x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素减法：&#x27;</span>,x-x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素乘法：&#x27;</span>,x*x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素除法：&#x27;</span>,x/x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素幂运算：&#x27;</span>,x**x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素开方：&#x27;</span>,x.sqrt())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;求幂运算：&#x27;</span>,torch.exp(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 矩阵运算</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 合并张量(记得加括号)</span></span><br><span class=\"line\">x=torch.zeros(<span class=\"number\">12</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">y=torch.ones(<span class=\"number\">12</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;沿行合并：&#x27;</span>,torch.cat((x,y),dim=<span class=\"number\">0</span>)) <span class=\"comment\"># 沿行合并</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;沿列合并：&#x27;</span>,torch.cat((x,y),dim=<span class=\"number\">1</span>)) <span class=\"comment\"># 沿列合并</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 逻辑运算</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x==y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;求和：&#x27;</span>,y.<span class=\"built_in\">sum</span>())</span><br></pre></td></tr></table></figure>\n\n<pre><code>按元素加法： tensor([0, 2, 4, 6])\n按元素减法： tensor([0, 0, 0, 0])\n按元素乘法： tensor([0, 1, 4, 9])\n按元素除法： tensor([nan, 1., 1., 1.])\n按元素幂运算： tensor([ 1,  1,  4, 27])\n按元素开方： tensor([0.0000, 1.0000, 1.4142, 1.7321])\n求幂运算： tensor([ 1.0000,  2.7183,  7.3891, 20.0855])\n沿行合并： tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n沿列合并： tensor([[0., 0., 0., 0., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 1., 1., 1., 1.]])\ntensor([[False, False, False, False],\n        [False, False, False, False],\n        [False, False, False, False]])\n求和： tensor(12.)\n</code></pre>\n<h2 id=\"1-3-广播机制\"><a href=\"#1-3-广播机制\" class=\"headerlink\" title=\"1.3 广播机制\"></a>1.3 广播机制</h2><ul>\n<li>对两个形状不同的张量按元素运算时，可能会触发广播机制：先适当复制元素使这两个张量形状相同后再按元素运算</li>\n</ul>\n<ol>\n<li>如果两个张量的维度数不同，可以在较小的张量的形状前面补1，直到两者的维度数相同。</li>\n<li>如果两个张量在某个维度上的大小不同，但其中一个张量在该维度上的大小为1，那么可以通过在该维度上重复扩展该张量，使得两个张量在该维度上的大小相同。</li>\n<li>如果两个张量在某个维度上的大小都不为1，且大小不同，那么会发生形状不匹配，导致无法进行广播</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.arange(<span class=\"number\">3</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">b=torch.arange(<span class=\"number\">2</span>).reshape(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;a:&#x27;</span>,a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;b:&#x27;</span>,b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;a+b:&#x27;</span>,a+b) <span class=\"comment\">#通常沿着长度为1的维度进行广播</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>a: tensor([[0],\n        [1],\n        [2]])\nb: tensor([[0, 1]])\na+b: tensor([[0, 1],\n        [1, 2],\n        [2, 3]])\n</code></pre>\n<h2 id=\"1-4-索引和切片\"><a href=\"#1-4-索引和切片\" class=\"headerlink\" title=\"1.4 索引和切片\"></a>1.4 索引和切片</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x:&#x27;</span>,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[-1]:&#x27;</span>,x[-<span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[1:3]:&#x27;</span>,x[<span class=\"number\">1</span>:<span class=\"number\">3</span>]) <span class=\"comment\">#选择第2和第3个元素</span></span><br><span class=\"line\">x[<span class=\"number\">1</span>,<span class=\"number\">2</span>]=<span class=\"number\">9</span> <span class=\"comment\"># 修改元素</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[1,2]=9后 x:&#x27;</span>,x)</span><br><span class=\"line\">x[<span class=\"number\">0</span>:<span class=\"number\">2</span>,:]=<span class=\"number\">12</span> <span class=\"comment\"># 修改一行</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[0:2,:]=12后 x:&#x27;</span>,x)</span><br></pre></td></tr></table></figure>\n\n<pre><code>x: tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\nx[-1]: tensor([0., 0., 0., 0.])\nx[1:3]: tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\nx[1,2]=9后 x: tensor([[0., 0., 0., 0.],\n        [0., 0., 9., 0.],\n        [0., 0., 0., 0.]])\nx[0:2,:]=12后 x: tensor([[12., 12., 12., 12.],\n        [12., 12., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n</code></pre>\n<h2 id=\"1-5-节省内存\"><a href=\"#1-5-节省内存\" class=\"headerlink\" title=\"1.5 节省内存\"></a>1.5 节省内存</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">z=torch.zeros(<span class=\"number\">1</span>)</span><br><span class=\"line\">before=<span class=\"built_in\">id</span>(z)</span><br><span class=\"line\">z=z+x <span class=\"comment\">#对于这种类似列表的数据结构，加号会导致新的内存分配</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;z:&#x27;</span>,z)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;id(z)==before:&#x27;</span>,<span class=\"built_in\">id</span>(z)==before) <span class=\"comment\"># False，说明z指向了新的地址</span></span><br><span class=\"line\"></span><br><span class=\"line\">z=torch.zeros(<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\">#使用如下操作可以避免新的内存分配，但是无法广播，所以这里要求x和z的形状一致</span></span><br><span class=\"line\">before=<span class=\"built_in\">id</span>(z)</span><br><span class=\"line\">z+=x <span class=\"comment\"># +=不会导致新的内存分配</span></span><br><span class=\"line\">z[:]=x+z <span class=\"comment\"># 也不会导致新的内存分配</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;id(z)==before:&#x27;</span>,<span class=\"built_in\">id</span>(z)==before) <span class=\"comment\"># True</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>z: tensor([[12., 12., 12., 12.],\n        [12., 12., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\nid(z)==before: False\nid(z)==before: True\n</code></pre>\n<h2 id=\"1-6-转换为其他python对象\"><a href=\"#1-6-转换为其他python对象\" class=\"headerlink\" title=\"1.6 转换为其他python对象\"></a>1.6 转换为其他python对象</h2><ul>\n<li>tensor与numpy数组</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=x.numpy() <span class=\"comment\"># 将张量转换为numpy数组</span></span><br><span class=\"line\">B=torch.tensor(A) <span class=\"comment\"># 将numpy数组转换为张量</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A,B,sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">A[<span class=\"number\">1</span>,<span class=\"number\">1</span>]=<span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A,B,x,sep=<span class=\"string\">&#x27;\\n&#x27;</span>) <span class=\"comment\">#A与X共享内存</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>[[12. 12. 12. 12.]\n [12.  3. 12. 12.]\n [ 0.  0.  0.  0.]]\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n[[12. 12. 12. 12.]\n [12.  3. 12. 12.]\n [ 0.  0.  0.  0.]]\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n</code></pre>\n<ul>\n<li>张量转为python标量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.tensor([<span class=\"number\">1.3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#由于pytorch中小数用32位，python中用64位；尝试输出.20f就能发现精确度问题</span></span><br><span class=\"line\"><span class=\"comment\">#由于舍入（四舍五入到最接近的偶数），1.3在pytorch中表示是1.299多，而在python中是1.300多</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.item()) <span class=\"comment\">#使用item函数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">float</span>(a)) <span class=\"comment\">#python内置函数</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([1.3000])\n1.2999999523162842\n1.2999999523162842\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-pytorch数据操作\"><a href=\"#1-pytorch数据操作\" class=\"headerlink\" title=\"1. pytorch数据操作\"></a>1. pytorch数据操作</h1><ul>\n<li>pytorch与tensorflow中的Tensor类似于numpy的ndarray</li>\n<li>pytorch中的Tensor可以在GPU上运行</li>\n<li>pytorch中的Tensor可以用于自动求导</li>\n</ul>\n<h2 id=\"1-1-张量\"><a href=\"#1-1-张量\" class=\"headerlink\" title=\"1.1 张量\"></a>1.1 张量</h2><ul>\n<li>创建张量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 导入torch，不是pytorch</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 创建范围张量</span></span><br><span class=\"line\">x=torch.arange(<span class=\"number\">12</span>) <span class=\"comment\"># 0-11,默认为int64，可以指定dtype，默认存储在CPU上</span></span><br><span class=\"line\">y=torch.arange(<span class=\"number\">12</span>,dtype=torch.float32) <span class=\"comment\"># 指定dtype</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 创建全0张量</span></span><br><span class=\"line\">zeros=torch.zeros(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\"># 2*3*4的全0张量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 创建全1张量</span></span><br><span class=\"line\">ones=torch.ones(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\"># 2*3*4的全1张量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 创建采样张量</span></span><br><span class=\"line\">sample=torch.randn(<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\">#从标准高斯分布中采样</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 6. 列表张量</span></span><br><span class=\"line\">lists=torch.tensor([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(zeros)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(ones)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(sample)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(lists)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\ntensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\ntensor([[[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]])\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor([[-0.0847, -0.2406,  0.1735, -1.5543],\n        [-0.2820, -0.6689,  0.0565,  0.4746],\n        [ 0.9841, -1.6116, -0.1587, -1.5121]])\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n</code></pre>\n<ul>\n<li>张量的属性</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 3. 查看张量的形状</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x的规模：&#x27;</span>,x.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 查看张量的元素总数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x中元素个数：&#x27;</span>,x.numel())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 改变张量的形状</span></span><br><span class=\"line\">x=x.reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;改变x的形状：&#x27;</span>,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;自动计算的形状：&#x27;</span>,x.reshape(-<span class=\"number\">1</span>,<span class=\"number\">6</span>)) <span class=\"comment\"># -1表示自动计算这个维度</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>x的规模： torch.Size([12])\nx中元素个数： 12\n改变x的形状： tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])\n自动计算的形状： tensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\n</code></pre>\n<h2 id=\"1-2-运算符\"><a href=\"#1-2-运算符\" class=\"headerlink\" title=\"1.2 运算符\"></a>1.2 运算符</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 按元素运算</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素加法：&#x27;</span>,x+x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素减法：&#x27;</span>,x-x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素乘法：&#x27;</span>,x*x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素除法：&#x27;</span>,x/x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素幂运算：&#x27;</span>,x**x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;按元素开方：&#x27;</span>,x.sqrt())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;求幂运算：&#x27;</span>,torch.exp(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 矩阵运算</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 合并张量(记得加括号)</span></span><br><span class=\"line\">x=torch.zeros(<span class=\"number\">12</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">y=torch.ones(<span class=\"number\">12</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;沿行合并：&#x27;</span>,torch.cat((x,y),dim=<span class=\"number\">0</span>)) <span class=\"comment\"># 沿行合并</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;沿列合并：&#x27;</span>,torch.cat((x,y),dim=<span class=\"number\">1</span>)) <span class=\"comment\"># 沿列合并</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 逻辑运算</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x==y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;求和：&#x27;</span>,y.<span class=\"built_in\">sum</span>())</span><br></pre></td></tr></table></figure>\n\n<pre><code>按元素加法： tensor([0, 2, 4, 6])\n按元素减法： tensor([0, 0, 0, 0])\n按元素乘法： tensor([0, 1, 4, 9])\n按元素除法： tensor([nan, 1., 1., 1.])\n按元素幂运算： tensor([ 1,  1,  4, 27])\n按元素开方： tensor([0.0000, 1.0000, 1.4142, 1.7321])\n求幂运算： tensor([ 1.0000,  2.7183,  7.3891, 20.0855])\n沿行合并： tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n沿列合并： tensor([[0., 0., 0., 0., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 1., 1., 1., 1.]])\ntensor([[False, False, False, False],\n        [False, False, False, False],\n        [False, False, False, False]])\n求和： tensor(12.)\n</code></pre>\n<h2 id=\"1-3-广播机制\"><a href=\"#1-3-广播机制\" class=\"headerlink\" title=\"1.3 广播机制\"></a>1.3 广播机制</h2><ul>\n<li>对两个形状不同的张量按元素运算时，可能会触发广播机制：先适当复制元素使这两个张量形状相同后再按元素运算</li>\n</ul>\n<ol>\n<li>如果两个张量的维度数不同，可以在较小的张量的形状前面补1，直到两者的维度数相同。</li>\n<li>如果两个张量在某个维度上的大小不同，但其中一个张量在该维度上的大小为1，那么可以通过在该维度上重复扩展该张量，使得两个张量在该维度上的大小相同。</li>\n<li>如果两个张量在某个维度上的大小都不为1，且大小不同，那么会发生形状不匹配，导致无法进行广播</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.arange(<span class=\"number\">3</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">b=torch.arange(<span class=\"number\">2</span>).reshape(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;a:&#x27;</span>,a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;b:&#x27;</span>,b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;a+b:&#x27;</span>,a+b) <span class=\"comment\">#通常沿着长度为1的维度进行广播</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>a: tensor([[0],\n        [1],\n        [2]])\nb: tensor([[0, 1]])\na+b: tensor([[0, 1],\n        [1, 2],\n        [2, 3]])\n</code></pre>\n<h2 id=\"1-4-索引和切片\"><a href=\"#1-4-索引和切片\" class=\"headerlink\" title=\"1.4 索引和切片\"></a>1.4 索引和切片</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x:&#x27;</span>,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[-1]:&#x27;</span>,x[-<span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[1:3]:&#x27;</span>,x[<span class=\"number\">1</span>:<span class=\"number\">3</span>]) <span class=\"comment\">#选择第2和第3个元素</span></span><br><span class=\"line\">x[<span class=\"number\">1</span>,<span class=\"number\">2</span>]=<span class=\"number\">9</span> <span class=\"comment\"># 修改元素</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[1,2]=9后 x:&#x27;</span>,x)</span><br><span class=\"line\">x[<span class=\"number\">0</span>:<span class=\"number\">2</span>,:]=<span class=\"number\">12</span> <span class=\"comment\"># 修改一行</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x[0:2,:]=12后 x:&#x27;</span>,x)</span><br></pre></td></tr></table></figure>\n\n<pre><code>x: tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\nx[-1]: tensor([0., 0., 0., 0.])\nx[1:3]: tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\nx[1,2]=9后 x: tensor([[0., 0., 0., 0.],\n        [0., 0., 9., 0.],\n        [0., 0., 0., 0.]])\nx[0:2,:]=12后 x: tensor([[12., 12., 12., 12.],\n        [12., 12., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n</code></pre>\n<h2 id=\"1-5-节省内存\"><a href=\"#1-5-节省内存\" class=\"headerlink\" title=\"1.5 节省内存\"></a>1.5 节省内存</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">z=torch.zeros(<span class=\"number\">1</span>)</span><br><span class=\"line\">before=<span class=\"built_in\">id</span>(z)</span><br><span class=\"line\">z=z+x <span class=\"comment\">#对于这种类似列表的数据结构，加号会导致新的内存分配</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;z:&#x27;</span>,z)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;id(z)==before:&#x27;</span>,<span class=\"built_in\">id</span>(z)==before) <span class=\"comment\"># False，说明z指向了新的地址</span></span><br><span class=\"line\"></span><br><span class=\"line\">z=torch.zeros(<span class=\"number\">3</span>,<span class=\"number\">4</span>) <span class=\"comment\">#使用如下操作可以避免新的内存分配，但是无法广播，所以这里要求x和z的形状一致</span></span><br><span class=\"line\">before=<span class=\"built_in\">id</span>(z)</span><br><span class=\"line\">z+=x <span class=\"comment\"># +=不会导致新的内存分配</span></span><br><span class=\"line\">z[:]=x+z <span class=\"comment\"># 也不会导致新的内存分配</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;id(z)==before:&#x27;</span>,<span class=\"built_in\">id</span>(z)==before) <span class=\"comment\"># True</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>z: tensor([[12., 12., 12., 12.],\n        [12., 12., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\nid(z)==before: False\nid(z)==before: True\n</code></pre>\n<h2 id=\"1-6-转换为其他python对象\"><a href=\"#1-6-转换为其他python对象\" class=\"headerlink\" title=\"1.6 转换为其他python对象\"></a>1.6 转换为其他python对象</h2><ul>\n<li>tensor与numpy数组</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=x.numpy() <span class=\"comment\"># 将张量转换为numpy数组</span></span><br><span class=\"line\">B=torch.tensor(A) <span class=\"comment\"># 将numpy数组转换为张量</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A,B,sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">A[<span class=\"number\">1</span>,<span class=\"number\">1</span>]=<span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A,B,x,sep=<span class=\"string\">&#x27;\\n&#x27;</span>) <span class=\"comment\">#A与X共享内存</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>[[12. 12. 12. 12.]\n [12.  3. 12. 12.]\n [ 0.  0.  0.  0.]]\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n[[12. 12. 12. 12.]\n [12.  3. 12. 12.]\n [ 0.  0.  0.  0.]]\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\ntensor([[12., 12., 12., 12.],\n        [12.,  3., 12., 12.],\n        [ 0.,  0.,  0.,  0.]])\n</code></pre>\n<ul>\n<li>张量转为python标量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.tensor([<span class=\"number\">1.3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#由于pytorch中小数用32位，python中用64位；尝试输出.20f就能发现精确度问题</span></span><br><span class=\"line\"><span class=\"comment\">#由于舍入（四舍五入到最接近的偶数），1.3在pytorch中表示是1.299多，而在python中是1.300多</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.item()) <span class=\"comment\">#使用item函数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">float</span>(a)) <span class=\"comment\">#python内置函数</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([1.3000])\n1.2999999523162842\n1.2999999523162842\n</code></pre>"},{"title":"1.2 pytorch数据预处理","date":"2023-11-27T06:00:00.000Z","comment":false,"toc":true,"_content":"# \n<!--more-->\n\n# 2. pytorch数据预处理\n- 主要通过pandas预处理\n\n## 2.1 读取数据集\n\n\n```python\n# 1. 先自己准备一个数据集\nimport os\nos.makedirs(os.path.join('..','data'),exist_ok=True)\ndata_file=os.path.join('..','data','house_tiny.csv')\nwith open(data_file,'w') as f:\n    f.write('NumRooms, Alley, Price\\n') #列名\n    f.write('NA,Pave, 127500\\n') #每行表示一个数据样本\n    f.write('2,NA, 106000\\n')\n    f.write('4,NA, 178100\\n')\n    f.write('NA,NA, 14000\\n')\n\n# 2. 读取数据集\nimport pandas as pd\ndata=pd.read_csv(data_file)\nprint(data)\n```\n\n       NumRooms  Alley   Price\n    0       NaN   Pave  127500\n    1       2.0    NaN  106000\n    2       4.0    NaN  178100\n    3       NaN    NaN   14000\n    \n\n## 2.2 缺失值处理\n- 删除\n- 插值\n\n### 2.2.1 数值类型\n\n\n```python\n# 1. 位置索引iloc将data分为输入与输出\ninputs=data.iloc[:,0:2] #前两列作为输入\noutputs=data.iloc[:,2] #第三列作为输出\n\n# 2. 用每一列的均值替换空值\ninputs=inputs.fillna(inputs.mean())\nprint(inputs)\n```\n\n       NumRooms  Alley\n    0       3.0   Pave\n    1       2.0    NaN\n    2       4.0    NaN\n    3       3.0    NaN\n    \n\n### 2.2.2 类别类型或离散值\n- 将NaN视为一个类别，根据这一列类别的个数分出n列，每一列代表一个类别，如果该行的值为该列的类别，则为1，否则为0\n\n\n```python\ninputs=pd.get_dummies(inputs, dummy_na=True)\nprint(inputs)\n```\n\n       NumRooms   Alley_Pave   Alley_nan\n    0       3.0            1           0\n    1       2.0            0           1\n    2       4.0            0           1\n    3       3.0            0           1\n    \n\n## 2.3 转换为张量\n- torch.tensor()\n\n\n```python\nimport torch\nx=torch.tensor(inputs.to_numpy(dtype=float))\ny=torch.tensor(outputs.to_numpy(dtype=float))\nx,y\n```\n\n\n\n\n    (tensor([[3., 1., 0.],\n             [2., 0., 1.],\n             [4., 0., 1.],\n             [3., 0., 1.]], dtype=torch.float64),\n     tensor([127500., 106000., 178100.,  14000.], dtype=torch.float64))\n\n\n\n## 练习\n- 1. 创建一个更多行和列的数据集\n\n\n\n```python\nimport os\nos.makedirs(os.path.join('..','data'),exist_ok=True)\ndata_file=os.path.join('..','data','house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('NumRooms, Alley, Price, test\\n') # 列名\n    f.write('NA, Pave, 127500, 1\\n') # 每行表示一个数据样本\n    f.write('2, NA, 106000, 0\\n')\n    f.write('4, NA, 178100, 0\\n')\n    f.write('NA, NA, 140000, 1\\n')\n    f.write('2, Pave, 127500, 0\\n')\n\n#读取数据集\nimport pandas as pd\nprint(pd.read_csv(data_file))\n```\n\n       NumRooms  Alley   Price   test\n    0       NaN   Pave  127500      1\n    1       2.0     NA  106000      0\n    2       4.0     NA  178100      0\n    3       NaN     NA  140000      1\n    4       2.0   Pave  127500      0\n    \n\n- 2. 删除缺失值最多的列\n\n\n```python\n#删除缺失值最多的列\nimport pandas as pd\ndata=pd.read_csv(data_file)\n\n#计算每一列的缺失值个数\nmissing=data.isnull().sum() #按列求和\nprint(missing)\ncolumn=missing.idxmax() #返回缺失值最多的列名\nprint(column)\ndata=data.drop(columns=[column])\nprint(data)\n\n#保存处理后的数据集\ndata.to_csv(data_file,index=False) #index=False表示不保存行索引\n```\n\n    NumRooms    2\n     Alley      0\n     Price      0\n     test       0\n    dtype: int64\n    NumRooms\n       Alley   Price   test\n    0   Pave  127500      1\n    1     NA  106000      0\n    2     NA  178100      0\n    3     NA  140000      1\n    4   Pave  127500      0\n    \n\n- 3. 将处理后的数据集转换为张量\n\n\n```python\n#将数据集转换为张量格式\nimport torch\nimport os\ndata_file=os.path.join('..','data','house_tiny.csv')\ndata=pd.read_csv(data_file)\n#输出data的shape\nprint(data,data.shape,sep='\\n')\n\n#将字符串类型进行one-hot编码\ndata=pd.get_dummies(data,dummy_na=True) #dummy_na=True表示将缺失值也当作合法的特征值并为其创建指示特征\nprint(data)\n#将dataframe格式转换为张量格式\ndata=torch.tensor(data.to_numpy(dtype=float))\nprint(data)\n```\n\n       Alley   Price   test\n    0   Pave  127500      1\n    1     NA  106000      0\n    2     NA  178100      0\n    3     NA  140000      1\n    4   Pave  127500      0\n    (5, 3)\n        Price   test   Alley_ NA   Alley_ Pave   Alley_nan\n    0  127500      1           0             1           0\n    1  106000      0           1             0           0\n    2  178100      0           1             0           0\n    3  140000      1           1             0           0\n    4  127500      0           0             1           0\n    tensor([[1.2750e+05, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n            [1.0600e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.7810e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.4000e+05, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.2750e+05, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]],\n           dtype=torch.float64)\n    \n","source":"_posts/deeplearning/code/pytorch/1_prepare/2_preprocessing.md","raw":"---\ntitle: 1.2 pytorch数据预处理\ndate: 2023-11-27 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: false\ntoc: true\n---\n# \n<!--more-->\n\n# 2. pytorch数据预处理\n- 主要通过pandas预处理\n\n## 2.1 读取数据集\n\n\n```python\n# 1. 先自己准备一个数据集\nimport os\nos.makedirs(os.path.join('..','data'),exist_ok=True)\ndata_file=os.path.join('..','data','house_tiny.csv')\nwith open(data_file,'w') as f:\n    f.write('NumRooms, Alley, Price\\n') #列名\n    f.write('NA,Pave, 127500\\n') #每行表示一个数据样本\n    f.write('2,NA, 106000\\n')\n    f.write('4,NA, 178100\\n')\n    f.write('NA,NA, 14000\\n')\n\n# 2. 读取数据集\nimport pandas as pd\ndata=pd.read_csv(data_file)\nprint(data)\n```\n\n       NumRooms  Alley   Price\n    0       NaN   Pave  127500\n    1       2.0    NaN  106000\n    2       4.0    NaN  178100\n    3       NaN    NaN   14000\n    \n\n## 2.2 缺失值处理\n- 删除\n- 插值\n\n### 2.2.1 数值类型\n\n\n```python\n# 1. 位置索引iloc将data分为输入与输出\ninputs=data.iloc[:,0:2] #前两列作为输入\noutputs=data.iloc[:,2] #第三列作为输出\n\n# 2. 用每一列的均值替换空值\ninputs=inputs.fillna(inputs.mean())\nprint(inputs)\n```\n\n       NumRooms  Alley\n    0       3.0   Pave\n    1       2.0    NaN\n    2       4.0    NaN\n    3       3.0    NaN\n    \n\n### 2.2.2 类别类型或离散值\n- 将NaN视为一个类别，根据这一列类别的个数分出n列，每一列代表一个类别，如果该行的值为该列的类别，则为1，否则为0\n\n\n```python\ninputs=pd.get_dummies(inputs, dummy_na=True)\nprint(inputs)\n```\n\n       NumRooms   Alley_Pave   Alley_nan\n    0       3.0            1           0\n    1       2.0            0           1\n    2       4.0            0           1\n    3       3.0            0           1\n    \n\n## 2.3 转换为张量\n- torch.tensor()\n\n\n```python\nimport torch\nx=torch.tensor(inputs.to_numpy(dtype=float))\ny=torch.tensor(outputs.to_numpy(dtype=float))\nx,y\n```\n\n\n\n\n    (tensor([[3., 1., 0.],\n             [2., 0., 1.],\n             [4., 0., 1.],\n             [3., 0., 1.]], dtype=torch.float64),\n     tensor([127500., 106000., 178100.,  14000.], dtype=torch.float64))\n\n\n\n## 练习\n- 1. 创建一个更多行和列的数据集\n\n\n\n```python\nimport os\nos.makedirs(os.path.join('..','data'),exist_ok=True)\ndata_file=os.path.join('..','data','house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('NumRooms, Alley, Price, test\\n') # 列名\n    f.write('NA, Pave, 127500, 1\\n') # 每行表示一个数据样本\n    f.write('2, NA, 106000, 0\\n')\n    f.write('4, NA, 178100, 0\\n')\n    f.write('NA, NA, 140000, 1\\n')\n    f.write('2, Pave, 127500, 0\\n')\n\n#读取数据集\nimport pandas as pd\nprint(pd.read_csv(data_file))\n```\n\n       NumRooms  Alley   Price   test\n    0       NaN   Pave  127500      1\n    1       2.0     NA  106000      0\n    2       4.0     NA  178100      0\n    3       NaN     NA  140000      1\n    4       2.0   Pave  127500      0\n    \n\n- 2. 删除缺失值最多的列\n\n\n```python\n#删除缺失值最多的列\nimport pandas as pd\ndata=pd.read_csv(data_file)\n\n#计算每一列的缺失值个数\nmissing=data.isnull().sum() #按列求和\nprint(missing)\ncolumn=missing.idxmax() #返回缺失值最多的列名\nprint(column)\ndata=data.drop(columns=[column])\nprint(data)\n\n#保存处理后的数据集\ndata.to_csv(data_file,index=False) #index=False表示不保存行索引\n```\n\n    NumRooms    2\n     Alley      0\n     Price      0\n     test       0\n    dtype: int64\n    NumRooms\n       Alley   Price   test\n    0   Pave  127500      1\n    1     NA  106000      0\n    2     NA  178100      0\n    3     NA  140000      1\n    4   Pave  127500      0\n    \n\n- 3. 将处理后的数据集转换为张量\n\n\n```python\n#将数据集转换为张量格式\nimport torch\nimport os\ndata_file=os.path.join('..','data','house_tiny.csv')\ndata=pd.read_csv(data_file)\n#输出data的shape\nprint(data,data.shape,sep='\\n')\n\n#将字符串类型进行one-hot编码\ndata=pd.get_dummies(data,dummy_na=True) #dummy_na=True表示将缺失值也当作合法的特征值并为其创建指示特征\nprint(data)\n#将dataframe格式转换为张量格式\ndata=torch.tensor(data.to_numpy(dtype=float))\nprint(data)\n```\n\n       Alley   Price   test\n    0   Pave  127500      1\n    1     NA  106000      0\n    2     NA  178100      0\n    3     NA  140000      1\n    4   Pave  127500      0\n    (5, 3)\n        Price   test   Alley_ NA   Alley_ Pave   Alley_nan\n    0  127500      1           0             1           0\n    1  106000      0           1             0           0\n    2  178100      0           1             0           0\n    3  140000      1           1             0           0\n    4  127500      0           0             1           0\n    tensor([[1.2750e+05, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n            [1.0600e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.7810e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.4000e+05, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n            [1.2750e+05, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]],\n           dtype=torch.float64)\n    \n","slug":"deeplearning/code/pytorch/1_prepare/2_preprocessing","published":1,"updated":"2024-02-03T03:48:20.134Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198598003i7svw6mtscg67","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"2-pytorch数据预处理\"><a href=\"#2-pytorch数据预处理\" class=\"headerlink\" title=\"2. pytorch数据预处理\"></a>2. pytorch数据预处理</h1><ul>\n<li>主要通过pandas预处理</li>\n</ul>\n<h2 id=\"2-1-读取数据集\"><a href=\"#2-1-读取数据集\" class=\"headerlink\" title=\"2.1 读取数据集\"></a>2.1 读取数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 先自己准备一个数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.makedirs(os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>),exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(data_file,<span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NumRooms, Alley, Price\\n&#x27;</span>) <span class=\"comment\">#列名</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,Pave, 127500\\n&#x27;</span>) <span class=\"comment\">#每行表示一个数据样本</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2,NA, 106000\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;4,NA, 178100\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,NA, 14000\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley   Price\n0       NaN   Pave  127500\n1       2.0    NaN  106000\n2       4.0    NaN  178100\n3       NaN    NaN   14000\n</code></pre>\n<h2 id=\"2-2-缺失值处理\"><a href=\"#2-2-缺失值处理\" class=\"headerlink\" title=\"2.2 缺失值处理\"></a>2.2 缺失值处理</h2><ul>\n<li>删除</li>\n<li>插值</li>\n</ul>\n<h3 id=\"2-2-1-数值类型\"><a href=\"#2-2-1-数值类型\" class=\"headerlink\" title=\"2.2.1 数值类型\"></a>2.2.1 数值类型</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 位置索引iloc将data分为输入与输出</span></span><br><span class=\"line\">inputs=data.iloc[:,<span class=\"number\">0</span>:<span class=\"number\">2</span>] <span class=\"comment\">#前两列作为输入</span></span><br><span class=\"line\">outputs=data.iloc[:,<span class=\"number\">2</span>] <span class=\"comment\">#第三列作为输出</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 用每一列的均值替换空值</span></span><br><span class=\"line\">inputs=inputs.fillna(inputs.mean())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley\n0       3.0   Pave\n1       2.0    NaN\n2       4.0    NaN\n3       3.0    NaN\n</code></pre>\n<h3 id=\"2-2-2-类别类型或离散值\"><a href=\"#2-2-2-类别类型或离散值\" class=\"headerlink\" title=\"2.2.2 类别类型或离散值\"></a>2.2.2 类别类型或离散值</h3><ul>\n<li>将NaN视为一个类别，根据这一列类别的个数分出n列，每一列代表一个类别，如果该行的值为该列的类别，则为1，否则为0</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inputs=pd.get_dummies(inputs, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms   Alley_Pave   Alley_nan\n0       3.0            1           0\n1       2.0            0           1\n2       4.0            0           1\n3       3.0            0           1\n</code></pre>\n<h2 id=\"2-3-转换为张量\"><a href=\"#2-3-转换为张量\" class=\"headerlink\" title=\"2.3 转换为张量\"></a>2.3 转换为张量</h2><ul>\n<li>torch.tensor()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">x=torch.tensor(inputs.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\">y=torch.tensor(outputs.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\">x,y</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>(tensor([[3., 1., 0.],\n         [2., 0., 1.],\n         [4., 0., 1.],\n         [3., 0., 1.]], dtype=torch.float64),\n tensor([127500., 106000., 178100.,  14000.], dtype=torch.float64))\n</code></pre>\n<h2 id=\"练习\"><a href=\"#练习\" class=\"headerlink\" title=\"练习\"></a>练习</h2><ul>\n<li><ol>\n<li>创建一个更多行和列的数据集</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.makedirs(os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>),exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(data_file, <span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NumRooms, Alley, Price, test\\n&#x27;</span>) <span class=\"comment\"># 列名</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA, Pave, 127500, 1\\n&#x27;</span>) <span class=\"comment\"># 每行表示一个数据样本</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2, NA, 106000, 0\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;4, NA, 178100, 0\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA, NA, 140000, 1\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2, Pave, 127500, 0\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pd.read_csv(data_file))</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley   Price   test\n0       NaN   Pave  127500      1\n1       2.0     NA  106000      0\n2       4.0     NA  178100      0\n3       NaN     NA  140000      1\n4       2.0   Pave  127500      0\n</code></pre>\n<ul>\n<li><ol start=\"2\">\n<li>删除缺失值最多的列</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#删除缺失值最多的列</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#计算每一列的缺失值个数</span></span><br><span class=\"line\">missing=data.isnull().<span class=\"built_in\">sum</span>() <span class=\"comment\">#按列求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(missing)</span><br><span class=\"line\">column=missing.idxmax() <span class=\"comment\">#返回缺失值最多的列名</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(column)</span><br><span class=\"line\">data=data.drop(columns=[column])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#保存处理后的数据集</span></span><br><span class=\"line\">data.to_csv(data_file,index=<span class=\"literal\">False</span>) <span class=\"comment\">#index=False表示不保存行索引</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>NumRooms    2\n Alley      0\n Price      0\n test       0\ndtype: int64\nNumRooms\n   Alley   Price   test\n0   Pave  127500      1\n1     NA  106000      0\n2     NA  178100      0\n3     NA  140000      1\n4   Pave  127500      0\n</code></pre>\n<ul>\n<li><ol start=\"3\">\n<li>将处理后的数据集转换为张量</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将数据集转换为张量格式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"><span class=\"comment\">#输出data的shape</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data,data.shape,sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将字符串类型进行one-hot编码</span></span><br><span class=\"line\">data=pd.get_dummies(data,dummy_na=<span class=\"literal\">True</span>) <span class=\"comment\">#dummy_na=True表示将缺失值也当作合法的特征值并为其创建指示特征</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"><span class=\"comment\">#将dataframe格式转换为张量格式</span></span><br><span class=\"line\">data=torch.tensor(data.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   Alley   Price   test\n0   Pave  127500      1\n1     NA  106000      0\n2     NA  178100      0\n3     NA  140000      1\n4   Pave  127500      0\n(5, 3)\n    Price   test   Alley_ NA   Alley_ Pave   Alley_nan\n0  127500      1           0             1           0\n1  106000      0           1             0           0\n2  178100      0           1             0           0\n3  140000      1           1             0           0\n4  127500      0           0             1           0\ntensor([[1.2750e+05, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n        [1.0600e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.7810e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.4000e+05, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.2750e+05, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]],\n       dtype=torch.float64)\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"2-pytorch数据预处理\"><a href=\"#2-pytorch数据预处理\" class=\"headerlink\" title=\"2. pytorch数据预处理\"></a>2. pytorch数据预处理</h1><ul>\n<li>主要通过pandas预处理</li>\n</ul>\n<h2 id=\"2-1-读取数据集\"><a href=\"#2-1-读取数据集\" class=\"headerlink\" title=\"2.1 读取数据集\"></a>2.1 读取数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 先自己准备一个数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.makedirs(os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>),exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(data_file,<span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NumRooms, Alley, Price\\n&#x27;</span>) <span class=\"comment\">#列名</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,Pave, 127500\\n&#x27;</span>) <span class=\"comment\">#每行表示一个数据样本</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2,NA, 106000\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;4,NA, 178100\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,NA, 14000\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley   Price\n0       NaN   Pave  127500\n1       2.0    NaN  106000\n2       4.0    NaN  178100\n3       NaN    NaN   14000\n</code></pre>\n<h2 id=\"2-2-缺失值处理\"><a href=\"#2-2-缺失值处理\" class=\"headerlink\" title=\"2.2 缺失值处理\"></a>2.2 缺失值处理</h2><ul>\n<li>删除</li>\n<li>插值</li>\n</ul>\n<h3 id=\"2-2-1-数值类型\"><a href=\"#2-2-1-数值类型\" class=\"headerlink\" title=\"2.2.1 数值类型\"></a>2.2.1 数值类型</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 位置索引iloc将data分为输入与输出</span></span><br><span class=\"line\">inputs=data.iloc[:,<span class=\"number\">0</span>:<span class=\"number\">2</span>] <span class=\"comment\">#前两列作为输入</span></span><br><span class=\"line\">outputs=data.iloc[:,<span class=\"number\">2</span>] <span class=\"comment\">#第三列作为输出</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 用每一列的均值替换空值</span></span><br><span class=\"line\">inputs=inputs.fillna(inputs.mean())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley\n0       3.0   Pave\n1       2.0    NaN\n2       4.0    NaN\n3       3.0    NaN\n</code></pre>\n<h3 id=\"2-2-2-类别类型或离散值\"><a href=\"#2-2-2-类别类型或离散值\" class=\"headerlink\" title=\"2.2.2 类别类型或离散值\"></a>2.2.2 类别类型或离散值</h3><ul>\n<li>将NaN视为一个类别，根据这一列类别的个数分出n列，每一列代表一个类别，如果该行的值为该列的类别，则为1，否则为0</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inputs=pd.get_dummies(inputs, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms   Alley_Pave   Alley_nan\n0       3.0            1           0\n1       2.0            0           1\n2       4.0            0           1\n3       3.0            0           1\n</code></pre>\n<h2 id=\"2-3-转换为张量\"><a href=\"#2-3-转换为张量\" class=\"headerlink\" title=\"2.3 转换为张量\"></a>2.3 转换为张量</h2><ul>\n<li>torch.tensor()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">x=torch.tensor(inputs.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\">y=torch.tensor(outputs.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\">x,y</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>(tensor([[3., 1., 0.],\n         [2., 0., 1.],\n         [4., 0., 1.],\n         [3., 0., 1.]], dtype=torch.float64),\n tensor([127500., 106000., 178100.,  14000.], dtype=torch.float64))\n</code></pre>\n<h2 id=\"练习\"><a href=\"#练习\" class=\"headerlink\" title=\"练习\"></a>练习</h2><ul>\n<li><ol>\n<li>创建一个更多行和列的数据集</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.makedirs(os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>),exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(data_file, <span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NumRooms, Alley, Price, test\\n&#x27;</span>) <span class=\"comment\"># 列名</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA, Pave, 127500, 1\\n&#x27;</span>) <span class=\"comment\"># 每行表示一个数据样本</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2, NA, 106000, 0\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;4, NA, 178100, 0\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA, NA, 140000, 1\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2, Pave, 127500, 0\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pd.read_csv(data_file))</span><br></pre></td></tr></table></figure>\n\n<pre><code>   NumRooms  Alley   Price   test\n0       NaN   Pave  127500      1\n1       2.0     NA  106000      0\n2       4.0     NA  178100      0\n3       NaN     NA  140000      1\n4       2.0   Pave  127500      0\n</code></pre>\n<ul>\n<li><ol start=\"2\">\n<li>删除缺失值最多的列</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#删除缺失值最多的列</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#计算每一列的缺失值个数</span></span><br><span class=\"line\">missing=data.isnull().<span class=\"built_in\">sum</span>() <span class=\"comment\">#按列求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(missing)</span><br><span class=\"line\">column=missing.idxmax() <span class=\"comment\">#返回缺失值最多的列名</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(column)</span><br><span class=\"line\">data=data.drop(columns=[column])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#保存处理后的数据集</span></span><br><span class=\"line\">data.to_csv(data_file,index=<span class=\"literal\">False</span>) <span class=\"comment\">#index=False表示不保存行索引</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>NumRooms    2\n Alley      0\n Price      0\n test       0\ndtype: int64\nNumRooms\n   Alley   Price   test\n0   Pave  127500      1\n1     NA  106000      0\n2     NA  178100      0\n3     NA  140000      1\n4   Pave  127500      0\n</code></pre>\n<ul>\n<li><ol start=\"3\">\n<li>将处理后的数据集转换为张量</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将数据集转换为张量格式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">data_file=os.path.join(<span class=\"string\">&#x27;..&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span>,<span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\">data=pd.read_csv(data_file)</span><br><span class=\"line\"><span class=\"comment\">#输出data的shape</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data,data.shape,sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将字符串类型进行one-hot编码</span></span><br><span class=\"line\">data=pd.get_dummies(data,dummy_na=<span class=\"literal\">True</span>) <span class=\"comment\">#dummy_na=True表示将缺失值也当作合法的特征值并为其创建指示特征</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"><span class=\"comment\">#将dataframe格式转换为张量格式</span></span><br><span class=\"line\">data=torch.tensor(data.to_numpy(dtype=<span class=\"built_in\">float</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br></pre></td></tr></table></figure>\n\n<pre><code>   Alley   Price   test\n0   Pave  127500      1\n1     NA  106000      0\n2     NA  178100      0\n3     NA  140000      1\n4   Pave  127500      0\n(5, 3)\n    Price   test   Alley_ NA   Alley_ Pave   Alley_nan\n0  127500      1           0             1           0\n1  106000      0           1             0           0\n2  178100      0           1             0           0\n3  140000      1           1             0           0\n4  127500      0           0             1           0\ntensor([[1.2750e+05, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n        [1.0600e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.7810e+05, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.4000e+05, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.2750e+05, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]],\n       dtype=torch.float64)\n</code></pre>"},{"title":"1.3 线性代数","date":"2024-02-01T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 3. 线性代数\n## 3.1 标量\n\n\n\n```python\nimport torch\n\nx=torch.tensor(3.0)\n```\n\n## 3.2 向量\n\n\n```python\nx=torch.arange(4)\n\n#1 取值\nprint(x[3])\n\n#2 长度\nprint(len(x))\nprint(x.shape)\n```\n\n    tensor(3)\n    4\n    torch.Size([4])\n    \n\n## 3.3 矩阵\n\n\n\n```python\nA=torch.arange(20).reshape(5,4) #矩阵用大写字母\nprint(A)\n\n#1 转置\nprint(A.T)\n```\n\n    tensor([[ 0,  1,  2,  3],\n            [ 4,  5,  6,  7],\n            [ 8,  9, 10, 11],\n            [12, 13, 14, 15],\n            [16, 17, 18, 19]])\n    tensor([[ 0,  4,  8, 12, 16],\n            [ 1,  5,  9, 13, 17],\n            [ 2,  6, 10, 14, 18],\n            [ 3,  7, 11, 15, 19]])\n    \n\n## 3.4 张量\n\n\n```python\nX= torch.arange(24).reshape(2,3,4)\nX\n```\n\n\n\n\n    tensor([[[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]],\n    \n            [[12, 13, 14, 15],\n             [16, 17, 18, 19],\n             [20, 21, 22, 23]]])\n\n\n\n## 3.5 张量算法的基本性质\n\n\n```python\nA=torch.arange(20,dtype=torch.float32).reshape(5,4)\n\n#1 复制\nB=A.clone()\nprint(A==B)\n\n#2 Hadamard积⊙ (对应位置相乘)\nprint(A*B)\n\n#3 张量+标量（所有元素加上标量）\nprint(A+2)\n\n#4 元素个数\nprint(A.numel())\n```\n\n    tensor([[True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True]])\n    tensor([[  0.,   1.,   4.,   9.],\n            [ 16.,  25.,  36.,  49.],\n            [ 64.,  81., 100., 121.],\n            [144., 169., 196., 225.],\n            [256., 289., 324., 361.]])\n    tensor([[ 2.,  3.,  4.,  5.],\n            [ 6.,  7.,  8.,  9.],\n            [10., 11., 12., 13.],\n            [14., 15., 16., 17.],\n            [18., 19., 20., 21.]])\n    20\n    \n\n## 3.6 降维\n\n\n```python\nX= torch.arange(4,dtype=torch.float32).reshape(2,2)\n\n#1 按轴求和\nprint(X.sum(axis=0)) #压缩掉第0维\n\n#2 按轴求平均\nprint(X.mean(axis=0))\n\n#3 非降维求和\nsum_X=X.sum(axis=0,keepdims=True)\nprint(sum_X) #还是二维，只是第0维的长度为1\n\n#4 沿某个轴计算A元素的累积总和\nprint(A.cumsum(axis=0))\n```\n\n    tensor([2., 4.])\n    tensor([1., 2.])\n    tensor([[2., 4.]])\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  6.,  8., 10.],\n            [12., 15., 18., 21.],\n            [24., 28., 32., 36.],\n            [40., 45., 50., 55.]])\n    \n\n## 3.7 点积\n- $$<x,y>= x^Ty= \\Sigma^{d}_{i=1}x_iy_i$$\n\n\n```python\nx=y=torch.arange(4,dtype=torch.float32)\nprint(x,y,torch.dot(x,y),sep='\\n')\n```\n\n    tensor([0., 1., 2., 3.])\n    tensor([0., 1., 2., 3.])\n    tensor(14.)\n    \n\n## 3.8 矩阵-向量积\n\n\n```python\nprint(A)\nprint(x)\ntorch.mv(A,x) #输出是【5，1】但是1被压缩\n```\n\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11.],\n            [12., 13., 14., 15.],\n            [16., 17., 18., 19.]])\n    tensor([0., 1., 2., 3.])\n    \n\n\n\n\n    tensor([ 14.,  38.,  62.,  86., 110.])\n\n\n\n## 3.9 矩阵-矩阵乘法\n\n\n\n```python\nprint(A)\nB=torch.ones(4,3)\ntorch.mm(A,B)\n```\n\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11.],\n            [12., 13., 14., 15.],\n            [16., 17., 18., 19.]])\n    \n\n\n\n\n    tensor([[ 6.,  6.,  6.],\n            [22., 22., 22.],\n            [38., 38., 38.],\n            [54., 54., 54.],\n            [70., 70., 70.]])\n\n\n\n## 3.10 范数\n- 表示一个向量有多大。这里考虑的大小概念不涉及维度，而是分量的大小。\n### 3.10.1 向量范数\n- 将向量x映射到标量的函数$f$。\n- 向量范数必须满足以下性质：\n    - 1）按常数因子α缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n    $$f(\\alpha x)=|\\alpha|f(x)$$\n    - 2）三角不等式：\n    $$f(x+y)\\leq f(x)+f(y)$$\n    - 3）非负性：\n    $$f(x)\\geq 0$$\n    - 4）范数最小为0，当且仅当向量全由0组成：\n    $$\\forall i,[x]_i=0 \\Leftrightarrow f(x)=0 $$\n\n### 3.10.2 L2范数\n- 平方和的平方根：\n$$||x||=||x||_2 = \\sqrt{\\sum\\limits_{i=1}^{n}x_i^2}$$\n\n\n```python\nu=torch.tensor([3.0,-4.0])\ntorch.norm(u) #范数\n```\n\n\n\n\n    tensor(5.)\n\n\n\n### 3.10.3 L1范数\n- 绝对值之和\n$$||x||_1 = \\sum\\limits_{i=1}^{n}|x_i|$$\n- 与L2范数相比，L1范数受异常值的影响较小\n\n\n```python\ntorch.abs(u).sum() #L1范数\n```\n\n\n\n\n    tensor(7.)\n\n\n\n### 3.10.4 Lp范数\n$$||x||_p = (\\sum\\limits_{i=1}^{n}|x_i|^p)^{\\frac{1}{p}}$$\n\n### 3.10.5 Frobenius范数\n- 矩阵L2范数\n$$||X||_F = \\sqrt{\\sum\\limits_{i=1}^{m}\\sum\\limits_{j=1}^{n}x_{ij}^2}$$\n\n\n```python\ntorch.norm(torch.ones((4,9)))\n```\n\n\n\n\n    tensor(6.)\n\n\n\n- 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n## 3.11 练习\n\n\n```python\na=torch.tensor([[1,2,3],[4,5,6]])\nb=a.sum(axis=0)\nc=a.sum(axis=1)\nprint(a.shape,b.shape,c.shape)\n\nprint(a+b) #b->(2)->(1,2)->(2,3)\nprint(a+c) #c->(3)->(1,3)->不匹配\n```\n\n    torch.Size([2, 3]) torch.Size([3]) torch.Size([2])\n    tensor([[ 6,  9, 12],\n            [ 9, 12, 15]])\n    \n\n\n    ---------------------------------------------------------------------------\n\n    RuntimeError                              Traceback (most recent call last)\n\n    Cell In[37], line 7\n          4 print(a.shape,b.shape,c.shape)\n          6 print(a+b) #b->(2)->(1,2)->(2,3)\n    ----> 7 print(a+c) #c->(3)->(1,3)->不匹配\n    \n\n    RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n\n","source":"_posts/deeplearning/code/pytorch/1_prepare/3_linearalgebra.md","raw":"---\ntitle: 1.3 线性代数\ndate: 2024-2-1 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 3. 线性代数\n## 3.1 标量\n\n\n\n```python\nimport torch\n\nx=torch.tensor(3.0)\n```\n\n## 3.2 向量\n\n\n```python\nx=torch.arange(4)\n\n#1 取值\nprint(x[3])\n\n#2 长度\nprint(len(x))\nprint(x.shape)\n```\n\n    tensor(3)\n    4\n    torch.Size([4])\n    \n\n## 3.3 矩阵\n\n\n\n```python\nA=torch.arange(20).reshape(5,4) #矩阵用大写字母\nprint(A)\n\n#1 转置\nprint(A.T)\n```\n\n    tensor([[ 0,  1,  2,  3],\n            [ 4,  5,  6,  7],\n            [ 8,  9, 10, 11],\n            [12, 13, 14, 15],\n            [16, 17, 18, 19]])\n    tensor([[ 0,  4,  8, 12, 16],\n            [ 1,  5,  9, 13, 17],\n            [ 2,  6, 10, 14, 18],\n            [ 3,  7, 11, 15, 19]])\n    \n\n## 3.4 张量\n\n\n```python\nX= torch.arange(24).reshape(2,3,4)\nX\n```\n\n\n\n\n    tensor([[[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]],\n    \n            [[12, 13, 14, 15],\n             [16, 17, 18, 19],\n             [20, 21, 22, 23]]])\n\n\n\n## 3.5 张量算法的基本性质\n\n\n```python\nA=torch.arange(20,dtype=torch.float32).reshape(5,4)\n\n#1 复制\nB=A.clone()\nprint(A==B)\n\n#2 Hadamard积⊙ (对应位置相乘)\nprint(A*B)\n\n#3 张量+标量（所有元素加上标量）\nprint(A+2)\n\n#4 元素个数\nprint(A.numel())\n```\n\n    tensor([[True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True],\n            [True, True, True, True]])\n    tensor([[  0.,   1.,   4.,   9.],\n            [ 16.,  25.,  36.,  49.],\n            [ 64.,  81., 100., 121.],\n            [144., 169., 196., 225.],\n            [256., 289., 324., 361.]])\n    tensor([[ 2.,  3.,  4.,  5.],\n            [ 6.,  7.,  8.,  9.],\n            [10., 11., 12., 13.],\n            [14., 15., 16., 17.],\n            [18., 19., 20., 21.]])\n    20\n    \n\n## 3.6 降维\n\n\n```python\nX= torch.arange(4,dtype=torch.float32).reshape(2,2)\n\n#1 按轴求和\nprint(X.sum(axis=0)) #压缩掉第0维\n\n#2 按轴求平均\nprint(X.mean(axis=0))\n\n#3 非降维求和\nsum_X=X.sum(axis=0,keepdims=True)\nprint(sum_X) #还是二维，只是第0维的长度为1\n\n#4 沿某个轴计算A元素的累积总和\nprint(A.cumsum(axis=0))\n```\n\n    tensor([2., 4.])\n    tensor([1., 2.])\n    tensor([[2., 4.]])\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  6.,  8., 10.],\n            [12., 15., 18., 21.],\n            [24., 28., 32., 36.],\n            [40., 45., 50., 55.]])\n    \n\n## 3.7 点积\n- $$<x,y>= x^Ty= \\Sigma^{d}_{i=1}x_iy_i$$\n\n\n```python\nx=y=torch.arange(4,dtype=torch.float32)\nprint(x,y,torch.dot(x,y),sep='\\n')\n```\n\n    tensor([0., 1., 2., 3.])\n    tensor([0., 1., 2., 3.])\n    tensor(14.)\n    \n\n## 3.8 矩阵-向量积\n\n\n```python\nprint(A)\nprint(x)\ntorch.mv(A,x) #输出是【5，1】但是1被压缩\n```\n\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11.],\n            [12., 13., 14., 15.],\n            [16., 17., 18., 19.]])\n    tensor([0., 1., 2., 3.])\n    \n\n\n\n\n    tensor([ 14.,  38.,  62.,  86., 110.])\n\n\n\n## 3.9 矩阵-矩阵乘法\n\n\n\n```python\nprint(A)\nB=torch.ones(4,3)\ntorch.mm(A,B)\n```\n\n    tensor([[ 0.,  1.,  2.,  3.],\n            [ 4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11.],\n            [12., 13., 14., 15.],\n            [16., 17., 18., 19.]])\n    \n\n\n\n\n    tensor([[ 6.,  6.,  6.],\n            [22., 22., 22.],\n            [38., 38., 38.],\n            [54., 54., 54.],\n            [70., 70., 70.]])\n\n\n\n## 3.10 范数\n- 表示一个向量有多大。这里考虑的大小概念不涉及维度，而是分量的大小。\n### 3.10.1 向量范数\n- 将向量x映射到标量的函数$f$。\n- 向量范数必须满足以下性质：\n    - 1）按常数因子α缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n    $$f(\\alpha x)=|\\alpha|f(x)$$\n    - 2）三角不等式：\n    $$f(x+y)\\leq f(x)+f(y)$$\n    - 3）非负性：\n    $$f(x)\\geq 0$$\n    - 4）范数最小为0，当且仅当向量全由0组成：\n    $$\\forall i,[x]_i=0 \\Leftrightarrow f(x)=0 $$\n\n### 3.10.2 L2范数\n- 平方和的平方根：\n$$||x||=||x||_2 = \\sqrt{\\sum\\limits_{i=1}^{n}x_i^2}$$\n\n\n```python\nu=torch.tensor([3.0,-4.0])\ntorch.norm(u) #范数\n```\n\n\n\n\n    tensor(5.)\n\n\n\n### 3.10.3 L1范数\n- 绝对值之和\n$$||x||_1 = \\sum\\limits_{i=1}^{n}|x_i|$$\n- 与L2范数相比，L1范数受异常值的影响较小\n\n\n```python\ntorch.abs(u).sum() #L1范数\n```\n\n\n\n\n    tensor(7.)\n\n\n\n### 3.10.4 Lp范数\n$$||x||_p = (\\sum\\limits_{i=1}^{n}|x_i|^p)^{\\frac{1}{p}}$$\n\n### 3.10.5 Frobenius范数\n- 矩阵L2范数\n$$||X||_F = \\sqrt{\\sum\\limits_{i=1}^{m}\\sum\\limits_{j=1}^{n}x_{ij}^2}$$\n\n\n```python\ntorch.norm(torch.ones((4,9)))\n```\n\n\n\n\n    tensor(6.)\n\n\n\n- 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n## 3.11 练习\n\n\n```python\na=torch.tensor([[1,2,3],[4,5,6]])\nb=a.sum(axis=0)\nc=a.sum(axis=1)\nprint(a.shape,b.shape,c.shape)\n\nprint(a+b) #b->(2)->(1,2)->(2,3)\nprint(a+c) #c->(3)->(1,3)->不匹配\n```\n\n    torch.Size([2, 3]) torch.Size([3]) torch.Size([2])\n    tensor([[ 6,  9, 12],\n            [ 9, 12, 15]])\n    \n\n\n    ---------------------------------------------------------------------------\n\n    RuntimeError                              Traceback (most recent call last)\n\n    Cell In[37], line 7\n          4 print(a.shape,b.shape,c.shape)\n          6 print(a+b) #b->(2)->(1,2)->(2,3)\n    ----> 7 print(a+c) #c->(3)->(1,3)->不匹配\n    \n\n    RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n\n","slug":"deeplearning/code/pytorch/1_prepare/3_linearalgebra","published":1,"updated":"2024-02-03T03:48:10.090Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198599003n7svwe3sfglra","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"3-线性代数\"><a href=\"#3-线性代数\" class=\"headerlink\" title=\"3. 线性代数\"></a>3. 线性代数</h1><h2 id=\"3-1-标量\"><a href=\"#3-1-标量\" class=\"headerlink\" title=\"3.1 标量\"></a>3.1 标量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x=torch.tensor(<span class=\"number\">3.0</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-2-向量\"><a href=\"#3-2-向量\" class=\"headerlink\" title=\"3.2 向量\"></a>3.2 向量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 取值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x[<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 长度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(x))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.shape)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor(3)\n4\ntorch.Size([4])\n</code></pre>\n<h2 id=\"3-3-矩阵\"><a href=\"#3-3-矩阵\" class=\"headerlink\" title=\"3.3 矩阵\"></a>3.3 矩阵</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=torch.arange(<span class=\"number\">20</span>).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>) <span class=\"comment\">#矩阵用大写字母</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 转置</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.T)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15],\n        [16, 17, 18, 19]])\ntensor([[ 0,  4,  8, 12, 16],\n        [ 1,  5,  9, 13, 17],\n        [ 2,  6, 10, 14, 18],\n        [ 3,  7, 11, 15, 19]])\n</code></pre>\n<h2 id=\"3-4-张量\"><a href=\"#3-4-张量\" class=\"headerlink\" title=\"3.4 张量\"></a>3.4 张量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X= torch.arange(<span class=\"number\">24</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">X</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])\n</code></pre>\n<h2 id=\"3-5-张量算法的基本性质\"><a href=\"#3-5-张量算法的基本性质\" class=\"headerlink\" title=\"3.5 张量算法的基本性质\"></a>3.5 张量算法的基本性质</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=torch.arange(<span class=\"number\">20</span>,dtype=torch.float32).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 复制</span></span><br><span class=\"line\">B=A.clone()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A==B)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 Hadamard积⊙ (对应位置相乘)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A*B)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 张量+标量（所有元素加上标量）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A+<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 元素个数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.numel())</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.],\n        [144., 169., 196., 225.],\n        [256., 289., 324., 361.]])\ntensor([[ 2.,  3.,  4.,  5.],\n        [ 6.,  7.,  8.,  9.],\n        [10., 11., 12., 13.],\n        [14., 15., 16., 17.],\n        [18., 19., 20., 21.]])\n20\n</code></pre>\n<h2 id=\"3-6-降维\"><a href=\"#3-6-降维\" class=\"headerlink\" title=\"3.6 降维\"></a>3.6 降维</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X= torch.arange(<span class=\"number\">4</span>,dtype=torch.float32).reshape(<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 按轴求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(X.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)) <span class=\"comment\">#压缩掉第0维</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 按轴求平均</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(X.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 非降维求和</span></span><br><span class=\"line\">sum_X=X.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>,keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(sum_X) <span class=\"comment\">#还是二维，只是第0维的长度为1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 沿某个轴计算A元素的累积总和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.cumsum(axis=<span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([2., 4.])\ntensor([1., 2.])\ntensor([[2., 4.]])\ntensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  6.,  8., 10.],\n        [12., 15., 18., 21.],\n        [24., 28., 32., 36.],\n        [40., 45., 50., 55.]])\n</code></pre>\n<h2 id=\"3-7-点积\"><a href=\"#3-7-点积\" class=\"headerlink\" title=\"3.7 点积\"></a>3.7 点积</h2><ul>\n<li>$$&lt;x,y&gt;&#x3D; x^Ty&#x3D; \\Sigma^{d}_{i&#x3D;1}x_iy_i$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=y=torch.arange(<span class=\"number\">4</span>,dtype=torch.float32)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x,y,torch.dot(x,y),sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 2., 3.])\ntensor([0., 1., 2., 3.])\ntensor(14.)\n</code></pre>\n<h2 id=\"3-8-矩阵-向量积\"><a href=\"#3-8-矩阵-向量积\" class=\"headerlink\" title=\"3.8 矩阵-向量积\"></a>3.8 矩阵-向量积</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.mv(A,x) <span class=\"comment\">#输出是【5，1】但是1被压缩</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.],\n        [16., 17., 18., 19.]])\ntensor([0., 1., 2., 3.])\n\n\n\n\n\ntensor([ 14.,  38.,  62.,  86., 110.])\n</code></pre>\n<h2 id=\"3-9-矩阵-矩阵乘法\"><a href=\"#3-9-矩阵-矩阵乘法\" class=\"headerlink\" title=\"3.9 矩阵-矩阵乘法\"></a>3.9 矩阵-矩阵乘法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\">B=torch.ones(<span class=\"number\">4</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">torch.mm(A,B)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.],\n        [16., 17., 18., 19.]])\n\n\n\n\n\ntensor([[ 6.,  6.,  6.],\n        [22., 22., 22.],\n        [38., 38., 38.],\n        [54., 54., 54.],\n        [70., 70., 70.]])\n</code></pre>\n<h2 id=\"3-10-范数\"><a href=\"#3-10-范数\" class=\"headerlink\" title=\"3.10 范数\"></a>3.10 范数</h2><ul>\n<li>表示一个向量有多大。这里考虑的大小概念不涉及维度，而是分量的大小。</li>\n</ul>\n<h3 id=\"3-10-1-向量范数\"><a href=\"#3-10-1-向量范数\" class=\"headerlink\" title=\"3.10.1 向量范数\"></a>3.10.1 向量范数</h3><ul>\n<li>将向量x映射到标量的函数$f$。</li>\n<li>向量范数必须满足以下性质：<ul>\n<li>1）按常数因子α缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：<br>  $$f(\\alpha x)&#x3D;|\\alpha|f(x)$$</li>\n<li>2）三角不等式：<br>  $$f(x+y)\\leq f(x)+f(y)$$</li>\n<li>3）非负性：<br>  $$f(x)\\geq 0$$</li>\n<li>4）范数最小为0，当且仅当向量全由0组成：<br>  $$\\forall i,[x]_i&#x3D;0 \\Leftrightarrow f(x)&#x3D;0 $$</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-10-2-L2范数\"><a href=\"#3-10-2-L2范数\" class=\"headerlink\" title=\"3.10.2 L2范数\"></a>3.10.2 L2范数</h3><ul>\n<li>平方和的平方根：<br>$$||x||&#x3D;||x||<em>2 &#x3D; \\sqrt{\\sum\\limits</em>{i&#x3D;1}^{n}x_i^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u=torch.tensor([<span class=\"number\">3.0</span>,-<span class=\"number\">4.0</span>])</span><br><span class=\"line\">torch.norm(u) <span class=\"comment\">#范数</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(5.)\n</code></pre>\n<h3 id=\"3-10-3-L1范数\"><a href=\"#3-10-3-L1范数\" class=\"headerlink\" title=\"3.10.3 L1范数\"></a>3.10.3 L1范数</h3><ul>\n<li>绝对值之和<br>$$||x||<em>1 &#x3D; \\sum\\limits</em>{i&#x3D;1}^{n}|x_i|$$</li>\n<li>与L2范数相比，L1范数受异常值的影响较小</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">abs</span>(u).<span class=\"built_in\">sum</span>() <span class=\"comment\">#L1范数</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(7.)\n</code></pre>\n<h3 id=\"3-10-4-Lp范数\"><a href=\"#3-10-4-Lp范数\" class=\"headerlink\" title=\"3.10.4 Lp范数\"></a>3.10.4 Lp范数</h3><p>$$||x||<em>p &#x3D; (\\sum\\limits</em>{i&#x3D;1}^{n}|x_i|^p)^{\\frac{1}{p}}$$</p>\n<h3 id=\"3-10-5-Frobenius范数\"><a href=\"#3-10-5-Frobenius范数\" class=\"headerlink\" title=\"3.10.5 Frobenius范数\"></a>3.10.5 Frobenius范数</h3><ul>\n<li>矩阵L2范数<br>$$||X||<em>F &#x3D; \\sqrt{\\sum\\limits</em>{i&#x3D;1}^{m}\\sum\\limits_{j&#x3D;1}^{n}x_{ij}^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.norm(torch.ones((<span class=\"number\">4</span>,<span class=\"number\">9</span>)))</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(6.)\n</code></pre>\n<ul>\n<li>目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。</li>\n</ul>\n<h2 id=\"3-11-练习\"><a href=\"#3-11-练习\" class=\"headerlink\" title=\"3.11 练习\"></a>3.11 练习</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.tensor([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])</span><br><span class=\"line\">b=a.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">c=a.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.shape,b.shape,c.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a+b) <span class=\"comment\">#b-&gt;(2)-&gt;(1,2)-&gt;(2,3)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a+c) <span class=\"comment\">#c-&gt;(3)-&gt;(1,3)-&gt;不匹配</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>torch.Size([2, 3]) torch.Size([3]) torch.Size([2])\ntensor([[ 6,  9, 12],\n        [ 9, 12, 15]])\n\n\n\n---------------------------------------------------------------------------\n\nRuntimeError                              Traceback (most recent call last)\n\nCell In[37], line 7\n      4 print(a.shape,b.shape,c.shape)\n      6 print(a+b) #b-&gt;(2)-&gt;(1,2)-&gt;(2,3)\n----&gt; 7 print(a+c) #c-&gt;(3)-&gt;(1,3)-&gt;不匹配\n\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-线性代数\"><a href=\"#3-线性代数\" class=\"headerlink\" title=\"3. 线性代数\"></a>3. 线性代数</h1><h2 id=\"3-1-标量\"><a href=\"#3-1-标量\" class=\"headerlink\" title=\"3.1 标量\"></a>3.1 标量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x=torch.tensor(<span class=\"number\">3.0</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-2-向量\"><a href=\"#3-2-向量\" class=\"headerlink\" title=\"3.2 向量\"></a>3.2 向量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 取值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x[<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 长度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(x))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.shape)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor(3)\n4\ntorch.Size([4])\n</code></pre>\n<h2 id=\"3-3-矩阵\"><a href=\"#3-3-矩阵\" class=\"headerlink\" title=\"3.3 矩阵\"></a>3.3 矩阵</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=torch.arange(<span class=\"number\">20</span>).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>) <span class=\"comment\">#矩阵用大写字母</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 转置</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.T)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15],\n        [16, 17, 18, 19]])\ntensor([[ 0,  4,  8, 12, 16],\n        [ 1,  5,  9, 13, 17],\n        [ 2,  6, 10, 14, 18],\n        [ 3,  7, 11, 15, 19]])\n</code></pre>\n<h2 id=\"3-4-张量\"><a href=\"#3-4-张量\" class=\"headerlink\" title=\"3.4 张量\"></a>3.4 张量</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X= torch.arange(<span class=\"number\">24</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">X</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])\n</code></pre>\n<h2 id=\"3-5-张量算法的基本性质\"><a href=\"#3-5-张量算法的基本性质\" class=\"headerlink\" title=\"3.5 张量算法的基本性质\"></a>3.5 张量算法的基本性质</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=torch.arange(<span class=\"number\">20</span>,dtype=torch.float32).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 复制</span></span><br><span class=\"line\">B=A.clone()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A==B)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 Hadamard积⊙ (对应位置相乘)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A*B)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 张量+标量（所有元素加上标量）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A+<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 元素个数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.numel())</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.],\n        [144., 169., 196., 225.],\n        [256., 289., 324., 361.]])\ntensor([[ 2.,  3.,  4.,  5.],\n        [ 6.,  7.,  8.,  9.],\n        [10., 11., 12., 13.],\n        [14., 15., 16., 17.],\n        [18., 19., 20., 21.]])\n20\n</code></pre>\n<h2 id=\"3-6-降维\"><a href=\"#3-6-降维\" class=\"headerlink\" title=\"3.6 降维\"></a>3.6 降维</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X= torch.arange(<span class=\"number\">4</span>,dtype=torch.float32).reshape(<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 按轴求和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(X.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)) <span class=\"comment\">#压缩掉第0维</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 按轴求平均</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(X.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 非降维求和</span></span><br><span class=\"line\">sum_X=X.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>,keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(sum_X) <span class=\"comment\">#还是二维，只是第0维的长度为1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 沿某个轴计算A元素的累积总和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.cumsum(axis=<span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([2., 4.])\ntensor([1., 2.])\ntensor([[2., 4.]])\ntensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  6.,  8., 10.],\n        [12., 15., 18., 21.],\n        [24., 28., 32., 36.],\n        [40., 45., 50., 55.]])\n</code></pre>\n<h2 id=\"3-7-点积\"><a href=\"#3-7-点积\" class=\"headerlink\" title=\"3.7 点积\"></a>3.7 点积</h2><ul>\n<li>$$&lt;x,y&gt;&#x3D; x^Ty&#x3D; \\Sigma^{d}_{i&#x3D;1}x_iy_i$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=y=torch.arange(<span class=\"number\">4</span>,dtype=torch.float32)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x,y,torch.dot(x,y),sep=<span class=\"string\">&#x27;\\n&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 2., 3.])\ntensor([0., 1., 2., 3.])\ntensor(14.)\n</code></pre>\n<h2 id=\"3-8-矩阵-向量积\"><a href=\"#3-8-矩阵-向量积\" class=\"headerlink\" title=\"3.8 矩阵-向量积\"></a>3.8 矩阵-向量积</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.mv(A,x) <span class=\"comment\">#输出是【5，1】但是1被压缩</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.],\n        [16., 17., 18., 19.]])\ntensor([0., 1., 2., 3.])\n\n\n\n\n\ntensor([ 14.,  38.,  62.,  86., 110.])\n</code></pre>\n<h2 id=\"3-9-矩阵-矩阵乘法\"><a href=\"#3-9-矩阵-矩阵乘法\" class=\"headerlink\" title=\"3.9 矩阵-矩阵乘法\"></a>3.9 矩阵-矩阵乘法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\">B=torch.ones(<span class=\"number\">4</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">torch.mm(A,B)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.],\n        [16., 17., 18., 19.]])\n\n\n\n\n\ntensor([[ 6.,  6.,  6.],\n        [22., 22., 22.],\n        [38., 38., 38.],\n        [54., 54., 54.],\n        [70., 70., 70.]])\n</code></pre>\n<h2 id=\"3-10-范数\"><a href=\"#3-10-范数\" class=\"headerlink\" title=\"3.10 范数\"></a>3.10 范数</h2><ul>\n<li>表示一个向量有多大。这里考虑的大小概念不涉及维度，而是分量的大小。</li>\n</ul>\n<h3 id=\"3-10-1-向量范数\"><a href=\"#3-10-1-向量范数\" class=\"headerlink\" title=\"3.10.1 向量范数\"></a>3.10.1 向量范数</h3><ul>\n<li>将向量x映射到标量的函数$f$。</li>\n<li>向量范数必须满足以下性质：<ul>\n<li>1）按常数因子α缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：<br>  $$f(\\alpha x)&#x3D;|\\alpha|f(x)$$</li>\n<li>2）三角不等式：<br>  $$f(x+y)\\leq f(x)+f(y)$$</li>\n<li>3）非负性：<br>  $$f(x)\\geq 0$$</li>\n<li>4）范数最小为0，当且仅当向量全由0组成：<br>  $$\\forall i,[x]_i&#x3D;0 \\Leftrightarrow f(x)&#x3D;0 $$</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-10-2-L2范数\"><a href=\"#3-10-2-L2范数\" class=\"headerlink\" title=\"3.10.2 L2范数\"></a>3.10.2 L2范数</h3><ul>\n<li>平方和的平方根：<br>$$||x||&#x3D;||x||<em>2 &#x3D; \\sqrt{\\sum\\limits</em>{i&#x3D;1}^{n}x_i^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u=torch.tensor([<span class=\"number\">3.0</span>,-<span class=\"number\">4.0</span>])</span><br><span class=\"line\">torch.norm(u) <span class=\"comment\">#范数</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(5.)\n</code></pre>\n<h3 id=\"3-10-3-L1范数\"><a href=\"#3-10-3-L1范数\" class=\"headerlink\" title=\"3.10.3 L1范数\"></a>3.10.3 L1范数</h3><ul>\n<li>绝对值之和<br>$$||x||<em>1 &#x3D; \\sum\\limits</em>{i&#x3D;1}^{n}|x_i|$$</li>\n<li>与L2范数相比，L1范数受异常值的影响较小</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">abs</span>(u).<span class=\"built_in\">sum</span>() <span class=\"comment\">#L1范数</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(7.)\n</code></pre>\n<h3 id=\"3-10-4-Lp范数\"><a href=\"#3-10-4-Lp范数\" class=\"headerlink\" title=\"3.10.4 Lp范数\"></a>3.10.4 Lp范数</h3><p>$$||x||<em>p &#x3D; (\\sum\\limits</em>{i&#x3D;1}^{n}|x_i|^p)^{\\frac{1}{p}}$$</p>\n<h3 id=\"3-10-5-Frobenius范数\"><a href=\"#3-10-5-Frobenius范数\" class=\"headerlink\" title=\"3.10.5 Frobenius范数\"></a>3.10.5 Frobenius范数</h3><ul>\n<li>矩阵L2范数<br>$$||X||<em>F &#x3D; \\sqrt{\\sum\\limits</em>{i&#x3D;1}^{m}\\sum\\limits_{j&#x3D;1}^{n}x_{ij}^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.norm(torch.ones((<span class=\"number\">4</span>,<span class=\"number\">9</span>)))</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(6.)\n</code></pre>\n<ul>\n<li>目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。</li>\n</ul>\n<h2 id=\"3-11-练习\"><a href=\"#3-11-练习\" class=\"headerlink\" title=\"3.11 练习\"></a>3.11 练习</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.tensor([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])</span><br><span class=\"line\">b=a.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">c=a.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.shape,b.shape,c.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a+b) <span class=\"comment\">#b-&gt;(2)-&gt;(1,2)-&gt;(2,3)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a+c) <span class=\"comment\">#c-&gt;(3)-&gt;(1,3)-&gt;不匹配</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>torch.Size([2, 3]) torch.Size([3]) torch.Size([2])\ntensor([[ 6,  9, 12],\n        [ 9, 12, 15]])\n\n\n\n---------------------------------------------------------------------------\n\nRuntimeError                              Traceback (most recent call last)\n\nCell In[37], line 7\n      4 print(a.shape,b.shape,c.shape)\n      6 print(a+b) #b-&gt;(2)-&gt;(1,2)-&gt;(2,3)\n----&gt; 7 print(a+c) #c-&gt;(3)-&gt;(1,3)-&gt;不匹配\n\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n</code></pre>"},{"title":"1.4 微积分","date":"2024-02-01T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 4. 微积分\n- 拟合模型的任务分解为两个关键问题：\n    - 优化（optimization）：用模型拟合观测数据的过程；\n    - 泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。\n## 4.1 导数和微分\n- 通常选择对于模型参数可微的损失函数。简而言之，对于每个参数，如果我们把这个参数增加或减少一个无穷小的量，可以知道损失会以多快的速度增加或减少。\n- 导数：$f'(x)=\\lim\\limits_{h\\rightarrow 0}\\frac{f(x+h)-f(x)}{h}=y^\\prime=\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)=Df(x)=D_x f(x)$\n    - 1)常数相乘法则：$(Cf)^\\prime=C(f^\\prime)$\n    - 2)加法法则：$(f+g)^\\prime=f^\\prime+g^\\prime$   \n    - 3)乘法法则：$(fg)^\\prime=f^\\prime g+fg^\\prime$\n    - 4)除法法则：$(\\frac{f}{g})^\\prime=\\frac{f^\\prime g-fg^\\prime}{g^2}$ \n- 微分：若$f^\\prime(a)$存在，则称$f$在$a$处可微\n\n\n\n```python\n#将图形嵌入到Notebook中 %matplotlib inline\n\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #这两行可以解决崩溃的错误\nfrom IPython.display import set_matplotlib_formats\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from matplotlib_inline import backend_inline\nfrom d2l import torch as d2l\n\n#1 定义一个函数f\ndef f(x):\n    return 3 * x ** 2 - 4 * x\n\n#2 定义f'\ndef numerical_lim(f, x, h):\n    return (f(x + h) - f(x)) / h\n    \n#一些函数\ndef use_svg_display(): #@save\n    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n    set_matplotlib_formats('svg')\ndef set_figsize(figsize=(3.5, 2.5)): #@save\n    \"\"\"设置matplotlib的图表大小\"\"\"\n    use_svg_display()\n    d2l.plt.rcParams['figure.figsize'] = figsize\n#@save\ndef set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    \"\"\"设置matplotlib的轴\"\"\"\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale)\n    axes.set_yscale(yscale)\n    axes.set_xlim(xlim)\n    axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n#@save\ndef plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,ylim=None, xscale='linear', yscale='linear',fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"绘制数据点\"\"\"\n    if legend is None:\n        legend = []\n    set_figsize(figsize)\n    axes = axes if axes else d2l.plt.gca()\n    # 如果X有一个轴，输出True\n\n    def has_one_axis(X):\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list) and not hasattr(X[0], \"__len__\"))\n    if has_one_axis(X):\n        X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        if len(x):\n            axes.plot(x, y, fmt)\n        else:\n            axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n\n#3 绘制切线\nx = np.arange(0, 3, 0.1)\nplot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])\nplt.show()\n```\n\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2373785819.py:22: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n      set_matplotlib_formats('svg')\n    \n\n\n    \n![svg](4_calculus_files/4_calculus_1_1.svg)\n![](img/deeplearning/code/pytorch/1_prepare/4_calculus_1_1.svg)\n    \n\n\n## 4.2 偏导数\n- 偏导数：$f(x_1,x_2,...,x_n)$关于$x_i$的偏导数：$\\frac{\\partial f}{\\partial x_i}=\\lim\\limits_{h\\rightarrow 0}\\frac{f(x_1,...,x_i+h,...,x_n)-f(x_1,...,x_i,...,x_n)}{h}$\n\n## 4.3 梯度\n- 梯度：$\\nabla_x f(x)=[\\frac{\\partial f(x)}{\\partial x_1},\\frac{\\partial f(x)}{\\partial x_2},...,\\frac{\\partial f(x)}{\\partial x_n}]^T$\n- 一些性质：\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(Ax)=A^T$\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(x^TA)=A$\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(x^TAx)=(A+A^T)x$\n    - $\\nabla_x||x||_F^2=\\nabla_x(x^Tx)=2x$\n\n## 4.4 链式法则\n- $y=f(u_1,u_2,...,u_m),u_i=g_i(x_1,x_2,...,x_n),则\\frac{\\partial y}{\\partial x_i}=\\sum\\limits_{j=1}^m\\frac{\\partial y}{\\partial u_j}\\frac{\\partial u_j}{\\partial x_i}$\n\n## 练习\n- 绘制函数$y=X^3-\\frac{1}{X}$在x=1处的图像\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef f(x):\n    return x**3 - 1/x\nx=np.arange(0,3,0.1)\nplt.plot(x,f(x))\nplt.plot(x,3*x**2+1/x**2-4)\nplt.show()\n```\n\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:5: RuntimeWarning: divide by zero encountered in divide\n      return x**3 - 1/x\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:8: RuntimeWarning: divide by zero encountered in divide\n      plt.plot(x,3*x**2+1/x**2-4)\n    \n\n\n    \n![svg](4_calculus_files/4_calculus_3_1.svg)\n![](img/deeplearning/code/pytorch/1_prepare/4_calculus_3_1.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/1_prepare/4_calculus.md","raw":"---\ntitle: 1.4 微积分\ndate: 2024-2-1 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 4. 微积分\n- 拟合模型的任务分解为两个关键问题：\n    - 优化（optimization）：用模型拟合观测数据的过程；\n    - 泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。\n## 4.1 导数和微分\n- 通常选择对于模型参数可微的损失函数。简而言之，对于每个参数，如果我们把这个参数增加或减少一个无穷小的量，可以知道损失会以多快的速度增加或减少。\n- 导数：$f'(x)=\\lim\\limits_{h\\rightarrow 0}\\frac{f(x+h)-f(x)}{h}=y^\\prime=\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)=Df(x)=D_x f(x)$\n    - 1)常数相乘法则：$(Cf)^\\prime=C(f^\\prime)$\n    - 2)加法法则：$(f+g)^\\prime=f^\\prime+g^\\prime$   \n    - 3)乘法法则：$(fg)^\\prime=f^\\prime g+fg^\\prime$\n    - 4)除法法则：$(\\frac{f}{g})^\\prime=\\frac{f^\\prime g-fg^\\prime}{g^2}$ \n- 微分：若$f^\\prime(a)$存在，则称$f$在$a$处可微\n\n\n\n```python\n#将图形嵌入到Notebook中 %matplotlib inline\n\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #这两行可以解决崩溃的错误\nfrom IPython.display import set_matplotlib_formats\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from matplotlib_inline import backend_inline\nfrom d2l import torch as d2l\n\n#1 定义一个函数f\ndef f(x):\n    return 3 * x ** 2 - 4 * x\n\n#2 定义f'\ndef numerical_lim(f, x, h):\n    return (f(x + h) - f(x)) / h\n    \n#一些函数\ndef use_svg_display(): #@save\n    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n    set_matplotlib_formats('svg')\ndef set_figsize(figsize=(3.5, 2.5)): #@save\n    \"\"\"设置matplotlib的图表大小\"\"\"\n    use_svg_display()\n    d2l.plt.rcParams['figure.figsize'] = figsize\n#@save\ndef set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    \"\"\"设置matplotlib的轴\"\"\"\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale)\n    axes.set_yscale(yscale)\n    axes.set_xlim(xlim)\n    axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n#@save\ndef plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,ylim=None, xscale='linear', yscale='linear',fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"绘制数据点\"\"\"\n    if legend is None:\n        legend = []\n    set_figsize(figsize)\n    axes = axes if axes else d2l.plt.gca()\n    # 如果X有一个轴，输出True\n\n    def has_one_axis(X):\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list) and not hasattr(X[0], \"__len__\"))\n    if has_one_axis(X):\n        X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        if len(x):\n            axes.plot(x, y, fmt)\n        else:\n            axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n\n#3 绘制切线\nx = np.arange(0, 3, 0.1)\nplot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])\nplt.show()\n```\n\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2373785819.py:22: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n      set_matplotlib_formats('svg')\n    \n\n\n    \n![svg](4_calculus_files/4_calculus_1_1.svg)\n![](img/deeplearning/code/pytorch/1_prepare/4_calculus_1_1.svg)\n    \n\n\n## 4.2 偏导数\n- 偏导数：$f(x_1,x_2,...,x_n)$关于$x_i$的偏导数：$\\frac{\\partial f}{\\partial x_i}=\\lim\\limits_{h\\rightarrow 0}\\frac{f(x_1,...,x_i+h,...,x_n)-f(x_1,...,x_i,...,x_n)}{h}$\n\n## 4.3 梯度\n- 梯度：$\\nabla_x f(x)=[\\frac{\\partial f(x)}{\\partial x_1},\\frac{\\partial f(x)}{\\partial x_2},...,\\frac{\\partial f(x)}{\\partial x_n}]^T$\n- 一些性质：\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(Ax)=A^T$\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(x^TA)=A$\n    - $\\forall A\\in R^{m\\times n},\\nabla_x(x^TAx)=(A+A^T)x$\n    - $\\nabla_x||x||_F^2=\\nabla_x(x^Tx)=2x$\n\n## 4.4 链式法则\n- $y=f(u_1,u_2,...,u_m),u_i=g_i(x_1,x_2,...,x_n),则\\frac{\\partial y}{\\partial x_i}=\\sum\\limits_{j=1}^m\\frac{\\partial y}{\\partial u_j}\\frac{\\partial u_j}{\\partial x_i}$\n\n## 练习\n- 绘制函数$y=X^3-\\frac{1}{X}$在x=1处的图像\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef f(x):\n    return x**3 - 1/x\nx=np.arange(0,3,0.1)\nplt.plot(x,f(x))\nplt.plot(x,3*x**2+1/x**2-4)\nplt.show()\n```\n\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:5: RuntimeWarning: divide by zero encountered in divide\n      return x**3 - 1/x\n    C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:8: RuntimeWarning: divide by zero encountered in divide\n      plt.plot(x,3*x**2+1/x**2-4)\n    \n\n\n    \n![svg](4_calculus_files/4_calculus_3_1.svg)\n![](img/deeplearning/code/pytorch/1_prepare/4_calculus_3_1.svg)\n    \n\n","slug":"deeplearning/code/pytorch/1_prepare/4_calculus","published":1,"updated":"2024-02-05T14:23:23.801Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt198599003q7svwchg57j21","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"4-微积分\"><a href=\"#4-微积分\" class=\"headerlink\" title=\"4. 微积分\"></a>4. 微积分</h1><ul>\n<li>拟合模型的任务分解为两个关键问题：<ul>\n<li>优化（optimization）：用模型拟合观测数据的过程；</li>\n<li>泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-1-导数和微分\"><a href=\"#4-1-导数和微分\" class=\"headerlink\" title=\"4.1 导数和微分\"></a>4.1 导数和微分</h2><ul>\n<li>通常选择对于模型参数可微的损失函数。简而言之，对于每个参数，如果我们把这个参数增加或减少一个无穷小的量，可以知道损失会以多快的速度增加或减少。</li>\n<li>导数：$f’(x)&#x3D;\\lim\\limits_{h\\rightarrow 0}\\frac{f(x+h)-f(x)}{h}&#x3D;y^\\prime&#x3D;\\frac{dy}{dx}&#x3D;\\frac{df}{dx}&#x3D;\\frac{d}{dx}f(x)&#x3D;Df(x)&#x3D;D_x f(x)$<ul>\n<li>1)常数相乘法则：$(Cf)^\\prime&#x3D;C(f^\\prime)$</li>\n<li>2)加法法则：$(f+g)^\\prime&#x3D;f^\\prime+g^\\prime$   </li>\n<li>3)乘法法则：$(fg)^\\prime&#x3D;f^\\prime g+fg^\\prime$</li>\n<li>4)除法法则：$(\\frac{f}{g})^\\prime&#x3D;\\frac{f^\\prime g-fg^\\prime}{g^2}$</li>\n</ul>\n</li>\n<li>微分：若$f^\\prime(a)$存在，则称$f$在$a$处可微</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将图形嵌入到Notebook中 %matplotlib inline</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class=\"string\">&quot;TRUE&quot;</span> <span class=\"comment\">#这两行可以解决崩溃的错误</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> IPython.display <span class=\"keyword\">import</span> set_matplotlib_formats</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\">#from matplotlib_inline import backend_inline</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 定义一个函数f</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">3</span> * x ** <span class=\"number\">2</span> - <span class=\"number\">4</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 定义f&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">numerical_lim</span>(<span class=\"params\">f, x, h</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (f(x + h) - f(x)) / h</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">#一些函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">use_svg_display</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;使用svg格式在Jupyter中显示绘图&quot;&quot;&quot;</span></span><br><span class=\"line\">    set_matplotlib_formats(<span class=\"string\">&#x27;svg&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">set_figsize</span>(<span class=\"params\">figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>)</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;设置matplotlib的图表大小&quot;&quot;&quot;</span></span><br><span class=\"line\">    use_svg_display()</span><br><span class=\"line\">    d2l.plt.rcParams[<span class=\"string\">&#x27;figure.figsize&#x27;</span>] = figsize</span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">set_axes</span>(<span class=\"params\">axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;设置matplotlib的轴&quot;&quot;&quot;</span></span><br><span class=\"line\">    axes.set_xlabel(xlabel)</span><br><span class=\"line\">    axes.set_ylabel(ylabel)</span><br><span class=\"line\">    axes.set_xscale(xscale)</span><br><span class=\"line\">    axes.set_yscale(yscale)</span><br><span class=\"line\">    axes.set_xlim(xlim)</span><br><span class=\"line\">    axes.set_ylim(ylim)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> legend:</span><br><span class=\"line\">        axes.legend(legend)</span><br><span class=\"line\">    axes.grid()</span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">X, Y=<span class=\"literal\">None</span>, xlabel=<span class=\"literal\">None</span>, ylabel=<span class=\"literal\">None</span>, legend=<span class=\"literal\">None</span>, xlim=<span class=\"literal\">None</span>,ylim=<span class=\"literal\">None</span>, xscale=<span class=\"string\">&#x27;linear&#x27;</span>, yscale=<span class=\"string\">&#x27;linear&#x27;</span>,fmts=(<span class=\"params\"><span class=\"string\">&#x27;-&#x27;</span>, <span class=\"string\">&#x27;m--&#x27;</span>, <span class=\"string\">&#x27;g-.&#x27;</span>, <span class=\"string\">&#x27;r:&#x27;</span></span>), figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>), axes=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制数据点&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> legend <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        legend = []</span><br><span class=\"line\">    set_figsize(figsize)</span><br><span class=\"line\">    axes = axes <span class=\"keyword\">if</span> axes <span class=\"keyword\">else</span> d2l.plt.gca()</span><br><span class=\"line\">    <span class=\"comment\"># 如果X有一个轴，输出True</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">has_one_axis</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (<span class=\"built_in\">hasattr</span>(X, <span class=\"string\">&quot;ndim&quot;</span>) <span class=\"keyword\">and</span> X.ndim == <span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"built_in\">isinstance</span>(X, <span class=\"built_in\">list</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(X[<span class=\"number\">0</span>], <span class=\"string\">&quot;__len__&quot;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> has_one_axis(X):</span><br><span class=\"line\">        X = [X]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> Y <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        X, Y = [[]] * <span class=\"built_in\">len</span>(X), X</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> has_one_axis(Y):</span><br><span class=\"line\">        Y = [Y]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(X) != <span class=\"built_in\">len</span>(Y):</span><br><span class=\"line\">        X = X * <span class=\"built_in\">len</span>(Y)</span><br><span class=\"line\">    axes.cla()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x, y, fmt <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(X, Y, fmts):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(x):</span><br><span class=\"line\">            axes.plot(x, y, fmt)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            axes.plot(y, fmt)</span><br><span class=\"line\">    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 绘制切线</span></span><br><span class=\"line\">x = np.arange(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">0.1</span>)</span><br><span class=\"line\">plot(x, [f(x), <span class=\"number\">2</span> * x - <span class=\"number\">3</span>], <span class=\"string\">&#x27;x&#x27;</span>, <span class=\"string\">&#x27;f(x)&#x27;</span>, legend=[<span class=\"string\">&#x27;f(x)&#x27;</span>, <span class=\"string\">&#x27;Tangent line (x=1)&#x27;</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<pre><code>C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2373785819.py:22: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n  set_matplotlib_formats(&#39;svg&#39;)\n</code></pre>\n<p><img src=\"/4_calculus_files/4_calculus_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/4_calculus_1_1.svg\"></p>\n<h2 id=\"4-2-偏导数\"><a href=\"#4-2-偏导数\" class=\"headerlink\" title=\"4.2 偏导数\"></a>4.2 偏导数</h2><ul>\n<li>偏导数：$f(x_1,x_2,…,x_n)$关于$x_i$的偏导数：$\\frac{\\partial f}{\\partial x_i}&#x3D;\\lim\\limits_{h\\rightarrow 0}\\frac{f(x_1,…,x_i+h,…,x_n)-f(x_1,…,x_i,…,x_n)}{h}$</li>\n</ul>\n<h2 id=\"4-3-梯度\"><a href=\"#4-3-梯度\" class=\"headerlink\" title=\"4.3 梯度\"></a>4.3 梯度</h2><ul>\n<li>梯度：$\\nabla_x f(x)&#x3D;[\\frac{\\partial f(x)}{\\partial x_1},\\frac{\\partial f(x)}{\\partial x_2},…,\\frac{\\partial f(x)}{\\partial x_n}]^T$</li>\n<li>一些性质：<ul>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(Ax)&#x3D;A^T$</li>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(x^TA)&#x3D;A$</li>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(x^TAx)&#x3D;(A+A^T)x$</li>\n<li>$\\nabla_x||x||_F^2&#x3D;\\nabla_x(x^Tx)&#x3D;2x$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-4-链式法则\"><a href=\"#4-4-链式法则\" class=\"headerlink\" title=\"4.4 链式法则\"></a>4.4 链式法则</h2><ul>\n<li>$y&#x3D;f(u_1,u_2,…,u_m),u_i&#x3D;g_i(x_1,x_2,…,x_n),则\\frac{\\partial y}{\\partial x_i}&#x3D;\\sum\\limits_{j&#x3D;1}^m\\frac{\\partial y}{\\partial u_j}\\frac{\\partial u_j}{\\partial x_i}$</li>\n</ul>\n<h2 id=\"练习\"><a href=\"#练习\" class=\"headerlink\" title=\"练习\"></a>练习</h2><ul>\n<li>绘制函数$y&#x3D;X^3-\\frac{1}{X}$在x&#x3D;1处的图像</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x**<span class=\"number\">3</span> - <span class=\"number\">1</span>/x</span><br><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">3</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.plot(x,f(x))</span><br><span class=\"line\">plt.plot(x,<span class=\"number\">3</span>*x**<span class=\"number\">2</span>+<span class=\"number\">1</span>/x**<span class=\"number\">2</span>-<span class=\"number\">4</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<pre><code>C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:5: RuntimeWarning: divide by zero encountered in divide\n  return x**3 - 1/x\nC:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:8: RuntimeWarning: divide by zero encountered in divide\n  plt.plot(x,3*x**2+1/x**2-4)\n</code></pre>\n<p><img src=\"/4_calculus_files/4_calculus_3_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/4_calculus_3_1.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"4-微积分\"><a href=\"#4-微积分\" class=\"headerlink\" title=\"4. 微积分\"></a>4. 微积分</h1><ul>\n<li>拟合模型的任务分解为两个关键问题：<ul>\n<li>优化（optimization）：用模型拟合观测数据的过程；</li>\n<li>泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-1-导数和微分\"><a href=\"#4-1-导数和微分\" class=\"headerlink\" title=\"4.1 导数和微分\"></a>4.1 导数和微分</h2><ul>\n<li>通常选择对于模型参数可微的损失函数。简而言之，对于每个参数，如果我们把这个参数增加或减少一个无穷小的量，可以知道损失会以多快的速度增加或减少。</li>\n<li>导数：$f’(x)&#x3D;\\lim\\limits_{h\\rightarrow 0}\\frac{f(x+h)-f(x)}{h}&#x3D;y^\\prime&#x3D;\\frac{dy}{dx}&#x3D;\\frac{df}{dx}&#x3D;\\frac{d}{dx}f(x)&#x3D;Df(x)&#x3D;D_x f(x)$<ul>\n<li>1)常数相乘法则：$(Cf)^\\prime&#x3D;C(f^\\prime)$</li>\n<li>2)加法法则：$(f+g)^\\prime&#x3D;f^\\prime+g^\\prime$   </li>\n<li>3)乘法法则：$(fg)^\\prime&#x3D;f^\\prime g+fg^\\prime$</li>\n<li>4)除法法则：$(\\frac{f}{g})^\\prime&#x3D;\\frac{f^\\prime g-fg^\\prime}{g^2}$</li>\n</ul>\n</li>\n<li>微分：若$f^\\prime(a)$存在，则称$f$在$a$处可微</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将图形嵌入到Notebook中 %matplotlib inline</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class=\"string\">&quot;TRUE&quot;</span> <span class=\"comment\">#这两行可以解决崩溃的错误</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> IPython.display <span class=\"keyword\">import</span> set_matplotlib_formats</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\">#from matplotlib_inline import backend_inline</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 定义一个函数f</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">3</span> * x ** <span class=\"number\">2</span> - <span class=\"number\">4</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 定义f&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">numerical_lim</span>(<span class=\"params\">f, x, h</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (f(x + h) - f(x)) / h</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">#一些函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">use_svg_display</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;使用svg格式在Jupyter中显示绘图&quot;&quot;&quot;</span></span><br><span class=\"line\">    set_matplotlib_formats(<span class=\"string\">&#x27;svg&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">set_figsize</span>(<span class=\"params\">figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>)</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;设置matplotlib的图表大小&quot;&quot;&quot;</span></span><br><span class=\"line\">    use_svg_display()</span><br><span class=\"line\">    d2l.plt.rcParams[<span class=\"string\">&#x27;figure.figsize&#x27;</span>] = figsize</span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">set_axes</span>(<span class=\"params\">axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;设置matplotlib的轴&quot;&quot;&quot;</span></span><br><span class=\"line\">    axes.set_xlabel(xlabel)</span><br><span class=\"line\">    axes.set_ylabel(ylabel)</span><br><span class=\"line\">    axes.set_xscale(xscale)</span><br><span class=\"line\">    axes.set_yscale(yscale)</span><br><span class=\"line\">    axes.set_xlim(xlim)</span><br><span class=\"line\">    axes.set_ylim(ylim)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> legend:</span><br><span class=\"line\">        axes.legend(legend)</span><br><span class=\"line\">    axes.grid()</span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">X, Y=<span class=\"literal\">None</span>, xlabel=<span class=\"literal\">None</span>, ylabel=<span class=\"literal\">None</span>, legend=<span class=\"literal\">None</span>, xlim=<span class=\"literal\">None</span>,ylim=<span class=\"literal\">None</span>, xscale=<span class=\"string\">&#x27;linear&#x27;</span>, yscale=<span class=\"string\">&#x27;linear&#x27;</span>,fmts=(<span class=\"params\"><span class=\"string\">&#x27;-&#x27;</span>, <span class=\"string\">&#x27;m--&#x27;</span>, <span class=\"string\">&#x27;g-.&#x27;</span>, <span class=\"string\">&#x27;r:&#x27;</span></span>), figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>), axes=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制数据点&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> legend <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        legend = []</span><br><span class=\"line\">    set_figsize(figsize)</span><br><span class=\"line\">    axes = axes <span class=\"keyword\">if</span> axes <span class=\"keyword\">else</span> d2l.plt.gca()</span><br><span class=\"line\">    <span class=\"comment\"># 如果X有一个轴，输出True</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">has_one_axis</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (<span class=\"built_in\">hasattr</span>(X, <span class=\"string\">&quot;ndim&quot;</span>) <span class=\"keyword\">and</span> X.ndim == <span class=\"number\">1</span> <span class=\"keyword\">or</span> <span class=\"built_in\">isinstance</span>(X, <span class=\"built_in\">list</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(X[<span class=\"number\">0</span>], <span class=\"string\">&quot;__len__&quot;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> has_one_axis(X):</span><br><span class=\"line\">        X = [X]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> Y <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        X, Y = [[]] * <span class=\"built_in\">len</span>(X), X</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> has_one_axis(Y):</span><br><span class=\"line\">        Y = [Y]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(X) != <span class=\"built_in\">len</span>(Y):</span><br><span class=\"line\">        X = X * <span class=\"built_in\">len</span>(Y)</span><br><span class=\"line\">    axes.cla()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x, y, fmt <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(X, Y, fmts):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(x):</span><br><span class=\"line\">            axes.plot(x, y, fmt)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            axes.plot(y, fmt)</span><br><span class=\"line\">    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 绘制切线</span></span><br><span class=\"line\">x = np.arange(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">0.1</span>)</span><br><span class=\"line\">plot(x, [f(x), <span class=\"number\">2</span> * x - <span class=\"number\">3</span>], <span class=\"string\">&#x27;x&#x27;</span>, <span class=\"string\">&#x27;f(x)&#x27;</span>, legend=[<span class=\"string\">&#x27;f(x)&#x27;</span>, <span class=\"string\">&#x27;Tangent line (x=1)&#x27;</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<pre><code>C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2373785819.py:22: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n  set_matplotlib_formats(&#39;svg&#39;)\n</code></pre>\n<p><img src=\"/4_calculus_files/4_calculus_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/4_calculus_1_1.svg\"></p>\n<h2 id=\"4-2-偏导数\"><a href=\"#4-2-偏导数\" class=\"headerlink\" title=\"4.2 偏导数\"></a>4.2 偏导数</h2><ul>\n<li>偏导数：$f(x_1,x_2,…,x_n)$关于$x_i$的偏导数：$\\frac{\\partial f}{\\partial x_i}&#x3D;\\lim\\limits_{h\\rightarrow 0}\\frac{f(x_1,…,x_i+h,…,x_n)-f(x_1,…,x_i,…,x_n)}{h}$</li>\n</ul>\n<h2 id=\"4-3-梯度\"><a href=\"#4-3-梯度\" class=\"headerlink\" title=\"4.3 梯度\"></a>4.3 梯度</h2><ul>\n<li>梯度：$\\nabla_x f(x)&#x3D;[\\frac{\\partial f(x)}{\\partial x_1},\\frac{\\partial f(x)}{\\partial x_2},…,\\frac{\\partial f(x)}{\\partial x_n}]^T$</li>\n<li>一些性质：<ul>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(Ax)&#x3D;A^T$</li>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(x^TA)&#x3D;A$</li>\n<li>$\\forall A\\in R^{m\\times n},\\nabla_x(x^TAx)&#x3D;(A+A^T)x$</li>\n<li>$\\nabla_x||x||_F^2&#x3D;\\nabla_x(x^Tx)&#x3D;2x$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-4-链式法则\"><a href=\"#4-4-链式法则\" class=\"headerlink\" title=\"4.4 链式法则\"></a>4.4 链式法则</h2><ul>\n<li>$y&#x3D;f(u_1,u_2,…,u_m),u_i&#x3D;g_i(x_1,x_2,…,x_n),则\\frac{\\partial y}{\\partial x_i}&#x3D;\\sum\\limits_{j&#x3D;1}^m\\frac{\\partial y}{\\partial u_j}\\frac{\\partial u_j}{\\partial x_i}$</li>\n</ul>\n<h2 id=\"练习\"><a href=\"#练习\" class=\"headerlink\" title=\"练习\"></a>练习</h2><ul>\n<li>绘制函数$y&#x3D;X^3-\\frac{1}{X}$在x&#x3D;1处的图像</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x**<span class=\"number\">3</span> - <span class=\"number\">1</span>/x</span><br><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">3</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.plot(x,f(x))</span><br><span class=\"line\">plt.plot(x,<span class=\"number\">3</span>*x**<span class=\"number\">2</span>+<span class=\"number\">1</span>/x**<span class=\"number\">2</span>-<span class=\"number\">4</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<pre><code>C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:5: RuntimeWarning: divide by zero encountered in divide\n  return x**3 - 1/x\nC:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_13552\\2157169762.py:8: RuntimeWarning: divide by zero encountered in divide\n  plt.plot(x,3*x**2+1/x**2-4)\n</code></pre>\n<p><img src=\"/4_calculus_files/4_calculus_3_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/4_calculus_3_1.svg\"></p>"},{"title":"1.5 自动微分","date":"2024-02-01T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 5. 自动微分\n- 深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。根据设计好的模型，系统会构建一个计算图（computational graph），来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度。这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。\n## 5.1 \n- 对函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导\n\n\n```python\nimport torch\n#1 创建变量x\nx=torch.arange(4.0)\ny=2*torch.dot(x,x)\nprint(x)\n\n#2 存储梯度 （一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。）\nx.requires_grad_(True) #等价于x=torch.arange(4.0,requires_grad=True)\nprint(x)\n\n#3 计算y\ny=2*torch.dot(x,x) #点积\nprint(y)\n\n#4 反向传播计算梯度\nprint(x.grad) #默认为None\ny.backward() #反向传播\nprint(x.grad) #梯度为4x\n\n#5 阻止跟踪\ny=x.sum() #y=6\ny.backward()\nprint(x.grad) #x的梯度会累加\nx.grad.zero_() #清除梯度后就不会累加了\ny.backward()\nprint(x.grad)\n```\n\n    tensor([0., 1., 2., 3.])\n    tensor([0., 1., 2., 3.], requires_grad=True)\n    tensor(28., grad_fn=<MulBackward0>)\n    None\n    tensor([ 0.,  4.,  8., 12.])\n    tensor([ 1.,  5.,  9., 13.])\n    tensor([1., 1., 1., 1.])\n    \n\n## 5.2 非标量变量的反向传播\n\n\n\n```python\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny=x*x #这里y是向量\ny.sum().backward() #这里y.sum()是标量,所以可以调用backward，相当于y.backward(torch.ones(len(x)))\nprint(x.grad)\n\n```\n\n    tensor([0., 2., 4., 6.])\n    \n\n## 5.3 分离计算\n- 将某些计算移动到记录的计算图之外。（作为常数处理）\n    - 假设$y=f(x), z=g(x,y)$。我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n\n```python\nx.grad.zero_()\ny=x*x\nu=y.detach() #分u相当于一个常数，不需要求梯度\nz=u*x\nz.sum().backward()\nprint(x.grad) #u\n\nx.grad.zero_()\nz=y*x\nz.sum().backward()\nprint(x.grad) #3x^2\n```\n\n    tensor([0., 1., 4., 9.])\n    tensor([ 0.,  3., 12., 27.])\n    \n\n## 5.4 python控制流的梯度计算\n\n\n```python\ndef f(a):\n    b=a*2\n    while b.norm()<1000: #经过while后b=ka\n        b=b*2\n    if b.sum()>0:\n        c=b #c=kb=ka\n    else:\n        c=100*b #c=100kb=100ka\n    return c #ka\na=torch.randn(size=(),requires_grad=True)\nD=f(a) #\nD.backward()\na.grad==D/a #梯度就是k=D/a\n```\n\n\n\n\n    tensor(True)\n\n\n","source":"_posts/deeplearning/code/pytorch/1_prepare/5_autodifferential.md","raw":"---\ntitle: 1.5 自动微分\ndate: 2024-2-1 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 5. 自动微分\n- 深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。根据设计好的模型，系统会构建一个计算图（computational graph），来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度。这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。\n## 5.1 \n- 对函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导\n\n\n```python\nimport torch\n#1 创建变量x\nx=torch.arange(4.0)\ny=2*torch.dot(x,x)\nprint(x)\n\n#2 存储梯度 （一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。）\nx.requires_grad_(True) #等价于x=torch.arange(4.0,requires_grad=True)\nprint(x)\n\n#3 计算y\ny=2*torch.dot(x,x) #点积\nprint(y)\n\n#4 反向传播计算梯度\nprint(x.grad) #默认为None\ny.backward() #反向传播\nprint(x.grad) #梯度为4x\n\n#5 阻止跟踪\ny=x.sum() #y=6\ny.backward()\nprint(x.grad) #x的梯度会累加\nx.grad.zero_() #清除梯度后就不会累加了\ny.backward()\nprint(x.grad)\n```\n\n    tensor([0., 1., 2., 3.])\n    tensor([0., 1., 2., 3.], requires_grad=True)\n    tensor(28., grad_fn=<MulBackward0>)\n    None\n    tensor([ 0.,  4.,  8., 12.])\n    tensor([ 1.,  5.,  9., 13.])\n    tensor([1., 1., 1., 1.])\n    \n\n## 5.2 非标量变量的反向传播\n\n\n\n```python\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny=x*x #这里y是向量\ny.sum().backward() #这里y.sum()是标量,所以可以调用backward，相当于y.backward(torch.ones(len(x)))\nprint(x.grad)\n\n```\n\n    tensor([0., 2., 4., 6.])\n    \n\n## 5.3 分离计算\n- 将某些计算移动到记录的计算图之外。（作为常数处理）\n    - 假设$y=f(x), z=g(x,y)$。我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n\n```python\nx.grad.zero_()\ny=x*x\nu=y.detach() #分u相当于一个常数，不需要求梯度\nz=u*x\nz.sum().backward()\nprint(x.grad) #u\n\nx.grad.zero_()\nz=y*x\nz.sum().backward()\nprint(x.grad) #3x^2\n```\n\n    tensor([0., 1., 4., 9.])\n    tensor([ 0.,  3., 12., 27.])\n    \n\n## 5.4 python控制流的梯度计算\n\n\n```python\ndef f(a):\n    b=a*2\n    while b.norm()<1000: #经过while后b=ka\n        b=b*2\n    if b.sum()>0:\n        c=b #c=kb=ka\n    else:\n        c=100*b #c=100kb=100ka\n    return c #ka\na=torch.randn(size=(),requires_grad=True)\nD=f(a) #\nD.backward()\na.grad==D/a #梯度就是k=D/a\n```\n\n\n\n\n    tensor(True)\n\n\n","slug":"deeplearning/code/pytorch/1_prepare/5_autodifferential","published":1,"updated":"2024-02-03T03:47:51.611Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859a003u7svwa9j9h6le","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"5-自动微分\"><a href=\"#5-自动微分\" class=\"headerlink\" title=\"5. 自动微分\"></a>5. 自动微分</h1><ul>\n<li>深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。根据设计好的模型，系统会构建一个计算图（computational graph），来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度。这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。</li>\n</ul>\n<h2 id=\"5-1\"><a href=\"#5-1\" class=\"headerlink\" title=\"5.1\"></a>5.1</h2><ul>\n<li>对函数$y&#x3D;2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"comment\">#1 创建变量x</span></span><br><span class=\"line\">x=torch.arange(<span class=\"number\">4.0</span>)</span><br><span class=\"line\">y=<span class=\"number\">2</span>*torch.dot(x,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 存储梯度 （一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。）</span></span><br><span class=\"line\">x.requires_grad_(<span class=\"literal\">True</span>) <span class=\"comment\">#等价于x=torch.arange(4.0,requires_grad=True)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 计算y</span></span><br><span class=\"line\">y=<span class=\"number\">2</span>*torch.dot(x,x) <span class=\"comment\">#点积</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 反向传播计算梯度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#默认为None</span></span><br><span class=\"line\">y.backward() <span class=\"comment\">#反向传播</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#梯度为4x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 阻止跟踪</span></span><br><span class=\"line\">y=x.<span class=\"built_in\">sum</span>() <span class=\"comment\">#y=6</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#x的梯度会累加</span></span><br><span class=\"line\">x.grad.zero_() <span class=\"comment\">#清除梯度后就不会累加了</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 2., 3.])\ntensor([0., 1., 2., 3.], requires_grad=True)\ntensor(28., grad_fn=&lt;MulBackward0&gt;)\nNone\ntensor([ 0.,  4.,  8., 12.])\ntensor([ 1.,  5.,  9., 13.])\ntensor([1., 1., 1., 1.])\n</code></pre>\n<h2 id=\"5-2-非标量变量的反向传播\"><a href=\"#5-2-非标量变量的反向传播\" class=\"headerlink\" title=\"5.2 非标量变量的反向传播\"></a>5.2 非标量变量的反向传播</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span></span><br><span class=\"line\"><span class=\"comment\"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y=x*x <span class=\"comment\">#这里y是向量</span></span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#这里y.sum()是标量,所以可以调用backward，相当于y.backward(torch.ones(len(x)))</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 2., 4., 6.])\n</code></pre>\n<h2 id=\"5-3-分离计算\"><a href=\"#5-3-分离计算\" class=\"headerlink\" title=\"5.3 分离计算\"></a>5.3 分离计算</h2><ul>\n<li>将某些计算移动到记录的计算图之外。（作为常数处理）<ul>\n<li>假设$y&#x3D;f(x), z&#x3D;g(x,y)$。我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y=x*x</span><br><span class=\"line\">u=y.detach() <span class=\"comment\">#分u相当于一个常数，不需要求梯度</span></span><br><span class=\"line\">z=u*x</span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#u</span></span><br><span class=\"line\"></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">z=y*x</span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#3x^2</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 4., 9.])\ntensor([ 0.,  3., 12., 27.])\n</code></pre>\n<h2 id=\"5-4-python控制流的梯度计算\"><a href=\"#5-4-python控制流的梯度计算\" class=\"headerlink\" title=\"5.4 python控制流的梯度计算\"></a>5.4 python控制流的梯度计算</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">a</span>):</span><br><span class=\"line\">    b=a*<span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> b.norm()&lt;<span class=\"number\">1000</span>: <span class=\"comment\">#经过while后b=ka</span></span><br><span class=\"line\">        b=b*<span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> b.<span class=\"built_in\">sum</span>()&gt;<span class=\"number\">0</span>:</span><br><span class=\"line\">        c=b <span class=\"comment\">#c=kb=ka</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        c=<span class=\"number\">100</span>*b <span class=\"comment\">#c=100kb=100ka</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c <span class=\"comment\">#ka</span></span><br><span class=\"line\">a=torch.randn(size=(),requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">D=f(a) <span class=\"comment\">#</span></span><br><span class=\"line\">D.backward()</span><br><span class=\"line\">a.grad==D/a <span class=\"comment\">#梯度就是k=D/a</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(True)\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"5-自动微分\"><a href=\"#5-自动微分\" class=\"headerlink\" title=\"5. 自动微分\"></a>5. 自动微分</h1><ul>\n<li>深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。根据设计好的模型，系统会构建一个计算图（computational graph），来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度。这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。</li>\n</ul>\n<h2 id=\"5-1\"><a href=\"#5-1\" class=\"headerlink\" title=\"5.1\"></a>5.1</h2><ul>\n<li>对函数$y&#x3D;2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"comment\">#1 创建变量x</span></span><br><span class=\"line\">x=torch.arange(<span class=\"number\">4.0</span>)</span><br><span class=\"line\">y=<span class=\"number\">2</span>*torch.dot(x,x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 存储梯度 （一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。）</span></span><br><span class=\"line\">x.requires_grad_(<span class=\"literal\">True</span>) <span class=\"comment\">#等价于x=torch.arange(4.0,requires_grad=True)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 计算y</span></span><br><span class=\"line\">y=<span class=\"number\">2</span>*torch.dot(x,x) <span class=\"comment\">#点积</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 反向传播计算梯度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#默认为None</span></span><br><span class=\"line\">y.backward() <span class=\"comment\">#反向传播</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#梯度为4x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 阻止跟踪</span></span><br><span class=\"line\">y=x.<span class=\"built_in\">sum</span>() <span class=\"comment\">#y=6</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#x的梯度会累加</span></span><br><span class=\"line\">x.grad.zero_() <span class=\"comment\">#清除梯度后就不会累加了</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 2., 3.])\ntensor([0., 1., 2., 3.], requires_grad=True)\ntensor(28., grad_fn=&lt;MulBackward0&gt;)\nNone\ntensor([ 0.,  4.,  8., 12.])\ntensor([ 1.,  5.,  9., 13.])\ntensor([1., 1., 1., 1.])\n</code></pre>\n<h2 id=\"5-2-非标量变量的反向传播\"><a href=\"#5-2-非标量变量的反向传播\" class=\"headerlink\" title=\"5.2 非标量变量的反向传播\"></a>5.2 非标量变量的反向传播</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span></span><br><span class=\"line\"><span class=\"comment\"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y=x*x <span class=\"comment\">#这里y是向量</span></span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#这里y.sum()是标量,所以可以调用backward，相当于y.backward(torch.ones(len(x)))</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 2., 4., 6.])\n</code></pre>\n<h2 id=\"5-3-分离计算\"><a href=\"#5-3-分离计算\" class=\"headerlink\" title=\"5.3 分离计算\"></a>5.3 分离计算</h2><ul>\n<li>将某些计算移动到记录的计算图之外。（作为常数处理）<ul>\n<li>假设$y&#x3D;f(x), z&#x3D;g(x,y)$。我们想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y=x*x</span><br><span class=\"line\">u=y.detach() <span class=\"comment\">#分u相当于一个常数，不需要求梯度</span></span><br><span class=\"line\">z=u*x</span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#u</span></span><br><span class=\"line\"></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">z=y*x</span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\">#3x^2</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([0., 1., 4., 9.])\ntensor([ 0.,  3., 12., 27.])\n</code></pre>\n<h2 id=\"5-4-python控制流的梯度计算\"><a href=\"#5-4-python控制流的梯度计算\" class=\"headerlink\" title=\"5.4 python控制流的梯度计算\"></a>5.4 python控制流的梯度计算</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">a</span>):</span><br><span class=\"line\">    b=a*<span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> b.norm()&lt;<span class=\"number\">1000</span>: <span class=\"comment\">#经过while后b=ka</span></span><br><span class=\"line\">        b=b*<span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> b.<span class=\"built_in\">sum</span>()&gt;<span class=\"number\">0</span>:</span><br><span class=\"line\">        c=b <span class=\"comment\">#c=kb=ka</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        c=<span class=\"number\">100</span>*b <span class=\"comment\">#c=100kb=100ka</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c <span class=\"comment\">#ka</span></span><br><span class=\"line\">a=torch.randn(size=(),requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">D=f(a) <span class=\"comment\">#</span></span><br><span class=\"line\">D.backward()</span><br><span class=\"line\">a.grad==D/a <span class=\"comment\">#梯度就是k=D/a</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>tensor(True)\n</code></pre>"},{"title":"1.6 概率","date":"2024-02-02T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 6. 概率\n## 6.1 基本概率论\n### 6.1.1 一点代码\n- 笼统来说，可以把分布（distribution）看作对事件的概率分配\n\n\n```python\n#一下两行代码可选，有时候会出现崩溃\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\nimport torch\nfrom torch.distributions import multinomial\nfrom d2l import torch as d2l\nimport matplotlib.pyplot as plt\n\n#1 抽样\nfair_probs = torch.ones([6])/6 #六个数，每个数的概率都是1/6\ns = multinomial.Multinomial(99999, fair_probs).sample() #抽样99999次,根据概率分布抽样，抽中的数字对应的位置为+1，其他位置为0\nprint(s)\n#分组抽样\ncounts = multinomial.Multinomial(10,fair_probs).sample((500,)) #500组实验，每组抽样10个样本\ncum_counts = counts.cumsum(dim=0) #累加\nestimates = cum_counts/cum_counts.sum(dim=1,keepdims=True) #计算频率,第一组10个样本，计算频率；第二组10+10个，计算频率\n\n#2 绘图 越到后面，采样越多，估计的概率越接近真实概率\nd2l.set_figsize((6,4.5))\nfor i in range(6):\n    d2l.plt.plot(estimates[:,i].numpy(),label=(\"P(die=\" + str(i+1) + \")\"))\nd2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\nd2l.plt.gca().set_xlabel('Groups of experiments')\nd2l.plt.gca().set_ylabel('Estimated probability')\nd2l.plt.legend()\n```\n\n    tensor([16569., 16678., 16493., 16636., 16712., 16911.])\n    \n\n\n\n\n    <matplotlib.legend.Legend at 0x16dc26d9460>\n\n\n\n\n    \n![svg](6_probability_files/6_probability_1_2.svg)\n![](img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg)\n    \n\n\n### 6.1.2 概率论公理\n- 非负性：对于任意事件A，P(A) >= 0\n- 规范性：P(Ω) = 1\n- 可列可加性：对于任意两个不相容事件A和B，P(A∪B) = P(A) + P(B)\n### 6.1.3 随机变量\n## 6.2 处理多个随机变量\n### 6.2.1 联合概率\n- $P(A,B) = P(A|B)P(B)$\n### 6.2.2 条件概率\n- $P(A|B) = \\frac{P(A,B)}{P(B)}$\n### 6.2.3 贝叶斯定理\n- $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n### 6.2.4 边缘化\n- $P(A) = \\sum\\limits_{B}P(A,B)$\n- 边际化结果的概率或分布称为边际概率（marginal probability）或边际分布（marginal distribution）\n### 6.2.5 独立性\n- $A \\perp B \\Rightarrow P(A,B) = P(A)P(B)$\n- $A \\perp B|C \\Rightarrow P(A,B|C) = P(A|C)P(B|C)$\n## 6.3 期望和方差\n- 期望：$E_{x\\sim P}[f(x)] = \\sum\\limits_{x}P(x)f(x)$\n- 方差：$Var(f(x)) = E[(f(x) - E[f(x)])^2] = E[f(x)^2] - E[f(x)]^2$\n","source":"_posts/deeplearning/code/pytorch/1_prepare/6_probability.md","raw":"---\ntitle: 1.6 概率\ndate: 2024-2-2 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 6. 概率\n## 6.1 基本概率论\n### 6.1.1 一点代码\n- 笼统来说，可以把分布（distribution）看作对事件的概率分配\n\n\n```python\n#一下两行代码可选，有时候会出现崩溃\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\nimport torch\nfrom torch.distributions import multinomial\nfrom d2l import torch as d2l\nimport matplotlib.pyplot as plt\n\n#1 抽样\nfair_probs = torch.ones([6])/6 #六个数，每个数的概率都是1/6\ns = multinomial.Multinomial(99999, fair_probs).sample() #抽样99999次,根据概率分布抽样，抽中的数字对应的位置为+1，其他位置为0\nprint(s)\n#分组抽样\ncounts = multinomial.Multinomial(10,fair_probs).sample((500,)) #500组实验，每组抽样10个样本\ncum_counts = counts.cumsum(dim=0) #累加\nestimates = cum_counts/cum_counts.sum(dim=1,keepdims=True) #计算频率,第一组10个样本，计算频率；第二组10+10个，计算频率\n\n#2 绘图 越到后面，采样越多，估计的概率越接近真实概率\nd2l.set_figsize((6,4.5))\nfor i in range(6):\n    d2l.plt.plot(estimates[:,i].numpy(),label=(\"P(die=\" + str(i+1) + \")\"))\nd2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\nd2l.plt.gca().set_xlabel('Groups of experiments')\nd2l.plt.gca().set_ylabel('Estimated probability')\nd2l.plt.legend()\n```\n\n    tensor([16569., 16678., 16493., 16636., 16712., 16911.])\n    \n\n\n\n\n    <matplotlib.legend.Legend at 0x16dc26d9460>\n\n\n\n\n    \n![svg](6_probability_files/6_probability_1_2.svg)\n![](img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg)\n    \n\n\n### 6.1.2 概率论公理\n- 非负性：对于任意事件A，P(A) >= 0\n- 规范性：P(Ω) = 1\n- 可列可加性：对于任意两个不相容事件A和B，P(A∪B) = P(A) + P(B)\n### 6.1.3 随机变量\n## 6.2 处理多个随机变量\n### 6.2.1 联合概率\n- $P(A,B) = P(A|B)P(B)$\n### 6.2.2 条件概率\n- $P(A|B) = \\frac{P(A,B)}{P(B)}$\n### 6.2.3 贝叶斯定理\n- $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n### 6.2.4 边缘化\n- $P(A) = \\sum\\limits_{B}P(A,B)$\n- 边际化结果的概率或分布称为边际概率（marginal probability）或边际分布（marginal distribution）\n### 6.2.5 独立性\n- $A \\perp B \\Rightarrow P(A,B) = P(A)P(B)$\n- $A \\perp B|C \\Rightarrow P(A,B|C) = P(A|C)P(B|C)$\n## 6.3 期望和方差\n- 期望：$E_{x\\sim P}[f(x)] = \\sum\\limits_{x}P(x)f(x)$\n- 方差：$Var(f(x)) = E[(f(x) - E[f(x)])^2] = E[f(x)^2] - E[f(x)]^2$\n","slug":"deeplearning/code/pytorch/1_prepare/6_probability","published":1,"updated":"2024-02-05T14:25:18.539Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859b003x7svwd94ndbvi","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"6-概率\"><a href=\"#6-概率\" class=\"headerlink\" title=\"6. 概率\"></a>6. 概率</h1><h2 id=\"6-1-基本概率论\"><a href=\"#6-1-基本概率论\" class=\"headerlink\" title=\"6.1 基本概率论\"></a>6.1 基本概率论</h2><h3 id=\"6-1-1-一点代码\"><a href=\"#6-1-1-一点代码\" class=\"headerlink\" title=\"6.1.1 一点代码\"></a>6.1.1 一点代码</h3><ul>\n<li>笼统来说，可以把分布（distribution）看作对事件的概率分配</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#一下两行代码可选，有时候会出现崩溃</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.distributions <span class=\"keyword\">import</span> multinomial</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 抽样</span></span><br><span class=\"line\">fair_probs = torch.ones([<span class=\"number\">6</span>])/<span class=\"number\">6</span> <span class=\"comment\">#六个数，每个数的概率都是1/6</span></span><br><span class=\"line\">s = multinomial.Multinomial(<span class=\"number\">99999</span>, fair_probs).sample() <span class=\"comment\">#抽样99999次,根据概率分布抽样，抽中的数字对应的位置为+1，其他位置为0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(s)</span><br><span class=\"line\"><span class=\"comment\">#分组抽样</span></span><br><span class=\"line\">counts = multinomial.Multinomial(<span class=\"number\">10</span>,fair_probs).sample((<span class=\"number\">500</span>,)) <span class=\"comment\">#500组实验，每组抽样10个样本</span></span><br><span class=\"line\">cum_counts = counts.cumsum(dim=<span class=\"number\">0</span>) <span class=\"comment\">#累加</span></span><br><span class=\"line\">estimates = cum_counts/cum_counts.<span class=\"built_in\">sum</span>(dim=<span class=\"number\">1</span>,keepdims=<span class=\"literal\">True</span>) <span class=\"comment\">#计算频率,第一组10个样本，计算频率；第二组10+10个，计算频率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 绘图 越到后面，采样越多，估计的概率越接近真实概率</span></span><br><span class=\"line\">d2l.set_figsize((<span class=\"number\">6</span>,<span class=\"number\">4.5</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">6</span>):</span><br><span class=\"line\">    d2l.plt.plot(estimates[:,i].numpy(),label=(<span class=\"string\">&quot;P(die=&quot;</span> + <span class=\"built_in\">str</span>(i+<span class=\"number\">1</span>) + <span class=\"string\">&quot;)&quot;</span>))</span><br><span class=\"line\">d2l.plt.axhline(y=<span class=\"number\">0.167</span>, color=<span class=\"string\">&#x27;black&#x27;</span>, linestyle=<span class=\"string\">&#x27;dashed&#x27;</span>)</span><br><span class=\"line\">d2l.plt.gca().set_xlabel(<span class=\"string\">&#x27;Groups of experiments&#x27;</span>)</span><br><span class=\"line\">d2l.plt.gca().set_ylabel(<span class=\"string\">&#x27;Estimated probability&#x27;</span>)</span><br><span class=\"line\">d2l.plt.legend()</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([16569., 16678., 16493., 16636., 16712., 16911.])\n\n\n\n\n\n&lt;matplotlib.legend.Legend at 0x16dc26d9460&gt;\n</code></pre>\n<p><img src=\"/6_probability_files/6_probability_1_2.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg\"></p>\n<h3 id=\"6-1-2-概率论公理\"><a href=\"#6-1-2-概率论公理\" class=\"headerlink\" title=\"6.1.2 概率论公理\"></a>6.1.2 概率论公理</h3><ul>\n<li>非负性：对于任意事件A，P(A) &gt;&#x3D; 0</li>\n<li>规范性：P(Ω) &#x3D; 1</li>\n<li>可列可加性：对于任意两个不相容事件A和B，P(A∪B) &#x3D; P(A) + P(B)</li>\n</ul>\n<h3 id=\"6-1-3-随机变量\"><a href=\"#6-1-3-随机变量\" class=\"headerlink\" title=\"6.1.3 随机变量\"></a>6.1.3 随机变量</h3><h2 id=\"6-2-处理多个随机变量\"><a href=\"#6-2-处理多个随机变量\" class=\"headerlink\" title=\"6.2 处理多个随机变量\"></a>6.2 处理多个随机变量</h2><h3 id=\"6-2-1-联合概率\"><a href=\"#6-2-1-联合概率\" class=\"headerlink\" title=\"6.2.1 联合概率\"></a>6.2.1 联合概率</h3><ul>\n<li>$P(A,B) &#x3D; P(A|B)P(B)$</li>\n</ul>\n<h3 id=\"6-2-2-条件概率\"><a href=\"#6-2-2-条件概率\" class=\"headerlink\" title=\"6.2.2 条件概率\"></a>6.2.2 条件概率</h3><ul>\n<li>$P(A|B) &#x3D; \\frac{P(A,B)}{P(B)}$</li>\n</ul>\n<h3 id=\"6-2-3-贝叶斯定理\"><a href=\"#6-2-3-贝叶斯定理\" class=\"headerlink\" title=\"6.2.3 贝叶斯定理\"></a>6.2.3 贝叶斯定理</h3><ul>\n<li>$P(A|B) &#x3D; \\frac{P(B|A)P(A)}{P(B)}$</li>\n</ul>\n<h3 id=\"6-2-4-边缘化\"><a href=\"#6-2-4-边缘化\" class=\"headerlink\" title=\"6.2.4 边缘化\"></a>6.2.4 边缘化</h3><ul>\n<li>$P(A) &#x3D; \\sum\\limits_{B}P(A,B)$</li>\n<li>边际化结果的概率或分布称为边际概率（marginal probability）或边际分布（marginal distribution）</li>\n</ul>\n<h3 id=\"6-2-5-独立性\"><a href=\"#6-2-5-独立性\" class=\"headerlink\" title=\"6.2.5 独立性\"></a>6.2.5 独立性</h3><ul>\n<li>$A \\perp B \\Rightarrow P(A,B) &#x3D; P(A)P(B)$</li>\n<li>$A \\perp B|C \\Rightarrow P(A,B|C) &#x3D; P(A|C)P(B|C)$</li>\n</ul>\n<h2 id=\"6-3-期望和方差\"><a href=\"#6-3-期望和方差\" class=\"headerlink\" title=\"6.3 期望和方差\"></a>6.3 期望和方差</h2><ul>\n<li>期望：$E_{x\\sim P}[f(x)] &#x3D; \\sum\\limits_{x}P(x)f(x)$</li>\n<li>方差：$Var(f(x)) &#x3D; E[(f(x) - E[f(x)])^2] &#x3D; E[f(x)^2] - E[f(x)]^2$</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"6-概率\"><a href=\"#6-概率\" class=\"headerlink\" title=\"6. 概率\"></a>6. 概率</h1><h2 id=\"6-1-基本概率论\"><a href=\"#6-1-基本概率论\" class=\"headerlink\" title=\"6.1 基本概率论\"></a>6.1 基本概率论</h2><h3 id=\"6-1-1-一点代码\"><a href=\"#6-1-1-一点代码\" class=\"headerlink\" title=\"6.1.1 一点代码\"></a>6.1.1 一点代码</h3><ul>\n<li>笼统来说，可以把分布（distribution）看作对事件的概率分配</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#一下两行代码可选，有时候会出现崩溃</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.distributions <span class=\"keyword\">import</span> multinomial</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 抽样</span></span><br><span class=\"line\">fair_probs = torch.ones([<span class=\"number\">6</span>])/<span class=\"number\">6</span> <span class=\"comment\">#六个数，每个数的概率都是1/6</span></span><br><span class=\"line\">s = multinomial.Multinomial(<span class=\"number\">99999</span>, fair_probs).sample() <span class=\"comment\">#抽样99999次,根据概率分布抽样，抽中的数字对应的位置为+1，其他位置为0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(s)</span><br><span class=\"line\"><span class=\"comment\">#分组抽样</span></span><br><span class=\"line\">counts = multinomial.Multinomial(<span class=\"number\">10</span>,fair_probs).sample((<span class=\"number\">500</span>,)) <span class=\"comment\">#500组实验，每组抽样10个样本</span></span><br><span class=\"line\">cum_counts = counts.cumsum(dim=<span class=\"number\">0</span>) <span class=\"comment\">#累加</span></span><br><span class=\"line\">estimates = cum_counts/cum_counts.<span class=\"built_in\">sum</span>(dim=<span class=\"number\">1</span>,keepdims=<span class=\"literal\">True</span>) <span class=\"comment\">#计算频率,第一组10个样本，计算频率；第二组10+10个，计算频率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 绘图 越到后面，采样越多，估计的概率越接近真实概率</span></span><br><span class=\"line\">d2l.set_figsize((<span class=\"number\">6</span>,<span class=\"number\">4.5</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">6</span>):</span><br><span class=\"line\">    d2l.plt.plot(estimates[:,i].numpy(),label=(<span class=\"string\">&quot;P(die=&quot;</span> + <span class=\"built_in\">str</span>(i+<span class=\"number\">1</span>) + <span class=\"string\">&quot;)&quot;</span>))</span><br><span class=\"line\">d2l.plt.axhline(y=<span class=\"number\">0.167</span>, color=<span class=\"string\">&#x27;black&#x27;</span>, linestyle=<span class=\"string\">&#x27;dashed&#x27;</span>)</span><br><span class=\"line\">d2l.plt.gca().set_xlabel(<span class=\"string\">&#x27;Groups of experiments&#x27;</span>)</span><br><span class=\"line\">d2l.plt.gca().set_ylabel(<span class=\"string\">&#x27;Estimated probability&#x27;</span>)</span><br><span class=\"line\">d2l.plt.legend()</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([16569., 16678., 16493., 16636., 16712., 16911.])\n\n\n\n\n\n&lt;matplotlib.legend.Legend at 0x16dc26d9460&gt;\n</code></pre>\n<p><img src=\"/6_probability_files/6_probability_1_2.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/1_prepare/6_probability_files/6_probability_1_2.svg\"></p>\n<h3 id=\"6-1-2-概率论公理\"><a href=\"#6-1-2-概率论公理\" class=\"headerlink\" title=\"6.1.2 概率论公理\"></a>6.1.2 概率论公理</h3><ul>\n<li>非负性：对于任意事件A，P(A) &gt;&#x3D; 0</li>\n<li>规范性：P(Ω) &#x3D; 1</li>\n<li>可列可加性：对于任意两个不相容事件A和B，P(A∪B) &#x3D; P(A) + P(B)</li>\n</ul>\n<h3 id=\"6-1-3-随机变量\"><a href=\"#6-1-3-随机变量\" class=\"headerlink\" title=\"6.1.3 随机变量\"></a>6.1.3 随机变量</h3><h2 id=\"6-2-处理多个随机变量\"><a href=\"#6-2-处理多个随机变量\" class=\"headerlink\" title=\"6.2 处理多个随机变量\"></a>6.2 处理多个随机变量</h2><h3 id=\"6-2-1-联合概率\"><a href=\"#6-2-1-联合概率\" class=\"headerlink\" title=\"6.2.1 联合概率\"></a>6.2.1 联合概率</h3><ul>\n<li>$P(A,B) &#x3D; P(A|B)P(B)$</li>\n</ul>\n<h3 id=\"6-2-2-条件概率\"><a href=\"#6-2-2-条件概率\" class=\"headerlink\" title=\"6.2.2 条件概率\"></a>6.2.2 条件概率</h3><ul>\n<li>$P(A|B) &#x3D; \\frac{P(A,B)}{P(B)}$</li>\n</ul>\n<h3 id=\"6-2-3-贝叶斯定理\"><a href=\"#6-2-3-贝叶斯定理\" class=\"headerlink\" title=\"6.2.3 贝叶斯定理\"></a>6.2.3 贝叶斯定理</h3><ul>\n<li>$P(A|B) &#x3D; \\frac{P(B|A)P(A)}{P(B)}$</li>\n</ul>\n<h3 id=\"6-2-4-边缘化\"><a href=\"#6-2-4-边缘化\" class=\"headerlink\" title=\"6.2.4 边缘化\"></a>6.2.4 边缘化</h3><ul>\n<li>$P(A) &#x3D; \\sum\\limits_{B}P(A,B)$</li>\n<li>边际化结果的概率或分布称为边际概率（marginal probability）或边际分布（marginal distribution）</li>\n</ul>\n<h3 id=\"6-2-5-独立性\"><a href=\"#6-2-5-独立性\" class=\"headerlink\" title=\"6.2.5 独立性\"></a>6.2.5 独立性</h3><ul>\n<li>$A \\perp B \\Rightarrow P(A,B) &#x3D; P(A)P(B)$</li>\n<li>$A \\perp B|C \\Rightarrow P(A,B|C) &#x3D; P(A|C)P(B|C)$</li>\n</ul>\n<h2 id=\"6-3-期望和方差\"><a href=\"#6-3-期望和方差\" class=\"headerlink\" title=\"6.3 期望和方差\"></a>6.3 期望和方差</h2><ul>\n<li>期望：$E_{x\\sim P}[f(x)] &#x3D; \\sum\\limits_{x}P(x)f(x)$</li>\n<li>方差：$Var(f(x)) &#x3D; E[(f(x) - E[f(x)])^2] &#x3D; E[f(x)^2] - E[f(x)]^2$</li>\n</ul>"},{"title":"1.7 查阅文档","date":"2024-02-02T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 7. 查阅文档\n## 7.1 查找模块中的所有函数和类\n- dir()\n\n\n```python\nimport torch\nprint(dir(torch.distributions))\n```\n\n    ['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n    \n\n## 7.2 查找特定函数和类的使用\n- help()\n\n\n```python\nhelp(torch.ones)\n```\n\n    Help on built-in function ones in module torch:\n    \n    ones(...)\n        ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n        \n        Returns a tensor filled with the scalar value `1`, with the shape defined\n        by the variable argument :attr:`size`.\n        \n        Args:\n            size (int...): a sequence of integers defining the shape of the output tensor.\n                Can be a variable number of arguments or a collection like a list or tuple.\n        \n        Keyword arguments:\n            out (Tensor, optional): the output tensor.\n            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n                Default: ``torch.strided``.\n            device (:class:`torch.device`, optional): the desired device of returned tensor.\n                Default: if ``None``, uses the current device for the default tensor type\n                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n                for CPU tensor types and the current CUDA device for CUDA tensor types.\n            requires_grad (bool, optional): If autograd should record operations on the\n                returned tensor. Default: ``False``.\n        \n        Example::\n        \n            >>> torch.ones(2, 3)\n            tensor([[ 1.,  1.,  1.],\n                    [ 1.,  1.,  1.]])\n        \n            >>> torch.ones(5)\n            tensor([ 1.,  1.,  1.,  1.,  1.])\n    \n    \n\n\n```python\nlist?\n```\n\n    \u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n    \u001b[1;31mDocstring:\u001b[0m     \n    Built-in mutable sequence.\n    \n    If no argument is given, the constructor creates a new empty list.\n    The argument must be an iterable if specified.\n    \u001b[1;31mType:\u001b[0m           type\n    \u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, StackSummary, _Threads, ConvertingList, DeferredConfigList, _ymd, SList, ParamSpec, _ConcatenateGenericAlias, _ImmutableLineList, ...\n","source":"_posts/deeplearning/code/pytorch/1_prepare/7_api.md","raw":"---\ntitle: 1.7 查阅文档\ndate: 2024-2-2 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 7. 查阅文档\n## 7.1 查找模块中的所有函数和类\n- dir()\n\n\n```python\nimport torch\nprint(dir(torch.distributions))\n```\n\n    ['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n    \n\n## 7.2 查找特定函数和类的使用\n- help()\n\n\n```python\nhelp(torch.ones)\n```\n\n    Help on built-in function ones in module torch:\n    \n    ones(...)\n        ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n        \n        Returns a tensor filled with the scalar value `1`, with the shape defined\n        by the variable argument :attr:`size`.\n        \n        Args:\n            size (int...): a sequence of integers defining the shape of the output tensor.\n                Can be a variable number of arguments or a collection like a list or tuple.\n        \n        Keyword arguments:\n            out (Tensor, optional): the output tensor.\n            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n                Default: ``torch.strided``.\n            device (:class:`torch.device`, optional): the desired device of returned tensor.\n                Default: if ``None``, uses the current device for the default tensor type\n                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n                for CPU tensor types and the current CUDA device for CUDA tensor types.\n            requires_grad (bool, optional): If autograd should record operations on the\n                returned tensor. Default: ``False``.\n        \n        Example::\n        \n            >>> torch.ones(2, 3)\n            tensor([[ 1.,  1.,  1.],\n                    [ 1.,  1.,  1.]])\n        \n            >>> torch.ones(5)\n            tensor([ 1.,  1.,  1.,  1.,  1.])\n    \n    \n\n\n```python\nlist?\n```\n\n    \u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n    \u001b[1;31mDocstring:\u001b[0m     \n    Built-in mutable sequence.\n    \n    If no argument is given, the constructor creates a new empty list.\n    The argument must be an iterable if specified.\n    \u001b[1;31mType:\u001b[0m           type\n    \u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, StackSummary, _Threads, ConvertingList, DeferredConfigList, _ymd, SList, ParamSpec, _ConcatenateGenericAlias, _ImmutableLineList, ...\n","slug":"deeplearning/code/pytorch/1_prepare/7_api","published":1,"updated":"2024-03-18T09:25:17.306Z","_id":"clt19859c00417svwf55tbtmz","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"7-查阅文档\"><a href=\"#7-查阅文档\" class=\"headerlink\" title=\"7. 查阅文档\"></a>7. 查阅文档</h1><h2 id=\"7-1-查找模块中的所有函数和类\"><a href=\"#7-1-查找模块中的所有函数和类\" class=\"headerlink\" title=\"7.1 查找模块中的所有函数和类\"></a>7.1 查找模块中的所有函数和类</h2><ul>\n<li>dir()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">dir</span>(torch.distributions))</span><br></pre></td></tr></table></figure>\n\n<pre><code>[&#39;AbsTransform&#39;, &#39;AffineTransform&#39;, &#39;Bernoulli&#39;, &#39;Beta&#39;, &#39;Binomial&#39;, &#39;CatTransform&#39;, &#39;Categorical&#39;, &#39;Cauchy&#39;, &#39;Chi2&#39;, &#39;ComposeTransform&#39;, &#39;ContinuousBernoulli&#39;, &#39;CorrCholeskyTransform&#39;, &#39;CumulativeDistributionTransform&#39;, &#39;Dirichlet&#39;, &#39;Distribution&#39;, &#39;ExpTransform&#39;, &#39;Exponential&#39;, &#39;ExponentialFamily&#39;, &#39;FisherSnedecor&#39;, &#39;Gamma&#39;, &#39;Geometric&#39;, &#39;Gumbel&#39;, &#39;HalfCauchy&#39;, &#39;HalfNormal&#39;, &#39;Independent&#39;, &#39;IndependentTransform&#39;, &#39;Kumaraswamy&#39;, &#39;LKJCholesky&#39;, &#39;Laplace&#39;, &#39;LogNormal&#39;, &#39;LogisticNormal&#39;, &#39;LowRankMultivariateNormal&#39;, &#39;LowerCholeskyTransform&#39;, &#39;MixtureSameFamily&#39;, &#39;Multinomial&#39;, &#39;MultivariateNormal&#39;, &#39;NegativeBinomial&#39;, &#39;Normal&#39;, &#39;OneHotCategorical&#39;, &#39;OneHotCategoricalStraightThrough&#39;, &#39;Pareto&#39;, &#39;Poisson&#39;, &#39;PowerTransform&#39;, &#39;RelaxedBernoulli&#39;, &#39;RelaxedOneHotCategorical&#39;, &#39;ReshapeTransform&#39;, &#39;SigmoidTransform&#39;, &#39;SoftmaxTransform&#39;, &#39;SoftplusTransform&#39;, &#39;StackTransform&#39;, &#39;StickBreakingTransform&#39;, &#39;StudentT&#39;, &#39;TanhTransform&#39;, &#39;Transform&#39;, &#39;TransformedDistribution&#39;, &#39;Uniform&#39;, &#39;VonMises&#39;, &#39;Weibull&#39;, &#39;Wishart&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;bernoulli&#39;, &#39;beta&#39;, &#39;biject_to&#39;, &#39;binomial&#39;, &#39;categorical&#39;, &#39;cauchy&#39;, &#39;chi2&#39;, &#39;constraint_registry&#39;, &#39;constraints&#39;, &#39;continuous_bernoulli&#39;, &#39;dirichlet&#39;, &#39;distribution&#39;, &#39;exp_family&#39;, &#39;exponential&#39;, &#39;fishersnedecor&#39;, &#39;gamma&#39;, &#39;geometric&#39;, &#39;gumbel&#39;, &#39;half_cauchy&#39;, &#39;half_normal&#39;, &#39;identity_transform&#39;, &#39;independent&#39;, &#39;kl&#39;, &#39;kl_divergence&#39;, &#39;kumaraswamy&#39;, &#39;laplace&#39;, &#39;lkj_cholesky&#39;, &#39;log_normal&#39;, &#39;logistic_normal&#39;, &#39;lowrank_multivariate_normal&#39;, &#39;mixture_same_family&#39;, &#39;multinomial&#39;, &#39;multivariate_normal&#39;, &#39;negative_binomial&#39;, &#39;normal&#39;, &#39;one_hot_categorical&#39;, &#39;pareto&#39;, &#39;poisson&#39;, &#39;register_kl&#39;, &#39;relaxed_bernoulli&#39;, &#39;relaxed_categorical&#39;, &#39;studentT&#39;, &#39;transform_to&#39;, &#39;transformed_distribution&#39;, &#39;transforms&#39;, &#39;uniform&#39;, &#39;utils&#39;, &#39;von_mises&#39;, &#39;weibull&#39;, &#39;wishart&#39;]\n</code></pre>\n<h2 id=\"7-2-查找特定函数和类的使用\"><a href=\"#7-2-查找特定函数和类的使用\" class=\"headerlink\" title=\"7.2 查找特定函数和类的使用\"></a>7.2 查找特定函数和类的使用</h2><ul>\n<li>help()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">help</span>(torch.ones)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Help on built-in function ones in module torch:\n\nones(...)\n    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&gt; Tensor\n    \n    Returns a tensor filled with the scalar value `1`, with the shape defined\n    by the variable argument :attr:`size`.\n    \n    Args:\n        size (int...): a sequence of integers defining the shape of the output tensor.\n            Can be a variable number of arguments or a collection like a list or tuple.\n    \n    Keyword arguments:\n        out (Tensor, optional): the output tensor.\n        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n            Default: ``torch.strided``.\n        device (:class:`torch.device`, optional): the desired device of returned tensor.\n            Default: if ``None``, uses the current device for the default tensor type\n            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n            for CPU tensor types and the current CUDA device for CUDA tensor types.\n        requires_grad (bool, optional): If autograd should record operations on the\n            returned tensor. Default: ``False``.\n    \n    Example::\n    \n        &gt;&gt;&gt; torch.ones(2, 3)\n        tensor([[ 1.,  1.,  1.],\n                [ 1.,  1.,  1.]])\n    \n        &gt;&gt;&gt; torch.ones(5)\n        tensor([ 1.,  1.,  1.,  1.,  1.])\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">list</span>?</span><br></pre></td></tr></table></figure>\n\n<pre><code>\u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;31mDocstring:\u001b[0m     \nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\u001b[1;31mType:\u001b[0m           type\n\u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, StackSummary, _Threads, ConvertingList, DeferredConfigList, _ymd, SList, ParamSpec, _ConcatenateGenericAlias, _ImmutableLineList, ...\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"7-查阅文档\"><a href=\"#7-查阅文档\" class=\"headerlink\" title=\"7. 查阅文档\"></a>7. 查阅文档</h1><h2 id=\"7-1-查找模块中的所有函数和类\"><a href=\"#7-1-查找模块中的所有函数和类\" class=\"headerlink\" title=\"7.1 查找模块中的所有函数和类\"></a>7.1 查找模块中的所有函数和类</h2><ul>\n<li>dir()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">dir</span>(torch.distributions))</span><br></pre></td></tr></table></figure>\n\n<pre><code>[&#39;AbsTransform&#39;, &#39;AffineTransform&#39;, &#39;Bernoulli&#39;, &#39;Beta&#39;, &#39;Binomial&#39;, &#39;CatTransform&#39;, &#39;Categorical&#39;, &#39;Cauchy&#39;, &#39;Chi2&#39;, &#39;ComposeTransform&#39;, &#39;ContinuousBernoulli&#39;, &#39;CorrCholeskyTransform&#39;, &#39;CumulativeDistributionTransform&#39;, &#39;Dirichlet&#39;, &#39;Distribution&#39;, &#39;ExpTransform&#39;, &#39;Exponential&#39;, &#39;ExponentialFamily&#39;, &#39;FisherSnedecor&#39;, &#39;Gamma&#39;, &#39;Geometric&#39;, &#39;Gumbel&#39;, &#39;HalfCauchy&#39;, &#39;HalfNormal&#39;, &#39;Independent&#39;, &#39;IndependentTransform&#39;, &#39;Kumaraswamy&#39;, &#39;LKJCholesky&#39;, &#39;Laplace&#39;, &#39;LogNormal&#39;, &#39;LogisticNormal&#39;, &#39;LowRankMultivariateNormal&#39;, &#39;LowerCholeskyTransform&#39;, &#39;MixtureSameFamily&#39;, &#39;Multinomial&#39;, &#39;MultivariateNormal&#39;, &#39;NegativeBinomial&#39;, &#39;Normal&#39;, &#39;OneHotCategorical&#39;, &#39;OneHotCategoricalStraightThrough&#39;, &#39;Pareto&#39;, &#39;Poisson&#39;, &#39;PowerTransform&#39;, &#39;RelaxedBernoulli&#39;, &#39;RelaxedOneHotCategorical&#39;, &#39;ReshapeTransform&#39;, &#39;SigmoidTransform&#39;, &#39;SoftmaxTransform&#39;, &#39;SoftplusTransform&#39;, &#39;StackTransform&#39;, &#39;StickBreakingTransform&#39;, &#39;StudentT&#39;, &#39;TanhTransform&#39;, &#39;Transform&#39;, &#39;TransformedDistribution&#39;, &#39;Uniform&#39;, &#39;VonMises&#39;, &#39;Weibull&#39;, &#39;Wishart&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;bernoulli&#39;, &#39;beta&#39;, &#39;biject_to&#39;, &#39;binomial&#39;, &#39;categorical&#39;, &#39;cauchy&#39;, &#39;chi2&#39;, &#39;constraint_registry&#39;, &#39;constraints&#39;, &#39;continuous_bernoulli&#39;, &#39;dirichlet&#39;, &#39;distribution&#39;, &#39;exp_family&#39;, &#39;exponential&#39;, &#39;fishersnedecor&#39;, &#39;gamma&#39;, &#39;geometric&#39;, &#39;gumbel&#39;, &#39;half_cauchy&#39;, &#39;half_normal&#39;, &#39;identity_transform&#39;, &#39;independent&#39;, &#39;kl&#39;, &#39;kl_divergence&#39;, &#39;kumaraswamy&#39;, &#39;laplace&#39;, &#39;lkj_cholesky&#39;, &#39;log_normal&#39;, &#39;logistic_normal&#39;, &#39;lowrank_multivariate_normal&#39;, &#39;mixture_same_family&#39;, &#39;multinomial&#39;, &#39;multivariate_normal&#39;, &#39;negative_binomial&#39;, &#39;normal&#39;, &#39;one_hot_categorical&#39;, &#39;pareto&#39;, &#39;poisson&#39;, &#39;register_kl&#39;, &#39;relaxed_bernoulli&#39;, &#39;relaxed_categorical&#39;, &#39;studentT&#39;, &#39;transform_to&#39;, &#39;transformed_distribution&#39;, &#39;transforms&#39;, &#39;uniform&#39;, &#39;utils&#39;, &#39;von_mises&#39;, &#39;weibull&#39;, &#39;wishart&#39;]\n</code></pre>\n<h2 id=\"7-2-查找特定函数和类的使用\"><a href=\"#7-2-查找特定函数和类的使用\" class=\"headerlink\" title=\"7.2 查找特定函数和类的使用\"></a>7.2 查找特定函数和类的使用</h2><ul>\n<li>help()</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">help</span>(torch.ones)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Help on built-in function ones in module torch:\n\nones(...)\n    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&gt; Tensor\n    \n    Returns a tensor filled with the scalar value `1`, with the shape defined\n    by the variable argument :attr:`size`.\n    \n    Args:\n        size (int...): a sequence of integers defining the shape of the output tensor.\n            Can be a variable number of arguments or a collection like a list or tuple.\n    \n    Keyword arguments:\n        out (Tensor, optional): the output tensor.\n        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n            Default: ``torch.strided``.\n        device (:class:`torch.device`, optional): the desired device of returned tensor.\n            Default: if ``None``, uses the current device for the default tensor type\n            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n            for CPU tensor types and the current CUDA device for CUDA tensor types.\n        requires_grad (bool, optional): If autograd should record operations on the\n            returned tensor. Default: ``False``.\n    \n    Example::\n    \n        &gt;&gt;&gt; torch.ones(2, 3)\n        tensor([[ 1.,  1.,  1.],\n                [ 1.,  1.,  1.]])\n    \n        &gt;&gt;&gt; torch.ones(5)\n        tensor([ 1.,  1.,  1.,  1.,  1.])\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">list</span>?</span><br></pre></td></tr></table></figure>\n\n<pre><code>\u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;31mDocstring:\u001b[0m     \nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\u001b[1;31mType:\u001b[0m           type\n\u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, StackSummary, _Threads, ConvertingList, DeferredConfigList, _ymd, SList, ParamSpec, _ConcatenateGenericAlias, _ImmutableLineList, ...\n</code></pre>"},{"title":"2.1 线性回归","date":"2024-02-03T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 1. 线性回归\n## 1.1 线性回归的基本元素\n- 基于几个简单的假设：\n    - 假设自变量x和因变量y之间的关系是线性的\n    - 假设y的观测值是通过均值为0的噪声扰动后得到的\n- 一些概念：\n    - 训练集：训练模型的数据集\n    - 样本：每行数据\n    - 标签：试图预测的值\n    - 特征（feature，协变量（covariate））：预测所依赖的输入变量\n### 1.1.1 线性模型\n$$\\hat y = w_1x1+w_2x_2+b \\rightarrow \\hat y = \\mathbf{w}^T\\mathbf{x}+b$$\n- $w_1$和$w_2$是权重\n- $b$是偏置(bias),也叫偏移量(offset),截距(intercept)：当所有特征都取值为0时，预测值应该为多少。\n- 严格来说，上述公式是输入特征的一个 仿射变换（affine transformation）：仿射变换的特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项来进行平移（translation）。\n- 对于整个数据集，特征集合是一个矩阵：$\\hat y = \\mathbf{X}\\mathbf{w}+b$\n### 1.1.2 损失函数\n- 量化目标的实际值与预测值之间的差距。\n- 回归问题中最常用的损失函数是平方误差函数:\n    - $l^{(i)}(\\mathbf{w},b) = \\frac{1}{2}(\\hat y^{(i)}-y^{(i)})^2$\n- 训练目标：寻找一组参数（$\\mathbf{w^*},b^*$）,使得所有样本的损失函数之和最小：\n$$\\mathbf{w^*},b^* = L(\\mathbf{w},b) \\underset{\\mathbf{w},b}{\\arg\\min} \\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w},b)$$\n### 1.1.3 解析解\n$$\\mathbf{w^*} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n### 1.1.4 随机梯度下降\n- $$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\partial_{(\\mathbf{w},b)}l^{(i)}(\\mathbf{w},b)$$\n- 通过不断地在损失函数递减的方向上更新参数来降低误差。\n- 梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本$\\mathcal{B}$，并计算损失函数关于这些样本的平均损失的梯度。\n- 算法过程：\n    - 1）初始化模型参数的值，如随机初始化\n    - 2）从数据集中随机抽取一小批样本且在负梯度方向上更新参数\n    - 3）重复步骤2直到收敛\n    - 例如对于平方损失和放射变换：\n        - $\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$\n        - $b \\leftarrow b - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$\n            - $\\eta$是学习率\n            - $\\mathcal{B}$是小批量样本的大小(batch size)\n    - 对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失，这一挑战被称为泛化（generalization）。\n### 1.1.5 用模型进行预测\n$$\\hat y = \\mathbf{\\hat w}^T\\mathbf{x}+\\hat b$$\n## 1.2 矢量化加速\n- 在训练我们的模型时，我们经常希望能够同时处理整个小批量的样本。而不是在Python中编写开销高昂的for循环。\n\n\n\n\n```python\nimport math\nimport time\nimport numpy as np\nimport torch\nfrom d2l import torch as d2l\n#计时器\nclass Timer: #@save\n    \"\"\"记录多次运行时间\"\"\"\n    def __init__(self):\n        self.times = []\n        self.start()\n    def start(self):\n        \"\"\"启动计时器\"\"\"\n        self.tik = time.time()\n    def stop(self):\n        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n    def avg(self):\n        \"\"\"返回平均时间\"\"\"\n        return sum(self.times) / len(self.times)\n    def sum(self):\n        \"\"\"返回时间总和\"\"\"\n        return sum(self.times)\n    def cumsum(self):\n        \"\"\"返回累计时间\"\"\"\n        return np.array(self.times).cumsum().tolist()\n```\n\n\n```python\n#1 两个10000维向量\nn = 10000\na = torch.ones(n)\nb = torch.ones(n)\nc = torch.zeros(n)\n\n#2 for循环计算\ntimer = Timer()\nfor i in range(n):\n    c[i] = a[i] + b[i]\nprint(f'{timer.stop():.5f} sec')\n\n#3 一次性计算\ntimer.start()\nd = a + b\nprint(f'{timer.stop():.7f} sec')\n```\n\n    0.11051 sec\n    0.0000000 sec\n    \n\n## 1.3 正态分布与平方损失\n- 正态分布（高斯分布）：\n$$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n#1 定义一个函数来计算高斯分布\ndef normal(x,mu,sigma):\n    p = 1 / math.sqrt(2 * math.pi * sigma**2)\n    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)\n\n#2 可视化高斯分布\nx = np.arange(-7,7,0.01)\n#均值和标准差对\nparams = [(0,1),(0,2),(3,1)]\nd2l.plot(x,[normal(x,mu,sigma) for mu,sigma in params],xlabel='x',ylabel='p(x)',legend=[f'mean {mu},std {sigma}' for mu,sigma in params])\n```\n\n\n    \n![svg](1_linear_regression_files/1_linear_regression_4_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg)\n    \n\n\n- 假设观测中包含噪声：$$y = \\mathbf{w}^T\\mathbf{x}+b+\\epsilon$$\n    - 噪声$\\epsilon \\sim N(0,\\sigma^2)$\n    - 因此有：(y服从正态分布，y的均值是$\\mathbf{w}^T\\mathbf{x}+b$，方差是$\\sigma^2$)\n        - 1）通过给定的$\\mathbf{x}$观测到特定y的似然（likelihood）：$$p(y|\\mathbf{x}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(y-\\mathbf{w}^T\\mathbf{x}-b)^2}{2\\sigma^2})$$\n        - 2）根据极大似然估计，参数（$\\mathbf{w},b$）的最优值使整个数据集的似然最大：$$p(\\mathbf{y}|\\mathbf{X}) = \\prod \\limits_{i=1}^n p(y^{(i)}|\\mathbf{x}^{(i)})$$\n        - 3）根据极大似然估计法选择的估计量称为极大似然估计量。虽然使许多指数函数的乘积最大化看起来很困难，但是我们可以在不改变目标的前提下，通过最大化似然对数来简化：$$-log P(\\mathbf{y}|\\mathbf{X}) = \\frac{n}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}\\sum \\limits_{i=1}^n(y^{(i)}-\\mathbf{w}^T\\mathbf{x}^{(i)}-b)^2$$\n        - 4）假设$\\sigma$是常数，则可以忽略第一项；第二项除了常数项$\\frac{1}{\\sigma^2}$之外，就是平方损失函数。因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。\n\n## 1.4 从线性回归到深度网络\n### 1.4.1 神经网络\n- 线性回归是一个单层神经网络（隐去了权重和偏置）：\n- 每个输入都与每个输出相连，成为全连接层（fully connected layer）或稠密层（dense layer）。\n![](1_linear_regression_files/1.png)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png)\n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression.md","raw":"---\ntitle: 2.1 线性回归\ndate: 2024-2-3 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 1. 线性回归\n## 1.1 线性回归的基本元素\n- 基于几个简单的假设：\n    - 假设自变量x和因变量y之间的关系是线性的\n    - 假设y的观测值是通过均值为0的噪声扰动后得到的\n- 一些概念：\n    - 训练集：训练模型的数据集\n    - 样本：每行数据\n    - 标签：试图预测的值\n    - 特征（feature，协变量（covariate））：预测所依赖的输入变量\n### 1.1.1 线性模型\n$$\\hat y = w_1x1+w_2x_2+b \\rightarrow \\hat y = \\mathbf{w}^T\\mathbf{x}+b$$\n- $w_1$和$w_2$是权重\n- $b$是偏置(bias),也叫偏移量(offset),截距(intercept)：当所有特征都取值为0时，预测值应该为多少。\n- 严格来说，上述公式是输入特征的一个 仿射变换（affine transformation）：仿射变换的特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项来进行平移（translation）。\n- 对于整个数据集，特征集合是一个矩阵：$\\hat y = \\mathbf{X}\\mathbf{w}+b$\n### 1.1.2 损失函数\n- 量化目标的实际值与预测值之间的差距。\n- 回归问题中最常用的损失函数是平方误差函数:\n    - $l^{(i)}(\\mathbf{w},b) = \\frac{1}{2}(\\hat y^{(i)}-y^{(i)})^2$\n- 训练目标：寻找一组参数（$\\mathbf{w^*},b^*$）,使得所有样本的损失函数之和最小：\n$$\\mathbf{w^*},b^* = L(\\mathbf{w},b) \\underset{\\mathbf{w},b}{\\arg\\min} \\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w},b)$$\n### 1.1.3 解析解\n$$\\mathbf{w^*} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n### 1.1.4 随机梯度下降\n- $$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\partial_{(\\mathbf{w},b)}l^{(i)}(\\mathbf{w},b)$$\n- 通过不断地在损失函数递减的方向上更新参数来降低误差。\n- 梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本$\\mathcal{B}$，并计算损失函数关于这些样本的平均损失的梯度。\n- 算法过程：\n    - 1）初始化模型参数的值，如随机初始化\n    - 2）从数据集中随机抽取一小批样本且在负梯度方向上更新参数\n    - 3）重复步骤2直到收敛\n    - 例如对于平方损失和放射变换：\n        - $\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$\n        - $b \\leftarrow b - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$\n            - $\\eta$是学习率\n            - $\\mathcal{B}$是小批量样本的大小(batch size)\n    - 对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失，这一挑战被称为泛化（generalization）。\n### 1.1.5 用模型进行预测\n$$\\hat y = \\mathbf{\\hat w}^T\\mathbf{x}+\\hat b$$\n## 1.2 矢量化加速\n- 在训练我们的模型时，我们经常希望能够同时处理整个小批量的样本。而不是在Python中编写开销高昂的for循环。\n\n\n\n\n```python\nimport math\nimport time\nimport numpy as np\nimport torch\nfrom d2l import torch as d2l\n#计时器\nclass Timer: #@save\n    \"\"\"记录多次运行时间\"\"\"\n    def __init__(self):\n        self.times = []\n        self.start()\n    def start(self):\n        \"\"\"启动计时器\"\"\"\n        self.tik = time.time()\n    def stop(self):\n        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n    def avg(self):\n        \"\"\"返回平均时间\"\"\"\n        return sum(self.times) / len(self.times)\n    def sum(self):\n        \"\"\"返回时间总和\"\"\"\n        return sum(self.times)\n    def cumsum(self):\n        \"\"\"返回累计时间\"\"\"\n        return np.array(self.times).cumsum().tolist()\n```\n\n\n```python\n#1 两个10000维向量\nn = 10000\na = torch.ones(n)\nb = torch.ones(n)\nc = torch.zeros(n)\n\n#2 for循环计算\ntimer = Timer()\nfor i in range(n):\n    c[i] = a[i] + b[i]\nprint(f'{timer.stop():.5f} sec')\n\n#3 一次性计算\ntimer.start()\nd = a + b\nprint(f'{timer.stop():.7f} sec')\n```\n\n    0.11051 sec\n    0.0000000 sec\n    \n\n## 1.3 正态分布与平方损失\n- 正态分布（高斯分布）：\n$$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n#1 定义一个函数来计算高斯分布\ndef normal(x,mu,sigma):\n    p = 1 / math.sqrt(2 * math.pi * sigma**2)\n    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)\n\n#2 可视化高斯分布\nx = np.arange(-7,7,0.01)\n#均值和标准差对\nparams = [(0,1),(0,2),(3,1)]\nd2l.plot(x,[normal(x,mu,sigma) for mu,sigma in params],xlabel='x',ylabel='p(x)',legend=[f'mean {mu},std {sigma}' for mu,sigma in params])\n```\n\n\n    \n![svg](1_linear_regression_files/1_linear_regression_4_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg)\n    \n\n\n- 假设观测中包含噪声：$$y = \\mathbf{w}^T\\mathbf{x}+b+\\epsilon$$\n    - 噪声$\\epsilon \\sim N(0,\\sigma^2)$\n    - 因此有：(y服从正态分布，y的均值是$\\mathbf{w}^T\\mathbf{x}+b$，方差是$\\sigma^2$)\n        - 1）通过给定的$\\mathbf{x}$观测到特定y的似然（likelihood）：$$p(y|\\mathbf{x}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(y-\\mathbf{w}^T\\mathbf{x}-b)^2}{2\\sigma^2})$$\n        - 2）根据极大似然估计，参数（$\\mathbf{w},b$）的最优值使整个数据集的似然最大：$$p(\\mathbf{y}|\\mathbf{X}) = \\prod \\limits_{i=1}^n p(y^{(i)}|\\mathbf{x}^{(i)})$$\n        - 3）根据极大似然估计法选择的估计量称为极大似然估计量。虽然使许多指数函数的乘积最大化看起来很困难，但是我们可以在不改变目标的前提下，通过最大化似然对数来简化：$$-log P(\\mathbf{y}|\\mathbf{X}) = \\frac{n}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}\\sum \\limits_{i=1}^n(y^{(i)}-\\mathbf{w}^T\\mathbf{x}^{(i)}-b)^2$$\n        - 4）假设$\\sigma$是常数，则可以忽略第一项；第二项除了常数项$\\frac{1}{\\sigma^2}$之外，就是平方损失函数。因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。\n\n## 1.4 从线性回归到深度网络\n### 1.4.1 神经网络\n- 线性回归是一个单层神经网络（隐去了权重和偏置）：\n- 每个输入都与每个输出相连，成为全连接层（fully connected layer）或稠密层（dense layer）。\n![](1_linear_regression_files/1.png)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png)\n","slug":"deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression","published":1,"updated":"2024-02-05T14:27:39.955Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859c00437svw41olhu0f","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"1-线性回归\"><a href=\"#1-线性回归\" class=\"headerlink\" title=\"1. 线性回归\"></a>1. 线性回归</h1><h2 id=\"1-1-线性回归的基本元素\"><a href=\"#1-1-线性回归的基本元素\" class=\"headerlink\" title=\"1.1 线性回归的基本元素\"></a>1.1 线性回归的基本元素</h2><ul>\n<li>基于几个简单的假设：<ul>\n<li>假设自变量x和因变量y之间的关系是线性的</li>\n<li>假设y的观测值是通过均值为0的噪声扰动后得到的</li>\n</ul>\n</li>\n<li>一些概念：<ul>\n<li>训练集：训练模型的数据集</li>\n<li>样本：每行数据</li>\n<li>标签：试图预测的值</li>\n<li>特征（feature，协变量（covariate））：预测所依赖的输入变量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-1-1-线性模型\"><a href=\"#1-1-1-线性模型\" class=\"headerlink\" title=\"1.1.1 线性模型\"></a>1.1.1 线性模型</h3><p>$$\\hat y &#x3D; w_1x1+w_2x_2+b \\rightarrow \\hat y &#x3D; \\mathbf{w}^T\\mathbf{x}+b$$</p>\n<ul>\n<li>$w_1$和$w_2$是权重</li>\n<li>$b$是偏置(bias),也叫偏移量(offset),截距(intercept)：当所有特征都取值为0时，预测值应该为多少。</li>\n<li>严格来说，上述公式是输入特征的一个 仿射变换（affine transformation）：仿射变换的特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项来进行平移（translation）。</li>\n<li>对于整个数据集，特征集合是一个矩阵：$\\hat y &#x3D; \\mathbf{X}\\mathbf{w}+b$</li>\n</ul>\n<h3 id=\"1-1-2-损失函数\"><a href=\"#1-1-2-损失函数\" class=\"headerlink\" title=\"1.1.2 损失函数\"></a>1.1.2 损失函数</h3><ul>\n<li>量化目标的实际值与预测值之间的差距。</li>\n<li>回归问题中最常用的损失函数是平方误差函数:<ul>\n<li>$l^{(i)}(\\mathbf{w},b) &#x3D; \\frac{1}{2}(\\hat y^{(i)}-y^{(i)})^2$</li>\n</ul>\n</li>\n<li>训练目标：寻找一组参数（$\\mathbf{w^*},b^*$）,使得所有样本的损失函数之和最小：<br>$$\\mathbf{w^*},b^* &#x3D; L(\\mathbf{w},b) \\underset{\\mathbf{w},b}{\\arg\\min} \\frac{1}{n}\\sum_{i&#x3D;1}^n l^{(i)}(\\mathbf{w},b)$$</li>\n</ul>\n<h3 id=\"1-1-3-解析解\"><a href=\"#1-1-3-解析解\" class=\"headerlink\" title=\"1.1.3 解析解\"></a>1.1.3 解析解</h3><p>$$\\mathbf{w^*} &#x3D; (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$</p>\n<h3 id=\"1-1-4-随机梯度下降\"><a href=\"#1-1-4-随机梯度下降\" class=\"headerlink\" title=\"1.1.4 随机梯度下降\"></a>1.1.4 随机梯度下降</h3><ul>\n<li>$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\partial_{(\\mathbf{w},b)}l^{(i)}(\\mathbf{w},b)$$</li>\n<li>通过不断地在损失函数递减的方向上更新参数来降低误差。</li>\n<li>梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本$\\mathcal{B}$，并计算损失函数关于这些样本的平均损失的梯度。</li>\n<li>算法过程：<ul>\n<li>1）初始化模型参数的值，如随机初始化</li>\n<li>2）从数据集中随机抽取一小批样本且在负梯度方向上更新参数</li>\n<li>3）重复步骤2直到收敛</li>\n<li>例如对于平方损失和放射变换：<ul>\n<li>$\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$</li>\n<li>$b \\leftarrow b - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$<ul>\n<li>$\\eta$是学习率</li>\n<li>$\\mathcal{B}$是小批量样本的大小(batch size)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失，这一挑战被称为泛化（generalization）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-1-5-用模型进行预测\"><a href=\"#1-1-5-用模型进行预测\" class=\"headerlink\" title=\"1.1.5 用模型进行预测\"></a>1.1.5 用模型进行预测</h3><p>$$\\hat y &#x3D; \\mathbf{\\hat w}^T\\mathbf{x}+\\hat b$$</p>\n<h2 id=\"1-2-矢量化加速\"><a href=\"#1-2-矢量化加速\" class=\"headerlink\" title=\"1.2 矢量化加速\"></a>1.2 矢量化加速</h2><ul>\n<li>在训练我们的模型时，我们经常希望能够同时处理整个小批量的样本。而不是在Python中编写开销高昂的for循环。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"comment\">#计时器</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Timer</span>: <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;记录多次运行时间&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.times = []</span><br><span class=\"line\">        self.start()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">start</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;启动计时器&quot;&quot;&quot;</span></span><br><span class=\"line\">        self.tik = time.time()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">stop</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;停止计时器并将时间记录在列表中&quot;&quot;&quot;</span></span><br><span class=\"line\">        self.times.append(time.time() - self.tik)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.times[-<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">avg</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回平均时间&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(self.times) / <span class=\"built_in\">len</span>(self.times)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">sum</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回时间总和&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(self.times)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">cumsum</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回累计时间&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> np.array(self.times).cumsum().tolist()</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 两个10000维向量</span></span><br><span class=\"line\">n = <span class=\"number\">10000</span></span><br><span class=\"line\">a = torch.ones(n)</span><br><span class=\"line\">b = torch.ones(n)</span><br><span class=\"line\">c = torch.zeros(n)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 for循环计算</span></span><br><span class=\"line\">timer = Timer()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">    c[i] = a[i] + b[i]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.5</span>f&#125;</span> sec&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 一次性计算</span></span><br><span class=\"line\">timer.start()</span><br><span class=\"line\">d = a + b</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.7</span>f&#125;</span> sec&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>0.11051 sec\n0.0000000 sec\n</code></pre>\n<h2 id=\"1-3-正态分布与平方损失\"><a href=\"#1-3-正态分布与平方损失\" class=\"headerlink\" title=\"1.3 正态分布与平方损失\"></a>1.3 正态分布与平方损失</h2><ul>\n<li>正态分布（高斯分布）：<br>$$p(x) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"comment\">#1 定义一个函数来计算高斯分布</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">normal</span>(<span class=\"params\">x,mu,sigma</span>):</span><br><span class=\"line\">    p = <span class=\"number\">1</span> / math.sqrt(<span class=\"number\">2</span> * math.pi * sigma**<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p * np.exp(-<span class=\"number\">0.5</span> / sigma**<span class=\"number\">2</span> * (x - mu)**<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 可视化高斯分布</span></span><br><span class=\"line\">x = np.arange(-<span class=\"number\">7</span>,<span class=\"number\">7</span>,<span class=\"number\">0.01</span>)</span><br><span class=\"line\"><span class=\"comment\">#均值和标准差对</span></span><br><span class=\"line\">params = [(<span class=\"number\">0</span>,<span class=\"number\">1</span>),(<span class=\"number\">0</span>,<span class=\"number\">2</span>),(<span class=\"number\">3</span>,<span class=\"number\">1</span>)]</span><br><span class=\"line\">d2l.plot(x,[normal(x,mu,sigma) <span class=\"keyword\">for</span> mu,sigma <span class=\"keyword\">in</span> params],xlabel=<span class=\"string\">&#x27;x&#x27;</span>,ylabel=<span class=\"string\">&#x27;p(x)&#x27;</span>,legend=[<span class=\"string\">f&#x27;mean <span class=\"subst\">&#123;mu&#125;</span>,std <span class=\"subst\">&#123;sigma&#125;</span>&#x27;</span> <span class=\"keyword\">for</span> mu,sigma <span class=\"keyword\">in</span> params])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"/1_linear_regression_files/1_linear_regression_4_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg\"></p>\n<ul>\n<li>假设观测中包含噪声：$$y &#x3D; \\mathbf{w}^T\\mathbf{x}+b+\\epsilon$$<ul>\n<li>噪声$\\epsilon \\sim N(0,\\sigma^2)$</li>\n<li>因此有：(y服从正态分布，y的均值是$\\mathbf{w}^T\\mathbf{x}+b$，方差是$\\sigma^2$)<ul>\n<li>1）通过给定的$\\mathbf{x}$观测到特定y的似然（likelihood）：$$p(y|\\mathbf{x}) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(y-\\mathbf{w}^T\\mathbf{x}-b)^2}{2\\sigma^2})$$</li>\n<li>2）根据极大似然估计，参数（$\\mathbf{w},b$）的最优值使整个数据集的似然最大：$$p(\\mathbf{y}|\\mathbf{X}) &#x3D; \\prod \\limits_{i&#x3D;1}^n p(y^{(i)}|\\mathbf{x}^{(i)})$$</li>\n<li>3）根据极大似然估计法选择的估计量称为极大似然估计量。虽然使许多指数函数的乘积最大化看起来很困难，但是我们可以在不改变目标的前提下，通过最大化似然对数来简化：$$-log P(\\mathbf{y}|\\mathbf{X}) &#x3D; \\frac{n}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}\\sum \\limits_{i&#x3D;1}^n(y^{(i)}-\\mathbf{w}^T\\mathbf{x}^{(i)}-b)^2$$</li>\n<li>4）假设$\\sigma$是常数，则可以忽略第一项；第二项除了常数项$\\frac{1}{\\sigma^2}$之外，就是平方损失函数。因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"1-4-从线性回归到深度网络\"><a href=\"#1-4-从线性回归到深度网络\" class=\"headerlink\" title=\"1.4 从线性回归到深度网络\"></a>1.4 从线性回归到深度网络</h2><h3 id=\"1-4-1-神经网络\"><a href=\"#1-4-1-神经网络\" class=\"headerlink\" title=\"1.4.1 神经网络\"></a>1.4.1 神经网络</h3><ul>\n<li>线性回归是一个单层神经网络（隐去了权重和偏置）：</li>\n<li>每个输入都与每个输出相连，成为全连接层（fully connected layer）或稠密层（dense layer）。<br><img src=\"/1_linear_regression_files/1.png\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png\"></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-线性回归\"><a href=\"#1-线性回归\" class=\"headerlink\" title=\"1. 线性回归\"></a>1. 线性回归</h1><h2 id=\"1-1-线性回归的基本元素\"><a href=\"#1-1-线性回归的基本元素\" class=\"headerlink\" title=\"1.1 线性回归的基本元素\"></a>1.1 线性回归的基本元素</h2><ul>\n<li>基于几个简单的假设：<ul>\n<li>假设自变量x和因变量y之间的关系是线性的</li>\n<li>假设y的观测值是通过均值为0的噪声扰动后得到的</li>\n</ul>\n</li>\n<li>一些概念：<ul>\n<li>训练集：训练模型的数据集</li>\n<li>样本：每行数据</li>\n<li>标签：试图预测的值</li>\n<li>特征（feature，协变量（covariate））：预测所依赖的输入变量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-1-1-线性模型\"><a href=\"#1-1-1-线性模型\" class=\"headerlink\" title=\"1.1.1 线性模型\"></a>1.1.1 线性模型</h3><p>$$\\hat y &#x3D; w_1x1+w_2x_2+b \\rightarrow \\hat y &#x3D; \\mathbf{w}^T\\mathbf{x}+b$$</p>\n<ul>\n<li>$w_1$和$w_2$是权重</li>\n<li>$b$是偏置(bias),也叫偏移量(offset),截距(intercept)：当所有特征都取值为0时，预测值应该为多少。</li>\n<li>严格来说，上述公式是输入特征的一个 仿射变换（affine transformation）：仿射变换的特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项来进行平移（translation）。</li>\n<li>对于整个数据集，特征集合是一个矩阵：$\\hat y &#x3D; \\mathbf{X}\\mathbf{w}+b$</li>\n</ul>\n<h3 id=\"1-1-2-损失函数\"><a href=\"#1-1-2-损失函数\" class=\"headerlink\" title=\"1.1.2 损失函数\"></a>1.1.2 损失函数</h3><ul>\n<li>量化目标的实际值与预测值之间的差距。</li>\n<li>回归问题中最常用的损失函数是平方误差函数:<ul>\n<li>$l^{(i)}(\\mathbf{w},b) &#x3D; \\frac{1}{2}(\\hat y^{(i)}-y^{(i)})^2$</li>\n</ul>\n</li>\n<li>训练目标：寻找一组参数（$\\mathbf{w^*},b^*$）,使得所有样本的损失函数之和最小：<br>$$\\mathbf{w^*},b^* &#x3D; L(\\mathbf{w},b) \\underset{\\mathbf{w},b}{\\arg\\min} \\frac{1}{n}\\sum_{i&#x3D;1}^n l^{(i)}(\\mathbf{w},b)$$</li>\n</ul>\n<h3 id=\"1-1-3-解析解\"><a href=\"#1-1-3-解析解\" class=\"headerlink\" title=\"1.1.3 解析解\"></a>1.1.3 解析解</h3><p>$$\\mathbf{w^*} &#x3D; (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$</p>\n<h3 id=\"1-1-4-随机梯度下降\"><a href=\"#1-1-4-随机梯度下降\" class=\"headerlink\" title=\"1.1.4 随机梯度下降\"></a>1.1.4 随机梯度下降</h3><ul>\n<li>$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\partial_{(\\mathbf{w},b)}l^{(i)}(\\mathbf{w},b)$$</li>\n<li>通过不断地在损失函数递减的方向上更新参数来降低误差。</li>\n<li>梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本$\\mathcal{B}$，并计算损失函数关于这些样本的平均损失的梯度。</li>\n<li>算法过程：<ul>\n<li>1）初始化模型参数的值，如随机初始化</li>\n<li>2）从数据集中随机抽取一小批样本且在负梯度方向上更新参数</li>\n<li>3）重复步骤2直到收敛</li>\n<li>例如对于平方损失和放射变换：<ul>\n<li>$\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$</li>\n<li>$b \\leftarrow b - \\frac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$<ul>\n<li>$\\eta$是学习率</li>\n<li>$\\mathcal{B}$是小批量样本的大小(batch size)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失，这一挑战被称为泛化（generalization）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-1-5-用模型进行预测\"><a href=\"#1-1-5-用模型进行预测\" class=\"headerlink\" title=\"1.1.5 用模型进行预测\"></a>1.1.5 用模型进行预测</h3><p>$$\\hat y &#x3D; \\mathbf{\\hat w}^T\\mathbf{x}+\\hat b$$</p>\n<h2 id=\"1-2-矢量化加速\"><a href=\"#1-2-矢量化加速\" class=\"headerlink\" title=\"1.2 矢量化加速\"></a>1.2 矢量化加速</h2><ul>\n<li>在训练我们的模型时，我们经常希望能够同时处理整个小批量的样本。而不是在Python中编写开销高昂的for循环。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"comment\">#计时器</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Timer</span>: <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;记录多次运行时间&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.times = []</span><br><span class=\"line\">        self.start()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">start</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;启动计时器&quot;&quot;&quot;</span></span><br><span class=\"line\">        self.tik = time.time()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">stop</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;停止计时器并将时间记录在列表中&quot;&quot;&quot;</span></span><br><span class=\"line\">        self.times.append(time.time() - self.tik)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.times[-<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">avg</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回平均时间&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(self.times) / <span class=\"built_in\">len</span>(self.times)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">sum</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回时间总和&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(self.times)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">cumsum</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;返回累计时间&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> np.array(self.times).cumsum().tolist()</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 两个10000维向量</span></span><br><span class=\"line\">n = <span class=\"number\">10000</span></span><br><span class=\"line\">a = torch.ones(n)</span><br><span class=\"line\">b = torch.ones(n)</span><br><span class=\"line\">c = torch.zeros(n)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 for循环计算</span></span><br><span class=\"line\">timer = Timer()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">    c[i] = a[i] + b[i]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.5</span>f&#125;</span> sec&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 一次性计算</span></span><br><span class=\"line\">timer.start()</span><br><span class=\"line\">d = a + b</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.7</span>f&#125;</span> sec&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>0.11051 sec\n0.0000000 sec\n</code></pre>\n<h2 id=\"1-3-正态分布与平方损失\"><a href=\"#1-3-正态分布与平方损失\" class=\"headerlink\" title=\"1.3 正态分布与平方损失\"></a>1.3 正态分布与平方损失</h2><ul>\n<li>正态分布（高斯分布）：<br>$$p(x) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"comment\">#1 定义一个函数来计算高斯分布</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">normal</span>(<span class=\"params\">x,mu,sigma</span>):</span><br><span class=\"line\">    p = <span class=\"number\">1</span> / math.sqrt(<span class=\"number\">2</span> * math.pi * sigma**<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p * np.exp(-<span class=\"number\">0.5</span> / sigma**<span class=\"number\">2</span> * (x - mu)**<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 可视化高斯分布</span></span><br><span class=\"line\">x = np.arange(-<span class=\"number\">7</span>,<span class=\"number\">7</span>,<span class=\"number\">0.01</span>)</span><br><span class=\"line\"><span class=\"comment\">#均值和标准差对</span></span><br><span class=\"line\">params = [(<span class=\"number\">0</span>,<span class=\"number\">1</span>),(<span class=\"number\">0</span>,<span class=\"number\">2</span>),(<span class=\"number\">3</span>,<span class=\"number\">1</span>)]</span><br><span class=\"line\">d2l.plot(x,[normal(x,mu,sigma) <span class=\"keyword\">for</span> mu,sigma <span class=\"keyword\">in</span> params],xlabel=<span class=\"string\">&#x27;x&#x27;</span>,ylabel=<span class=\"string\">&#x27;p(x)&#x27;</span>,legend=[<span class=\"string\">f&#x27;mean <span class=\"subst\">&#123;mu&#125;</span>,std <span class=\"subst\">&#123;sigma&#125;</span>&#x27;</span> <span class=\"keyword\">for</span> mu,sigma <span class=\"keyword\">in</span> params])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"/1_linear_regression_files/1_linear_regression_4_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1_linear_regression_4_0.svg\"></p>\n<ul>\n<li>假设观测中包含噪声：$$y &#x3D; \\mathbf{w}^T\\mathbf{x}+b+\\epsilon$$<ul>\n<li>噪声$\\epsilon \\sim N(0,\\sigma^2)$</li>\n<li>因此有：(y服从正态分布，y的均值是$\\mathbf{w}^T\\mathbf{x}+b$，方差是$\\sigma^2$)<ul>\n<li>1）通过给定的$\\mathbf{x}$观测到特定y的似然（likelihood）：$$p(y|\\mathbf{x}) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(y-\\mathbf{w}^T\\mathbf{x}-b)^2}{2\\sigma^2})$$</li>\n<li>2）根据极大似然估计，参数（$\\mathbf{w},b$）的最优值使整个数据集的似然最大：$$p(\\mathbf{y}|\\mathbf{X}) &#x3D; \\prod \\limits_{i&#x3D;1}^n p(y^{(i)}|\\mathbf{x}^{(i)})$$</li>\n<li>3）根据极大似然估计法选择的估计量称为极大似然估计量。虽然使许多指数函数的乘积最大化看起来很困难，但是我们可以在不改变目标的前提下，通过最大化似然对数来简化：$$-log P(\\mathbf{y}|\\mathbf{X}) &#x3D; \\frac{n}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}\\sum \\limits_{i&#x3D;1}^n(y^{(i)}-\\mathbf{w}^T\\mathbf{x}^{(i)}-b)^2$$</li>\n<li>4）假设$\\sigma$是常数，则可以忽略第一项；第二项除了常数项$\\frac{1}{\\sigma^2}$之外，就是平方损失函数。因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"1-4-从线性回归到深度网络\"><a href=\"#1-4-从线性回归到深度网络\" class=\"headerlink\" title=\"1.4 从线性回归到深度网络\"></a>1.4 从线性回归到深度网络</h2><h3 id=\"1-4-1-神经网络\"><a href=\"#1-4-1-神经网络\" class=\"headerlink\" title=\"1.4.1 神经网络\"></a>1.4.1 神经网络</h3><ul>\n<li>线性回归是一个单层神经网络（隐去了权重和偏置）：</li>\n<li>每个输入都与每个输出相连，成为全连接层（fully connected layer）或稠密层（dense layer）。<br><img src=\"/1_linear_regression_files/1.png\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/1_linear_regression_files/1.png\"></li>\n</ul>"},{"title":"2.2 线性回归实现","date":"2024-02-03T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 2. 线性回归实现\n\n\n\n```python\nimport random\nimport torch\nfrom d2l import torch as d2l\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n```\n\n# 2.1 生成数据集\n- 使用线性模型参数w = [2, −3.4]⊤、b = 4.2 和噪声项ϵ~N(0,0.01)生成数据集及其标签：\n\n\n```python\n#1 生成数据集\ndef synthetic_data(w,b,num_examples): #@save\n    \"\"\"生成 y = Xw + b + 噪声。\"\"\"\n    X = torch.normal(0,1,(num_examples,len(w))) #生成服从正态分布的数据\n    y = torch.matmul(X,w) + b #矩阵乘法\n    y += torch.normal(0,0.01,y.shape) #加上噪声\n    return X,y.reshape((-1,1))\ntrue_w = torch.tensor([2,-3.4])\ntrue_b = 4.2\nfeatures,labels = synthetic_data(true_w,true_b,1000)\nprint('features:',features[0],'\\nlabel:',labels[0])\n\n#2 可以看到x1与y是线性关系\nd2l.set_figsize()\nd2l.plt.scatter(features[:,1].detach().numpy(),labels.detach().numpy(),1)\n\n```\n\n    features: tensor([1.2604, 0.9351]) \n    label: tensor([3.5493])\n    \n\n\n\n\n    <matplotlib.collections.PathCollection at 0x168296a63a0>\n\n\n\n\n    \n![svg](2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg)\n    \n\n\n## 2.2 读取数据集\n- 定义一个函数打乱样本并返回批量数据：\n    - 输入：批量大小、特征、标签\n    - 输出：批量数据\n\n\n```python\ndef data_iter(batch_size,features,labels):\n    num_examples = len(features) #1 样本数\n    indices = list(range(num_examples)) #2 生成下标\n    random.shuffle(indices) #3 打乱下标\n    for i in range(0,num_examples,batch_size): #4 遍历数据集，每次取出batch_size个样本\n        batch_indices = torch.tensor(indices[i:min(i+batch_size,num_examples)])\n        yield features[batch_indices],labels[batch_indices] #5 可迭代对象，每次返回batch_size个样本\n\nbatch_size = 10\nfor X,y in data_iter(batch_size,features,labels):\n    print(X,'\\n',y)\n    break\n```\n\n    tensor([[ 0.1474, -0.8037],\n            [ 0.3242,  0.3905],\n            [-0.1883,  0.1497],\n            [ 0.4741,  0.2937],\n            [ 1.6234, -0.3555],\n            [ 1.2714, -1.5737],\n            [-0.6498,  1.9078],\n            [ 0.6298,  0.4764],\n            [ 0.2344, -1.3566],\n            [-0.4173, -0.4298]]) \n     tensor([[ 7.2271],\n            [ 3.5186],\n            [ 3.3331],\n            [ 4.1500],\n            [ 8.6549],\n            [12.0805],\n            [-3.5749],\n            [ 3.8355],\n            [ 9.2662],\n            [ 4.8142]])\n    \n\n## 2.3 初始化模型参数\n- 从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，并将偏置初始化为0。\n\n\n\n```python\nw = torch.normal(0,0.01,size=(2,1),requires_grad=True)\nb = torch.zeros(1,requires_grad=True)\n```\n\n## 2.4 定义模型\n\n\n\n```python\ndef linreg(X,w,b): #@save\n    \"\"\"线性回归模型。\"\"\"\n    return torch.matmul(X,w) + b\n```\n\n## 2.5 定义损失函数\n- 平方损失函数\n\n\n```python\ndef squred_loss(y_hat,y): #@save\n    \"\"\"均方损失。\"\"\"\n    return (y_hat - y.reshape(y_hat.shape))**2/2\n```\n\n## 2.6 定义优化算法\n\n\n\n```python\ndef sge(params,lr,batch_size): #@save\n    \"\"\"小批量随机梯度下降。\"\"\"\n    with torch.no_grad(): #在该模块下，所有计算得出的tensor的requires_grad都自动设置为False ???\n        for param in params:\n            param -= lr*param.grad/batch_size #这是一个计算操作，会产生新的梯度信息，所以需要关闭梯度信息 ???\n            param.grad.zero_() #将param.grad清零\n```\n\n## 2.7 训练\n- 初始化参数\n- 重复以下训练，知道完成：\n    - 计算梯度$g \\leftarrow \\partial_{(\\mathbf{w},b)}\\frac{1}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}l(x^{(i)},y^{(i)},\\mathbf{w},b)$\n    - 更新参数$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\eta g$\n\n\n```python\n#1 超参数\nlr = 0.03\nnum_epochs = 3\nnet = linreg\nloss = squred_loss\n\n#2 训练\nfor epoch in range(num_epochs):\n    for X,y in data_iter(batch_size,features,labels):\n        l = loss(net(X,w,b),y) #l是有关小批量X和y的损失\n        l.sum().backward() #小批量的损失对模型参数求梯度,因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n        sge([w,b],lr,batch_size) #使用小批量随机梯度下降迭代模型参数\n    with torch.no_grad():\n        train_l = loss(net(features,w,b),labels)\n        print(f'epoch {epoch+1},loss {float(train_l.mean()):f}')\n\n#3 检验\nprint(f'w的估计误差：{true_w - w.reshape(true_w.shape)}')\nprint(f'b的估计误差：{true_b - b}')\n```\n\n    epoch 1,loss 0.030588\n    epoch 2,loss 0.000105\n    epoch 3,loss 0.000049\n    w的估计误差：tensor([ 0.0010, -0.0008], grad_fn=<SubBackward0>)\n    b的估计误差：tensor([0.0008], grad_fn=<RsubBackward1>)\n    \n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize.md","raw":"---\ntitle: 2.2 线性回归实现\ndate: 2024-2-3 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 2. 线性回归实现\n\n\n\n```python\nimport random\nimport torch\nfrom d2l import torch as d2l\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n```\n\n# 2.1 生成数据集\n- 使用线性模型参数w = [2, −3.4]⊤、b = 4.2 和噪声项ϵ~N(0,0.01)生成数据集及其标签：\n\n\n```python\n#1 生成数据集\ndef synthetic_data(w,b,num_examples): #@save\n    \"\"\"生成 y = Xw + b + 噪声。\"\"\"\n    X = torch.normal(0,1,(num_examples,len(w))) #生成服从正态分布的数据\n    y = torch.matmul(X,w) + b #矩阵乘法\n    y += torch.normal(0,0.01,y.shape) #加上噪声\n    return X,y.reshape((-1,1))\ntrue_w = torch.tensor([2,-3.4])\ntrue_b = 4.2\nfeatures,labels = synthetic_data(true_w,true_b,1000)\nprint('features:',features[0],'\\nlabel:',labels[0])\n\n#2 可以看到x1与y是线性关系\nd2l.set_figsize()\nd2l.plt.scatter(features[:,1].detach().numpy(),labels.detach().numpy(),1)\n\n```\n\n    features: tensor([1.2604, 0.9351]) \n    label: tensor([3.5493])\n    \n\n\n\n\n    <matplotlib.collections.PathCollection at 0x168296a63a0>\n\n\n\n\n    \n![svg](2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg)\n    \n\n\n## 2.2 读取数据集\n- 定义一个函数打乱样本并返回批量数据：\n    - 输入：批量大小、特征、标签\n    - 输出：批量数据\n\n\n```python\ndef data_iter(batch_size,features,labels):\n    num_examples = len(features) #1 样本数\n    indices = list(range(num_examples)) #2 生成下标\n    random.shuffle(indices) #3 打乱下标\n    for i in range(0,num_examples,batch_size): #4 遍历数据集，每次取出batch_size个样本\n        batch_indices = torch.tensor(indices[i:min(i+batch_size,num_examples)])\n        yield features[batch_indices],labels[batch_indices] #5 可迭代对象，每次返回batch_size个样本\n\nbatch_size = 10\nfor X,y in data_iter(batch_size,features,labels):\n    print(X,'\\n',y)\n    break\n```\n\n    tensor([[ 0.1474, -0.8037],\n            [ 0.3242,  0.3905],\n            [-0.1883,  0.1497],\n            [ 0.4741,  0.2937],\n            [ 1.6234, -0.3555],\n            [ 1.2714, -1.5737],\n            [-0.6498,  1.9078],\n            [ 0.6298,  0.4764],\n            [ 0.2344, -1.3566],\n            [-0.4173, -0.4298]]) \n     tensor([[ 7.2271],\n            [ 3.5186],\n            [ 3.3331],\n            [ 4.1500],\n            [ 8.6549],\n            [12.0805],\n            [-3.5749],\n            [ 3.8355],\n            [ 9.2662],\n            [ 4.8142]])\n    \n\n## 2.3 初始化模型参数\n- 从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，并将偏置初始化为0。\n\n\n\n```python\nw = torch.normal(0,0.01,size=(2,1),requires_grad=True)\nb = torch.zeros(1,requires_grad=True)\n```\n\n## 2.4 定义模型\n\n\n\n```python\ndef linreg(X,w,b): #@save\n    \"\"\"线性回归模型。\"\"\"\n    return torch.matmul(X,w) + b\n```\n\n## 2.5 定义损失函数\n- 平方损失函数\n\n\n```python\ndef squred_loss(y_hat,y): #@save\n    \"\"\"均方损失。\"\"\"\n    return (y_hat - y.reshape(y_hat.shape))**2/2\n```\n\n## 2.6 定义优化算法\n\n\n\n```python\ndef sge(params,lr,batch_size): #@save\n    \"\"\"小批量随机梯度下降。\"\"\"\n    with torch.no_grad(): #在该模块下，所有计算得出的tensor的requires_grad都自动设置为False ???\n        for param in params:\n            param -= lr*param.grad/batch_size #这是一个计算操作，会产生新的梯度信息，所以需要关闭梯度信息 ???\n            param.grad.zero_() #将param.grad清零\n```\n\n## 2.7 训练\n- 初始化参数\n- 重复以下训练，知道完成：\n    - 计算梯度$g \\leftarrow \\partial_{(\\mathbf{w},b)}\\frac{1}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}l(x^{(i)},y^{(i)},\\mathbf{w},b)$\n    - 更新参数$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\eta g$\n\n\n```python\n#1 超参数\nlr = 0.03\nnum_epochs = 3\nnet = linreg\nloss = squred_loss\n\n#2 训练\nfor epoch in range(num_epochs):\n    for X,y in data_iter(batch_size,features,labels):\n        l = loss(net(X,w,b),y) #l是有关小批量X和y的损失\n        l.sum().backward() #小批量的损失对模型参数求梯度,因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n        sge([w,b],lr,batch_size) #使用小批量随机梯度下降迭代模型参数\n    with torch.no_grad():\n        train_l = loss(net(features,w,b),labels)\n        print(f'epoch {epoch+1},loss {float(train_l.mean()):f}')\n\n#3 检验\nprint(f'w的估计误差：{true_w - w.reshape(true_w.shape)}')\nprint(f'b的估计误差：{true_b - b}')\n```\n\n    epoch 1,loss 0.030588\n    epoch 2,loss 0.000105\n    epoch 3,loss 0.000049\n    w的估计误差：tensor([ 0.0010, -0.0008], grad_fn=<SubBackward0>)\n    b的估计误差：tensor([0.0008], grad_fn=<RsubBackward1>)\n    \n","slug":"deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize","published":1,"updated":"2024-02-05T14:28:13.472Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859d00477svwbit3es0h","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"2-线性回归实现\"><a href=\"#2-线性回归实现\" class=\"headerlink\" title=\"2. 线性回归实现\"></a>2. 线性回归实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-1-生成数据集\"><a href=\"#2-1-生成数据集\" class=\"headerlink\" title=\"2.1 生成数据集\"></a>2.1 生成数据集</h1><ul>\n<li>使用线性模型参数w &#x3D; [2, −3.4]⊤、b &#x3D; 4.2 和噪声项ϵ~N(0,0.01)生成数据集及其标签：</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 生成数据集</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">synthetic_data</span>(<span class=\"params\">w,b,num_examples</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;生成 y = Xw + b + 噪声。&quot;&quot;&quot;</span></span><br><span class=\"line\">    X = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>,(num_examples,<span class=\"built_in\">len</span>(w))) <span class=\"comment\">#生成服从正态分布的数据</span></span><br><span class=\"line\">    y = torch.matmul(X,w) + b <span class=\"comment\">#矩阵乘法</span></span><br><span class=\"line\">    y += torch.normal(<span class=\"number\">0</span>,<span class=\"number\">0.01</span>,y.shape) <span class=\"comment\">#加上噪声</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> X,y.reshape((-<span class=\"number\">1</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>,-<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features,labels = synthetic_data(true_w,true_b,<span class=\"number\">1000</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;features:&#x27;</span>,features[<span class=\"number\">0</span>],<span class=\"string\">&#x27;\\nlabel:&#x27;</span>,labels[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 可以看到x1与y是线性关系</span></span><br><span class=\"line\">d2l.set_figsize()</span><br><span class=\"line\">d2l.plt.scatter(features[:,<span class=\"number\">1</span>].detach().numpy(),labels.detach().numpy(),<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>features: tensor([1.2604, 0.9351]) \nlabel: tensor([3.5493])\n\n\n\n\n\n&lt;matplotlib.collections.PathCollection at 0x168296a63a0&gt;\n</code></pre>\n<p><img src=\"/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg\"></p>\n<h2 id=\"2-2-读取数据集\"><a href=\"#2-2-读取数据集\" class=\"headerlink\" title=\"2.2 读取数据集\"></a>2.2 读取数据集</h2><ul>\n<li>定义一个函数打乱样本并返回批量数据：<ul>\n<li>输入：批量大小、特征、标签</li>\n<li>输出：批量数据</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">data_iter</span>(<span class=\"params\">batch_size,features,labels</span>):</span><br><span class=\"line\">    num_examples = <span class=\"built_in\">len</span>(features) <span class=\"comment\">#1 样本数</span></span><br><span class=\"line\">    indices = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(num_examples)) <span class=\"comment\">#2 生成下标</span></span><br><span class=\"line\">    random.shuffle(indices) <span class=\"comment\">#3 打乱下标</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,num_examples,batch_size): <span class=\"comment\">#4 遍历数据集，每次取出batch_size个样本</span></span><br><span class=\"line\">        batch_indices = torch.tensor(indices[i:<span class=\"built_in\">min</span>(i+batch_size,num_examples)])</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> features[batch_indices],labels[batch_indices] <span class=\"comment\">#5 可迭代对象，每次返回batch_size个样本</span></span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter(batch_size,features,labels):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X,<span class=\"string\">&#x27;\\n&#x27;</span>,y)</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.1474, -0.8037],\n        [ 0.3242,  0.3905],\n        [-0.1883,  0.1497],\n        [ 0.4741,  0.2937],\n        [ 1.6234, -0.3555],\n        [ 1.2714, -1.5737],\n        [-0.6498,  1.9078],\n        [ 0.6298,  0.4764],\n        [ 0.2344, -1.3566],\n        [-0.4173, -0.4298]]) \n tensor([[ 7.2271],\n        [ 3.5186],\n        [ 3.3331],\n        [ 4.1500],\n        [ 8.6549],\n        [12.0805],\n        [-3.5749],\n        [ 3.8355],\n        [ 9.2662],\n        [ 4.8142]])\n</code></pre>\n<h2 id=\"2-3-初始化模型参数\"><a href=\"#2-3-初始化模型参数\" class=\"headerlink\" title=\"2.3 初始化模型参数\"></a>2.3 初始化模型参数</h2><ul>\n<li>从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，并将偏置初始化为0。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">w = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">0.01</span>,size=(<span class=\"number\">2</span>,<span class=\"number\">1</span>),requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(<span class=\"number\">1</span>,requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-4-定义模型\"><a href=\"#2-4-定义模型\" class=\"headerlink\" title=\"2.4 定义模型\"></a>2.4 定义模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">linreg</span>(<span class=\"params\">X,w,b</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;线性回归模型。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.matmul(X,w) + b</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-5-定义损失函数\"><a href=\"#2-5-定义损失函数\" class=\"headerlink\" title=\"2.5 定义损失函数\"></a>2.5 定义损失函数</h2><ul>\n<li>平方损失函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">squred_loss</span>(<span class=\"params\">y_hat,y</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;均方损失。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (y_hat - y.reshape(y_hat.shape))**<span class=\"number\">2</span>/<span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-6-定义优化算法\"><a href=\"#2-6-定义优化算法\" class=\"headerlink\" title=\"2.6 定义优化算法\"></a>2.6 定义优化算法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sge</span>(<span class=\"params\">params,lr,batch_size</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;小批量随机梯度下降。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad(): <span class=\"comment\">#在该模块下，所有计算得出的tensor的requires_grad都自动设置为False ???</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">            param -= lr*param.grad/batch_size <span class=\"comment\">#这是一个计算操作，会产生新的梯度信息，所以需要关闭梯度信息 ???</span></span><br><span class=\"line\">            param.grad.zero_() <span class=\"comment\">#将param.grad清零</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-7-训练\"><a href=\"#2-7-训练\" class=\"headerlink\" title=\"2.7 训练\"></a>2.7 训练</h2><ul>\n<li>初始化参数</li>\n<li>重复以下训练，知道完成：<ul>\n<li>计算梯度$g \\leftarrow \\partial_{(\\mathbf{w},b)}\\frac{1}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}l(x^{(i)},y^{(i)},\\mathbf{w},b)$</li>\n<li>更新参数$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\eta g$</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 超参数</span></span><br><span class=\"line\">lr = <span class=\"number\">0.03</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\">net = linreg</span><br><span class=\"line\">loss = squred_loss</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter(batch_size,features,labels):</span><br><span class=\"line\">        l = loss(net(X,w,b),y) <span class=\"comment\">#l是有关小批量X和y的损失</span></span><br><span class=\"line\">        l.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#小批量的损失对模型参数求梯度,因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，</span></span><br><span class=\"line\">        sge([w,b],lr,batch_size) <span class=\"comment\">#使用小批量随机梯度下降迭代模型参数</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        train_l = loss(net(features,w,b),labels)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch+<span class=\"number\">1</span>&#125;</span>,loss <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 检验</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;w的估计误差：<span class=\"subst\">&#123;true_w - w.reshape(true_w.shape)&#125;</span>&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;b的估计误差：<span class=\"subst\">&#123;true_b - b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>epoch 1,loss 0.030588\nepoch 2,loss 0.000105\nepoch 3,loss 0.000049\nw的估计误差：tensor([ 0.0010, -0.0008], grad_fn=&lt;SubBackward0&gt;)\nb的估计误差：tensor([0.0008], grad_fn=&lt;RsubBackward1&gt;)\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"2-线性回归实现\"><a href=\"#2-线性回归实现\" class=\"headerlink\" title=\"2. 线性回归实现\"></a>2. 线性回归实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-1-生成数据集\"><a href=\"#2-1-生成数据集\" class=\"headerlink\" title=\"2.1 生成数据集\"></a>2.1 生成数据集</h1><ul>\n<li>使用线性模型参数w &#x3D; [2, −3.4]⊤、b &#x3D; 4.2 和噪声项ϵ~N(0,0.01)生成数据集及其标签：</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 生成数据集</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">synthetic_data</span>(<span class=\"params\">w,b,num_examples</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;生成 y = Xw + b + 噪声。&quot;&quot;&quot;</span></span><br><span class=\"line\">    X = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>,(num_examples,<span class=\"built_in\">len</span>(w))) <span class=\"comment\">#生成服从正态分布的数据</span></span><br><span class=\"line\">    y = torch.matmul(X,w) + b <span class=\"comment\">#矩阵乘法</span></span><br><span class=\"line\">    y += torch.normal(<span class=\"number\">0</span>,<span class=\"number\">0.01</span>,y.shape) <span class=\"comment\">#加上噪声</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> X,y.reshape((-<span class=\"number\">1</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>,-<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features,labels = synthetic_data(true_w,true_b,<span class=\"number\">1000</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;features:&#x27;</span>,features[<span class=\"number\">0</span>],<span class=\"string\">&#x27;\\nlabel:&#x27;</span>,labels[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 可以看到x1与y是线性关系</span></span><br><span class=\"line\">d2l.set_figsize()</span><br><span class=\"line\">d2l.plt.scatter(features[:,<span class=\"number\">1</span>].detach().numpy(),labels.detach().numpy(),<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>features: tensor([1.2604, 0.9351]) \nlabel: tensor([3.5493])\n\n\n\n\n\n&lt;matplotlib.collections.PathCollection at 0x168296a63a0&gt;\n</code></pre>\n<p><img src=\"/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/2_linear_regression_realize_files/2_linear_regression_realize_3_2.svg\"></p>\n<h2 id=\"2-2-读取数据集\"><a href=\"#2-2-读取数据集\" class=\"headerlink\" title=\"2.2 读取数据集\"></a>2.2 读取数据集</h2><ul>\n<li>定义一个函数打乱样本并返回批量数据：<ul>\n<li>输入：批量大小、特征、标签</li>\n<li>输出：批量数据</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">data_iter</span>(<span class=\"params\">batch_size,features,labels</span>):</span><br><span class=\"line\">    num_examples = <span class=\"built_in\">len</span>(features) <span class=\"comment\">#1 样本数</span></span><br><span class=\"line\">    indices = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(num_examples)) <span class=\"comment\">#2 生成下标</span></span><br><span class=\"line\">    random.shuffle(indices) <span class=\"comment\">#3 打乱下标</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,num_examples,batch_size): <span class=\"comment\">#4 遍历数据集，每次取出batch_size个样本</span></span><br><span class=\"line\">        batch_indices = torch.tensor(indices[i:<span class=\"built_in\">min</span>(i+batch_size,num_examples)])</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> features[batch_indices],labels[batch_indices] <span class=\"comment\">#5 可迭代对象，每次返回batch_size个样本</span></span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter(batch_size,features,labels):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X,<span class=\"string\">&#x27;\\n&#x27;</span>,y)</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.1474, -0.8037],\n        [ 0.3242,  0.3905],\n        [-0.1883,  0.1497],\n        [ 0.4741,  0.2937],\n        [ 1.6234, -0.3555],\n        [ 1.2714, -1.5737],\n        [-0.6498,  1.9078],\n        [ 0.6298,  0.4764],\n        [ 0.2344, -1.3566],\n        [-0.4173, -0.4298]]) \n tensor([[ 7.2271],\n        [ 3.5186],\n        [ 3.3331],\n        [ 4.1500],\n        [ 8.6549],\n        [12.0805],\n        [-3.5749],\n        [ 3.8355],\n        [ 9.2662],\n        [ 4.8142]])\n</code></pre>\n<h2 id=\"2-3-初始化模型参数\"><a href=\"#2-3-初始化模型参数\" class=\"headerlink\" title=\"2.3 初始化模型参数\"></a>2.3 初始化模型参数</h2><ul>\n<li>从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，并将偏置初始化为0。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">w = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">0.01</span>,size=(<span class=\"number\">2</span>,<span class=\"number\">1</span>),requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(<span class=\"number\">1</span>,requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-4-定义模型\"><a href=\"#2-4-定义模型\" class=\"headerlink\" title=\"2.4 定义模型\"></a>2.4 定义模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">linreg</span>(<span class=\"params\">X,w,b</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;线性回归模型。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.matmul(X,w) + b</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-5-定义损失函数\"><a href=\"#2-5-定义损失函数\" class=\"headerlink\" title=\"2.5 定义损失函数\"></a>2.5 定义损失函数</h2><ul>\n<li>平方损失函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">squred_loss</span>(<span class=\"params\">y_hat,y</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;均方损失。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (y_hat - y.reshape(y_hat.shape))**<span class=\"number\">2</span>/<span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-6-定义优化算法\"><a href=\"#2-6-定义优化算法\" class=\"headerlink\" title=\"2.6 定义优化算法\"></a>2.6 定义优化算法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sge</span>(<span class=\"params\">params,lr,batch_size</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;小批量随机梯度下降。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad(): <span class=\"comment\">#在该模块下，所有计算得出的tensor的requires_grad都自动设置为False ???</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">            param -= lr*param.grad/batch_size <span class=\"comment\">#这是一个计算操作，会产生新的梯度信息，所以需要关闭梯度信息 ???</span></span><br><span class=\"line\">            param.grad.zero_() <span class=\"comment\">#将param.grad清零</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-7-训练\"><a href=\"#2-7-训练\" class=\"headerlink\" title=\"2.7 训练\"></a>2.7 训练</h2><ul>\n<li>初始化参数</li>\n<li>重复以下训练，知道完成：<ul>\n<li>计算梯度$g \\leftarrow \\partial_{(\\mathbf{w},b)}\\frac{1}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}l(x^{(i)},y^{(i)},\\mathbf{w},b)$</li>\n<li>更新参数$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\eta g$</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 超参数</span></span><br><span class=\"line\">lr = <span class=\"number\">0.03</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\">net = linreg</span><br><span class=\"line\">loss = squred_loss</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter(batch_size,features,labels):</span><br><span class=\"line\">        l = loss(net(X,w,b),y) <span class=\"comment\">#l是有关小批量X和y的损失</span></span><br><span class=\"line\">        l.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#小批量的损失对模型参数求梯度,因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，</span></span><br><span class=\"line\">        sge([w,b],lr,batch_size) <span class=\"comment\">#使用小批量随机梯度下降迭代模型参数</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        train_l = loss(net(features,w,b),labels)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch+<span class=\"number\">1</span>&#125;</span>,loss <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 检验</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;w的估计误差：<span class=\"subst\">&#123;true_w - w.reshape(true_w.shape)&#125;</span>&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;b的估计误差：<span class=\"subst\">&#123;true_b - b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>epoch 1,loss 0.030588\nepoch 2,loss 0.000105\nepoch 3,loss 0.000049\nw的估计误差：tensor([ 0.0010, -0.0008], grad_fn=&lt;SubBackward0&gt;)\nb的估计误差：tensor([0.0008], grad_fn=&lt;RsubBackward1&gt;)\n</code></pre>"},{"title":"2.3 线性回归简洁实现","date":"2024-02-03T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 3 线性回归简洁实现\n\n\n```python\nimport numpy as np\nimport torch\nfrom torch.utils import data\nfrom d2l import torch as d2l\n\n#1 生成数据集\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\nfeatures, labels = d2l.synthetic_data(true_w, true_b, 1000) #生成方式为y = Xw + b + e，e为噪声默认为服从N(0,1)的正态分布\n\n\n#2 读取数据集\ndef load_array(data_arrays, batch_size, is_train=True):  #@save\n    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\nbatch_size = 10\ndata_iter = load_array((features, labels), batch_size)\nprint(next(iter(data_iter)))\n\n#3 定义模型\nfrom torch import nn\nnet = nn.Sequential(nn.Linear(2, 1))\n\n#4 初始化模型参数\nnet[0].weight.data.normal_(0, 0.01) #将第一层的权重初始化为均值为0，标准差为0.01的正态分布\nnet[0].bias.data.fill_(0) #将偏置初始化为0\n\n#5 定义损失函数\nloss = nn.MSELoss() #均方误差损失函数\n\n#6 定义优化算法\ntrainer = torch.optim.SGD(net.parameters(), lr=0.03)\n```\n\n    [tensor([[ 0.9365, -0.9840],\n            [ 0.9369,  1.5472],\n            [ 0.1462,  0.3326],\n            [-0.1900,  0.8358],\n            [ 1.1384, -1.4987],\n            [-0.4850, -0.8085],\n            [-2.1479, -0.8616],\n            [ 0.9232,  0.0479],\n            [ 0.3618, -0.7924],\n            [-1.2253,  0.1714]]), tensor([[ 9.4372],\n            [ 0.8145],\n            [ 3.3749],\n            [ 0.9582],\n            [11.5770],\n            [ 5.9775],\n            [ 2.8450],\n            [ 5.8905],\n            [ 7.6133],\n            [ 1.1836]])]\n    \n\n## 2.7 训练\n- 重复以下训练，知道完成：\n    - net(x)生成预测并计算损失l（正向传播）\n    - backward()计算梯度（反向传播）\n    - 优化器更新模型参数\n\n\n```python\n#1 超参数\nnum_epochs = 3\n\n#2 训练\nfor epoch in range(num_epochs):\n    for X,y in data_iter:\n        l = loss(net(X),y) #l是小批量X和y的损失\n        trainer.zero_grad()\n        l.backward()\n        trainer.step() #更新模型参数\n    l = loss(net(features),labels) #整个数据集的损失\n    print(f'epoch {epoch + 1}, loss {l:f}')\n\n#3 检验\nw = net[0].weight.data\nprint('w的估计误差：', true_w - w.reshape(true_w.shape))\nb = net[0].bias.data\nprint('b的估计误差：',true_b-b)\n```\n\n    epoch 1, loss 0.000270\n    epoch 2, loss 0.000103\n    epoch 3, loss 0.000103\n    w的估计误差： tensor([-0.0003, -0.0005])\n    b的估计误差： tensor([0.0007])\n    \n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/3_linear_regression_simplerealize.md","raw":"---\ntitle: 2.3 线性回归简洁实现\ndate: 2024-2-3 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 3 线性回归简洁实现\n\n\n```python\nimport numpy as np\nimport torch\nfrom torch.utils import data\nfrom d2l import torch as d2l\n\n#1 生成数据集\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\nfeatures, labels = d2l.synthetic_data(true_w, true_b, 1000) #生成方式为y = Xw + b + e，e为噪声默认为服从N(0,1)的正态分布\n\n\n#2 读取数据集\ndef load_array(data_arrays, batch_size, is_train=True):  #@save\n    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\nbatch_size = 10\ndata_iter = load_array((features, labels), batch_size)\nprint(next(iter(data_iter)))\n\n#3 定义模型\nfrom torch import nn\nnet = nn.Sequential(nn.Linear(2, 1))\n\n#4 初始化模型参数\nnet[0].weight.data.normal_(0, 0.01) #将第一层的权重初始化为均值为0，标准差为0.01的正态分布\nnet[0].bias.data.fill_(0) #将偏置初始化为0\n\n#5 定义损失函数\nloss = nn.MSELoss() #均方误差损失函数\n\n#6 定义优化算法\ntrainer = torch.optim.SGD(net.parameters(), lr=0.03)\n```\n\n    [tensor([[ 0.9365, -0.9840],\n            [ 0.9369,  1.5472],\n            [ 0.1462,  0.3326],\n            [-0.1900,  0.8358],\n            [ 1.1384, -1.4987],\n            [-0.4850, -0.8085],\n            [-2.1479, -0.8616],\n            [ 0.9232,  0.0479],\n            [ 0.3618, -0.7924],\n            [-1.2253,  0.1714]]), tensor([[ 9.4372],\n            [ 0.8145],\n            [ 3.3749],\n            [ 0.9582],\n            [11.5770],\n            [ 5.9775],\n            [ 2.8450],\n            [ 5.8905],\n            [ 7.6133],\n            [ 1.1836]])]\n    \n\n## 2.7 训练\n- 重复以下训练，知道完成：\n    - net(x)生成预测并计算损失l（正向传播）\n    - backward()计算梯度（反向传播）\n    - 优化器更新模型参数\n\n\n```python\n#1 超参数\nnum_epochs = 3\n\n#2 训练\nfor epoch in range(num_epochs):\n    for X,y in data_iter:\n        l = loss(net(X),y) #l是小批量X和y的损失\n        trainer.zero_grad()\n        l.backward()\n        trainer.step() #更新模型参数\n    l = loss(net(features),labels) #整个数据集的损失\n    print(f'epoch {epoch + 1}, loss {l:f}')\n\n#3 检验\nw = net[0].weight.data\nprint('w的估计误差：', true_w - w.reshape(true_w.shape))\nb = net[0].bias.data\nprint('b的估计误差：',true_b-b)\n```\n\n    epoch 1, loss 0.000270\n    epoch 2, loss 0.000103\n    epoch 3, loss 0.000103\n    w的估计误差： tensor([-0.0003, -0.0005])\n    b的估计误差： tensor([0.0007])\n    \n","slug":"deeplearning/code/pytorch/2_linear_neural_network/3_linear_regression_simplerealize","published":1,"updated":"2024-02-03T11:49:53.844Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859e004a7svw07ww6ao9","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"3-线性回归简洁实现\"><a href=\"#3-线性回归简洁实现\" class=\"headerlink\" title=\"3 线性回归简洁实现\"></a>3 线性回归简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 生成数据集</span></span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>, -<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features, labels = d2l.synthetic_data(true_w, true_b, <span class=\"number\">1000</span>) <span class=\"comment\">#生成方式为y = Xw + b + e，e为噪声默认为服从N(0,1)的正态分布</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_array</span>(<span class=\"params\">data_arrays, batch_size, is_train=<span class=\"literal\">True</span></span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;构造一个PyTorch数据迭代器。&quot;&quot;&quot;</span></span><br><span class=\"line\">    dataset = data.TensorDataset(*data_arrays)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)</span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\">data_iter = load_array((features, labels), batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(data_iter)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 定义模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">2</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 初始化模型参数</span></span><br><span class=\"line\">net[<span class=\"number\">0</span>].weight.data.normal_(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>) <span class=\"comment\">#将第一层的权重初始化为均值为0，标准差为0.01的正态分布</span></span><br><span class=\"line\">net[<span class=\"number\">0</span>].bias.data.fill_(<span class=\"number\">0</span>) <span class=\"comment\">#将偏置初始化为0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 定义损失函数</span></span><br><span class=\"line\">loss = nn.MSELoss() <span class=\"comment\">#均方误差损失函数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#6 定义优化算法</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.03</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>[tensor([[ 0.9365, -0.9840],\n        [ 0.9369,  1.5472],\n        [ 0.1462,  0.3326],\n        [-0.1900,  0.8358],\n        [ 1.1384, -1.4987],\n        [-0.4850, -0.8085],\n        [-2.1479, -0.8616],\n        [ 0.9232,  0.0479],\n        [ 0.3618, -0.7924],\n        [-1.2253,  0.1714]]), tensor([[ 9.4372],\n        [ 0.8145],\n        [ 3.3749],\n        [ 0.9582],\n        [11.5770],\n        [ 5.9775],\n        [ 2.8450],\n        [ 5.8905],\n        [ 7.6133],\n        [ 1.1836]])]\n</code></pre>\n<h2 id=\"2-7-训练\"><a href=\"#2-7-训练\" class=\"headerlink\" title=\"2.7 训练\"></a>2.7 训练</h2><ul>\n<li>重复以下训练，知道完成：<ul>\n<li>net(x)生成预测并计算损失l（正向传播）</li>\n<li>backward()计算梯度（反向传播）</li>\n<li>优化器更新模型参数</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 超参数</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        l = loss(net(X),y) <span class=\"comment\">#l是小批量X和y的损失</span></span><br><span class=\"line\">        trainer.zero_grad()</span><br><span class=\"line\">        l.backward()</span><br><span class=\"line\">        trainer.step() <span class=\"comment\">#更新模型参数</span></span><br><span class=\"line\">    l = loss(net(features),labels) <span class=\"comment\">#整个数据集的损失</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;l:f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 检验</span></span><br><span class=\"line\">w = net[<span class=\"number\">0</span>].weight.data</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的估计误差：&#x27;</span>, true_w - w.reshape(true_w.shape))</span><br><span class=\"line\">b = net[<span class=\"number\">0</span>].bias.data</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;b的估计误差：&#x27;</span>,true_b-b)</span><br></pre></td></tr></table></figure>\n\n<pre><code>epoch 1, loss 0.000270\nepoch 2, loss 0.000103\nepoch 3, loss 0.000103\nw的估计误差： tensor([-0.0003, -0.0005])\nb的估计误差： tensor([0.0007])\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-线性回归简洁实现\"><a href=\"#3-线性回归简洁实现\" class=\"headerlink\" title=\"3 线性回归简洁实现\"></a>3 线性回归简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 生成数据集</span></span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>, -<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features, labels = d2l.synthetic_data(true_w, true_b, <span class=\"number\">1000</span>) <span class=\"comment\">#生成方式为y = Xw + b + e，e为噪声默认为服从N(0,1)的正态分布</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 读取数据集</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_array</span>(<span class=\"params\">data_arrays, batch_size, is_train=<span class=\"literal\">True</span></span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;构造一个PyTorch数据迭代器。&quot;&quot;&quot;</span></span><br><span class=\"line\">    dataset = data.TensorDataset(*data_arrays)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)</span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\">data_iter = load_array((features, labels), batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(data_iter)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 定义模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">2</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 初始化模型参数</span></span><br><span class=\"line\">net[<span class=\"number\">0</span>].weight.data.normal_(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>) <span class=\"comment\">#将第一层的权重初始化为均值为0，标准差为0.01的正态分布</span></span><br><span class=\"line\">net[<span class=\"number\">0</span>].bias.data.fill_(<span class=\"number\">0</span>) <span class=\"comment\">#将偏置初始化为0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 定义损失函数</span></span><br><span class=\"line\">loss = nn.MSELoss() <span class=\"comment\">#均方误差损失函数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#6 定义优化算法</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.03</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>[tensor([[ 0.9365, -0.9840],\n        [ 0.9369,  1.5472],\n        [ 0.1462,  0.3326],\n        [-0.1900,  0.8358],\n        [ 1.1384, -1.4987],\n        [-0.4850, -0.8085],\n        [-2.1479, -0.8616],\n        [ 0.9232,  0.0479],\n        [ 0.3618, -0.7924],\n        [-1.2253,  0.1714]]), tensor([[ 9.4372],\n        [ 0.8145],\n        [ 3.3749],\n        [ 0.9582],\n        [11.5770],\n        [ 5.9775],\n        [ 2.8450],\n        [ 5.8905],\n        [ 7.6133],\n        [ 1.1836]])]\n</code></pre>\n<h2 id=\"2-7-训练\"><a href=\"#2-7-训练\" class=\"headerlink\" title=\"2.7 训练\"></a>2.7 训练</h2><ul>\n<li>重复以下训练，知道完成：<ul>\n<li>net(x)生成预测并计算损失l（正向传播）</li>\n<li>backward()计算梯度（反向传播）</li>\n<li>优化器更新模型参数</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 超参数</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        l = loss(net(X),y) <span class=\"comment\">#l是小批量X和y的损失</span></span><br><span class=\"line\">        trainer.zero_grad()</span><br><span class=\"line\">        l.backward()</span><br><span class=\"line\">        trainer.step() <span class=\"comment\">#更新模型参数</span></span><br><span class=\"line\">    l = loss(net(features),labels) <span class=\"comment\">#整个数据集的损失</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;l:f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 检验</span></span><br><span class=\"line\">w = net[<span class=\"number\">0</span>].weight.data</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的估计误差：&#x27;</span>, true_w - w.reshape(true_w.shape))</span><br><span class=\"line\">b = net[<span class=\"number\">0</span>].bias.data</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;b的估计误差：&#x27;</span>,true_b-b)</span><br></pre></td></tr></table></figure>\n\n<pre><code>epoch 1, loss 0.000270\nepoch 2, loss 0.000103\nepoch 3, loss 0.000103\nw的估计误差： tensor([-0.0003, -0.0005])\nb的估计误差： tensor([0.0007])\n</code></pre>"},{"title":"2.4 softmax回归","date":"2024-02-03T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 4 softmax回归\n## 4.1 分类问题\n- 独热编码（one-hot encoding）：$y\\in{(1,0,0),(0,1,0),(0,0,1)}\n## 4.2 网络架构\n- 为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）。$$o_1=x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b1$$ $$o_1=x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b2$$ $$o_1=x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b3$$\n![$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$](4img/1.png)\n![$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$](img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png)\n## 4.3 softmax全连接层的参数开销\n- $d$个输入和$q$个输出的全连接层，参数开销为$O(dq)$\n- 可以将成本减少到$O(\\frac{dq}{n})$,n可以灵活指定\n## 4.4 softmax运算\n- softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。$$\\hat{y}_j=\\frac{exp(o_j)}{\\sum_{i=1}^qexp(o_i)}$$\n- 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型（linear model）。\n## 4.5 小批量样本的矢量化\n- 批量：$\\mathbf{X}$；特征维度：$d$；批量大小：$n$；类别数：$q$；\n\n\n- 批量样本特征：$\\mathbf{X}\\in\\mathbb{R}^{n\\times d}$；权重：$\\mathbf{W}\\in\\mathbb{R}^{d\\times q}$；偏置：$\\mathbf{b}\\in\\mathbb{R}^{1\\times q}$ $$\\mathbf{O}=\\mathbf{XW}+\\mathbf{b}$$ $$\\hat{\\mathbf{Y}}=\\text{softmax}(\\mathbf{O})$$\n## 4.6 损失函数\n- 使用极大似然估计\n### 4.6.1 对数似然\n- softmax函数输出向量$\\hat{\\mathbf{Y}}$：x属于各个类别的概率分布（$\\hat{y}_1=P(y=猫|x),\\hat{y}_2=P(y=狗|x),\\hat{y}_3=P(y=鸡|x)$）\n- 1）根据最大似然估计，需要最大化观测数据的联合概率。$$P(\\mathbf{Y}|\\mathbf{X})=\\prod_{i=1}^nP(\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)})$$\n    - $\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)}$：对于样本i，特征向量为：$\\mathbf{x}^{(i)}$，标签向量为：$\\mathbf{y}^{(i)}$\n    - $y_j^{(i)}$：样本i的标签向量中属于类别j的概率\n- 2）相当于最小化负对数似然(损失函数)：$$-\\log P(\\mathbf{Y}|\\mathbf{X})=-\\sum_{i=1}^n\\log P(y^{(i)}|\\mathbf{x}^{(i)})=\\sum_{i=1}^nl(\\mathbf{y}^{(i)},\\mathbf{\\hat{y}}^{(i)})$$\n    - 损失函数为（交叉熵损失 cross-entropy loss）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})=-\\sum_{j=1}^qy_j\\log\\hat{y}_j$$\n```\n由于y是一个长度为q的独热编码向量，所以除了一个项以外的所有项j都消失了。由于所有yˆj都是预测的概率，所以它们的对数永远不会大于0。因此，如果正确地预测实际标签，即如果实际标签P(y | x) = 1，则损失函数不能进一步最小化。注意，这往往是不可能的。例如，数据集中可能存在标签噪声（比如某些样本可能被误标），或输入特征没有足够的信息来完美地对每一个样本分类。？？？\n```\n\n\n### 4.6.2 softmax及其导数\n- 对损失函数：$$\\begin{aligned} l(\\mathbf{y},\\mathbf{\\hat{y}})&=-\\sum_{j=1}^qy_j\\log\\hat{y}_j \\\\ &=-\\sum_{j=1}^qy_j\\log\\frac{\\exp(o_j)}{\\sum_{i=1}^q\\exp(o_i)} \\\\ &=-\\sum_{j=1}^q(y_j(o_j-\\log\\sum_{i=1}^q\\exp(o_i))) \\\\ &=\\sum_{j=1}^qy_j\\log\\sum_{i=1}^q\\exp(o_i)-\\sum_{j=1}^qy_jo_j \\\\ &=\\log\\sum_{i=1}^q\\exp(o_i)-\\sum_{j=1}^qy_jo_j \\end{aligned}$$\n- 损失函数对$o_j$的导数(log以e为底)：$$\\frac{\\partial l(\\mathbf{y},\\mathbf{\\hat{y}})}{\\partial o_j}=\\frac{\\exp(o_j)}{\\sum_{i=1}^q\\exp(o_i)}-y_j=softmax(o)_j-y_j$$\n    - **这与我们在回归中看到的非常相似，其中梯度是观测值y和估计值yˆ之间的差异。这不是巧合，在任何指数族分布模型中对数似然的梯度正是由此得出的。这使梯度计算在实践中变得容易很多。**\n\n### 4.6.3 交叉熵损失\n- 对于标签$\\mathbf{y}$，我们可以使用与以前相同的表示形式。唯一的区别是，我们现在用一个概率向量表示，如(0.1, 0.2, 0.7)，而不是仅包含二元项的向量(0, 0, 1)。\n- 交叉熵损失（分类问题最常用）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})=-\\sum_{j=1}^qy_j\\log\\hat{y}_j$$\n\n## 4.7 信息论基础\n- 信息论（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。\n### 4.7.1 熵(entropy)\n$$H[P]=-\\sum_{j}-P(j)\\log P(j)$$\n- 量化数据中的信息内容\n- 为了对从分布$p$中取样的数据进行编码，至少需要$H[p]$个纳特（nat）对其进行编码。（纳特相当于比特，底数是$e$，1nat= $\\frac{1}{\\log(2)}$ bit）\n### 4.7.2 信息量\n- 压缩与预测：如果我们很容易预测下一个数据，那么这个数据就很容易压缩。\n- 如果我们不能完全预测每一个事件，那么我们会感到“惊异”。克劳德·香农决定用信息量$-\\log P(j)$来量化这种惊异度。在观察一个事件j时，并赋予它（主观）概率 $P(j)$。当我们赋予一个事件较低的概率时，我们的惊异会更大，该事件的信息量也就更大。\n- 熵：当分配的概率真正匹配数据生成过程时的信息量的期望。\n\n### 4.7.3 交叉熵\n- 如果把熵$H(p)$当作“知道真实概率的人所经历的惊异程度”，那么交叉熵从P到Q，记为H(P, Q)。我们可以把交叉熵想象为“主观概率为Q的观察者在看到根据概率P生成的数据时的预期惊异”。当P = Q时，交叉熵达到最低。在这种情况下，从P到Q的交叉熵是H(P, P) = H(P)。\n- 可以从两方面来考虑交叉熵分类目标：（i）最大化观测数据的似然；（ii）最小化传达标签所需的惊异。\n\n## 4.8 模型预测和评估\n- 使用预测概率最高的类别作为输出类别。如果预测与实际类别（标签）一致，则预测是正确的。\n- 用精度（accuracy）来评估模型的性能。精度=正确个数/总个数\n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/4_softmax_regression.md","raw":"---\ntitle: 2.4 softmax回归\ndate: 2024-2-3 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 4 softmax回归\n## 4.1 分类问题\n- 独热编码（one-hot encoding）：$y\\in{(1,0,0),(0,1,0),(0,0,1)}\n## 4.2 网络架构\n- 为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）。$$o_1=x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b1$$ $$o_1=x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b2$$ $$o_1=x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b3$$\n![$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$](4img/1.png)\n![$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$](img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png)\n## 4.3 softmax全连接层的参数开销\n- $d$个输入和$q$个输出的全连接层，参数开销为$O(dq)$\n- 可以将成本减少到$O(\\frac{dq}{n})$,n可以灵活指定\n## 4.4 softmax运算\n- softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。$$\\hat{y}_j=\\frac{exp(o_j)}{\\sum_{i=1}^qexp(o_i)}$$\n- 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型（linear model）。\n## 4.5 小批量样本的矢量化\n- 批量：$\\mathbf{X}$；特征维度：$d$；批量大小：$n$；类别数：$q$；\n\n\n- 批量样本特征：$\\mathbf{X}\\in\\mathbb{R}^{n\\times d}$；权重：$\\mathbf{W}\\in\\mathbb{R}^{d\\times q}$；偏置：$\\mathbf{b}\\in\\mathbb{R}^{1\\times q}$ $$\\mathbf{O}=\\mathbf{XW}+\\mathbf{b}$$ $$\\hat{\\mathbf{Y}}=\\text{softmax}(\\mathbf{O})$$\n## 4.6 损失函数\n- 使用极大似然估计\n### 4.6.1 对数似然\n- softmax函数输出向量$\\hat{\\mathbf{Y}}$：x属于各个类别的概率分布（$\\hat{y}_1=P(y=猫|x),\\hat{y}_2=P(y=狗|x),\\hat{y}_3=P(y=鸡|x)$）\n- 1）根据最大似然估计，需要最大化观测数据的联合概率。$$P(\\mathbf{Y}|\\mathbf{X})=\\prod_{i=1}^nP(\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)})$$\n    - $\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)}$：对于样本i，特征向量为：$\\mathbf{x}^{(i)}$，标签向量为：$\\mathbf{y}^{(i)}$\n    - $y_j^{(i)}$：样本i的标签向量中属于类别j的概率\n- 2）相当于最小化负对数似然(损失函数)：$$-\\log P(\\mathbf{Y}|\\mathbf{X})=-\\sum_{i=1}^n\\log P(y^{(i)}|\\mathbf{x}^{(i)})=\\sum_{i=1}^nl(\\mathbf{y}^{(i)},\\mathbf{\\hat{y}}^{(i)})$$\n    - 损失函数为（交叉熵损失 cross-entropy loss）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})=-\\sum_{j=1}^qy_j\\log\\hat{y}_j$$\n```\n由于y是一个长度为q的独热编码向量，所以除了一个项以外的所有项j都消失了。由于所有yˆj都是预测的概率，所以它们的对数永远不会大于0。因此，如果正确地预测实际标签，即如果实际标签P(y | x) = 1，则损失函数不能进一步最小化。注意，这往往是不可能的。例如，数据集中可能存在标签噪声（比如某些样本可能被误标），或输入特征没有足够的信息来完美地对每一个样本分类。？？？\n```\n\n\n### 4.6.2 softmax及其导数\n- 对损失函数：$$\\begin{aligned} l(\\mathbf{y},\\mathbf{\\hat{y}})&=-\\sum_{j=1}^qy_j\\log\\hat{y}_j \\\\ &=-\\sum_{j=1}^qy_j\\log\\frac{\\exp(o_j)}{\\sum_{i=1}^q\\exp(o_i)} \\\\ &=-\\sum_{j=1}^q(y_j(o_j-\\log\\sum_{i=1}^q\\exp(o_i))) \\\\ &=\\sum_{j=1}^qy_j\\log\\sum_{i=1}^q\\exp(o_i)-\\sum_{j=1}^qy_jo_j \\\\ &=\\log\\sum_{i=1}^q\\exp(o_i)-\\sum_{j=1}^qy_jo_j \\end{aligned}$$\n- 损失函数对$o_j$的导数(log以e为底)：$$\\frac{\\partial l(\\mathbf{y},\\mathbf{\\hat{y}})}{\\partial o_j}=\\frac{\\exp(o_j)}{\\sum_{i=1}^q\\exp(o_i)}-y_j=softmax(o)_j-y_j$$\n    - **这与我们在回归中看到的非常相似，其中梯度是观测值y和估计值yˆ之间的差异。这不是巧合，在任何指数族分布模型中对数似然的梯度正是由此得出的。这使梯度计算在实践中变得容易很多。**\n\n### 4.6.3 交叉熵损失\n- 对于标签$\\mathbf{y}$，我们可以使用与以前相同的表示形式。唯一的区别是，我们现在用一个概率向量表示，如(0.1, 0.2, 0.7)，而不是仅包含二元项的向量(0, 0, 1)。\n- 交叉熵损失（分类问题最常用）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})=-\\sum_{j=1}^qy_j\\log\\hat{y}_j$$\n\n## 4.7 信息论基础\n- 信息论（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。\n### 4.7.1 熵(entropy)\n$$H[P]=-\\sum_{j}-P(j)\\log P(j)$$\n- 量化数据中的信息内容\n- 为了对从分布$p$中取样的数据进行编码，至少需要$H[p]$个纳特（nat）对其进行编码。（纳特相当于比特，底数是$e$，1nat= $\\frac{1}{\\log(2)}$ bit）\n### 4.7.2 信息量\n- 压缩与预测：如果我们很容易预测下一个数据，那么这个数据就很容易压缩。\n- 如果我们不能完全预测每一个事件，那么我们会感到“惊异”。克劳德·香农决定用信息量$-\\log P(j)$来量化这种惊异度。在观察一个事件j时，并赋予它（主观）概率 $P(j)$。当我们赋予一个事件较低的概率时，我们的惊异会更大，该事件的信息量也就更大。\n- 熵：当分配的概率真正匹配数据生成过程时的信息量的期望。\n\n### 4.7.3 交叉熵\n- 如果把熵$H(p)$当作“知道真实概率的人所经历的惊异程度”，那么交叉熵从P到Q，记为H(P, Q)。我们可以把交叉熵想象为“主观概率为Q的观察者在看到根据概率P生成的数据时的预期惊异”。当P = Q时，交叉熵达到最低。在这种情况下，从P到Q的交叉熵是H(P, P) = H(P)。\n- 可以从两方面来考虑交叉熵分类目标：（i）最大化观测数据的似然；（ii）最小化传达标签所需的惊异。\n\n## 4.8 模型预测和评估\n- 使用预测概率最高的类别作为输出类别。如果预测与实际类别（标签）一致，则预测是正确的。\n- 用精度（accuracy）来评估模型的性能。精度=正确个数/总个数\n","slug":"deeplearning/code/pytorch/2_linear_neural_network/4_softmax_regression","published":1,"updated":"2024-02-05T14:30:01.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859e004f7svwd2g02hpy","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"4-softmax回归\"><a href=\"#4-softmax回归\" class=\"headerlink\" title=\"4 softmax回归\"></a>4 softmax回归</h1><h2 id=\"4-1-分类问题\"><a href=\"#4-1-分类问题\" class=\"headerlink\" title=\"4.1 分类问题\"></a>4.1 分类问题</h2><ul>\n<li>独热编码（one-hot encoding）：$y\\in{(1,0,0),(0,1,0),(0,0,1)}</li>\n</ul>\n<h2 id=\"4-2-网络架构\"><a href=\"#4-2-网络架构\" class=\"headerlink\" title=\"4.2 网络架构\"></a>4.2 网络架构</h2><ul>\n<li>为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）。$$o_1&#x3D;x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b1$$ $$o_1&#x3D;x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b2$$ $$o_1&#x3D;x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b3$$<br><img src=\"/4img/1.png\" alt=\"$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png\" alt=\"$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$\"></li>\n</ul>\n<h2 id=\"4-3-softmax全连接层的参数开销\"><a href=\"#4-3-softmax全连接层的参数开销\" class=\"headerlink\" title=\"4.3 softmax全连接层的参数开销\"></a>4.3 softmax全连接层的参数开销</h2><ul>\n<li>$d$个输入和$q$个输出的全连接层，参数开销为$O(dq)$</li>\n<li>可以将成本减少到$O(\\frac{dq}{n})$,n可以灵活指定</li>\n</ul>\n<h2 id=\"4-4-softmax运算\"><a href=\"#4-4-softmax运算\" class=\"headerlink\" title=\"4.4 softmax运算\"></a>4.4 softmax运算</h2><ul>\n<li>softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。$$\\hat{y}<em>j&#x3D;\\frac{exp(o_j)}{\\sum</em>{i&#x3D;1}^qexp(o_i)}$$</li>\n<li>尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型（linear model）。</li>\n</ul>\n<h2 id=\"4-5-小批量样本的矢量化\"><a href=\"#4-5-小批量样本的矢量化\" class=\"headerlink\" title=\"4.5 小批量样本的矢量化\"></a>4.5 小批量样本的矢量化</h2><ul>\n<li><p>批量：$\\mathbf{X}$；特征维度：$d$；批量大小：$n$；类别数：$q$；</p>\n</li>\n<li><p>批量样本特征：$\\mathbf{X}\\in\\mathbb{R}^{n\\times d}$；权重：$\\mathbf{W}\\in\\mathbb{R}^{d\\times q}$；偏置：$\\mathbf{b}\\in\\mathbb{R}^{1\\times q}$ $$\\mathbf{O}&#x3D;\\mathbf{XW}+\\mathbf{b}$$ $$\\hat{\\mathbf{Y}}&#x3D;\\text{softmax}(\\mathbf{O})$$</p>\n</li>\n</ul>\n<h2 id=\"4-6-损失函数\"><a href=\"#4-6-损失函数\" class=\"headerlink\" title=\"4.6 损失函数\"></a>4.6 损失函数</h2><ul>\n<li>使用极大似然估计</li>\n</ul>\n<h3 id=\"4-6-1-对数似然\"><a href=\"#4-6-1-对数似然\" class=\"headerlink\" title=\"4.6.1 对数似然\"></a>4.6.1 对数似然</h3><ul>\n<li>softmax函数输出向量$\\hat{\\mathbf{Y}}$：x属于各个类别的概率分布（$\\hat{y}_1&#x3D;P(y&#x3D;猫|x),\\hat{y}_2&#x3D;P(y&#x3D;狗|x),\\hat{y}_3&#x3D;P(y&#x3D;鸡|x)$）</li>\n<li>1）根据最大似然估计，需要最大化观测数据的联合概率。$$P(\\mathbf{Y}|\\mathbf{X})&#x3D;\\prod_{i&#x3D;1}^nP(\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)})$$<ul>\n<li>$\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)}$：对于样本i，特征向量为：$\\mathbf{x}^{(i)}$，标签向量为：$\\mathbf{y}^{(i)}$</li>\n<li>$y_j^{(i)}$：样本i的标签向量中属于类别j的概率</li>\n</ul>\n</li>\n<li>2）相当于最小化负对数似然(损失函数)：$$-\\log P(\\mathbf{Y}|\\mathbf{X})&#x3D;-\\sum_{i&#x3D;1}^n\\log P(y^{(i)}|\\mathbf{x}^{(i)})&#x3D;\\sum_{i&#x3D;1}^nl(\\mathbf{y}^{(i)},\\mathbf{\\hat{y}}^{(i)})$$<ul>\n<li>损失函数为（交叉熵损失 cross-entropy loss）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}_j$$<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">由于y是一个长度为q的独热编码向量，所以除了一个项以外的所有项j都消失了。由于所有yˆj都是预测的概率，所以它们的对数永远不会大于0。因此，如果正确地预测实际标签，即如果实际标签P(y | x) = 1，则损失函数不能进一步最小化。注意，这往往是不可能的。例如，数据集中可能存在标签噪声（比如某些样本可能被误标），或输入特征没有足够的信息来完美地对每一个样本分类。？？？</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-6-2-softmax及其导数\"><a href=\"#4-6-2-softmax及其导数\" class=\"headerlink\" title=\"4.6.2 softmax及其导数\"></a>4.6.2 softmax及其导数</h3><ul>\n<li>对损失函数：$$\\begin{aligned} l(\\mathbf{y},\\mathbf{\\hat{y}})&amp;&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}<em>j \\ &amp;&#x3D;-\\sum</em>{j&#x3D;1}^qy_j\\log\\frac{\\exp(o_j)}{\\sum_{i&#x3D;1}^q\\exp(o_i)} \\ &amp;&#x3D;-\\sum_{j&#x3D;1}^q(y_j(o_j-\\log\\sum_{i&#x3D;1}^q\\exp(o_i))) \\ &amp;&#x3D;\\sum_{j&#x3D;1}^qy_j\\log\\sum_{i&#x3D;1}^q\\exp(o_i)-\\sum_{j&#x3D;1}^qy_jo_j \\ &amp;&#x3D;\\log\\sum_{i&#x3D;1}^q\\exp(o_i)-\\sum_{j&#x3D;1}^qy_jo_j \\end{aligned}$$</li>\n<li>损失函数对$o_j$的导数(log以e为底)：$$\\frac{\\partial l(\\mathbf{y},\\mathbf{\\hat{y}})}{\\partial o_j}&#x3D;\\frac{\\exp(o_j)}{\\sum_{i&#x3D;1}^q\\exp(o_i)}-y_j&#x3D;softmax(o)_j-y_j$$<ul>\n<li><strong>这与我们在回归中看到的非常相似，其中梯度是观测值y和估计值yˆ之间的差异。这不是巧合，在任何指数族分布模型中对数似然的梯度正是由此得出的。这使梯度计算在实践中变得容易很多。</strong></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-6-3-交叉熵损失\"><a href=\"#4-6-3-交叉熵损失\" class=\"headerlink\" title=\"4.6.3 交叉熵损失\"></a>4.6.3 交叉熵损失</h3><ul>\n<li>对于标签$\\mathbf{y}$，我们可以使用与以前相同的表示形式。唯一的区别是，我们现在用一个概率向量表示，如(0.1, 0.2, 0.7)，而不是仅包含二元项的向量(0, 0, 1)。</li>\n<li>交叉熵损失（分类问题最常用）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}_j$$</li>\n</ul>\n<h2 id=\"4-7-信息论基础\"><a href=\"#4-7-信息论基础\" class=\"headerlink\" title=\"4.7 信息论基础\"></a>4.7 信息论基础</h2><ul>\n<li>信息论（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。</li>\n</ul>\n<h3 id=\"4-7-1-熵-entropy\"><a href=\"#4-7-1-熵-entropy\" class=\"headerlink\" title=\"4.7.1 熵(entropy)\"></a>4.7.1 熵(entropy)</h3><p>$$H[P]&#x3D;-\\sum_{j}-P(j)\\log P(j)$$</p>\n<ul>\n<li>量化数据中的信息内容</li>\n<li>为了对从分布$p$中取样的数据进行编码，至少需要$H[p]$个纳特（nat）对其进行编码。（纳特相当于比特，底数是$e$，1nat&#x3D; $\\frac{1}{\\log(2)}$ bit）</li>\n</ul>\n<h3 id=\"4-7-2-信息量\"><a href=\"#4-7-2-信息量\" class=\"headerlink\" title=\"4.7.2 信息量\"></a>4.7.2 信息量</h3><ul>\n<li>压缩与预测：如果我们很容易预测下一个数据，那么这个数据就很容易压缩。</li>\n<li>如果我们不能完全预测每一个事件，那么我们会感到“惊异”。克劳德·香农决定用信息量$-\\log P(j)$来量化这种惊异度。在观察一个事件j时，并赋予它（主观）概率 $P(j)$。当我们赋予一个事件较低的概率时，我们的惊异会更大，该事件的信息量也就更大。</li>\n<li>熵：当分配的概率真正匹配数据生成过程时的信息量的期望。</li>\n</ul>\n<h3 id=\"4-7-3-交叉熵\"><a href=\"#4-7-3-交叉熵\" class=\"headerlink\" title=\"4.7.3 交叉熵\"></a>4.7.3 交叉熵</h3><ul>\n<li>如果把熵$H(p)$当作“知道真实概率的人所经历的惊异程度”，那么交叉熵从P到Q，记为H(P, Q)。我们可以把交叉熵想象为“主观概率为Q的观察者在看到根据概率P生成的数据时的预期惊异”。当P &#x3D; Q时，交叉熵达到最低。在这种情况下，从P到Q的交叉熵是H(P, P) &#x3D; H(P)。</li>\n<li>可以从两方面来考虑交叉熵分类目标：（i）最大化观测数据的似然；（ii）最小化传达标签所需的惊异。</li>\n</ul>\n<h2 id=\"4-8-模型预测和评估\"><a href=\"#4-8-模型预测和评估\" class=\"headerlink\" title=\"4.8 模型预测和评估\"></a>4.8 模型预测和评估</h2><ul>\n<li>使用预测概率最高的类别作为输出类别。如果预测与实际类别（标签）一致，则预测是正确的。</li>\n<li>用精度（accuracy）来评估模型的性能。精度&#x3D;正确个数&#x2F;总个数</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"4-softmax回归\"><a href=\"#4-softmax回归\" class=\"headerlink\" title=\"4 softmax回归\"></a>4 softmax回归</h1><h2 id=\"4-1-分类问题\"><a href=\"#4-1-分类问题\" class=\"headerlink\" title=\"4.1 分类问题\"></a>4.1 分类问题</h2><ul>\n<li>独热编码（one-hot encoding）：$y\\in{(1,0,0),(0,1,0),(0,0,1)}</li>\n</ul>\n<h2 id=\"4-2-网络架构\"><a href=\"#4-2-网络架构\" class=\"headerlink\" title=\"4.2 网络架构\"></a>4.2 网络架构</h2><ul>\n<li>为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）。$$o_1&#x3D;x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b1$$ $$o_1&#x3D;x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b2$$ $$o_1&#x3D;x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b3$$<br><img src=\"/4img/1.png\" alt=\"$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/4img/1.png\" alt=\"$\\mathfb{o}=\\mathfb{W}\\mathfb{x}+\\mathfb{b}$\"></li>\n</ul>\n<h2 id=\"4-3-softmax全连接层的参数开销\"><a href=\"#4-3-softmax全连接层的参数开销\" class=\"headerlink\" title=\"4.3 softmax全连接层的参数开销\"></a>4.3 softmax全连接层的参数开销</h2><ul>\n<li>$d$个输入和$q$个输出的全连接层，参数开销为$O(dq)$</li>\n<li>可以将成本减少到$O(\\frac{dq}{n})$,n可以灵活指定</li>\n</ul>\n<h2 id=\"4-4-softmax运算\"><a href=\"#4-4-softmax运算\" class=\"headerlink\" title=\"4.4 softmax运算\"></a>4.4 softmax运算</h2><ul>\n<li>softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。$$\\hat{y}<em>j&#x3D;\\frac{exp(o_j)}{\\sum</em>{i&#x3D;1}^qexp(o_i)}$$</li>\n<li>尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型（linear model）。</li>\n</ul>\n<h2 id=\"4-5-小批量样本的矢量化\"><a href=\"#4-5-小批量样本的矢量化\" class=\"headerlink\" title=\"4.5 小批量样本的矢量化\"></a>4.5 小批量样本的矢量化</h2><ul>\n<li><p>批量：$\\mathbf{X}$；特征维度：$d$；批量大小：$n$；类别数：$q$；</p>\n</li>\n<li><p>批量样本特征：$\\mathbf{X}\\in\\mathbb{R}^{n\\times d}$；权重：$\\mathbf{W}\\in\\mathbb{R}^{d\\times q}$；偏置：$\\mathbf{b}\\in\\mathbb{R}^{1\\times q}$ $$\\mathbf{O}&#x3D;\\mathbf{XW}+\\mathbf{b}$$ $$\\hat{\\mathbf{Y}}&#x3D;\\text{softmax}(\\mathbf{O})$$</p>\n</li>\n</ul>\n<h2 id=\"4-6-损失函数\"><a href=\"#4-6-损失函数\" class=\"headerlink\" title=\"4.6 损失函数\"></a>4.6 损失函数</h2><ul>\n<li>使用极大似然估计</li>\n</ul>\n<h3 id=\"4-6-1-对数似然\"><a href=\"#4-6-1-对数似然\" class=\"headerlink\" title=\"4.6.1 对数似然\"></a>4.6.1 对数似然</h3><ul>\n<li>softmax函数输出向量$\\hat{\\mathbf{Y}}$：x属于各个类别的概率分布（$\\hat{y}_1&#x3D;P(y&#x3D;猫|x),\\hat{y}_2&#x3D;P(y&#x3D;狗|x),\\hat{y}_3&#x3D;P(y&#x3D;鸡|x)$）</li>\n<li>1）根据最大似然估计，需要最大化观测数据的联合概率。$$P(\\mathbf{Y}|\\mathbf{X})&#x3D;\\prod_{i&#x3D;1}^nP(\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)})$$<ul>\n<li>$\\mathbf{y}^{(i)}|\\mathbf{x}^{(i)}$：对于样本i，特征向量为：$\\mathbf{x}^{(i)}$，标签向量为：$\\mathbf{y}^{(i)}$</li>\n<li>$y_j^{(i)}$：样本i的标签向量中属于类别j的概率</li>\n</ul>\n</li>\n<li>2）相当于最小化负对数似然(损失函数)：$$-\\log P(\\mathbf{Y}|\\mathbf{X})&#x3D;-\\sum_{i&#x3D;1}^n\\log P(y^{(i)}|\\mathbf{x}^{(i)})&#x3D;\\sum_{i&#x3D;1}^nl(\\mathbf{y}^{(i)},\\mathbf{\\hat{y}}^{(i)})$$<ul>\n<li>损失函数为（交叉熵损失 cross-entropy loss）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}_j$$<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">由于y是一个长度为q的独热编码向量，所以除了一个项以外的所有项j都消失了。由于所有yˆj都是预测的概率，所以它们的对数永远不会大于0。因此，如果正确地预测实际标签，即如果实际标签P(y | x) = 1，则损失函数不能进一步最小化。注意，这往往是不可能的。例如，数据集中可能存在标签噪声（比如某些样本可能被误标），或输入特征没有足够的信息来完美地对每一个样本分类。？？？</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-6-2-softmax及其导数\"><a href=\"#4-6-2-softmax及其导数\" class=\"headerlink\" title=\"4.6.2 softmax及其导数\"></a>4.6.2 softmax及其导数</h3><ul>\n<li>对损失函数：$$\\begin{aligned} l(\\mathbf{y},\\mathbf{\\hat{y}})&amp;&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}<em>j \\ &amp;&#x3D;-\\sum</em>{j&#x3D;1}^qy_j\\log\\frac{\\exp(o_j)}{\\sum_{i&#x3D;1}^q\\exp(o_i)} \\ &amp;&#x3D;-\\sum_{j&#x3D;1}^q(y_j(o_j-\\log\\sum_{i&#x3D;1}^q\\exp(o_i))) \\ &amp;&#x3D;\\sum_{j&#x3D;1}^qy_j\\log\\sum_{i&#x3D;1}^q\\exp(o_i)-\\sum_{j&#x3D;1}^qy_jo_j \\ &amp;&#x3D;\\log\\sum_{i&#x3D;1}^q\\exp(o_i)-\\sum_{j&#x3D;1}^qy_jo_j \\end{aligned}$$</li>\n<li>损失函数对$o_j$的导数(log以e为底)：$$\\frac{\\partial l(\\mathbf{y},\\mathbf{\\hat{y}})}{\\partial o_j}&#x3D;\\frac{\\exp(o_j)}{\\sum_{i&#x3D;1}^q\\exp(o_i)}-y_j&#x3D;softmax(o)_j-y_j$$<ul>\n<li><strong>这与我们在回归中看到的非常相似，其中梯度是观测值y和估计值yˆ之间的差异。这不是巧合，在任何指数族分布模型中对数似然的梯度正是由此得出的。这使梯度计算在实践中变得容易很多。</strong></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-6-3-交叉熵损失\"><a href=\"#4-6-3-交叉熵损失\" class=\"headerlink\" title=\"4.6.3 交叉熵损失\"></a>4.6.3 交叉熵损失</h3><ul>\n<li>对于标签$\\mathbf{y}$，我们可以使用与以前相同的表示形式。唯一的区别是，我们现在用一个概率向量表示，如(0.1, 0.2, 0.7)，而不是仅包含二元项的向量(0, 0, 1)。</li>\n<li>交叉熵损失（分类问题最常用）：$$l(\\mathbf{y},\\mathbf{\\hat{y}})&#x3D;-\\sum_{j&#x3D;1}^qy_j\\log\\hat{y}_j$$</li>\n</ul>\n<h2 id=\"4-7-信息论基础\"><a href=\"#4-7-信息论基础\" class=\"headerlink\" title=\"4.7 信息论基础\"></a>4.7 信息论基础</h2><ul>\n<li>信息论（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。</li>\n</ul>\n<h3 id=\"4-7-1-熵-entropy\"><a href=\"#4-7-1-熵-entropy\" class=\"headerlink\" title=\"4.7.1 熵(entropy)\"></a>4.7.1 熵(entropy)</h3><p>$$H[P]&#x3D;-\\sum_{j}-P(j)\\log P(j)$$</p>\n<ul>\n<li>量化数据中的信息内容</li>\n<li>为了对从分布$p$中取样的数据进行编码，至少需要$H[p]$个纳特（nat）对其进行编码。（纳特相当于比特，底数是$e$，1nat&#x3D; $\\frac{1}{\\log(2)}$ bit）</li>\n</ul>\n<h3 id=\"4-7-2-信息量\"><a href=\"#4-7-2-信息量\" class=\"headerlink\" title=\"4.7.2 信息量\"></a>4.7.2 信息量</h3><ul>\n<li>压缩与预测：如果我们很容易预测下一个数据，那么这个数据就很容易压缩。</li>\n<li>如果我们不能完全预测每一个事件，那么我们会感到“惊异”。克劳德·香农决定用信息量$-\\log P(j)$来量化这种惊异度。在观察一个事件j时，并赋予它（主观）概率 $P(j)$。当我们赋予一个事件较低的概率时，我们的惊异会更大，该事件的信息量也就更大。</li>\n<li>熵：当分配的概率真正匹配数据生成过程时的信息量的期望。</li>\n</ul>\n<h3 id=\"4-7-3-交叉熵\"><a href=\"#4-7-3-交叉熵\" class=\"headerlink\" title=\"4.7.3 交叉熵\"></a>4.7.3 交叉熵</h3><ul>\n<li>如果把熵$H(p)$当作“知道真实概率的人所经历的惊异程度”，那么交叉熵从P到Q，记为H(P, Q)。我们可以把交叉熵想象为“主观概率为Q的观察者在看到根据概率P生成的数据时的预期惊异”。当P &#x3D; Q时，交叉熵达到最低。在这种情况下，从P到Q的交叉熵是H(P, P) &#x3D; H(P)。</li>\n<li>可以从两方面来考虑交叉熵分类目标：（i）最大化观测数据的似然；（ii）最小化传达标签所需的惊异。</li>\n</ul>\n<h2 id=\"4-8-模型预测和评估\"><a href=\"#4-8-模型预测和评估\" class=\"headerlink\" title=\"4.8 模型预测和评估\"></a>4.8 模型预测和评估</h2><ul>\n<li>使用预测概率最高的类别作为输出类别。如果预测与实际类别（标签）一致，则预测是正确的。</li>\n<li>用精度（accuracy）来评估模型的性能。精度&#x3D;正确个数&#x2F;总个数</li>\n</ul>"},{"title":"2.5 图像分类数据集","date":"2024-02-04T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 5 图像分类数据集\n- MNIST是一个常见图像分类数据集，但过于简单。我们将使用一个更复杂的图像数据集Fashion-MNIST,10个类60000+10000张28*28的灰度图像。\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom d2l import torch as d2l\nd2l.use_svg_display()\n\n```\n\n## 5.1 读取数据集\n- 我们可以通过框架中的内置函数将Fashion-MNIST下载并读取到内存中。\n\n\n```python\n#通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式,并除以255使得所有像素的数值均在0到1之间\ntrans= transforms.ToTensor()\nmnist_train = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=True, transform=trans, download=True)\nmnist_test = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=False, transform=trans, download=True)\n\nprint(len(mnist_train), len(mnist_test))\nprint(mnist_train[0][0].shape)\n\n# 数字标签->文本标签\ndef get_fashion_mnist_labels(labels): #@save\n    \"\"\"返回Fashion-MNIST数据集的文本标签。\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n# 可视化样本\ndef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save\n    \"\"\"绘制图像列表。\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten() # 返回一个展平的数组\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if torch.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy()) #将图片放在axes的ax位置\n        else:\n            # PIL图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False) #不显示x轴\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\n# 可视化样本\nX, y = next(iter(data.DataLoader(mnist_train, batch_size=18))) #iter()返回一个迭代器\nshow_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));\n```\n\n    60000 10000\n    torch.Size([1, 28, 28])\n    \n\n\n    \n![svg](5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg)\n    \n\n\n## 5.2 读取小批量\n- 使用内置数据迭代器，可以随机打乱所有样本\n\n\n\n```python\n# 读取小批量\nbatch_size = 256\ndef get_dataloader_workers(): #@save\n    \"\"\"使用4个进程来读取数据。\"\"\"\n    return 4\ntrain_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers())\n\n#读取数据需要的时间\ntimer = d2l.Timer()\nfor X,y in train_iter:\n    continue\nprint(f'{timer.stop():.2f} sec')\n```\n\n    3.66 sec\n    \n\n## 5.3 整合\n\n\n\n```python\n#1 读取数据集，返回迭代器\ndef load_data_fashion_mnist(batch_size, resize=None): #@save\n    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n    trans = [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans = transforms.Compose(trans)\n    mnist_train= torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=True, transform=trans, download=True)\n    mnist_test = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=False, transform=trans, download=True)\n    return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), \n            data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers()))\n#2 resize图像大小\ntrain_iter, test_iter = load_data_fashion_mnist(32, resize=64) #resize为64\nfor X, y in train_iter:\n    print(X.shape, X.dtype, y.shape, y.dtype)\n    break\n```\n\n    torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64\n    \n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset.md","raw":"---\ntitle: 2.5 图像分类数据集\ndate: 2024-2-4 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 5 图像分类数据集\n- MNIST是一个常见图像分类数据集，但过于简单。我们将使用一个更复杂的图像数据集Fashion-MNIST,10个类60000+10000张28*28的灰度图像。\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom d2l import torch as d2l\nd2l.use_svg_display()\n\n```\n\n## 5.1 读取数据集\n- 我们可以通过框架中的内置函数将Fashion-MNIST下载并读取到内存中。\n\n\n```python\n#通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式,并除以255使得所有像素的数值均在0到1之间\ntrans= transforms.ToTensor()\nmnist_train = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=True, transform=trans, download=True)\nmnist_test = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=False, transform=trans, download=True)\n\nprint(len(mnist_train), len(mnist_test))\nprint(mnist_train[0][0].shape)\n\n# 数字标签->文本标签\ndef get_fashion_mnist_labels(labels): #@save\n    \"\"\"返回Fashion-MNIST数据集的文本标签。\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n# 可视化样本\ndef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save\n    \"\"\"绘制图像列表。\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten() # 返回一个展平的数组\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if torch.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy()) #将图片放在axes的ax位置\n        else:\n            # PIL图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False) #不显示x轴\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\n# 可视化样本\nX, y = next(iter(data.DataLoader(mnist_train, batch_size=18))) #iter()返回一个迭代器\nshow_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));\n```\n\n    60000 10000\n    torch.Size([1, 28, 28])\n    \n\n\n    \n![svg](5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg)\n    \n\n\n## 5.2 读取小批量\n- 使用内置数据迭代器，可以随机打乱所有样本\n\n\n\n```python\n# 读取小批量\nbatch_size = 256\ndef get_dataloader_workers(): #@save\n    \"\"\"使用4个进程来读取数据。\"\"\"\n    return 4\ntrain_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers())\n\n#读取数据需要的时间\ntimer = d2l.Timer()\nfor X,y in train_iter:\n    continue\nprint(f'{timer.stop():.2f} sec')\n```\n\n    3.66 sec\n    \n\n## 5.3 整合\n\n\n\n```python\n#1 读取数据集，返回迭代器\ndef load_data_fashion_mnist(batch_size, resize=None): #@save\n    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n    trans = [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans = transforms.Compose(trans)\n    mnist_train= torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=True, transform=trans, download=True)\n    mnist_test = torchvision.datasets.FashionMNIST(root=\"D:/fashionmnist\", train=False, transform=trans, download=True)\n    return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), \n            data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers()))\n#2 resize图像大小\ntrain_iter, test_iter = load_data_fashion_mnist(32, resize=64) #resize为64\nfor X, y in train_iter:\n    print(X.shape, X.dtype, y.shape, y.dtype)\n    break\n```\n\n    torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64\n    \n","slug":"deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset","published":1,"updated":"2024-02-05T14:30:40.285Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859f004i7svw9j87ajzi","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"5-图像分类数据集\"><a href=\"#5-图像分类数据集\" class=\"headerlink\" title=\"5 图像分类数据集\"></a>5 图像分类数据集</h1><ul>\n<li>MNIST是一个常见图像分类数据集，但过于简单。我们将使用一个更复杂的图像数据集Fashion-MNIST,10个类60000+10000张28*28的灰度图像。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\">d2l.use_svg_display()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-1-读取数据集\"><a href=\"#5-1-读取数据集\" class=\"headerlink\" title=\"5.1 读取数据集\"></a>5.1 读取数据集</h2><ul>\n<li>我们可以通过框架中的内置函数将Fashion-MNIST下载并读取到内存中。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式,并除以255使得所有像素的数值均在0到1之间</span></span><br><span class=\"line\">trans= transforms.ToTensor()</span><br><span class=\"line\">mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(mnist_train), <span class=\"built_in\">len</span>(mnist_test))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(mnist_train[<span class=\"number\">0</span>][<span class=\"number\">0</span>].shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数字标签-&gt;文本标签</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_fashion_mnist_labels</span>(<span class=\"params\">labels</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签。&quot;&quot;&quot;</span></span><br><span class=\"line\">    text_labels = [<span class=\"string\">&#x27;t-shirt&#x27;</span>, <span class=\"string\">&#x27;trouser&#x27;</span>, <span class=\"string\">&#x27;pullover&#x27;</span>, <span class=\"string\">&#x27;dress&#x27;</span>, <span class=\"string\">&#x27;coat&#x27;</span>,</span><br><span class=\"line\">                   <span class=\"string\">&#x27;sandal&#x27;</span>, <span class=\"string\">&#x27;shirt&#x27;</span>, <span class=\"string\">&#x27;sneaker&#x27;</span>, <span class=\"string\">&#x27;bag&#x27;</span>, <span class=\"string\">&#x27;ankle boot&#x27;</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [text_labels[<span class=\"built_in\">int</span>(i)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> labels]</span><br><span class=\"line\"><span class=\"comment\"># 可视化样本</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_images</span>(<span class=\"params\">imgs, num_rows, num_cols, titles=<span class=\"literal\">None</span>, scale=<span class=\"number\">1.5</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制图像列表。&quot;&quot;&quot;</span></span><br><span class=\"line\">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class=\"line\">    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class=\"line\">    axes = axes.flatten() <span class=\"comment\"># 返回一个展平的数组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (ax, img) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(axes, imgs)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> torch.is_tensor(img):</span><br><span class=\"line\">            <span class=\"comment\"># 图片张量</span></span><br><span class=\"line\">            ax.imshow(img.numpy()) <span class=\"comment\">#将图片放在axes的ax位置</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># PIL图片</span></span><br><span class=\"line\">            ax.imshow(img)</span><br><span class=\"line\">        ax.axes.get_xaxis().set_visible(<span class=\"literal\">False</span>) <span class=\"comment\">#不显示x轴</span></span><br><span class=\"line\">        ax.axes.get_yaxis().set_visible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> titles:</span><br><span class=\"line\">            ax.set_title(titles[i])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> axes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化样本</span></span><br><span class=\"line\">X, y = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(data.DataLoader(mnist_train, batch_size=<span class=\"number\">18</span>))) <span class=\"comment\">#iter()返回一个迭代器</span></span><br><span class=\"line\">show_images(X.reshape(<span class=\"number\">18</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>), <span class=\"number\">2</span>, <span class=\"number\">9</span>, titles=get_fashion_mnist_labels(y));</span><br></pre></td></tr></table></figure>\n\n<pre><code>60000 10000\ntorch.Size([1, 28, 28])\n</code></pre>\n<p><img src=\"/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg\"></p>\n<h2 id=\"5-2-读取小批量\"><a href=\"#5-2-读取小批量\" class=\"headerlink\" title=\"5.2 读取小批量\"></a>5.2 读取小批量</h2><ul>\n<li>使用内置数据迭代器，可以随机打乱所有样本</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 读取小批量</span></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_dataloader_workers</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;使用4个进程来读取数据。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">4</span></span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=get_dataloader_workers())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取数据需要的时间</span></span><br><span class=\"line\">timer = d2l.Timer()</span><br><span class=\"line\"><span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"keyword\">continue</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.2</span>f&#125;</span> sec&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>3.66 sec\n</code></pre>\n<h2 id=\"5-3-整合\"><a href=\"#5-3-整合\" class=\"headerlink\" title=\"5.3 整合\"></a>5.3 整合</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 读取数据集，返回迭代器</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_fashion_mnist</span>(<span class=\"params\">batch_size, resize=<span class=\"literal\">None</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;</span></span><br><span class=\"line\">    trans = [transforms.ToTensor()]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> resize:</span><br><span class=\"line\">        trans.insert(<span class=\"number\">0</span>, transforms.Resize(resize))</span><br><span class=\"line\">    trans = transforms.Compose(trans)</span><br><span class=\"line\">    mnist_train= torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=get_dataloader_workers()), </span><br><span class=\"line\">            data.DataLoader(mnist_test, batch_size, shuffle=<span class=\"literal\">False</span>, num_workers=get_dataloader_workers()))</span><br><span class=\"line\"><span class=\"comment\">#2 resize图像大小</span></span><br><span class=\"line\">train_iter, test_iter = load_data_fashion_mnist(<span class=\"number\">32</span>, resize=<span class=\"number\">64</span>) <span class=\"comment\">#resize为64</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X.shape, X.dtype, y.shape, y.dtype)</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64\n</code></pre>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"5-图像分类数据集\"><a href=\"#5-图像分类数据集\" class=\"headerlink\" title=\"5 图像分类数据集\"></a>5 图像分类数据集</h1><ul>\n<li>MNIST是一个常见图像分类数据集，但过于简单。我们将使用一个更复杂的图像数据集Fashion-MNIST,10个类60000+10000张28*28的灰度图像。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\">d2l.use_svg_display()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-1-读取数据集\"><a href=\"#5-1-读取数据集\" class=\"headerlink\" title=\"5.1 读取数据集\"></a>5.1 读取数据集</h2><ul>\n<li>我们可以通过框架中的内置函数将Fashion-MNIST下载并读取到内存中。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式,并除以255使得所有像素的数值均在0到1之间</span></span><br><span class=\"line\">trans= transforms.ToTensor()</span><br><span class=\"line\">mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(mnist_train), <span class=\"built_in\">len</span>(mnist_test))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(mnist_train[<span class=\"number\">0</span>][<span class=\"number\">0</span>].shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数字标签-&gt;文本标签</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_fashion_mnist_labels</span>(<span class=\"params\">labels</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签。&quot;&quot;&quot;</span></span><br><span class=\"line\">    text_labels = [<span class=\"string\">&#x27;t-shirt&#x27;</span>, <span class=\"string\">&#x27;trouser&#x27;</span>, <span class=\"string\">&#x27;pullover&#x27;</span>, <span class=\"string\">&#x27;dress&#x27;</span>, <span class=\"string\">&#x27;coat&#x27;</span>,</span><br><span class=\"line\">                   <span class=\"string\">&#x27;sandal&#x27;</span>, <span class=\"string\">&#x27;shirt&#x27;</span>, <span class=\"string\">&#x27;sneaker&#x27;</span>, <span class=\"string\">&#x27;bag&#x27;</span>, <span class=\"string\">&#x27;ankle boot&#x27;</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [text_labels[<span class=\"built_in\">int</span>(i)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> labels]</span><br><span class=\"line\"><span class=\"comment\"># 可视化样本</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_images</span>(<span class=\"params\">imgs, num_rows, num_cols, titles=<span class=\"literal\">None</span>, scale=<span class=\"number\">1.5</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;绘制图像列表。&quot;&quot;&quot;</span></span><br><span class=\"line\">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class=\"line\">    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class=\"line\">    axes = axes.flatten() <span class=\"comment\"># 返回一个展平的数组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (ax, img) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(axes, imgs)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> torch.is_tensor(img):</span><br><span class=\"line\">            <span class=\"comment\"># 图片张量</span></span><br><span class=\"line\">            ax.imshow(img.numpy()) <span class=\"comment\">#将图片放在axes的ax位置</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># PIL图片</span></span><br><span class=\"line\">            ax.imshow(img)</span><br><span class=\"line\">        ax.axes.get_xaxis().set_visible(<span class=\"literal\">False</span>) <span class=\"comment\">#不显示x轴</span></span><br><span class=\"line\">        ax.axes.get_yaxis().set_visible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> titles:</span><br><span class=\"line\">            ax.set_title(titles[i])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> axes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化样本</span></span><br><span class=\"line\">X, y = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(data.DataLoader(mnist_train, batch_size=<span class=\"number\">18</span>))) <span class=\"comment\">#iter()返回一个迭代器</span></span><br><span class=\"line\">show_images(X.reshape(<span class=\"number\">18</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>), <span class=\"number\">2</span>, <span class=\"number\">9</span>, titles=get_fashion_mnist_labels(y));</span><br></pre></td></tr></table></figure>\n\n<pre><code>60000 10000\ntorch.Size([1, 28, 28])\n</code></pre>\n<p><img src=\"/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/5_image_classification_dataset_files/5_image_classification_dataset_3_1.svg\"></p>\n<h2 id=\"5-2-读取小批量\"><a href=\"#5-2-读取小批量\" class=\"headerlink\" title=\"5.2 读取小批量\"></a>5.2 读取小批量</h2><ul>\n<li>使用内置数据迭代器，可以随机打乱所有样本</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 读取小批量</span></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_dataloader_workers</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;使用4个进程来读取数据。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">4</span></span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=get_dataloader_workers())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取数据需要的时间</span></span><br><span class=\"line\">timer = d2l.Timer()</span><br><span class=\"line\"><span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"keyword\">continue</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;timer.stop():<span class=\"number\">.2</span>f&#125;</span> sec&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>3.66 sec\n</code></pre>\n<h2 id=\"5-3-整合\"><a href=\"#5-3-整合\" class=\"headerlink\" title=\"5.3 整合\"></a>5.3 整合</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 读取数据集，返回迭代器</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_fashion_mnist</span>(<span class=\"params\">batch_size, resize=<span class=\"literal\">None</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;</span></span><br><span class=\"line\">    trans = [transforms.ToTensor()]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> resize:</span><br><span class=\"line\">        trans.insert(<span class=\"number\">0</span>, transforms.Resize(resize))</span><br><span class=\"line\">    trans = transforms.Compose(trans)</span><br><span class=\"line\">    mnist_train= torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;D:/fashionmnist&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=get_dataloader_workers()), </span><br><span class=\"line\">            data.DataLoader(mnist_test, batch_size, shuffle=<span class=\"literal\">False</span>, num_workers=get_dataloader_workers()))</span><br><span class=\"line\"><span class=\"comment\">#2 resize图像大小</span></span><br><span class=\"line\">train_iter, test_iter = load_data_fashion_mnist(<span class=\"number\">32</span>, resize=<span class=\"number\">64</span>) <span class=\"comment\">#resize为64</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X.shape, X.dtype, y.shape, y.dtype)</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64\n</code></pre>"},{"title":"2.6 softmax回归从零实现","date":"2024-02-04T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 6 softmax回归从零实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom IPython import display\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n```\n\n## 6.1 初始化模型参数\n\n\n```python\nnum_inputs = 784\nnum_outputs = 10\n\nW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\nb = torch.zeros(num_outputs, requires_grad=True)\n```\n\n## 6.2 定义softmax操作\n$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$\n\n\n- 1）对每个项求幂\n- 2）对每一行（样本）求和，得到每个样本的规范化常数\n- 3）对每一行（样本）各个项除以该常数，确保和为1\n- 分母或规范化常数，有时也称为配分函数（其对数称为对数‐配分函数）。\n\n\n```python\n# 定义softmax操作\ndef softmax(X): #矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。\n    X_exp = torch.exp(X)\n    partition = X_exp.sum(1, keepdim=True)\n    return X_exp / partition # 这里应用了广播机制\n```\n\n## 6.3 定义模型\n\n\n```python\n# 定义模型\ndef net(X):\n    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)\n```\n\n## 6.4 定义损失函数\n$$l(y_i,y_i')=-\\sum_{j=1}^{q}y_{j}log(\\hat{y}_{j})$$\n\n\n```python\n# 定义损失函数\ndef cross_entropy(y_hat, y): #根据交叉熵公式，yi是一个（0001）的向量，所以对于一个样本，他的交叉熵是：真实类别对应的那个概率求对数\n    return -torch.log(y_hat[range(len(y_hat)), y])\n```\n\n## 6.5 分类精度\n\n\n\n```python\n# 计算正确预测的数量\ndef accuracy(y_hat, y): #@save\n    \"\"\"计算预测正确的数量。\"\"\"\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = y_hat.argmax(axis=1) #argmax(axis=1)返回矩阵每行最大值的索引\n    cmp = y_hat.type(y.dtype) == y #返回一个bool矩阵\n    return float(cmp.type(y.dtype).sum())\n# 评估模型的准确率\ndef evaluate_accuracy(net, data_iter): #@save\n    \"\"\"计算在指定数据集上模型的精度。\"\"\"\n    if isinstance(net, torch.nn.Module):\n        net.eval()  # 将模型设置为评估模式\n    metric = Accumulator(2)  # 正确预测数、预测总数\n    with torch.no_grad():\n        for X, y in data_iter:\n            metric.add(accuracy(net(X), y), y.numel()) #y.numel()返回y中元素的个数\n    return metric[0] / metric[1]\n# 累加器\nclass Accumulator:  #@save\n    \"\"\"在`n`个变量上累加。\"\"\"\n    def __init__(self, n):\n        self.data = [0.0] * n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n# 由于随机初始化，因此最开始的精度只有大概10%\nprint(evaluate_accuracy(net, test_iter))\n```\n\n    0.1141\n\n\n## 6.6 训练\n\n\n\n```python\n#1 训练一个epoch\ndef train_epoch_ch3(net, train_iter, loss, updater):  #@save\n    \"\"\"训练模型一个迭代周期\"\"\"\n    # 将模型设置为训练模式\n    if isinstance(net, torch.nn.Module):\n        net.train()\n    # 训练损失总和、训练准确度总和、样本数\n    metric = Accumulator(3)\n    for X, y in train_iter:\n        # 计算梯度并更新参数\n        y_hat = net(X)\n        l = loss(y_hat, y)\n        if isinstance(updater, torch.optim.Optimizer):\n            # 使用PyTorch内置的优化器和损失函数\n            updater.zero_grad()\n            l.mean.backward() #l.mean()返回l中所有元素的均值\n            updater.step()\n        else:\n            # 使用定制的优化器和损失函数\n            l.sum().backward() #l.sum()返回l中所有元素的和\n            updater(X.shape[0])\n        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) #记录损失、准确率、样本数\n    # 返回训练损失和训练准确率\n    return metric[0] / metric[2], metric[1] / metric[2] #因为损失做了sum，所以要除以样本数\n\n#画图程序\nclass Animator: #@save\n    \"\"\"在动画中绘制数据\"\"\"\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        # 增量地绘制多条线\n        if legend is None:\n            legend = []\n        d2l.use_svg_display()\n        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes,]\n        # 使用lambda函数捕获参数\n        self.config_axes = lambda: d2l.set_axes(self.axes[\n            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n    def add(self,x,y):\n        # 向图表中添加多个数据点\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.display(self.fig)\n        display.clear_output(wait=True)\n\n#2 训练函数\ndef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n    \"\"\"训练模型\"\"\"\n    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n                        legend=['train loss', 'train acc', 'test acc'])\n    for epoch in range(num_epochs):\n        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n        test_acc = evaluate_accuracy(net, test_iter)\n        animator.add(epoch + 1, train_metrics + (test_acc,)) #记录epoch,训练损失、训练准确率、测试准确率\n    train_loss, train_acc = train_metrics\n    assert train_loss < 0.5, train_loss #如果train_loss大于0.5，说明模型训练失败\n    assert train_acc <= 1 and train_acc > 0.7, train_acc\n    assert test_acc <= 1 and test_acc > 0.7, test_acc\n\n#3 优化器\nlr = 0.1\ndef updater(batch_size):\n    return d2l.sgd([W, b], lr, batch_size)\n\n#4 训练\nnum_epochs = 10\ntrain_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)\n```\n\n\n​    \n![svg](6_softmax_realize_files/6_softmax_realize_13_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg)\n​    \n\n\n# 6.7 预测\n\n\n\n```python\ndef predict_ch3(net, test_iter, n=6): #@save\n    \"\"\"预测标签\"\"\"\n    for X, y in test_iter:\n        break\n    trues = d2l.get_fashion_mnist_labels(y)\n    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n    d2l.show_images(X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\npredict_ch3(net, test_iter)\n```\n\n\n​    \n![svg](6_softmax_realize_files/6_softmax_realize_15_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg)\n​    \n\n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize.md","raw":"---\ntitle: 2.6 softmax回归从零实现\ndate: 2024-2-4 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 6 softmax回归从零实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom IPython import display\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n```\n\n## 6.1 初始化模型参数\n\n\n```python\nnum_inputs = 784\nnum_outputs = 10\n\nW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\nb = torch.zeros(num_outputs, requires_grad=True)\n```\n\n## 6.2 定义softmax操作\n$$ softmax(\\mathbf{X})_{ij} = \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$\n\n\n- 1）对每个项求幂\n- 2）对每一行（样本）求和，得到每个样本的规范化常数\n- 3）对每一行（样本）各个项除以该常数，确保和为1\n- 分母或规范化常数，有时也称为配分函数（其对数称为对数‐配分函数）。\n\n\n```python\n# 定义softmax操作\ndef softmax(X): #矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。\n    X_exp = torch.exp(X)\n    partition = X_exp.sum(1, keepdim=True)\n    return X_exp / partition # 这里应用了广播机制\n```\n\n## 6.3 定义模型\n\n\n```python\n# 定义模型\ndef net(X):\n    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)\n```\n\n## 6.4 定义损失函数\n$$l(y_i,y_i')=-\\sum_{j=1}^{q}y_{j}log(\\hat{y}_{j})$$\n\n\n```python\n# 定义损失函数\ndef cross_entropy(y_hat, y): #根据交叉熵公式，yi是一个（0001）的向量，所以对于一个样本，他的交叉熵是：真实类别对应的那个概率求对数\n    return -torch.log(y_hat[range(len(y_hat)), y])\n```\n\n## 6.5 分类精度\n\n\n\n```python\n# 计算正确预测的数量\ndef accuracy(y_hat, y): #@save\n    \"\"\"计算预测正确的数量。\"\"\"\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = y_hat.argmax(axis=1) #argmax(axis=1)返回矩阵每行最大值的索引\n    cmp = y_hat.type(y.dtype) == y #返回一个bool矩阵\n    return float(cmp.type(y.dtype).sum())\n# 评估模型的准确率\ndef evaluate_accuracy(net, data_iter): #@save\n    \"\"\"计算在指定数据集上模型的精度。\"\"\"\n    if isinstance(net, torch.nn.Module):\n        net.eval()  # 将模型设置为评估模式\n    metric = Accumulator(2)  # 正确预测数、预测总数\n    with torch.no_grad():\n        for X, y in data_iter:\n            metric.add(accuracy(net(X), y), y.numel()) #y.numel()返回y中元素的个数\n    return metric[0] / metric[1]\n# 累加器\nclass Accumulator:  #@save\n    \"\"\"在`n`个变量上累加。\"\"\"\n    def __init__(self, n):\n        self.data = [0.0] * n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n# 由于随机初始化，因此最开始的精度只有大概10%\nprint(evaluate_accuracy(net, test_iter))\n```\n\n    0.1141\n\n\n## 6.6 训练\n\n\n\n```python\n#1 训练一个epoch\ndef train_epoch_ch3(net, train_iter, loss, updater):  #@save\n    \"\"\"训练模型一个迭代周期\"\"\"\n    # 将模型设置为训练模式\n    if isinstance(net, torch.nn.Module):\n        net.train()\n    # 训练损失总和、训练准确度总和、样本数\n    metric = Accumulator(3)\n    for X, y in train_iter:\n        # 计算梯度并更新参数\n        y_hat = net(X)\n        l = loss(y_hat, y)\n        if isinstance(updater, torch.optim.Optimizer):\n            # 使用PyTorch内置的优化器和损失函数\n            updater.zero_grad()\n            l.mean.backward() #l.mean()返回l中所有元素的均值\n            updater.step()\n        else:\n            # 使用定制的优化器和损失函数\n            l.sum().backward() #l.sum()返回l中所有元素的和\n            updater(X.shape[0])\n        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) #记录损失、准确率、样本数\n    # 返回训练损失和训练准确率\n    return metric[0] / metric[2], metric[1] / metric[2] #因为损失做了sum，所以要除以样本数\n\n#画图程序\nclass Animator: #@save\n    \"\"\"在动画中绘制数据\"\"\"\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        # 增量地绘制多条线\n        if legend is None:\n            legend = []\n        d2l.use_svg_display()\n        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes,]\n        # 使用lambda函数捕获参数\n        self.config_axes = lambda: d2l.set_axes(self.axes[\n            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n    def add(self,x,y):\n        # 向图表中添加多个数据点\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.display(self.fig)\n        display.clear_output(wait=True)\n\n#2 训练函数\ndef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n    \"\"\"训练模型\"\"\"\n    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n                        legend=['train loss', 'train acc', 'test acc'])\n    for epoch in range(num_epochs):\n        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n        test_acc = evaluate_accuracy(net, test_iter)\n        animator.add(epoch + 1, train_metrics + (test_acc,)) #记录epoch,训练损失、训练准确率、测试准确率\n    train_loss, train_acc = train_metrics\n    assert train_loss < 0.5, train_loss #如果train_loss大于0.5，说明模型训练失败\n    assert train_acc <= 1 and train_acc > 0.7, train_acc\n    assert test_acc <= 1 and test_acc > 0.7, test_acc\n\n#3 优化器\nlr = 0.1\ndef updater(batch_size):\n    return d2l.sgd([W, b], lr, batch_size)\n\n#4 训练\nnum_epochs = 10\ntrain_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)\n```\n\n\n​    \n![svg](6_softmax_realize_files/6_softmax_realize_13_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg)\n​    \n\n\n# 6.7 预测\n\n\n\n```python\ndef predict_ch3(net, test_iter, n=6): #@save\n    \"\"\"预测标签\"\"\"\n    for X, y in test_iter:\n        break\n    trues = d2l.get_fashion_mnist_labels(y)\n    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n    d2l.show_images(X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\npredict_ch3(net, test_iter)\n```\n\n\n​    \n![svg](6_softmax_realize_files/6_softmax_realize_15_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg)\n​    \n\n","slug":"deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize","published":1,"updated":"2024-02-25T09:49:54.685Z","_id":"clt19859g004m7svw09gyfooa","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"6-softmax回归从零实现\"><a href=\"#6-softmax回归从零实现\" class=\"headerlink\" title=\"6 softmax回归从零实现\"></a>6 softmax回归从零实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> IPython <span class=\"keyword\">import</span> display</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-1-初始化模型参数\"><a href=\"#6-1-初始化模型参数\" class=\"headerlink\" title=\"6.1 初始化模型参数\"></a>6.1 初始化模型参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_inputs = <span class=\"number\">784</span></span><br><span class=\"line\">num_outputs = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">W = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-2-定义softmax操作\"><a href=\"#6-2-定义softmax操作\" class=\"headerlink\" title=\"6.2 定义softmax操作\"></a>6.2 定义softmax操作</h2><p>$$ softmax(\\mathbf{X})_{ij} &#x3D; \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$</p>\n<ul>\n<li>1）对每个项求幂</li>\n<li>2）对每一行（样本）求和，得到每个样本的规范化常数</li>\n<li>3）对每一行（样本）各个项除以该常数，确保和为1</li>\n<li>分母或规范化常数，有时也称为配分函数（其对数称为对数‐配分函数）。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义softmax操作</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">softmax</span>(<span class=\"params\">X</span>): <span class=\"comment\">#矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。</span></span><br><span class=\"line\">    X_exp = torch.exp(X)</span><br><span class=\"line\">    partition = X_exp.<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_exp / partition <span class=\"comment\"># 这里应用了广播机制</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-3-定义模型\"><a href=\"#6-3-定义模型\" class=\"headerlink\" title=\"6.3 定义模型\"></a>6.3 定义模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义模型</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> softmax(torch.matmul(X.reshape(-<span class=\"number\">1</span>, W.shape[<span class=\"number\">0</span>]), W) + b)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-4-定义损失函数\"><a href=\"#6-4-定义损失函数\" class=\"headerlink\" title=\"6.4 定义损失函数\"></a>6.4 定义损失函数</h2><p>$$l(y_i,y_i’)&#x3D;-\\sum_{j&#x3D;1}^{q}y_{j}log(\\hat{y}_{j})$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义损失函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy</span>(<span class=\"params\">y_hat, y</span>): <span class=\"comment\">#根据交叉熵公式，yi是一个（0001）的向量，所以对于一个样本，他的交叉熵是：真实类别对应的那个概率求对数</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> -torch.log(y_hat[<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(y_hat)), y])</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-5-分类精度\"><a href=\"#6-5-分类精度\" class=\"headerlink\" title=\"6.5 分类精度\"></a>6.5 分类精度</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算正确预测的数量</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">accuracy</span>(<span class=\"params\">y_hat, y</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;计算预测正确的数量。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(y_hat.shape) &gt; <span class=\"number\">1</span> <span class=\"keyword\">and</span> y_hat.shape[<span class=\"number\">1</span>] &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">        y_hat = y_hat.argmax(axis=<span class=\"number\">1</span>) <span class=\"comment\">#argmax(axis=1)返回矩阵每行最大值的索引</span></span><br><span class=\"line\">    cmp = y_hat.<span class=\"built_in\">type</span>(y.dtype) == y <span class=\"comment\">#返回一个bool矩阵</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">float</span>(cmp.<span class=\"built_in\">type</span>(y.dtype).<span class=\"built_in\">sum</span>())</span><br><span class=\"line\"><span class=\"comment\"># 评估模型的准确率</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">evaluate_accuracy</span>(<span class=\"params\">net, data_iter</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;计算在指定数据集上模型的精度。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):</span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># 将模型设置为评估模式</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">2</span>)  <span class=\"comment\"># 正确预测数、预测总数</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">            metric.add(accuracy(net(X), y), y.numel()) <span class=\"comment\">#y.numel()返回y中元素的个数</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 累加器</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Accumulator</span>:  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;在`n`个变量上累加。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, n</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * n</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">add</span>(<span class=\"params\">self, *args</span>):</span><br><span class=\"line\">        self.data = [a + <span class=\"built_in\">float</span>(b) <span class=\"keyword\">for</span> a, b <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(self.data, args)]</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">reset</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * <span class=\"built_in\">len</span>(self.data)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.data[idx]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 由于随机初始化，因此最开始的精度只有大概10%</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(evaluate_accuracy(net, test_iter))</span><br></pre></td></tr></table></figure>\n\n<pre><code>0.1141\n</code></pre>\n<h2 id=\"6-6-训练\"><a href=\"#6-6-训练\" class=\"headerlink\" title=\"6.6 训练\"></a>6.6 训练</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 训练一个epoch</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch_ch3</span>(<span class=\"params\">net, train_iter, loss, updater</span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;训练模型一个迭代周期&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 将模型设置为训练模式</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">    <span class=\"comment\"># 训练损失总和、训练准确度总和、样本数</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">3</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">        <span class=\"comment\"># 计算梯度并更新参数</span></span><br><span class=\"line\">        y_hat = net(X)</span><br><span class=\"line\">        l = loss(y_hat, y)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class=\"line\">            <span class=\"comment\"># 使用PyTorch内置的优化器和损失函数</span></span><br><span class=\"line\">            updater.zero_grad()</span><br><span class=\"line\">            l.mean.backward() <span class=\"comment\">#l.mean()返回l中所有元素的均值</span></span><br><span class=\"line\">            updater.step()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 使用定制的优化器和损失函数</span></span><br><span class=\"line\">            l.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#l.sum()返回l中所有元素的和</span></span><br><span class=\"line\">            updater(X.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">        metric.add(<span class=\"built_in\">float</span>(l.<span class=\"built_in\">sum</span>()), accuracy(y_hat, y), y.numel()) <span class=\"comment\">#记录损失、准确率、样本数</span></span><br><span class=\"line\">    <span class=\"comment\"># 返回训练损失和训练准确率</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">2</span>], metric[<span class=\"number\">1</span>] / metric[<span class=\"number\">2</span>] <span class=\"comment\">#因为损失做了sum，所以要除以样本数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图程序</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Animator</span>: <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, xlabel=<span class=\"literal\">None</span>, ylabel=<span class=\"literal\">None</span>, legend=<span class=\"literal\">None</span>, xlim=<span class=\"literal\">None</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 ylim=<span class=\"literal\">None</span>, xscale=<span class=\"string\">&#x27;linear&#x27;</span>, yscale=<span class=\"string\">&#x27;linear&#x27;</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 fmts=(<span class=\"params\"><span class=\"string\">&#x27;-&#x27;</span>, <span class=\"string\">&#x27;m--&#x27;</span>, <span class=\"string\">&#x27;g-.&#x27;</span>, <span class=\"string\">&#x27;r:&#x27;</span></span>), nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">1</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>)</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 增量地绘制多条线</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> legend <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            legend = []</span><br><span class=\"line\">        d2l.use_svg_display()</span><br><span class=\"line\">        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> nrows * ncols == <span class=\"number\">1</span>:</span><br><span class=\"line\">            self.axes = [self.axes,]</span><br><span class=\"line\">        <span class=\"comment\"># 使用lambda函数捕获参数</span></span><br><span class=\"line\">        self.config_axes = <span class=\"keyword\">lambda</span>: d2l.set_axes(self.axes[</span><br><span class=\"line\">            <span class=\"number\">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class=\"line\">        self.X, self.Y, self.fmts = <span class=\"literal\">None</span>, <span class=\"literal\">None</span>, fmts</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">add</span>(<span class=\"params\">self,x,y</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 向图表中添加多个数据点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(y, <span class=\"string\">&quot;__len__&quot;</span>):</span><br><span class=\"line\">            y = [y]</span><br><span class=\"line\">        n = <span class=\"built_in\">len</span>(y)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(x, <span class=\"string\">&quot;__len__&quot;</span>):</span><br><span class=\"line\">            x = [x] * n</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.X:</span><br><span class=\"line\">            self.X = [[] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.Y:</span><br><span class=\"line\">            self.Y = [[] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, (a, b) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(x, y)):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> a <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span> <span class=\"keyword\">and</span> b <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                self.X[i].append(a)</span><br><span class=\"line\">                self.Y[i].append(b)</span><br><span class=\"line\">        self.axes[<span class=\"number\">0</span>].cla()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x, y, fmt <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(self.X, self.Y, self.fmts):</span><br><span class=\"line\">            self.axes[<span class=\"number\">0</span>].plot(x, y, fmt)</span><br><span class=\"line\">        self.config_axes()</span><br><span class=\"line\">        display.display(self.fig)</span><br><span class=\"line\">        display.clear_output(wait=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_ch3</span>(<span class=\"params\">net, train_iter, test_iter, loss, num_epochs, updater</span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;训练模型&quot;&quot;&quot;</span></span><br><span class=\"line\">    animator = Animator(xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], ylim=[<span class=\"number\">0.3</span>, <span class=\"number\">0.9</span>],</span><br><span class=\"line\">                        legend=[<span class=\"string\">&#x27;train loss&#x27;</span>, <span class=\"string\">&#x27;train acc&#x27;</span>, <span class=\"string\">&#x27;test acc&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)</span><br><span class=\"line\">        test_acc = evaluate_accuracy(net, test_iter)</span><br><span class=\"line\">        animator.add(epoch + <span class=\"number\">1</span>, train_metrics + (test_acc,)) <span class=\"comment\">#记录epoch,训练损失、训练准确率、测试准确率</span></span><br><span class=\"line\">    train_loss, train_acc = train_metrics</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_loss &lt; <span class=\"number\">0.5</span>, train_loss <span class=\"comment\">#如果train_loss大于0.5，说明模型训练失败</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> train_acc &gt; <span class=\"number\">0.7</span>, train_acc</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> test_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> test_acc &gt; <span class=\"number\">0.7</span>, test_acc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 优化器</span></span><br><span class=\"line\">lr = <span class=\"number\">0.1</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">updater</span>(<span class=\"params\">batch_size</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d2l.sgd([W, b], lr, batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 训练</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">10</span></span><br><span class=\"line\">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)</span><br></pre></td></tr></table></figure>\n\n\n<p>​<br><img src=\"/6_softmax_realize_files/6_softmax_realize_13_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg\"><br>​    </p>\n<h1 id=\"6-7-预测\"><a href=\"#6-7-预测\" class=\"headerlink\" title=\"6.7 预测\"></a>6.7 预测</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">predict_ch3</span>(<span class=\"params\">net, test_iter, n=<span class=\"number\">6</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;预测标签&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> test_iter:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    trues = d2l.get_fashion_mnist_labels(y)</span><br><span class=\"line\">    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class=\"number\">1</span>))</span><br><span class=\"line\">    titles = [true + <span class=\"string\">&#x27;\\n&#x27;</span> + pred <span class=\"keyword\">for</span> true, pred <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(trues, preds)]</span><br><span class=\"line\">    d2l.show_images(X[<span class=\"number\">0</span>:n].reshape((n, <span class=\"number\">28</span>, <span class=\"number\">28</span>)), <span class=\"number\">1</span>, n, titles=titles[<span class=\"number\">0</span>:n])</span><br><span class=\"line\">predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure>\n\n\n<p>​<br><img src=\"/6_softmax_realize_files/6_softmax_realize_15_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg\"><br>​    </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"6-softmax回归从零实现\"><a href=\"#6-softmax回归从零实现\" class=\"headerlink\" title=\"6 softmax回归从零实现\"></a>6 softmax回归从零实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> IPython <span class=\"keyword\">import</span> display</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-1-初始化模型参数\"><a href=\"#6-1-初始化模型参数\" class=\"headerlink\" title=\"6.1 初始化模型参数\"></a>6.1 初始化模型参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_inputs = <span class=\"number\">784</span></span><br><span class=\"line\">num_outputs = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">W = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-2-定义softmax操作\"><a href=\"#6-2-定义softmax操作\" class=\"headerlink\" title=\"6.2 定义softmax操作\"></a>6.2 定义softmax操作</h2><p>$$ softmax(\\mathbf{X})_{ij} &#x3D; \\frac{ \\exp(\\mathbf{X} _{ij}) } { \\sum_k \\exp(\\mathbf{X} _{ik}) } $$</p>\n<ul>\n<li>1）对每个项求幂</li>\n<li>2）对每一行（样本）求和，得到每个样本的规范化常数</li>\n<li>3）对每一行（样本）各个项除以该常数，确保和为1</li>\n<li>分母或规范化常数，有时也称为配分函数（其对数称为对数‐配分函数）。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义softmax操作</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">softmax</span>(<span class=\"params\">X</span>): <span class=\"comment\">#矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。</span></span><br><span class=\"line\">    X_exp = torch.exp(X)</span><br><span class=\"line\">    partition = X_exp.<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_exp / partition <span class=\"comment\"># 这里应用了广播机制</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-3-定义模型\"><a href=\"#6-3-定义模型\" class=\"headerlink\" title=\"6.3 定义模型\"></a>6.3 定义模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义模型</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> softmax(torch.matmul(X.reshape(-<span class=\"number\">1</span>, W.shape[<span class=\"number\">0</span>]), W) + b)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-4-定义损失函数\"><a href=\"#6-4-定义损失函数\" class=\"headerlink\" title=\"6.4 定义损失函数\"></a>6.4 定义损失函数</h2><p>$$l(y_i,y_i’)&#x3D;-\\sum_{j&#x3D;1}^{q}y_{j}log(\\hat{y}_{j})$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义损失函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy</span>(<span class=\"params\">y_hat, y</span>): <span class=\"comment\">#根据交叉熵公式，yi是一个（0001）的向量，所以对于一个样本，他的交叉熵是：真实类别对应的那个概率求对数</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> -torch.log(y_hat[<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(y_hat)), y])</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6-5-分类精度\"><a href=\"#6-5-分类精度\" class=\"headerlink\" title=\"6.5 分类精度\"></a>6.5 分类精度</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算正确预测的数量</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">accuracy</span>(<span class=\"params\">y_hat, y</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;计算预测正确的数量。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(y_hat.shape) &gt; <span class=\"number\">1</span> <span class=\"keyword\">and</span> y_hat.shape[<span class=\"number\">1</span>] &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">        y_hat = y_hat.argmax(axis=<span class=\"number\">1</span>) <span class=\"comment\">#argmax(axis=1)返回矩阵每行最大值的索引</span></span><br><span class=\"line\">    cmp = y_hat.<span class=\"built_in\">type</span>(y.dtype) == y <span class=\"comment\">#返回一个bool矩阵</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">float</span>(cmp.<span class=\"built_in\">type</span>(y.dtype).<span class=\"built_in\">sum</span>())</span><br><span class=\"line\"><span class=\"comment\"># 评估模型的准确率</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">evaluate_accuracy</span>(<span class=\"params\">net, data_iter</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;计算在指定数据集上模型的精度。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):</span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># 将模型设置为评估模式</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">2</span>)  <span class=\"comment\"># 正确预测数、预测总数</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">            metric.add(accuracy(net(X), y), y.numel()) <span class=\"comment\">#y.numel()返回y中元素的个数</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 累加器</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Accumulator</span>:  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;在`n`个变量上累加。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, n</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * n</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">add</span>(<span class=\"params\">self, *args</span>):</span><br><span class=\"line\">        self.data = [a + <span class=\"built_in\">float</span>(b) <span class=\"keyword\">for</span> a, b <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(self.data, args)]</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">reset</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * <span class=\"built_in\">len</span>(self.data)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.data[idx]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 由于随机初始化，因此最开始的精度只有大概10%</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(evaluate_accuracy(net, test_iter))</span><br></pre></td></tr></table></figure>\n\n<pre><code>0.1141\n</code></pre>\n<h2 id=\"6-6-训练\"><a href=\"#6-6-训练\" class=\"headerlink\" title=\"6.6 训练\"></a>6.6 训练</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 训练一个epoch</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch_ch3</span>(<span class=\"params\">net, train_iter, loss, updater</span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;训练模型一个迭代周期&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 将模型设置为训练模式</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">    <span class=\"comment\"># 训练损失总和、训练准确度总和、样本数</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">3</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">        <span class=\"comment\"># 计算梯度并更新参数</span></span><br><span class=\"line\">        y_hat = net(X)</span><br><span class=\"line\">        l = loss(y_hat, y)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class=\"line\">            <span class=\"comment\"># 使用PyTorch内置的优化器和损失函数</span></span><br><span class=\"line\">            updater.zero_grad()</span><br><span class=\"line\">            l.mean.backward() <span class=\"comment\">#l.mean()返回l中所有元素的均值</span></span><br><span class=\"line\">            updater.step()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 使用定制的优化器和损失函数</span></span><br><span class=\"line\">            l.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#l.sum()返回l中所有元素的和</span></span><br><span class=\"line\">            updater(X.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">        metric.add(<span class=\"built_in\">float</span>(l.<span class=\"built_in\">sum</span>()), accuracy(y_hat, y), y.numel()) <span class=\"comment\">#记录损失、准确率、样本数</span></span><br><span class=\"line\">    <span class=\"comment\"># 返回训练损失和训练准确率</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">2</span>], metric[<span class=\"number\">1</span>] / metric[<span class=\"number\">2</span>] <span class=\"comment\">#因为损失做了sum，所以要除以样本数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图程序</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Animator</span>: <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, xlabel=<span class=\"literal\">None</span>, ylabel=<span class=\"literal\">None</span>, legend=<span class=\"literal\">None</span>, xlim=<span class=\"literal\">None</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 ylim=<span class=\"literal\">None</span>, xscale=<span class=\"string\">&#x27;linear&#x27;</span>, yscale=<span class=\"string\">&#x27;linear&#x27;</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 fmts=(<span class=\"params\"><span class=\"string\">&#x27;-&#x27;</span>, <span class=\"string\">&#x27;m--&#x27;</span>, <span class=\"string\">&#x27;g-.&#x27;</span>, <span class=\"string\">&#x27;r:&#x27;</span></span>), nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">1</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 figsize=(<span class=\"params\"><span class=\"number\">3.5</span>, <span class=\"number\">2.5</span></span>)</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 增量地绘制多条线</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> legend <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            legend = []</span><br><span class=\"line\">        d2l.use_svg_display()</span><br><span class=\"line\">        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> nrows * ncols == <span class=\"number\">1</span>:</span><br><span class=\"line\">            self.axes = [self.axes,]</span><br><span class=\"line\">        <span class=\"comment\"># 使用lambda函数捕获参数</span></span><br><span class=\"line\">        self.config_axes = <span class=\"keyword\">lambda</span>: d2l.set_axes(self.axes[</span><br><span class=\"line\">            <span class=\"number\">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class=\"line\">        self.X, self.Y, self.fmts = <span class=\"literal\">None</span>, <span class=\"literal\">None</span>, fmts</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">add</span>(<span class=\"params\">self,x,y</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 向图表中添加多个数据点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(y, <span class=\"string\">&quot;__len__&quot;</span>):</span><br><span class=\"line\">            y = [y]</span><br><span class=\"line\">        n = <span class=\"built_in\">len</span>(y)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">hasattr</span>(x, <span class=\"string\">&quot;__len__&quot;</span>):</span><br><span class=\"line\">            x = [x] * n</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.X:</span><br><span class=\"line\">            self.X = [[] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.Y:</span><br><span class=\"line\">            self.Y = [[] <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, (a, b) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(x, y)):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> a <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span> <span class=\"keyword\">and</span> b <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                self.X[i].append(a)</span><br><span class=\"line\">                self.Y[i].append(b)</span><br><span class=\"line\">        self.axes[<span class=\"number\">0</span>].cla()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x, y, fmt <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(self.X, self.Y, self.fmts):</span><br><span class=\"line\">            self.axes[<span class=\"number\">0</span>].plot(x, y, fmt)</span><br><span class=\"line\">        self.config_axes()</span><br><span class=\"line\">        display.display(self.fig)</span><br><span class=\"line\">        display.clear_output(wait=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 训练函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_ch3</span>(<span class=\"params\">net, train_iter, test_iter, loss, num_epochs, updater</span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;训练模型&quot;&quot;&quot;</span></span><br><span class=\"line\">    animator = Animator(xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], ylim=[<span class=\"number\">0.3</span>, <span class=\"number\">0.9</span>],</span><br><span class=\"line\">                        legend=[<span class=\"string\">&#x27;train loss&#x27;</span>, <span class=\"string\">&#x27;train acc&#x27;</span>, <span class=\"string\">&#x27;test acc&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)</span><br><span class=\"line\">        test_acc = evaluate_accuracy(net, test_iter)</span><br><span class=\"line\">        animator.add(epoch + <span class=\"number\">1</span>, train_metrics + (test_acc,)) <span class=\"comment\">#记录epoch,训练损失、训练准确率、测试准确率</span></span><br><span class=\"line\">    train_loss, train_acc = train_metrics</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_loss &lt; <span class=\"number\">0.5</span>, train_loss <span class=\"comment\">#如果train_loss大于0.5，说明模型训练失败</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> train_acc &gt; <span class=\"number\">0.7</span>, train_acc</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> test_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> test_acc &gt; <span class=\"number\">0.7</span>, test_acc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 优化器</span></span><br><span class=\"line\">lr = <span class=\"number\">0.1</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">updater</span>(<span class=\"params\">batch_size</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d2l.sgd([W, b], lr, batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 训练</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">10</span></span><br><span class=\"line\">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)</span><br></pre></td></tr></table></figure>\n\n\n<p>​<br><img src=\"/6_softmax_realize_files/6_softmax_realize_13_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_13_0.svg\"><br>​    </p>\n<h1 id=\"6-7-预测\"><a href=\"#6-7-预测\" class=\"headerlink\" title=\"6.7 预测\"></a>6.7 预测</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">predict_ch3</span>(<span class=\"params\">net, test_iter, n=<span class=\"number\">6</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;预测标签&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> test_iter:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    trues = d2l.get_fashion_mnist_labels(y)</span><br><span class=\"line\">    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class=\"number\">1</span>))</span><br><span class=\"line\">    titles = [true + <span class=\"string\">&#x27;\\n&#x27;</span> + pred <span class=\"keyword\">for</span> true, pred <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(trues, preds)]</span><br><span class=\"line\">    d2l.show_images(X[<span class=\"number\">0</span>:n].reshape((n, <span class=\"number\">28</span>, <span class=\"number\">28</span>)), <span class=\"number\">1</span>, n, titles=titles[<span class=\"number\">0</span>:n])</span><br><span class=\"line\">predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure>\n\n\n<p>​<br><img src=\"/6_softmax_realize_files/6_softmax_realize_15_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/6_softmax_realize_files/6_softmax_realize_15_0.svg\"><br>​    </p>"},{"title":"2.7 softmax回归简洁实现","date":"2024-02-04T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 7 softmax回归简洁实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n```\n\n## 7.1 初始化模型参数\n\n\n\n```python\n#1 初始化模型参数\n# pytorch不会隐式地调整输入的形状，因此我们在线性层前定义展平层来调整网络输入的形状\nnet = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 10))\n\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight, std=0.01)\n\nnet.apply(init_weights)\n```\n\n\n\n\n    Sequential(\n      (0): Flatten(start_dim=1, end_dim=-1)\n      (1): Linear(in_features=784, out_features=10, bias=True)\n    )\n\n\n\n## 7.2 优化softmax计算\n- 为了防止溢出，我们先将每个元素减去该行的最大值（每个$o_k$按常数进行移动不会改变softmax的输出）。$$\\begin{aligned} \\hat{y}_j &= \\frac{\\exp(o_j)}{\\sum_{i=1}^q \\exp(o_i)} \\\\ &= \\frac{\\exp(o_j - \\max(o))\\exp(\\max(o))}{\\sum_{i=1}^q \\exp(o_i - \\max(o))\\exp(\\max(o))} \\\\ &= \\frac{\\exp(o_j - \\max(o))}{\\sum_{i=1}^q \\exp(o_i - \\max(o))} \\end{aligned}$$\n- 有些oj − max(ok)具有较大的负值。由于精度受限，exp(oj − max(ok))将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使yˆj为零，并且使得log(ˆyj )的值为-inf。反向传播几步后，我们可能会发现自己面对一屏幕可怕的nan结果。\n- 通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。避免计算$\\exp{o_j-\\max(o_k)}$,因为log与exp抵消了 $$\\begin{aligned} log(\\hat{y}_j) &= log\\left(\\frac{\\exp(o_j - \\max(o_k))}{\\sum_{k=1}^q \\exp(o_k - \\max(o_k))}\\right) \\\\ &= log(\\exp(o_j - \\max(o_k))) - log(\\sum_{k=1}^q \\exp(o_k - \\max(o_k))) \\\\ &= o_j - \\max(o_k) - log(\\sum_{k=1}^q \\exp(o_k - \\max(o_k))) \\end{aligned}$$\n\n\n\n```python\n#2 损失函数\nloss = nn.CrossEntropyLoss(reduction='none') # reduction='none'表示返回每个样本的损失\n\n#3 优化算法\ntrainer = torch.optim.SGD(net.parameters(), lr=0.1)\n\n#4 训练\nnum_epochs = 10\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n\n    \n![svg](7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple.md","raw":"---\ntitle: 2.7 softmax回归简洁实现\ndate: 2024-2-4 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 7 softmax回归简洁实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n```\n\n## 7.1 初始化模型参数\n\n\n\n```python\n#1 初始化模型参数\n# pytorch不会隐式地调整输入的形状，因此我们在线性层前定义展平层来调整网络输入的形状\nnet = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 10))\n\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight, std=0.01)\n\nnet.apply(init_weights)\n```\n\n\n\n\n    Sequential(\n      (0): Flatten(start_dim=1, end_dim=-1)\n      (1): Linear(in_features=784, out_features=10, bias=True)\n    )\n\n\n\n## 7.2 优化softmax计算\n- 为了防止溢出，我们先将每个元素减去该行的最大值（每个$o_k$按常数进行移动不会改变softmax的输出）。$$\\begin{aligned} \\hat{y}_j &= \\frac{\\exp(o_j)}{\\sum_{i=1}^q \\exp(o_i)} \\\\ &= \\frac{\\exp(o_j - \\max(o))\\exp(\\max(o))}{\\sum_{i=1}^q \\exp(o_i - \\max(o))\\exp(\\max(o))} \\\\ &= \\frac{\\exp(o_j - \\max(o))}{\\sum_{i=1}^q \\exp(o_i - \\max(o))} \\end{aligned}$$\n- 有些oj − max(ok)具有较大的负值。由于精度受限，exp(oj − max(ok))将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使yˆj为零，并且使得log(ˆyj )的值为-inf。反向传播几步后，我们可能会发现自己面对一屏幕可怕的nan结果。\n- 通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。避免计算$\\exp{o_j-\\max(o_k)}$,因为log与exp抵消了 $$\\begin{aligned} log(\\hat{y}_j) &= log\\left(\\frac{\\exp(o_j - \\max(o_k))}{\\sum_{k=1}^q \\exp(o_k - \\max(o_k))}\\right) \\\\ &= log(\\exp(o_j - \\max(o_k))) - log(\\sum_{k=1}^q \\exp(o_k - \\max(o_k))) \\\\ &= o_j - \\max(o_k) - log(\\sum_{k=1}^q \\exp(o_k - \\max(o_k))) \\end{aligned}$$\n\n\n\n```python\n#2 损失函数\nloss = nn.CrossEntropyLoss(reduction='none') # reduction='none'表示返回每个样本的损失\n\n#3 优化算法\ntrainer = torch.optim.SGD(net.parameters(), lr=0.1)\n\n#4 训练\nnum_epochs = 10\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n\n    \n![svg](7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg)\n![](img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg)\n    \n\n","slug":"deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple","published":1,"updated":"2024-02-05T14:31:48.993Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clt19859g004o7svw06xnefkl","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"7-softmax回归简洁实现\"><a href=\"#7-softmax回归简洁实现\" class=\"headerlink\" title=\"7 softmax回归简洁实现\"></a>7 softmax回归简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7-1-初始化模型参数\"><a href=\"#7-1-初始化模型参数\" class=\"headerlink\" title=\"7.1 初始化模型参数\"></a>7.1 初始化模型参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\"><span class=\"comment\"># pytorch不会隐式地调整输入的形状，因此我们在线性层前定义展平层来调整网络输入的形状</span></span><br><span class=\"line\">net = nn.Sequential(nn.Flatten(), nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(init_weights)</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>Sequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=10, bias=True)\n)\n</code></pre>\n<h2 id=\"7-2-优化softmax计算\"><a href=\"#7-2-优化softmax计算\" class=\"headerlink\" title=\"7.2 优化softmax计算\"></a>7.2 优化softmax计算</h2><ul>\n<li>为了防止溢出，我们先将每个元素减去该行的最大值（每个$o_k$按常数进行移动不会改变softmax的输出）。$$\\begin{aligned} \\hat{y}<em>j &amp;&#x3D; \\frac{\\exp(o_j)}{\\sum</em>{i&#x3D;1}^q \\exp(o_i)} \\ &amp;&#x3D; \\frac{\\exp(o_j - \\max(o))\\exp(\\max(o))}{\\sum_{i&#x3D;1}^q \\exp(o_i - \\max(o))\\exp(\\max(o))} \\ &amp;&#x3D; \\frac{\\exp(o_j - \\max(o))}{\\sum_{i&#x3D;1}^q \\exp(o_i - \\max(o))} \\end{aligned}$$</li>\n<li>有些oj − max(ok)具有较大的负值。由于精度受限，exp(oj − max(ok))将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使yˆj为零，并且使得log(ˆyj )的值为-inf。反向传播几步后，我们可能会发现自己面对一屏幕可怕的nan结果。</li>\n<li>通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。避免计算$\\exp{o_j-\\max(o_k)}$,因为log与exp抵消了 $$\\begin{aligned} log(\\hat{y}<em>j) &amp;&#x3D; log\\left(\\frac{\\exp(o_j - \\max(o_k))}{\\sum</em>{k&#x3D;1}^q \\exp(o_k - \\max(o_k))}\\right) \\ &amp;&#x3D; log(\\exp(o_j - \\max(o_k))) - log(\\sum_{k&#x3D;1}^q \\exp(o_k - \\max(o_k))) \\ &amp;&#x3D; o_j - \\max(o_k) - log(\\sum_{k&#x3D;1}^q \\exp(o_k - \\max(o_k))) \\end{aligned}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#2 损失函数</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>) <span class=\"comment\"># reduction=&#x27;none&#x27;表示返回每个样本的损失</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 优化算法</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 训练</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">10</span></span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"7-softmax回归简洁实现\"><a href=\"#7-softmax回归简洁实现\" class=\"headerlink\" title=\"7 softmax回归简洁实现\"></a>7 softmax回归简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7-1-初始化模型参数\"><a href=\"#7-1-初始化模型参数\" class=\"headerlink\" title=\"7.1 初始化模型参数\"></a>7.1 初始化模型参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\"><span class=\"comment\"># pytorch不会隐式地调整输入的形状，因此我们在线性层前定义展平层来调整网络输入的形状</span></span><br><span class=\"line\">net = nn.Sequential(nn.Flatten(), nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(init_weights)</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>Sequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=10, bias=True)\n)\n</code></pre>\n<h2 id=\"7-2-优化softmax计算\"><a href=\"#7-2-优化softmax计算\" class=\"headerlink\" title=\"7.2 优化softmax计算\"></a>7.2 优化softmax计算</h2><ul>\n<li>为了防止溢出，我们先将每个元素减去该行的最大值（每个$o_k$按常数进行移动不会改变softmax的输出）。$$\\begin{aligned} \\hat{y}<em>j &amp;&#x3D; \\frac{\\exp(o_j)}{\\sum</em>{i&#x3D;1}^q \\exp(o_i)} \\ &amp;&#x3D; \\frac{\\exp(o_j - \\max(o))\\exp(\\max(o))}{\\sum_{i&#x3D;1}^q \\exp(o_i - \\max(o))\\exp(\\max(o))} \\ &amp;&#x3D; \\frac{\\exp(o_j - \\max(o))}{\\sum_{i&#x3D;1}^q \\exp(o_i - \\max(o))} \\end{aligned}$$</li>\n<li>有些oj − max(ok)具有较大的负值。由于精度受限，exp(oj − max(ok))将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使yˆj为零，并且使得log(ˆyj )的值为-inf。反向传播几步后，我们可能会发现自己面对一屏幕可怕的nan结果。</li>\n<li>通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。避免计算$\\exp{o_j-\\max(o_k)}$,因为log与exp抵消了 $$\\begin{aligned} log(\\hat{y}<em>j) &amp;&#x3D; log\\left(\\frac{\\exp(o_j - \\max(o_k))}{\\sum</em>{k&#x3D;1}^q \\exp(o_k - \\max(o_k))}\\right) \\ &amp;&#x3D; log(\\exp(o_j - \\max(o_k))) - log(\\sum_{k&#x3D;1}^q \\exp(o_k - \\max(o_k))) \\ &amp;&#x3D; o_j - \\max(o_k) - log(\\sum_{k&#x3D;1}^q \\exp(o_k - \\max(o_k))) \\end{aligned}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#2 损失函数</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>) <span class=\"comment\"># reduction=&#x27;none&#x27;表示返回每个样本的损失</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 优化算法</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 训练</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">10</span></span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/2_linear_neural_network/7_softmax_realize_simple_files/7_softmax_realize_simple_5_0.svg\"></p>"},{"title":"3.1 多层感知机","date":"2024-02-04T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 1 多层感知机\n## 1.1 隐藏层\n- 仿射变换中的线性是一个很强的假设。可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制，使其能处理更普遍的函数关系类型。我们可以把前L−1层看作表示，把最后一层看作线性预测器。这种架构通常称为多层感知机（multilayer perceptron），通常缩写为MLP\n![mlp](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1img\\1.png)\n![mlp](img/deeplearning/code/pytorch/3_mlp/1img/1.png)\n### 1.1.1 从线性到非线性\n\n- $X \\in R^{n \\times d}$，$W^{(1)} \\in R^{d \\times h}$，$H \\in R^{n \\times h}$，$W^{(2)} \\in R^{h \\times q}$，$O \\in R^{n \\times q}$\n- $X$是输入，$W^{(1)}$是第一层权重，$H$是第一层输出，$W^{(2)}$是第二层权重，$O$是输出\n$$H = XW^{(1)}+b^{(1)}$$\n$$O = HW^{(2)}+b^{(2)}$$\n- 仅添加隐藏层并不能扩展表达能力：\n$$O = (XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)} = XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}=XW+b$$\n- 还需要激活函数\n- 通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。\n\n## 1.2 激活函数\n### 1.2.1 ReLU函数\n- 修正线性单元（linear unit）提供了一个简单的非线性变换：$$ReLU(x) = max(x,0)$$\n- 使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题\n- ReLU函数有许多变体，包括参数化ReLU（Parameterized ReLU，pReLU）函数。该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过：$$pReLU(x) = max(0,x)+\\alpha min(0,x)$$\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom d2l import torch as d2l\n\n#relu函数\nx=torch.arange(-8.0,8.0,0.1,requires_grad=True)\ny=torch.relu(x)\n\n#relu函数的导数\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['relu','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg)\n    \n\n\n### 1.2.2 Sigmoid函数\n- sigmoid通常称为挤压函数（squashing function）：它将范围（‐inf, inf）中的任意输入压缩到区间（0, 1）中的某个值：$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n- 导数：$$sigmoid'(x) = sigmoid(x)(1-sigmoid(x))$$\n\n\n```python\n#sigmoid函数\ny = torch.sigmoid(x)\n\n#sigmoid函数的导数\nx.grad.data.zero_()\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['sigmoid','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_3_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg)\n    \n\n\n### 1.2.3 tanh函数\n- 函数的形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。\n$$tanh(x) = \\frac{1-e^{-2x}}{1+e^{-2x}}$$\n- 导数：$$tanh'(x) = 1-tanh^2(x)$$\n\n\n```python\n#tanh函数\ny=torch.tanh(x)\n\n#tanh函数的导数\nx.grad.data.zero_()\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['tanh','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_5_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/1_mlp.md","raw":"---\ntitle: 3.1 多层感知机\ndate: 2024-2-4 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 1 多层感知机\n## 1.1 隐藏层\n- 仿射变换中的线性是一个很强的假设。可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制，使其能处理更普遍的函数关系类型。我们可以把前L−1层看作表示，把最后一层看作线性预测器。这种架构通常称为多层感知机（multilayer perceptron），通常缩写为MLP\n![mlp](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1img\\1.png)\n![mlp](img/deeplearning/code/pytorch/3_mlp/1img/1.png)\n### 1.1.1 从线性到非线性\n\n- $X \\in R^{n \\times d}$，$W^{(1)} \\in R^{d \\times h}$，$H \\in R^{n \\times h}$，$W^{(2)} \\in R^{h \\times q}$，$O \\in R^{n \\times q}$\n- $X$是输入，$W^{(1)}$是第一层权重，$H$是第一层输出，$W^{(2)}$是第二层权重，$O$是输出\n$$H = XW^{(1)}+b^{(1)}$$\n$$O = HW^{(2)}+b^{(2)}$$\n- 仅添加隐藏层并不能扩展表达能力：\n$$O = (XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)} = XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}=XW+b$$\n- 还需要激活函数\n- 通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。\n\n## 1.2 激活函数\n### 1.2.1 ReLU函数\n- 修正线性单元（linear unit）提供了一个简单的非线性变换：$$ReLU(x) = max(x,0)$$\n- 使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题\n- ReLU函数有许多变体，包括参数化ReLU（Parameterized ReLU，pReLU）函数。该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过：$$pReLU(x) = max(0,x)+\\alpha min(0,x)$$\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom d2l import torch as d2l\n\n#relu函数\nx=torch.arange(-8.0,8.0,0.1,requires_grad=True)\ny=torch.relu(x)\n\n#relu函数的导数\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['relu','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg)\n    \n\n\n### 1.2.2 Sigmoid函数\n- sigmoid通常称为挤压函数（squashing function）：它将范围（‐inf, inf）中的任意输入压缩到区间（0, 1）中的某个值：$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n- 导数：$$sigmoid'(x) = sigmoid(x)(1-sigmoid(x))$$\n\n\n```python\n#sigmoid函数\ny = torch.sigmoid(x)\n\n#sigmoid函数的导数\nx.grad.data.zero_()\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['sigmoid','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_3_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg)\n    \n\n\n### 1.2.3 tanh函数\n- 函数的形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。\n$$tanh(x) = \\frac{1-e^{-2x}}{1+e^{-2x}}$$\n- 导数：$$tanh'(x) = 1-tanh^2(x)$$\n\n\n```python\n#tanh函数\ny=torch.tanh(x)\n\n#tanh函数的导数\nx.grad.data.zero_()\ny.backward(torch.ones_like(x),retain_graph=True)\n\n#画图\nd2l.plot(x.detach(),[y.detach(),x.grad],'x','y',figsize=(5,2.5),legend=['tanh','grad'])\n```\n\n\n![svg](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_5_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/1_mlp","published":1,"updated":"2024-03-20T11:04:56.049Z","_id":"clt19859h004s7svwat2y487d","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"1-多层感知机\"><a href=\"#1-多层感知机\" class=\"headerlink\" title=\"1 多层感知机\"></a>1 多层感知机</h1><h2 id=\"1-1-隐藏层\"><a href=\"#1-1-隐藏层\" class=\"headerlink\" title=\"1.1 隐藏层\"></a>1.1 隐藏层</h2><ul>\n<li>仿射变换中的线性是一个很强的假设。可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制，使其能处理更普遍的函数关系类型。我们可以把前L−1层看作表示，把最后一层看作线性预测器。这种架构通常称为多层感知机（multilayer perceptron），通常缩写为MLP<br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1img\\1.png\" alt=\"mlp\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1img/1.png\" alt=\"mlp\"></li>\n</ul>\n<h3 id=\"1-1-1-从线性到非线性\"><a href=\"#1-1-1-从线性到非线性\" class=\"headerlink\" title=\"1.1.1 从线性到非线性\"></a>1.1.1 从线性到非线性</h3><ul>\n<li>$X \\in R^{n \\times d}$，$W^{(1)} \\in R^{d \\times h}$，$H \\in R^{n \\times h}$，$W^{(2)} \\in R^{h \\times q}$，$O \\in R^{n \\times q}$</li>\n<li>$X$是输入，$W^{(1)}$是第一层权重，$H$是第一层输出，$W^{(2)}$是第二层权重，$O$是输出<br>$$H &#x3D; XW^{(1)}+b^{(1)}$$<br>$$O &#x3D; HW^{(2)}+b^{(2)}$$</li>\n<li>仅添加隐藏层并不能扩展表达能力：<br>$$O &#x3D; (XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)} &#x3D; XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}&#x3D;XW+b$$</li>\n<li>还需要激活函数</li>\n<li>通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。</li>\n</ul>\n<h2 id=\"1-2-激活函数\"><a href=\"#1-2-激活函数\" class=\"headerlink\" title=\"1.2 激活函数\"></a>1.2 激活函数</h2><h3 id=\"1-2-1-ReLU函数\"><a href=\"#1-2-1-ReLU函数\" class=\"headerlink\" title=\"1.2.1 ReLU函数\"></a>1.2.1 ReLU函数</h3><ul>\n<li>修正线性单元（linear unit）提供了一个简单的非线性变换：$$ReLU(x) &#x3D; max(x,0)$$</li>\n<li>使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题</li>\n<li>ReLU函数有许多变体，包括参数化ReLU（Parameterized ReLU，pReLU）函数。该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过：$$pReLU(x) &#x3D; max(0,x)+\\alpha min(0,x)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#relu函数</span></span><br><span class=\"line\">x=torch.arange(-<span class=\"number\">8.0</span>,<span class=\"number\">8.0</span>,<span class=\"number\">0.1</span>,requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y=torch.relu(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#relu函数的导数</span></span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;relu&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg\"></p>\n<h3 id=\"1-2-2-Sigmoid函数\"><a href=\"#1-2-2-Sigmoid函数\" class=\"headerlink\" title=\"1.2.2 Sigmoid函数\"></a>1.2.2 Sigmoid函数</h3><ul>\n<li>sigmoid通常称为挤压函数（squashing function）：它将范围（‐inf, inf）中的任意输入压缩到区间（0, 1）中的某个值：$$sigmoid(x) &#x3D; \\frac{1}{1+e^{-x}}$$</li>\n<li>导数：$$sigmoid’(x) &#x3D; sigmoid(x)(1-sigmoid(x))$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#sigmoid函数</span></span><br><span class=\"line\">y = torch.sigmoid(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#sigmoid函数的导数</span></span><br><span class=\"line\">x.grad.data.zero_()</span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;sigmoid&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_3_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg\"></p>\n<h3 id=\"1-2-3-tanh函数\"><a href=\"#1-2-3-tanh函数\" class=\"headerlink\" title=\"1.2.3 tanh函数\"></a>1.2.3 tanh函数</h3><ul>\n<li>函数的形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。<br>$$tanh(x) &#x3D; \\frac{1-e^{-2x}}{1+e^{-2x}}$$</li>\n<li>导数：$$tanh’(x) &#x3D; 1-tanh^2(x)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#tanh函数</span></span><br><span class=\"line\">y=torch.tanh(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#tanh函数的导数</span></span><br><span class=\"line\">x.grad.data.zero_()</span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;tanh&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_5_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-多层感知机\"><a href=\"#1-多层感知机\" class=\"headerlink\" title=\"1 多层感知机\"></a>1 多层感知机</h1><h2 id=\"1-1-隐藏层\"><a href=\"#1-1-隐藏层\" class=\"headerlink\" title=\"1.1 隐藏层\"></a>1.1 隐藏层</h2><ul>\n<li>仿射变换中的线性是一个很强的假设。可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制，使其能处理更普遍的函数关系类型。我们可以把前L−1层看作表示，把最后一层看作线性预测器。这种架构通常称为多层感知机（multilayer perceptron），通常缩写为MLP<br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1img\\1.png\" alt=\"mlp\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1img/1.png\" alt=\"mlp\"></li>\n</ul>\n<h3 id=\"1-1-1-从线性到非线性\"><a href=\"#1-1-1-从线性到非线性\" class=\"headerlink\" title=\"1.1.1 从线性到非线性\"></a>1.1.1 从线性到非线性</h3><ul>\n<li>$X \\in R^{n \\times d}$，$W^{(1)} \\in R^{d \\times h}$，$H \\in R^{n \\times h}$，$W^{(2)} \\in R^{h \\times q}$，$O \\in R^{n \\times q}$</li>\n<li>$X$是输入，$W^{(1)}$是第一层权重，$H$是第一层输出，$W^{(2)}$是第二层权重，$O$是输出<br>$$H &#x3D; XW^{(1)}+b^{(1)}$$<br>$$O &#x3D; HW^{(2)}+b^{(2)}$$</li>\n<li>仅添加隐藏层并不能扩展表达能力：<br>$$O &#x3D; (XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)} &#x3D; XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}&#x3D;XW+b$$</li>\n<li>还需要激活函数</li>\n<li>通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。</li>\n</ul>\n<h2 id=\"1-2-激活函数\"><a href=\"#1-2-激活函数\" class=\"headerlink\" title=\"1.2 激活函数\"></a>1.2 激活函数</h2><h3 id=\"1-2-1-ReLU函数\"><a href=\"#1-2-1-ReLU函数\" class=\"headerlink\" title=\"1.2.1 ReLU函数\"></a>1.2.1 ReLU函数</h3><ul>\n<li>修正线性单元（linear unit）提供了一个简单的非线性变换：$$ReLU(x) &#x3D; max(x,0)$$</li>\n<li>使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题</li>\n<li>ReLU函数有许多变体，包括参数化ReLU（Parameterized ReLU，pReLU）函数。该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过：$$pReLU(x) &#x3D; max(0,x)+\\alpha min(0,x)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#relu函数</span></span><br><span class=\"line\">x=torch.arange(-<span class=\"number\">8.0</span>,<span class=\"number\">8.0</span>,<span class=\"number\">0.1</span>,requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y=torch.relu(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#relu函数的导数</span></span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;relu&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_1_0.svg\"></p>\n<h3 id=\"1-2-2-Sigmoid函数\"><a href=\"#1-2-2-Sigmoid函数\" class=\"headerlink\" title=\"1.2.2 Sigmoid函数\"></a>1.2.2 Sigmoid函数</h3><ul>\n<li>sigmoid通常称为挤压函数（squashing function）：它将范围（‐inf, inf）中的任意输入压缩到区间（0, 1）中的某个值：$$sigmoid(x) &#x3D; \\frac{1}{1+e^{-x}}$$</li>\n<li>导数：$$sigmoid’(x) &#x3D; sigmoid(x)(1-sigmoid(x))$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#sigmoid函数</span></span><br><span class=\"line\">y = torch.sigmoid(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#sigmoid函数的导数</span></span><br><span class=\"line\">x.grad.data.zero_()</span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;sigmoid&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_3_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_3_0.svg\"></p>\n<h3 id=\"1-2-3-tanh函数\"><a href=\"#1-2-3-tanh函数\" class=\"headerlink\" title=\"1.2.3 tanh函数\"></a>1.2.3 tanh函数</h3><ul>\n<li>函数的形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。<br>$$tanh(x) &#x3D; \\frac{1-e^{-2x}}{1+e^{-2x}}$$</li>\n<li>导数：$$tanh’(x) &#x3D; 1-tanh^2(x)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#tanh函数</span></span><br><span class=\"line\">y=torch.tanh(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#tanh函数的导数</span></span><br><span class=\"line\">x.grad.data.zero_()</span><br><span class=\"line\">y.backward(torch.ones_like(x),retain_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">d2l.plot(x.detach(),[y.detach(),x.grad],<span class=\"string\">&#x27;x&#x27;</span>,<span class=\"string\">&#x27;y&#x27;</span>,figsize=(<span class=\"number\">5</span>,<span class=\"number\">2.5</span>),legend=[<span class=\"string\">&#x27;tanh&#x27;</span>,<span class=\"string\">&#x27;grad&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\1_mlp_files\\1_mlp_5_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/1_mlp_files/1_mlp_5_0.svg\"></p>"},{"title":"3.2 多层感知机实现","date":"2024-02-05T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n\n# 2 多层感知机实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n\n#1 初始化模型参数\nnum_inputs, num_outputs, num_hiddens = 28*28, 10, 256\nW1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)\nb1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\nW2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)\nb2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\nparams = [W1, b1, W2, b2]\n\n#2 激活函数\ndef relu(X):\n    a = torch.zeros_like(X)\n    return torch.max(X, a)\n\n#3 模型\ndef net(X):\n    X = X.reshape(-1, num_inputs)\n    H = relu(X @ W1 + b1) # @代表矩阵乘法\n    return (H @ W2 + b2)\n\n#4 损失函数\nloss = nn.CrossEntropyLoss(reduction='none')\n\n#5 训练\nnum_epochs, lr = 10, 0.1\nupdater = torch.optim.SGD(params, lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)\n\n#6 预测\nd2l.predict_ch3(net, test_iter)\n```\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg)\n    \n\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/2_mlp_realize.md","raw":"---\ntitle: 3.2 多层感知机实现\ndate: 2024-2-5 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n\n# 2 多层感知机实现\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n\n#1 初始化模型参数\nnum_inputs, num_outputs, num_hiddens = 28*28, 10, 256\nW1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)\nb1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\nW2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)\nb2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\nparams = [W1, b1, W2, b2]\n\n#2 激活函数\ndef relu(X):\n    a = torch.zeros_like(X)\n    return torch.max(X, a)\n\n#3 模型\ndef net(X):\n    X = X.reshape(-1, num_inputs)\n    H = relu(X @ W1 + b1) # @代表矩阵乘法\n    return (H @ W2 + b2)\n\n#4 损失函数\nloss = nn.CrossEntropyLoss(reduction='none')\n\n#5 训练\nnum_epochs, lr = 10, 0.1\nupdater = torch.optim.SGD(params, lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)\n\n#6 预测\nd2l.predict_ch3(net, test_iter)\n```\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg)\n    \n\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/2_mlp_realize","published":1,"updated":"2024-03-20T11:06:27.272Z","_id":"clt19859h004v7svwgw1j3zxp","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"2-多层感知机实现\"><a href=\"#2-多层感知机实现\" class=\"headerlink\" title=\"2 多层感知机实现\"></a>2 多层感知机实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens = <span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span></span><br><span class=\"line\">W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\">W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\">params = [W1, b1, W2, b2]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 激活函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">relu</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    a = torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">max</span>(X, a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 模型</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    X = X.reshape(-<span class=\"number\">1</span>, num_inputs)</span><br><span class=\"line\">    H = relu(X @ W1 + b1) <span class=\"comment\"># @代表矩阵乘法</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (H @ W2 + b2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 损失函数</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 训练</span></span><br><span class=\"line\">num_epochs, lr = <span class=\"number\">10</span>, <span class=\"number\">0.1</span></span><br><span class=\"line\">updater = torch.optim.SGD(params, lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#6 预测</span></span><br><span class=\"line\">d2l.predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"2-多层感知机实现\"><a href=\"#2-多层感知机实现\" class=\"headerlink\" title=\"2 多层感知机实现\"></a>2 多层感知机实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens = <span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span></span><br><span class=\"line\">W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\">W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\">params = [W1, b1, W2, b2]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 激活函数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">relu</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    a = torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">max</span>(X, a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 模型</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    X = X.reshape(-<span class=\"number\">1</span>, num_inputs)</span><br><span class=\"line\">    H = relu(X @ W1 + b1) <span class=\"comment\"># @代表矩阵乘法</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (H @ W2 + b2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 损失函数</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 训练</span></span><br><span class=\"line\">num_epochs, lr = <span class=\"number\">10</span>, <span class=\"number\">0.1</span></span><br><span class=\"line\">updater = torch.optim.SGD(params, lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#6 预测</span></span><br><span class=\"line\">d2l.predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_0.svg\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/2_mlp_realize_files/2_mlp_realize_1_1.svg\"></p>"},{"title":"3.3 多层感知机简洁实现","date":"2024-02-05T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 3 多层感知机简洁实现\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]= 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\n#1 模型\nnet = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(28*28,256),\n    nn.ReLU(),\n    nn.Linear(256,10)\n)\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight,std=0.01)\nnet.apply(init_weights)\n\n#2 参数\nbatch_size, lr, num_epochs= 256, 0.1, 10\n\n#3 损失\nloss= nn.CrossEntropyLoss(reduction='none')\n\n#4 优化器\ntrainer= torch.optim.SGD(net.parameters(),lr=lr)\n\n#5 训练\ntrain_iter, test_iter= d2l.load_data_fashion_mnist(batch_size)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple.md","raw":"---\ntitle: 3.3 多层感知机简洁实现\ndate: 2024-2-5 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 3 多层感知机简洁实现\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]= 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\n#1 模型\nnet = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(28*28,256),\n    nn.ReLU(),\n    nn.Linear(256,10)\n)\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight,std=0.01)\nnet.apply(init_weights)\n\n#2 参数\nbatch_size, lr, num_epochs= 256, 0.1, 10\n\n#3 损失\nloss= nn.CrossEntropyLoss(reduction='none')\n\n#4 优化器\ntrainer= torch.optim.SGD(net.parameters(),lr=lr)\n\n#5 训练\ntrain_iter, test_iter= d2l.load_data_fashion_mnist(batch_size)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg)\n![](img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple","published":1,"updated":"2024-03-20T11:07:20.484Z","_id":"clt19859i00507svw17qo18o4","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"3-多层感知机简洁实现\"><a href=\"#3-多层感知机简洁实现\" class=\"headerlink\" title=\"3 多层感知机简洁实现\"></a>3 多层感知机简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]= <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 模型</span></span><br><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight,std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 参数</span></span><br><span class=\"line\">batch_size, lr, num_epochs= <span class=\"number\">256</span>, <span class=\"number\">0.1</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 损失</span></span><br><span class=\"line\">loss= nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 优化器</span></span><br><span class=\"line\">trainer= torch.optim.SGD(net.parameters(),lr=lr)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 训练</span></span><br><span class=\"line\">train_iter, test_iter= d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-多层感知机简洁实现\"><a href=\"#3-多层感知机简洁实现\" class=\"headerlink\" title=\"3 多层感知机简洁实现\"></a>3 多层感知机简洁实现</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]= <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 模型</span></span><br><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight,std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 参数</span></span><br><span class=\"line\">batch_size, lr, num_epochs= <span class=\"number\">256</span>, <span class=\"number\">0.1</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 损失</span></span><br><span class=\"line\">loss= nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 优化器</span></span><br><span class=\"line\">trainer= torch.optim.SGD(net.parameters(),lr=lr)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#5 训练</span></span><br><span class=\"line\">train_iter, test_iter= d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/3_mlp_realize_simple_files/3_mlp_realize_simple_1_0.svg\"></p>"},{"title":"3.4 模型选择、欠拟合和过拟合","date":"2024-02-05T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 4 模型选择、欠拟合和过拟合\n- 将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting），用于对抗过拟合的技术称为正则化（regularization）。\n- 如果有足够多的神经元、层数和训练迭代周期，模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。\n## 4.1 训练误差和泛化误差\n- 训练误差（training error）：模型在训练数据集上计算得到的误差。\n- 泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。\n### 4.1.1 统计学习理论\n- 假设训练数据和测试数据都是从相同的分布中独立提取的。这通常被称为独立同分布假设。（这意味着对数据进行采样的过程没有进行“记忆”。换句话说，抽取的第2个样本和第3个样本的相关性，并不比抽取的第2个样本和第200万个样本的相关性更强。）\n\n### 4.1.2 模型复杂性\n- 一个模型是否能很好地泛化取决于很多因素。例如，具有更多参数的模型可能被认为更复杂，参数有更大取值范围的模型可能更为复杂。通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂，而需要早停（earlystopping）的模型（即较少训练迭代周期）就不那么复杂。\n- 几个影响模型泛化的因素：\n    - 可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。\n    - 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。\n    - 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。\n## 4.2 验证集\n- 为了确定候选模型中的最佳模型，我们通常会使用验证集。\n- 在我们确定所有的超参数之前，我们不希望用到测试集。如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。\n- 验证数据和测试数据的边界模糊，我写的代码中使用的测试集严格来说是验证集。\n\n### 4.2.1 K折交叉验证\n- 当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集\n- 原始训练数据被分成K个不重叠的子集。然后执行K次模型训练和验证，每次在K − 1个子集上进行训练，并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。最后，通过对K次实验的结果取平均来估计训练和验证误差。\n\n## 4.3 欠拟合与过拟合\n- 欠拟合：训练误差和验证误差都很大，但有一点差距。说明模型表达能力不足，需要更复杂的模型。\n- 过拟合：训练误差和验证误差之间的差距很大。最终关心的是验证误差。\n- 是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小。\n\n### 4.3.1 模型复杂性\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png) \n![](img/deeplearning/code/pytorch/3_mlp/4img/1.png)\n\n### 4.3.2 数据集大小\n\n- 模型复杂性和数据集大小之间通常存在关系。如果没有足够的数据，简单的模型可能更有用。\\\n\n## 4.4 多项式回归\n- 为了更好地理解模型选择、欠拟合和过拟合，我们可以通过多项式回归来考虑这些问题。\n\n\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\nimport math\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n```\n\n### 4.4.1 生成数据集\n- $$y= 5+1.2x-\\frac{x^2}{2!}+5.6\\frac{x^3}{3!}+\\epsilon， \\quad \\epsilon \\sim N(0,0.1^2)$$\n\n\n```python\n#1 生成100个样本\nmax_degree= 20 #多项式的最大阶数, 用更多的阶数表示更复杂的模型为了演示过拟合，正常用四项就可，仅用两项欠拟合，用20项过拟合\nn_train, n_test= 100,100 #训练集、测试集大小\ntrue_w= np.zeros(max_degree) #分配大量的空间(20,)\ntrue_w[0:4]= np.array([5, 1.2, -3.4, 5.6])#w前4项赋值\nfeatures= np.random.normal(size=(n_train+n_test,1)) #（200,1）\nnp.random.shuffle(features)\npoly_features= np.power(features,np.arange(max_degree).reshape(1,-1)) #一个feature扩展成20项：0次方到19次方（200,20）\nfor i in range(max_degree):\n    poly_features[:,i]/=math.gamma(i+1) #gamma(n)=(n-1)! #一个feature的每一项都除以i的阶乘\nlabels= np.dot(poly_features,true_w) #（200,20）*（20,）=（200,）\nlabels += np.random.normal(scale=0.1,size=labels.shape) #加上噪声\n\n#NumPy ndarray -> tensor\ntrue_w, features, poly_features, labels= [torch.tensor(x, dtype=torch.float32) for x in [true_w, features, poly_features, labels]]\nprint(features[:2], poly_features[:2,:], labels[:2],sep='\\n') #两个x, 两个20项后的x，两个y\n```\n\n    tensor([[ 0.3571],\n            [-1.5272]])\n    tensor([[ 1.0000e+00,  3.5710e-01,  6.3759e-02,  7.5893e-03,  6.7753e-04,\n              4.8388e-05,  2.8799e-06,  1.4691e-07,  6.5578e-09,  2.6019e-10,\n              9.2914e-12,  3.0163e-13,  8.9759e-15,  2.4656e-16,  6.2889e-18,\n              1.4972e-19,  3.3414e-21,  7.0189e-23,  1.3925e-24,  2.6170e-26],\n            [ 1.0000e+00, -1.5272e+00,  1.1661e+00, -5.9360e-01,  2.2663e-01,\n             -6.9220e-02,  1.7618e-02, -3.8437e-03,  7.3374e-04, -1.2450e-04,\n              1.9014e-05, -2.6397e-06,  3.3594e-07, -3.9464e-08,  4.3048e-09,\n             -4.3827e-10,  4.1832e-11, -3.7579e-12,  3.1882e-13, -2.5626e-14]])\n    tensor([ 5.0956, -4.0147])\n\n\n### 4.4.2 训练与测试\n\n\n\n```python\n#2 评估损失\ndef evaluate_loss(net, data_iter, loss): #@save\n    \"\"\"评估给定数据集上模型的损失\"\"\"\n    metric= d2l.Accumulator(2) #损失总和，样本数量\n    for X,y in data_iter:\n        out= net(X)\n        y= y.reshape(out.shape)\n        l= loss(out,y)\n        metric.add(l.sum(),l.numel())\n    return metric[0]/metric[1] #平均损失\n\n#3 训练\ndef train(train_features, test_features, train_labels, test_labels, num_epochs=400):\n    loss= nn.MSELoss(reduction='none')\n    input_shape= train_features.shape[-1]\n    net= nn.Sequential(nn.Linear(input_shape,1,bias=False))\n    batch_size= min(10, train_labels.shape[0])\n    train_iter= d2l.load_array((train_features, train_labels.reshape(-1,1)), batch_size)\n    test_iter= d2l.load_array((test_features, test_labels.reshape(-1,1)), batch_size, is_train=False)\n    trainer= torch.optim.SGD(net.parameters(), lr=0.01)\n    animator= d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log', xlim=[1, num_epochs], ylim=[1e-3, 1e2], legend=['train','test'])\n    for epoch in range(num_epochs):\n        d2l.train_epoch_ch3(net, train_iter, loss, trainer)\n        if epoch==0 or (epoch+1)%20==0:\n            animator.add(epoch+1, (evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)))\n    print('weight:', net[0].weight.data.numpy())\n```\n\n### 4.4.3 三阶多项式函数拟合（正常）\n\n\n\n```python\n# 从多项式特征中选择前4个维度：1，x，x^2，x^3\ntrain(poly_features[:n_train,:4], poly_features[n_train:, :4], labels[:n_train], labels[n_train:])\n```\n\n    weight: [[ 4.98059    1.1953405 -3.389903   5.607252 ]]\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg)\n    \n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg)\n    \n\n\n### 4.4.4 线性函数拟合（欠拟合）\n\n\n\n```python\n# 从多项式特征中选择前2个维度：1，x\ntrain(poly_features[:n_train,:2], poly_features[n_train:, :2], labels[:n_train], labels[n_train:])\n```\n\n    weight: [[2.9687963 4.1943007]]\n\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg)\n    \n\n\n### 4.4.5 高阶多项式函数拟合（过拟合）\n\n\n```python\ntrain(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=1500)\n```\n\n    weight: [[ 4.96578789e+00  1.30018699e+00 -3.35006833e+00  5.17666531e+00\n      -1.19773000e-01  9.30291474e-01 -9.37245637e-02 -2.67241318e-02\n       1.06728293e-01 -1.89072818e-01 -1.45296961e-01 -1.12053894e-01\n       1.03521936e-01 -3.26722339e-02  1.13504946e-01  3.62291411e-02\n      -4.04332444e-04  3.25103179e-02 -7.38418847e-02 -1.19887017e-01]]\n\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/4_overfitting.md","raw":"---\ntitle: 3.4 模型选择、欠拟合和过拟合\ndate: 2024-2-5 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 4 模型选择、欠拟合和过拟合\n- 将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting），用于对抗过拟合的技术称为正则化（regularization）。\n- 如果有足够多的神经元、层数和训练迭代周期，模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。\n## 4.1 训练误差和泛化误差\n- 训练误差（training error）：模型在训练数据集上计算得到的误差。\n- 泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。\n### 4.1.1 统计学习理论\n- 假设训练数据和测试数据都是从相同的分布中独立提取的。这通常被称为独立同分布假设。（这意味着对数据进行采样的过程没有进行“记忆”。换句话说，抽取的第2个样本和第3个样本的相关性，并不比抽取的第2个样本和第200万个样本的相关性更强。）\n\n### 4.1.2 模型复杂性\n- 一个模型是否能很好地泛化取决于很多因素。例如，具有更多参数的模型可能被认为更复杂，参数有更大取值范围的模型可能更为复杂。通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂，而需要早停（earlystopping）的模型（即较少训练迭代周期）就不那么复杂。\n- 几个影响模型泛化的因素：\n    - 可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。\n    - 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。\n    - 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。\n## 4.2 验证集\n- 为了确定候选模型中的最佳模型，我们通常会使用验证集。\n- 在我们确定所有的超参数之前，我们不希望用到测试集。如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。\n- 验证数据和测试数据的边界模糊，我写的代码中使用的测试集严格来说是验证集。\n\n### 4.2.1 K折交叉验证\n- 当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集\n- 原始训练数据被分成K个不重叠的子集。然后执行K次模型训练和验证，每次在K − 1个子集上进行训练，并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。最后，通过对K次实验的结果取平均来估计训练和验证误差。\n\n## 4.3 欠拟合与过拟合\n- 欠拟合：训练误差和验证误差都很大，但有一点差距。说明模型表达能力不足，需要更复杂的模型。\n- 过拟合：训练误差和验证误差之间的差距很大。最终关心的是验证误差。\n- 是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小。\n\n### 4.3.1 模型复杂性\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png) \n![](img/deeplearning/code/pytorch/3_mlp/4img/1.png)\n\n### 4.3.2 数据集大小\n\n- 模型复杂性和数据集大小之间通常存在关系。如果没有足够的数据，简单的模型可能更有用。\\\n\n## 4.4 多项式回归\n- 为了更好地理解模型选择、欠拟合和过拟合，我们可以通过多项式回归来考虑这些问题。\n\n\n\n\n```python\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\nimport math\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n```\n\n### 4.4.1 生成数据集\n- $$y= 5+1.2x-\\frac{x^2}{2!}+5.6\\frac{x^3}{3!}+\\epsilon， \\quad \\epsilon \\sim N(0,0.1^2)$$\n\n\n```python\n#1 生成100个样本\nmax_degree= 20 #多项式的最大阶数, 用更多的阶数表示更复杂的模型为了演示过拟合，正常用四项就可，仅用两项欠拟合，用20项过拟合\nn_train, n_test= 100,100 #训练集、测试集大小\ntrue_w= np.zeros(max_degree) #分配大量的空间(20,)\ntrue_w[0:4]= np.array([5, 1.2, -3.4, 5.6])#w前4项赋值\nfeatures= np.random.normal(size=(n_train+n_test,1)) #（200,1）\nnp.random.shuffle(features)\npoly_features= np.power(features,np.arange(max_degree).reshape(1,-1)) #一个feature扩展成20项：0次方到19次方（200,20）\nfor i in range(max_degree):\n    poly_features[:,i]/=math.gamma(i+1) #gamma(n)=(n-1)! #一个feature的每一项都除以i的阶乘\nlabels= np.dot(poly_features,true_w) #（200,20）*（20,）=（200,）\nlabels += np.random.normal(scale=0.1,size=labels.shape) #加上噪声\n\n#NumPy ndarray -> tensor\ntrue_w, features, poly_features, labels= [torch.tensor(x, dtype=torch.float32) for x in [true_w, features, poly_features, labels]]\nprint(features[:2], poly_features[:2,:], labels[:2],sep='\\n') #两个x, 两个20项后的x，两个y\n```\n\n    tensor([[ 0.3571],\n            [-1.5272]])\n    tensor([[ 1.0000e+00,  3.5710e-01,  6.3759e-02,  7.5893e-03,  6.7753e-04,\n              4.8388e-05,  2.8799e-06,  1.4691e-07,  6.5578e-09,  2.6019e-10,\n              9.2914e-12,  3.0163e-13,  8.9759e-15,  2.4656e-16,  6.2889e-18,\n              1.4972e-19,  3.3414e-21,  7.0189e-23,  1.3925e-24,  2.6170e-26],\n            [ 1.0000e+00, -1.5272e+00,  1.1661e+00, -5.9360e-01,  2.2663e-01,\n             -6.9220e-02,  1.7618e-02, -3.8437e-03,  7.3374e-04, -1.2450e-04,\n              1.9014e-05, -2.6397e-06,  3.3594e-07, -3.9464e-08,  4.3048e-09,\n             -4.3827e-10,  4.1832e-11, -3.7579e-12,  3.1882e-13, -2.5626e-14]])\n    tensor([ 5.0956, -4.0147])\n\n\n### 4.4.2 训练与测试\n\n\n\n```python\n#2 评估损失\ndef evaluate_loss(net, data_iter, loss): #@save\n    \"\"\"评估给定数据集上模型的损失\"\"\"\n    metric= d2l.Accumulator(2) #损失总和，样本数量\n    for X,y in data_iter:\n        out= net(X)\n        y= y.reshape(out.shape)\n        l= loss(out,y)\n        metric.add(l.sum(),l.numel())\n    return metric[0]/metric[1] #平均损失\n\n#3 训练\ndef train(train_features, test_features, train_labels, test_labels, num_epochs=400):\n    loss= nn.MSELoss(reduction='none')\n    input_shape= train_features.shape[-1]\n    net= nn.Sequential(nn.Linear(input_shape,1,bias=False))\n    batch_size= min(10, train_labels.shape[0])\n    train_iter= d2l.load_array((train_features, train_labels.reshape(-1,1)), batch_size)\n    test_iter= d2l.load_array((test_features, test_labels.reshape(-1,1)), batch_size, is_train=False)\n    trainer= torch.optim.SGD(net.parameters(), lr=0.01)\n    animator= d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log', xlim=[1, num_epochs], ylim=[1e-3, 1e2], legend=['train','test'])\n    for epoch in range(num_epochs):\n        d2l.train_epoch_ch3(net, train_iter, loss, trainer)\n        if epoch==0 or (epoch+1)%20==0:\n            animator.add(epoch+1, (evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)))\n    print('weight:', net[0].weight.data.numpy())\n```\n\n### 4.4.3 三阶多项式函数拟合（正常）\n\n\n\n```python\n# 从多项式特征中选择前4个维度：1，x，x^2，x^3\ntrain(poly_features[:n_train,:4], poly_features[n_train:, :4], labels[:n_train], labels[n_train:])\n```\n\n    weight: [[ 4.98059    1.1953405 -3.389903   5.607252 ]]\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg)\n    \n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg)\n    \n\n\n### 4.4.4 线性函数拟合（欠拟合）\n\n\n\n```python\n# 从多项式特征中选择前2个维度：1，x\ntrain(poly_features[:n_train,:2], poly_features[n_train:, :2], labels[:n_train], labels[n_train:])\n```\n\n    weight: [[2.9687963 4.1943007]]\n\n\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg)\n    \n\n\n### 4.4.5 高阶多项式函数拟合（过拟合）\n\n\n```python\ntrain(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=1500)\n```\n\n    weight: [[ 4.96578789e+00  1.30018699e+00 -3.35006833e+00  5.17666531e+00\n      -1.19773000e-01  9.30291474e-01 -9.37245637e-02 -2.67241318e-02\n       1.06728293e-01 -1.89072818e-01 -1.45296961e-01 -1.12053894e-01\n       1.03521936e-01 -3.26722339e-02  1.13504946e-01  3.62291411e-02\n      -4.04332444e-04  3.25103179e-02 -7.38418847e-02 -1.19887017e-01]]\n\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/4_overfitting","published":1,"updated":"2024-03-20T11:10:37.936Z","_id":"clt1985ac00bh7svw0op4f2nr","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"4-模型选择、欠拟合和过拟合\"><a href=\"#4-模型选择、欠拟合和过拟合\" class=\"headerlink\" title=\"4 模型选择、欠拟合和过拟合\"></a>4 模型选择、欠拟合和过拟合</h1><ul>\n<li>将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting），用于对抗过拟合的技术称为正则化（regularization）。</li>\n<li>如果有足够多的神经元、层数和训练迭代周期，模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。</li>\n</ul>\n<h2 id=\"4-1-训练误差和泛化误差\"><a href=\"#4-1-训练误差和泛化误差\" class=\"headerlink\" title=\"4.1 训练误差和泛化误差\"></a>4.1 训练误差和泛化误差</h2><ul>\n<li>训练误差（training error）：模型在训练数据集上计算得到的误差。</li>\n<li>泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</li>\n</ul>\n<h3 id=\"4-1-1-统计学习理论\"><a href=\"#4-1-1-统计学习理论\" class=\"headerlink\" title=\"4.1.1 统计学习理论\"></a>4.1.1 统计学习理论</h3><ul>\n<li>假设训练数据和测试数据都是从相同的分布中独立提取的。这通常被称为独立同分布假设。（这意味着对数据进行采样的过程没有进行“记忆”。换句话说，抽取的第2个样本和第3个样本的相关性，并不比抽取的第2个样本和第200万个样本的相关性更强。）</li>\n</ul>\n<h3 id=\"4-1-2-模型复杂性\"><a href=\"#4-1-2-模型复杂性\" class=\"headerlink\" title=\"4.1.2 模型复杂性\"></a>4.1.2 模型复杂性</h3><ul>\n<li>一个模型是否能很好地泛化取决于很多因素。例如，具有更多参数的模型可能被认为更复杂，参数有更大取值范围的模型可能更为复杂。通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂，而需要早停（earlystopping）的模型（即较少训练迭代周期）就不那么复杂。</li>\n<li>几个影响模型泛化的因素：<ul>\n<li>可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。</li>\n<li>参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。</li>\n<li>训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-2-验证集\"><a href=\"#4-2-验证集\" class=\"headerlink\" title=\"4.2 验证集\"></a>4.2 验证集</h2><ul>\n<li>为了确定候选模型中的最佳模型，我们通常会使用验证集。</li>\n<li>在我们确定所有的超参数之前，我们不希望用到测试集。如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。</li>\n<li>验证数据和测试数据的边界模糊，我写的代码中使用的测试集严格来说是验证集。</li>\n</ul>\n<h3 id=\"4-2-1-K折交叉验证\"><a href=\"#4-2-1-K折交叉验证\" class=\"headerlink\" title=\"4.2.1 K折交叉验证\"></a>4.2.1 K折交叉验证</h3><ul>\n<li>当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集</li>\n<li>原始训练数据被分成K个不重叠的子集。然后执行K次模型训练和验证，每次在K − 1个子集上进行训练，并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。最后，通过对K次实验的结果取平均来估计训练和验证误差。</li>\n</ul>\n<h2 id=\"4-3-欠拟合与过拟合\"><a href=\"#4-3-欠拟合与过拟合\" class=\"headerlink\" title=\"4.3 欠拟合与过拟合\"></a>4.3 欠拟合与过拟合</h2><ul>\n<li>欠拟合：训练误差和验证误差都很大，但有一点差距。说明模型表达能力不足，需要更复杂的模型。</li>\n<li>过拟合：训练误差和验证误差之间的差距很大。最终关心的是验证误差。</li>\n<li>是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小。</li>\n</ul>\n<h3 id=\"4-3-1-模型复杂性\"><a href=\"#4-3-1-模型复杂性\" class=\"headerlink\" title=\"4.3.1 模型复杂性\"></a>4.3.1 模型复杂性</h3><p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4img/1.png\"></p>\n<h3 id=\"4-3-2-数据集大小\"><a href=\"#4-3-2-数据集大小\" class=\"headerlink\" title=\"4.3.2 数据集大小\"></a>4.3.2 数据集大小</h3><ul>\n<li>模型复杂性和数据集大小之间通常存在关系。如果没有足够的数据，简单的模型可能更有用。\\</li>\n</ul>\n<h2 id=\"4-4-多项式回归\"><a href=\"#4-4-多项式回归\" class=\"headerlink\" title=\"4.4 多项式回归\"></a>4.4 多项式回归</h2><ul>\n<li>为了更好地理解模型选择、欠拟合和过拟合，我们可以通过多项式回归来考虑这些问题。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-4-1-生成数据集\"><a href=\"#4-4-1-生成数据集\" class=\"headerlink\" title=\"4.4.1 生成数据集\"></a>4.4.1 生成数据集</h3><ul>\n<li>$$y&#x3D; 5+1.2x-\\frac{x^2}{2!}+5.6\\frac{x^3}{3!}+\\epsilon， \\quad \\epsilon \\sim N(0,0.1^2)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 生成100个样本</span></span><br><span class=\"line\">max_degree= <span class=\"number\">20</span> <span class=\"comment\">#多项式的最大阶数, 用更多的阶数表示更复杂的模型为了演示过拟合，正常用四项就可，仅用两项欠拟合，用20项过拟合</span></span><br><span class=\"line\">n_train, n_test= <span class=\"number\">100</span>,<span class=\"number\">100</span> <span class=\"comment\">#训练集、测试集大小</span></span><br><span class=\"line\">true_w= np.zeros(max_degree) <span class=\"comment\">#分配大量的空间(20,)</span></span><br><span class=\"line\">true_w[<span class=\"number\">0</span>:<span class=\"number\">4</span>]= np.array([<span class=\"number\">5</span>, <span class=\"number\">1.2</span>, -<span class=\"number\">3.4</span>, <span class=\"number\">5.6</span>])<span class=\"comment\">#w前4项赋值</span></span><br><span class=\"line\">features= np.random.normal(size=(n_train+n_test,<span class=\"number\">1</span>)) <span class=\"comment\">#（200,1）</span></span><br><span class=\"line\">np.random.shuffle(features)</span><br><span class=\"line\">poly_features= np.power(features,np.arange(max_degree).reshape(<span class=\"number\">1</span>,-<span class=\"number\">1</span>)) <span class=\"comment\">#一个feature扩展成20项：0次方到19次方（200,20）</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(max_degree):</span><br><span class=\"line\">    poly_features[:,i]/=math.gamma(i+<span class=\"number\">1</span>) <span class=\"comment\">#gamma(n)=(n-1)! #一个feature的每一项都除以i的阶乘</span></span><br><span class=\"line\">labels= np.dot(poly_features,true_w) <span class=\"comment\">#（200,20）*（20,）=（200,）</span></span><br><span class=\"line\">labels += np.random.normal(scale=<span class=\"number\">0.1</span>,size=labels.shape) <span class=\"comment\">#加上噪声</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#NumPy ndarray -&gt; tensor</span></span><br><span class=\"line\">true_w, features, poly_features, labels= [torch.tensor(x, dtype=torch.float32) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> [true_w, features, poly_features, labels]]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(features[:<span class=\"number\">2</span>], poly_features[:<span class=\"number\">2</span>,:], labels[:<span class=\"number\">2</span>],sep=<span class=\"string\">&#x27;\\n&#x27;</span>) <span class=\"comment\">#两个x, 两个20项后的x，两个y</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.3571],\n        [-1.5272]])\ntensor([[ 1.0000e+00,  3.5710e-01,  6.3759e-02,  7.5893e-03,  6.7753e-04,\n          4.8388e-05,  2.8799e-06,  1.4691e-07,  6.5578e-09,  2.6019e-10,\n          9.2914e-12,  3.0163e-13,  8.9759e-15,  2.4656e-16,  6.2889e-18,\n          1.4972e-19,  3.3414e-21,  7.0189e-23,  1.3925e-24,  2.6170e-26],\n        [ 1.0000e+00, -1.5272e+00,  1.1661e+00, -5.9360e-01,  2.2663e-01,\n         -6.9220e-02,  1.7618e-02, -3.8437e-03,  7.3374e-04, -1.2450e-04,\n          1.9014e-05, -2.6397e-06,  3.3594e-07, -3.9464e-08,  4.3048e-09,\n         -4.3827e-10,  4.1832e-11, -3.7579e-12,  3.1882e-13, -2.5626e-14]])\ntensor([ 5.0956, -4.0147])\n</code></pre>\n<h3 id=\"4-4-2-训练与测试\"><a href=\"#4-4-2-训练与测试\" class=\"headerlink\" title=\"4.4.2 训练与测试\"></a>4.4.2 训练与测试</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#2 评估损失</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">evaluate_loss</span>(<span class=\"params\">net, data_iter, loss</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;评估给定数据集上模型的损失&quot;&quot;&quot;</span></span><br><span class=\"line\">    metric= d2l.Accumulator(<span class=\"number\">2</span>) <span class=\"comment\">#损失总和，样本数量</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        out= net(X)</span><br><span class=\"line\">        y= y.reshape(out.shape)</span><br><span class=\"line\">        l= loss(out,y)</span><br><span class=\"line\">        metric.add(l.<span class=\"built_in\">sum</span>(),l.numel())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>]/metric[<span class=\"number\">1</span>] <span class=\"comment\">#平均损失</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 训练</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">train_features, test_features, train_labels, test_labels, num_epochs=<span class=\"number\">400</span></span>):</span><br><span class=\"line\">    loss= nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">    input_shape= train_features.shape[-<span class=\"number\">1</span>]</span><br><span class=\"line\">    net= nn.Sequential(nn.Linear(input_shape,<span class=\"number\">1</span>,bias=<span class=\"literal\">False</span>))</span><br><span class=\"line\">    batch_size= <span class=\"built_in\">min</span>(<span class=\"number\">10</span>, train_labels.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    train_iter= d2l.load_array((train_features, train_labels.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)), batch_size)</span><br><span class=\"line\">    test_iter= d2l.load_array((test_features, test_labels.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)), batch_size, is_train=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    trainer= torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">    animator= d2l.Animator(xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], ylim=[<span class=\"number\">1e-3</span>, <span class=\"number\">1e2</span>], legend=[<span class=\"string\">&#x27;train&#x27;</span>,<span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        d2l.train_epoch_ch3(net, train_iter, loss, trainer)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> epoch==<span class=\"number\">0</span> <span class=\"keyword\">or</span> (epoch+<span class=\"number\">1</span>)%<span class=\"number\">20</span>==<span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch+<span class=\"number\">1</span>, (evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;weight:&#x27;</span>, net[<span class=\"number\">0</span>].weight.data.numpy())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-4-3-三阶多项式函数拟合（正常）\"><a href=\"#4-4-3-三阶多项式函数拟合（正常）\" class=\"headerlink\" title=\"4.4.3 三阶多项式函数拟合（正常）\"></a>4.4.3 三阶多项式函数拟合（正常）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从多项式特征中选择前4个维度：1，x，x^2，x^3</span></span><br><span class=\"line\">train(poly_features[:n_train,:<span class=\"number\">4</span>], poly_features[n_train:, :<span class=\"number\">4</span>], labels[:n_train], labels[n_train:])</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[ 4.98059    1.1953405 -3.389903   5.607252 ]]\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg\"></p>\n<h3 id=\"4-4-4-线性函数拟合（欠拟合）\"><a href=\"#4-4-4-线性函数拟合（欠拟合）\" class=\"headerlink\" title=\"4.4.4 线性函数拟合（欠拟合）\"></a>4.4.4 线性函数拟合（欠拟合）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从多项式特征中选择前2个维度：1，x</span></span><br><span class=\"line\">train(poly_features[:n_train,:<span class=\"number\">2</span>], poly_features[n_train:, :<span class=\"number\">2</span>], labels[:n_train], labels[n_train:])</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[2.9687963 4.1943007]]\n</code></pre>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg\"></p>\n<h3 id=\"4-4-5-高阶多项式函数拟合（过拟合）\"><a href=\"#4-4-5-高阶多项式函数拟合（过拟合）\" class=\"headerlink\" title=\"4.4.5 高阶多项式函数拟合（过拟合）\"></a>4.4.5 高阶多项式函数拟合（过拟合）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=<span class=\"number\">1500</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[ 4.96578789e+00  1.30018699e+00 -3.35006833e+00  5.17666531e+00\n  -1.19773000e-01  9.30291474e-01 -9.37245637e-02 -2.67241318e-02\n   1.06728293e-01 -1.89072818e-01 -1.45296961e-01 -1.12053894e-01\n   1.03521936e-01 -3.26722339e-02  1.13504946e-01  3.62291411e-02\n  -4.04332444e-04  3.25103179e-02 -7.38418847e-02 -1.19887017e-01]]\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"4-模型选择、欠拟合和过拟合\"><a href=\"#4-模型选择、欠拟合和过拟合\" class=\"headerlink\" title=\"4 模型选择、欠拟合和过拟合\"></a>4 模型选择、欠拟合和过拟合</h1><ul>\n<li>将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting），用于对抗过拟合的技术称为正则化（regularization）。</li>\n<li>如果有足够多的神经元、层数和训练迭代周期，模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。</li>\n</ul>\n<h2 id=\"4-1-训练误差和泛化误差\"><a href=\"#4-1-训练误差和泛化误差\" class=\"headerlink\" title=\"4.1 训练误差和泛化误差\"></a>4.1 训练误差和泛化误差</h2><ul>\n<li>训练误差（training error）：模型在训练数据集上计算得到的误差。</li>\n<li>泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</li>\n</ul>\n<h3 id=\"4-1-1-统计学习理论\"><a href=\"#4-1-1-统计学习理论\" class=\"headerlink\" title=\"4.1.1 统计学习理论\"></a>4.1.1 统计学习理论</h3><ul>\n<li>假设训练数据和测试数据都是从相同的分布中独立提取的。这通常被称为独立同分布假设。（这意味着对数据进行采样的过程没有进行“记忆”。换句话说，抽取的第2个样本和第3个样本的相关性，并不比抽取的第2个样本和第200万个样本的相关性更强。）</li>\n</ul>\n<h3 id=\"4-1-2-模型复杂性\"><a href=\"#4-1-2-模型复杂性\" class=\"headerlink\" title=\"4.1.2 模型复杂性\"></a>4.1.2 模型复杂性</h3><ul>\n<li>一个模型是否能很好地泛化取决于很多因素。例如，具有更多参数的模型可能被认为更复杂，参数有更大取值范围的模型可能更为复杂。通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂，而需要早停（earlystopping）的模型（即较少训练迭代周期）就不那么复杂。</li>\n<li>几个影响模型泛化的因素：<ul>\n<li>可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。</li>\n<li>参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。</li>\n<li>训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-2-验证集\"><a href=\"#4-2-验证集\" class=\"headerlink\" title=\"4.2 验证集\"></a>4.2 验证集</h2><ul>\n<li>为了确定候选模型中的最佳模型，我们通常会使用验证集。</li>\n<li>在我们确定所有的超参数之前，我们不希望用到测试集。如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。</li>\n<li>验证数据和测试数据的边界模糊，我写的代码中使用的测试集严格来说是验证集。</li>\n</ul>\n<h3 id=\"4-2-1-K折交叉验证\"><a href=\"#4-2-1-K折交叉验证\" class=\"headerlink\" title=\"4.2.1 K折交叉验证\"></a>4.2.1 K折交叉验证</h3><ul>\n<li>当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集</li>\n<li>原始训练数据被分成K个不重叠的子集。然后执行K次模型训练和验证，每次在K − 1个子集上进行训练，并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。最后，通过对K次实验的结果取平均来估计训练和验证误差。</li>\n</ul>\n<h2 id=\"4-3-欠拟合与过拟合\"><a href=\"#4-3-欠拟合与过拟合\" class=\"headerlink\" title=\"4.3 欠拟合与过拟合\"></a>4.3 欠拟合与过拟合</h2><ul>\n<li>欠拟合：训练误差和验证误差都很大，但有一点差距。说明模型表达能力不足，需要更复杂的模型。</li>\n<li>过拟合：训练误差和验证误差之间的差距很大。最终关心的是验证误差。</li>\n<li>是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小。</li>\n</ul>\n<h3 id=\"4-3-1-模型复杂性\"><a href=\"#4-3-1-模型复杂性\" class=\"headerlink\" title=\"4.3.1 模型复杂性\"></a>4.3.1 模型复杂性</h3><p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4img/1.png\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4img/1.png\"></p>\n<h3 id=\"4-3-2-数据集大小\"><a href=\"#4-3-2-数据集大小\" class=\"headerlink\" title=\"4.3.2 数据集大小\"></a>4.3.2 数据集大小</h3><ul>\n<li>模型复杂性和数据集大小之间通常存在关系。如果没有足够的数据，简单的模型可能更有用。\\</li>\n</ul>\n<h2 id=\"4-4-多项式回归\"><a href=\"#4-4-多项式回归\" class=\"headerlink\" title=\"4.4 多项式回归\"></a>4.4 多项式回归</h2><ul>\n<li>为了更好地理解模型选择、欠拟合和过拟合，我们可以通过多项式回归来考虑这些问题。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class=\"string\">&quot;TRUE&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-4-1-生成数据集\"><a href=\"#4-4-1-生成数据集\" class=\"headerlink\" title=\"4.4.1 生成数据集\"></a>4.4.1 生成数据集</h3><ul>\n<li>$$y&#x3D; 5+1.2x-\\frac{x^2}{2!}+5.6\\frac{x^3}{3!}+\\epsilon， \\quad \\epsilon \\sim N(0,0.1^2)$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 生成100个样本</span></span><br><span class=\"line\">max_degree= <span class=\"number\">20</span> <span class=\"comment\">#多项式的最大阶数, 用更多的阶数表示更复杂的模型为了演示过拟合，正常用四项就可，仅用两项欠拟合，用20项过拟合</span></span><br><span class=\"line\">n_train, n_test= <span class=\"number\">100</span>,<span class=\"number\">100</span> <span class=\"comment\">#训练集、测试集大小</span></span><br><span class=\"line\">true_w= np.zeros(max_degree) <span class=\"comment\">#分配大量的空间(20,)</span></span><br><span class=\"line\">true_w[<span class=\"number\">0</span>:<span class=\"number\">4</span>]= np.array([<span class=\"number\">5</span>, <span class=\"number\">1.2</span>, -<span class=\"number\">3.4</span>, <span class=\"number\">5.6</span>])<span class=\"comment\">#w前4项赋值</span></span><br><span class=\"line\">features= np.random.normal(size=(n_train+n_test,<span class=\"number\">1</span>)) <span class=\"comment\">#（200,1）</span></span><br><span class=\"line\">np.random.shuffle(features)</span><br><span class=\"line\">poly_features= np.power(features,np.arange(max_degree).reshape(<span class=\"number\">1</span>,-<span class=\"number\">1</span>)) <span class=\"comment\">#一个feature扩展成20项：0次方到19次方（200,20）</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(max_degree):</span><br><span class=\"line\">    poly_features[:,i]/=math.gamma(i+<span class=\"number\">1</span>) <span class=\"comment\">#gamma(n)=(n-1)! #一个feature的每一项都除以i的阶乘</span></span><br><span class=\"line\">labels= np.dot(poly_features,true_w) <span class=\"comment\">#（200,20）*（20,）=（200,）</span></span><br><span class=\"line\">labels += np.random.normal(scale=<span class=\"number\">0.1</span>,size=labels.shape) <span class=\"comment\">#加上噪声</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#NumPy ndarray -&gt; tensor</span></span><br><span class=\"line\">true_w, features, poly_features, labels= [torch.tensor(x, dtype=torch.float32) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> [true_w, features, poly_features, labels]]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(features[:<span class=\"number\">2</span>], poly_features[:<span class=\"number\">2</span>,:], labels[:<span class=\"number\">2</span>],sep=<span class=\"string\">&#x27;\\n&#x27;</span>) <span class=\"comment\">#两个x, 两个20项后的x，两个y</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.3571],\n        [-1.5272]])\ntensor([[ 1.0000e+00,  3.5710e-01,  6.3759e-02,  7.5893e-03,  6.7753e-04,\n          4.8388e-05,  2.8799e-06,  1.4691e-07,  6.5578e-09,  2.6019e-10,\n          9.2914e-12,  3.0163e-13,  8.9759e-15,  2.4656e-16,  6.2889e-18,\n          1.4972e-19,  3.3414e-21,  7.0189e-23,  1.3925e-24,  2.6170e-26],\n        [ 1.0000e+00, -1.5272e+00,  1.1661e+00, -5.9360e-01,  2.2663e-01,\n         -6.9220e-02,  1.7618e-02, -3.8437e-03,  7.3374e-04, -1.2450e-04,\n          1.9014e-05, -2.6397e-06,  3.3594e-07, -3.9464e-08,  4.3048e-09,\n         -4.3827e-10,  4.1832e-11, -3.7579e-12,  3.1882e-13, -2.5626e-14]])\ntensor([ 5.0956, -4.0147])\n</code></pre>\n<h3 id=\"4-4-2-训练与测试\"><a href=\"#4-4-2-训练与测试\" class=\"headerlink\" title=\"4.4.2 训练与测试\"></a>4.4.2 训练与测试</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#2 评估损失</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">evaluate_loss</span>(<span class=\"params\">net, data_iter, loss</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;评估给定数据集上模型的损失&quot;&quot;&quot;</span></span><br><span class=\"line\">    metric= d2l.Accumulator(<span class=\"number\">2</span>) <span class=\"comment\">#损失总和，样本数量</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        out= net(X)</span><br><span class=\"line\">        y= y.reshape(out.shape)</span><br><span class=\"line\">        l= loss(out,y)</span><br><span class=\"line\">        metric.add(l.<span class=\"built_in\">sum</span>(),l.numel())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>]/metric[<span class=\"number\">1</span>] <span class=\"comment\">#平均损失</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 训练</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">train_features, test_features, train_labels, test_labels, num_epochs=<span class=\"number\">400</span></span>):</span><br><span class=\"line\">    loss= nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">    input_shape= train_features.shape[-<span class=\"number\">1</span>]</span><br><span class=\"line\">    net= nn.Sequential(nn.Linear(input_shape,<span class=\"number\">1</span>,bias=<span class=\"literal\">False</span>))</span><br><span class=\"line\">    batch_size= <span class=\"built_in\">min</span>(<span class=\"number\">10</span>, train_labels.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    train_iter= d2l.load_array((train_features, train_labels.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)), batch_size)</span><br><span class=\"line\">    test_iter= d2l.load_array((test_features, test_labels.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)), batch_size, is_train=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    trainer= torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">    animator= d2l.Animator(xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], ylim=[<span class=\"number\">1e-3</span>, <span class=\"number\">1e2</span>], legend=[<span class=\"string\">&#x27;train&#x27;</span>,<span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        d2l.train_epoch_ch3(net, train_iter, loss, trainer)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> epoch==<span class=\"number\">0</span> <span class=\"keyword\">or</span> (epoch+<span class=\"number\">1</span>)%<span class=\"number\">20</span>==<span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch+<span class=\"number\">1</span>, (evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;weight:&#x27;</span>, net[<span class=\"number\">0</span>].weight.data.numpy())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-4-3-三阶多项式函数拟合（正常）\"><a href=\"#4-4-3-三阶多项式函数拟合（正常）\" class=\"headerlink\" title=\"4.4.3 三阶多项式函数拟合（正常）\"></a>4.4.3 三阶多项式函数拟合（正常）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从多项式特征中选择前4个维度：1，x，x^2，x^3</span></span><br><span class=\"line\">train(poly_features[:n_train,:<span class=\"number\">4</span>], poly_features[n_train:, :<span class=\"number\">4</span>], labels[:n_train], labels[n_train:])</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[ 4.98059    1.1953405 -3.389903   5.607252 ]]\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_7_1.svg\"></p>\n<h3 id=\"4-4-4-线性函数拟合（欠拟合）\"><a href=\"#4-4-4-线性函数拟合（欠拟合）\" class=\"headerlink\" title=\"4.4.4 线性函数拟合（欠拟合）\"></a>4.4.4 线性函数拟合（欠拟合）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从多项式特征中选择前2个维度：1，x</span></span><br><span class=\"line\">train(poly_features[:n_train,:<span class=\"number\">2</span>], poly_features[n_train:, :<span class=\"number\">2</span>], labels[:n_train], labels[n_train:])</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[2.9687963 4.1943007]]\n</code></pre>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_9_1.svg\"></p>\n<h3 id=\"4-4-5-高阶多项式函数拟合（过拟合）\"><a href=\"#4-4-5-高阶多项式函数拟合（过拟合）\" class=\"headerlink\" title=\"4.4.5 高阶多项式函数拟合（过拟合）\"></a>4.4.5 高阶多项式函数拟合（过拟合）</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=<span class=\"number\">1500</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>weight: [[ 4.96578789e+00  1.30018699e+00 -3.35006833e+00  5.17666531e+00\n  -1.19773000e-01  9.30291474e-01 -9.37245637e-02 -2.67241318e-02\n   1.06728293e-01 -1.89072818e-01 -1.45296961e-01 -1.12053894e-01\n   1.03521936e-01 -3.26722339e-02  1.13504946e-01  3.62291411e-02\n  -4.04332444e-04  3.25103179e-02 -7.38418847e-02 -1.19887017e-01]]\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/4_overfitting_files/4_overfitting_11_1.svg\"></p>"},{"title":"3.5 权重衰减","date":"2024-02-06T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n\n# 5 权重衰减\n\n- 缓解过拟合：\n    - 更多数据\n    - 正则化技术\n- 权重衰减也称$L_2$正则化,通过函数与零的距离来衡量函数的复杂度。如何精确地测量一个函数和零之间的距离呢？一种简单的方法是通过线性函数 f(x) = w⊤x 中的权重向量的某个范数来度量其复杂性，例如$||W||^2$。将权重向量作为惩罚项加入损失函数。原始的损失：\n$$L(\\mathbf{w},b)=\\frac{1}{n}\\sum\\limits^{n}_{i=1}\\frac{1}{2}(\\mathbf{w}^T\\mathbf{x}^{(1)}+b-y^{(i)})^2$$\n- 加入惩罚项\n$$L=L(\\mathbf{w},b)+\\frac{\\lambda}{2}||\\mathbf{w}||^2$$\n- 除以2是为了求导时消掉，让表达式更简单。使用平方范数而不是标准范数（欧几里得距离）是为了便于计算，且它对权重向量的大分量施加了巨大的惩罚，这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。相比之下，L1惩罚会导致模型将权重集中在一小部分特征上，而将其他\n权重清除为零。这称为特征选择（feature selection）\n- 加入正则化项后的梯度更新：\n$$\\mathbf{w} \\leftarrow (1-\\eta \\lambda)\\mathbf{w}-\\frac{\\eta}{| \\Beta |}\\sum\\limits_{ i\\in \\Beta }\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$$\n## 5.1 高维线性回归(实现权重衰减)\n$$ y= 0.05+ \\sum\\limits^{d}_{i=1}0.01x_i+\\epsilon, \\epsilon \\in N(0,0.01^2)$$\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nn_train, n_test, num_inputs, batch_size = 20, 100, 200, 5\ntrue_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05\ntraind_data = d2l.synthetic_data(true_w, true_b, n_train)\ntraind_iter = d2l.load_array(traind_data, batch_size)\ntest_data = d2l.synthetic_data(true_w, true_b, n_test)\ntest_iter = d2l.load_array(test_data, batch_size, is_train=False)\n\n#1 初始化模型参数\ndef init_params():\n    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)\n    b = torch.zeros(1, requires_grad=True)\n    return [w, b]\n\n#2 定义L2范数惩罚\ndef l2_penalty(w):\n    return torch.sum(w.pow(2)) / 2\n\n#3 定义训练代码\ndef train(lambd):\n    w, b = init_params()\n    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n    num_epochs, lr = 100, 0.003\n    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])\n    for epoch in range(num_epochs):\n        for X, y in traind_iter:\n            l = loss(net(X), y) + lambd * l2_penalty(w) #计算损失后加上L2范数惩罚项\n            l.sum().backward()\n            d2l.sgd([w, b], lr, batch_size)\n        if (epoch + 1) % 5 == 0:\n            animator.add(epoch + 1, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))\n    print('w的L2范数是：', torch.norm(w).item())\n\n#4 测试\ntrain(lambd=0) #没有使用权重衰减\n```\n\n    w的L2范数是： 12.524763107299805\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg)\n    \n\n\n\n```python\ntrain(lambd=3) #使用权重衰减\n```\n\n    w的L2范数是： 0.3719361424446106\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg)\n    \n\n\n## 5.2 简洁实现\n- 通常将权重衰减集成到优化算法中，以便与任何损失函数结合使用，并允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。\n\n\n```python\ndef train_concise(wd):\n    net = nn.Sequential(nn.Linear(num_inputs, 1))\n    for param in net.parameters():\n        param.data.normal_()\n    loss = nn.MSELoss(reduction='none')\n    num_epochs, lr = 100, 0.003\n    # 偏置参数没有衰减\n    trainer = torch.optim.SGD([\n        { \"params\": net[0].weight, 'weight_decay': wd}, \n        { \"params\": net[0].bias}], lr=lr)\n    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])\n    for epoch in range(num_epochs):\n        for X, y in traind_iter:\n            trainer.zero_grad()\n            l = loss(net(X), y).mean()\n            trainer.zero_grad()\n            l.backward()\n            trainer.step()\n        if (epoch + 1) % 5 == 0:\n            animator.add(epoch + 1, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))\n    print('w的L2范数：', net[0].weight.norm().item())\n\ntrain_concise(0)\n```\n\n    w的L2范数： 12.297795295715332\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg)\n    \n\n\n\n```python\ntrain_concise(3)\n```\n\n    w的L2范数： 0.40956297516822815\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/5_weight_decay.md","raw":"---\ntitle: 3.5 权重衰减\ndate: 2024-2-6 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n\n# 5 权重衰减\n\n- 缓解过拟合：\n    - 更多数据\n    - 正则化技术\n- 权重衰减也称$L_2$正则化,通过函数与零的距离来衡量函数的复杂度。如何精确地测量一个函数和零之间的距离呢？一种简单的方法是通过线性函数 f(x) = w⊤x 中的权重向量的某个范数来度量其复杂性，例如$||W||^2$。将权重向量作为惩罚项加入损失函数。原始的损失：\n$$L(\\mathbf{w},b)=\\frac{1}{n}\\sum\\limits^{n}_{i=1}\\frac{1}{2}(\\mathbf{w}^T\\mathbf{x}^{(1)}+b-y^{(i)})^2$$\n- 加入惩罚项\n$$L=L(\\mathbf{w},b)+\\frac{\\lambda}{2}||\\mathbf{w}||^2$$\n- 除以2是为了求导时消掉，让表达式更简单。使用平方范数而不是标准范数（欧几里得距离）是为了便于计算，且它对权重向量的大分量施加了巨大的惩罚，这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。相比之下，L1惩罚会导致模型将权重集中在一小部分特征上，而将其他\n权重清除为零。这称为特征选择（feature selection）\n- 加入正则化项后的梯度更新：\n$$\\mathbf{w} \\leftarrow (1-\\eta \\lambda)\\mathbf{w}-\\frac{\\eta}{| \\Beta |}\\sum\\limits_{ i\\in \\Beta }\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$$\n## 5.1 高维线性回归(实现权重衰减)\n$$ y= 0.05+ \\sum\\limits^{d}_{i=1}0.01x_i+\\epsilon, \\epsilon \\in N(0,0.01^2)$$\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nn_train, n_test, num_inputs, batch_size = 20, 100, 200, 5\ntrue_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05\ntraind_data = d2l.synthetic_data(true_w, true_b, n_train)\ntraind_iter = d2l.load_array(traind_data, batch_size)\ntest_data = d2l.synthetic_data(true_w, true_b, n_test)\ntest_iter = d2l.load_array(test_data, batch_size, is_train=False)\n\n#1 初始化模型参数\ndef init_params():\n    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)\n    b = torch.zeros(1, requires_grad=True)\n    return [w, b]\n\n#2 定义L2范数惩罚\ndef l2_penalty(w):\n    return torch.sum(w.pow(2)) / 2\n\n#3 定义训练代码\ndef train(lambd):\n    w, b = init_params()\n    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n    num_epochs, lr = 100, 0.003\n    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])\n    for epoch in range(num_epochs):\n        for X, y in traind_iter:\n            l = loss(net(X), y) + lambd * l2_penalty(w) #计算损失后加上L2范数惩罚项\n            l.sum().backward()\n            d2l.sgd([w, b], lr, batch_size)\n        if (epoch + 1) % 5 == 0:\n            animator.add(epoch + 1, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))\n    print('w的L2范数是：', torch.norm(w).item())\n\n#4 测试\ntrain(lambd=0) #没有使用权重衰减\n```\n\n    w的L2范数是： 12.524763107299805\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg)\n    \n\n\n\n```python\ntrain(lambd=3) #使用权重衰减\n```\n\n    w的L2范数是： 0.3719361424446106\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg)\n    \n\n\n## 5.2 简洁实现\n- 通常将权重衰减集成到优化算法中，以便与任何损失函数结合使用，并允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。\n\n\n```python\ndef train_concise(wd):\n    net = nn.Sequential(nn.Linear(num_inputs, 1))\n    for param in net.parameters():\n        param.data.normal_()\n    loss = nn.MSELoss(reduction='none')\n    num_epochs, lr = 100, 0.003\n    # 偏置参数没有衰减\n    trainer = torch.optim.SGD([\n        { \"params\": net[0].weight, 'weight_decay': wd}, \n        { \"params\": net[0].bias}], lr=lr)\n    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])\n    for epoch in range(num_epochs):\n        for X, y in traind_iter:\n            trainer.zero_grad()\n            l = loss(net(X), y).mean()\n            trainer.zero_grad()\n            l.backward()\n            trainer.step()\n        if (epoch + 1) % 5 == 0:\n            animator.add(epoch + 1, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))\n    print('w的L2范数：', net[0].weight.norm().item())\n\ntrain_concise(0)\n```\n\n    w的L2范数： 12.297795295715332\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg)\n    \n\n\n\n```python\ntrain_concise(3)\n```\n\n    w的L2范数： 0.40956297516822815\n\n\n\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg)\n![](img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/5_weight_decay","published":1,"updated":"2024-03-20T11:12:16.715Z","_id":"clt1985ac00bi7svwbxeegipm","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"5-权重衰减\"><a href=\"#5-权重衰减\" class=\"headerlink\" title=\"5 权重衰减\"></a>5 权重衰减</h1><ul>\n<li>缓解过拟合：<ul>\n<li>更多数据</li>\n<li>正则化技术</li>\n</ul>\n</li>\n<li>权重衰减也称$L_2$正则化,通过函数与零的距离来衡量函数的复杂度。如何精确地测量一个函数和零之间的距离呢？一种简单的方法是通过线性函数 f(x) &#x3D; w⊤x 中的权重向量的某个范数来度量其复杂性，例如$||W||^2$。将权重向量作为惩罚项加入损失函数。原始的损失：<br>$$L(\\mathbf{w},b)&#x3D;\\frac{1}{n}\\sum\\limits^{n}_{i&#x3D;1}\\frac{1}{2}(\\mathbf{w}^T\\mathbf{x}^{(1)}+b-y^{(i)})^2$$</li>\n<li>加入惩罚项<br>$$L&#x3D;L(\\mathbf{w},b)+\\frac{\\lambda}{2}||\\mathbf{w}||^2$$</li>\n<li>除以2是为了求导时消掉，让表达式更简单。使用平方范数而不是标准范数（欧几里得距离）是为了便于计算，且它对权重向量的大分量施加了巨大的惩罚，这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。相比之下，L1惩罚会导致模型将权重集中在一小部分特征上，而将其他<br>权重清除为零。这称为特征选择（feature selection）</li>\n<li>加入正则化项后的梯度更新：<br>$$\\mathbf{w} \\leftarrow (1-\\eta \\lambda)\\mathbf{w}-\\frac{\\eta}{| \\Beta |}\\sum\\limits_{ i\\in \\Beta }\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$$</li>\n</ul>\n<h2 id=\"5-1-高维线性回归-实现权重衰减\"><a href=\"#5-1-高维线性回归-实现权重衰减\" class=\"headerlink\" title=\"5.1 高维线性回归(实现权重衰减)\"></a>5.1 高维线性回归(实现权重衰减)</h2><p>$$ y&#x3D; 0.05+ \\sum\\limits^{d}_{i&#x3D;1}0.01x_i+\\epsilon, \\epsilon \\in N(0,0.01^2)$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">n_train, n_test, num_inputs, batch_size = <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">200</span>, <span class=\"number\">5</span></span><br><span class=\"line\">true_w, true_b = torch.ones((num_inputs, <span class=\"number\">1</span>)) * <span class=\"number\">0.01</span>, <span class=\"number\">0.05</span></span><br><span class=\"line\">traind_data = d2l.synthetic_data(true_w, true_b, n_train)</span><br><span class=\"line\">traind_iter = d2l.load_array(traind_data, batch_size)</span><br><span class=\"line\">test_data = d2l.synthetic_data(true_w, true_b, n_test)</span><br><span class=\"line\">test_iter = d2l.load_array(test_data, batch_size, is_train=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_params</span>():</span><br><span class=\"line\">    w = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">1</span>, size=(num_inputs, <span class=\"number\">1</span>), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    b = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [w, b]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 定义L2范数惩罚</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">l2_penalty</span>(<span class=\"params\">w</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">sum</span>(w.<span class=\"built_in\">pow</span>(<span class=\"number\">2</span>)) / <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 定义训练代码</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">lambd</span>):</span><br><span class=\"line\">    w, b = init_params()</span><br><span class=\"line\">    net, loss = <span class=\"keyword\">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss</span><br><span class=\"line\">    num_epochs, lr = <span class=\"number\">100</span>, <span class=\"number\">0.003</span></span><br><span class=\"line\">    animator = d2l.Animator(xlabel=<span class=\"string\">&#x27;epochs&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">5</span>, num_epochs], legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> traind_iter:</span><br><span class=\"line\">            l = loss(net(X), y) + lambd * l2_penalty(w) <span class=\"comment\">#计算损失后加上L2范数惩罚项</span></span><br><span class=\"line\">            l.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">            d2l.sgd([w, b], lr, batch_size)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">5</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch + <span class=\"number\">1</span>, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的L2范数是：&#x27;</span>, torch.norm(w).item())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 测试</span></span><br><span class=\"line\">train(lambd=<span class=\"number\">0</span>) <span class=\"comment\">#没有使用权重衰减</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数是： 12.524763107299805\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(lambd=<span class=\"number\">3</span>) <span class=\"comment\">#使用权重衰减</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数是： 0.3719361424446106\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg\"></p>\n<h2 id=\"5-2-简洁实现\"><a href=\"#5-2-简洁实现\" class=\"headerlink\" title=\"5.2 简洁实现\"></a>5.2 简洁实现</h2><ul>\n<li>通常将权重衰减集成到优化算法中，以便与任何损失函数结合使用，并允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_concise</span>(<span class=\"params\">wd</span>):</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(num_inputs, <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> net.parameters():</span><br><span class=\"line\">        param.data.normal_()</span><br><span class=\"line\">    loss = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">    num_epochs, lr = <span class=\"number\">100</span>, <span class=\"number\">0.003</span></span><br><span class=\"line\">    <span class=\"comment\"># 偏置参数没有衰减</span></span><br><span class=\"line\">    trainer = torch.optim.SGD([</span><br><span class=\"line\">        &#123; <span class=\"string\">&quot;params&quot;</span>: net[<span class=\"number\">0</span>].weight, <span class=\"string\">&#x27;weight_decay&#x27;</span>: wd&#125;, </span><br><span class=\"line\">        &#123; <span class=\"string\">&quot;params&quot;</span>: net[<span class=\"number\">0</span>].bias&#125;], lr=lr)</span><br><span class=\"line\">    animator = d2l.Animator(xlabel=<span class=\"string\">&#x27;epochs&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">5</span>, num_epochs], legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> traind_iter:</span><br><span class=\"line\">            trainer.zero_grad()</span><br><span class=\"line\">            l = loss(net(X), y).mean()</span><br><span class=\"line\">            trainer.zero_grad()</span><br><span class=\"line\">            l.backward()</span><br><span class=\"line\">            trainer.step()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">5</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch + <span class=\"number\">1</span>, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的L2范数：&#x27;</span>, net[<span class=\"number\">0</span>].weight.norm().item())</span><br><span class=\"line\"></span><br><span class=\"line\">train_concise(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数： 12.297795295715332\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_concise(<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数： 0.40956297516822815\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"5-权重衰减\"><a href=\"#5-权重衰减\" class=\"headerlink\" title=\"5 权重衰减\"></a>5 权重衰减</h1><ul>\n<li>缓解过拟合：<ul>\n<li>更多数据</li>\n<li>正则化技术</li>\n</ul>\n</li>\n<li>权重衰减也称$L_2$正则化,通过函数与零的距离来衡量函数的复杂度。如何精确地测量一个函数和零之间的距离呢？一种简单的方法是通过线性函数 f(x) &#x3D; w⊤x 中的权重向量的某个范数来度量其复杂性，例如$||W||^2$。将权重向量作为惩罚项加入损失函数。原始的损失：<br>$$L(\\mathbf{w},b)&#x3D;\\frac{1}{n}\\sum\\limits^{n}_{i&#x3D;1}\\frac{1}{2}(\\mathbf{w}^T\\mathbf{x}^{(1)}+b-y^{(i)})^2$$</li>\n<li>加入惩罚项<br>$$L&#x3D;L(\\mathbf{w},b)+\\frac{\\lambda}{2}||\\mathbf{w}||^2$$</li>\n<li>除以2是为了求导时消掉，让表达式更简单。使用平方范数而不是标准范数（欧几里得距离）是为了便于计算，且它对权重向量的大分量施加了巨大的惩罚，这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。相比之下，L1惩罚会导致模型将权重集中在一小部分特征上，而将其他<br>权重清除为零。这称为特征选择（feature selection）</li>\n<li>加入正则化项后的梯度更新：<br>$$\\mathbf{w} \\leftarrow (1-\\eta \\lambda)\\mathbf{w}-\\frac{\\eta}{| \\Beta |}\\sum\\limits_{ i\\in \\Beta }\\mathbf{x}^{(i)}(\\mathbf{w}^T\\mathbf{x}^{(i)}+b-y^{(i)})$$</li>\n</ul>\n<h2 id=\"5-1-高维线性回归-实现权重衰减\"><a href=\"#5-1-高维线性回归-实现权重衰减\" class=\"headerlink\" title=\"5.1 高维线性回归(实现权重衰减)\"></a>5.1 高维线性回归(实现权重衰减)</h2><p>$$ y&#x3D; 0.05+ \\sum\\limits^{d}_{i&#x3D;1}0.01x_i+\\epsilon, \\epsilon \\in N(0,0.01^2)$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>]=<span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">n_train, n_test, num_inputs, batch_size = <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">200</span>, <span class=\"number\">5</span></span><br><span class=\"line\">true_w, true_b = torch.ones((num_inputs, <span class=\"number\">1</span>)) * <span class=\"number\">0.01</span>, <span class=\"number\">0.05</span></span><br><span class=\"line\">traind_data = d2l.synthetic_data(true_w, true_b, n_train)</span><br><span class=\"line\">traind_iter = d2l.load_array(traind_data, batch_size)</span><br><span class=\"line\">test_data = d2l.synthetic_data(true_w, true_b, n_test)</span><br><span class=\"line\">test_iter = d2l.load_array(test_data, batch_size, is_train=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 初始化模型参数</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_params</span>():</span><br><span class=\"line\">    w = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">1</span>, size=(num_inputs, <span class=\"number\">1</span>), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    b = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [w, b]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 定义L2范数惩罚</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">l2_penalty</span>(<span class=\"params\">w</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">sum</span>(w.<span class=\"built_in\">pow</span>(<span class=\"number\">2</span>)) / <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 定义训练代码</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">lambd</span>):</span><br><span class=\"line\">    w, b = init_params()</span><br><span class=\"line\">    net, loss = <span class=\"keyword\">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss</span><br><span class=\"line\">    num_epochs, lr = <span class=\"number\">100</span>, <span class=\"number\">0.003</span></span><br><span class=\"line\">    animator = d2l.Animator(xlabel=<span class=\"string\">&#x27;epochs&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">5</span>, num_epochs], legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> traind_iter:</span><br><span class=\"line\">            l = loss(net(X), y) + lambd * l2_penalty(w) <span class=\"comment\">#计算损失后加上L2范数惩罚项</span></span><br><span class=\"line\">            l.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">            d2l.sgd([w, b], lr, batch_size)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">5</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch + <span class=\"number\">1</span>, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的L2范数是：&#x27;</span>, torch.norm(w).item())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#4 测试</span></span><br><span class=\"line\">train(lambd=<span class=\"number\">0</span>) <span class=\"comment\">#没有使用权重衰减</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数是： 12.524763107299805\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_1_1.svg\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(lambd=<span class=\"number\">3</span>) <span class=\"comment\">#使用权重衰减</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数是： 0.3719361424446106\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_2_1.svg\"></p>\n<h2 id=\"5-2-简洁实现\"><a href=\"#5-2-简洁实现\" class=\"headerlink\" title=\"5.2 简洁实现\"></a>5.2 简洁实现</h2><ul>\n<li>通常将权重衰减集成到优化算法中，以便与任何损失函数结合使用，并允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_concise</span>(<span class=\"params\">wd</span>):</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(num_inputs, <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> net.parameters():</span><br><span class=\"line\">        param.data.normal_()</span><br><span class=\"line\">    loss = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">    num_epochs, lr = <span class=\"number\">100</span>, <span class=\"number\">0.003</span></span><br><span class=\"line\">    <span class=\"comment\"># 偏置参数没有衰减</span></span><br><span class=\"line\">    trainer = torch.optim.SGD([</span><br><span class=\"line\">        &#123; <span class=\"string\">&quot;params&quot;</span>: net[<span class=\"number\">0</span>].weight, <span class=\"string\">&#x27;weight_decay&#x27;</span>: wd&#125;, </span><br><span class=\"line\">        &#123; <span class=\"string\">&quot;params&quot;</span>: net[<span class=\"number\">0</span>].bias&#125;], lr=lr)</span><br><span class=\"line\">    animator = d2l.Animator(xlabel=<span class=\"string\">&#x27;epochs&#x27;</span>, ylabel=<span class=\"string\">&#x27;loss&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, xlim=[<span class=\"number\">5</span>, num_epochs], legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> traind_iter:</span><br><span class=\"line\">            trainer.zero_grad()</span><br><span class=\"line\">            l = loss(net(X), y).mean()</span><br><span class=\"line\">            trainer.zero_grad()</span><br><span class=\"line\">            l.backward()</span><br><span class=\"line\">            trainer.step()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">5</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            animator.add(epoch + <span class=\"number\">1</span>, (d2l.evaluate_loss(net, traind_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;w的L2范数：&#x27;</span>, net[<span class=\"number\">0</span>].weight.norm().item())</span><br><span class=\"line\"></span><br><span class=\"line\">train_concise(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数： 12.297795295715332\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_4_1.svg\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_concise(<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>w的L2范数： 0.40956297516822815\n</code></pre>\n<p> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/5_weight_decay_files/5_weight_decay_5_1.svg\"></p>"},{"title":"3.6 暂退法","date":"2024-02-07T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 6 暂退法\n- 模型简单性：\n    - 维度小\n    - 参数泛化\n    - 平滑性\n    \n- 平滑性：函数不应该对其输入的微小变化敏感。例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。具有输入噪声的训练等价于Tikhonov正则化。基于此，提出暂退法：在计算后续层之前向网络的每一层注入噪声。因为当训练一个有多层的深层网络时，注入噪声只会在输入‐输出映射上增强平滑性。从表面上看是在训练过程中丢弃（dropout）一些神经元。\n\n- 需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比：神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。???  \n\n- 做法：\n\n  <span style=\"display:block\">\n  $h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$ \n\n  </span>\n\n- 这样，输出层的计算不能过度依赖于h1, . . . , h5的任何一个元素。通常，我们在测试时不用暂退法。(一些研究人员在测试时使用暂退法，用于估计神经网络预测的“不确定性”：如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。)\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png)\n![](img/deeplearning/code/pytorch/3_mlp/6img/1.png)\n\n## 6.1 代码实现\n- 1）从U[0,1]抽样\n- 2）保留大于p的点/(1-p)\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\n#1 定义dropout\ndef dropout_layer(X, dropout):\n    assert 0 <= dropout <= 1\n    if dropout == 1:\n        return torch.zeros_like(X)\n    if dropout == 0:\n        return X\n    mask = (torch.rand(X.shape) > dropout).float() #大于p的元素->1\n    return mask * X / (1.0 - dropout)\n\n#2 测试dropout\nX = torch.arange(16, dtype=torch.float32).reshape((2, 8))\nprint(X)\nprint(dropout_layer(X, 0.))\nprint(dropout_layer(X, 0.5))\nprint(dropout_layer(X, 1.))\n```\n\n    tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n    tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n    tensor([[ 0.,  2.,  0.,  6.,  0., 10., 12.,  0.],\n            [16.,  0.,  0., 22., 24.,  0.,  0.,  0.]])\n    tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n            [0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n### 6.1.1 dropout应用到模型\n- 将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。\n\n\n```python\n#1 参数\nnum_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\ndropout1, dropout2 = 0.2, 0.5\n\n#2 模型\nclass Net(nn.Module):\n    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,\n                 is_training=True):\n        super(Net, self).__init__()\n        self.num_inputs = num_inputs\n        self.training = is_training\n        self.lin1 = nn.Linear(num_inputs, num_hiddens1)\n        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)\n        self.lin3 = nn.Linear(num_hiddens2, num_outputs)\n        self.relu = nn.ReLU()\n    def forward(self, X):\n        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))\n        if self.training: # 只在训练模型时使用dropout\n            H1 = dropout_layer(H1, dropout1)\n        H2 = self.relu(self.lin2(H1))\n        if self.training: #第二个全连接层后也使用dropout\n            H2 = dropout_layer(H2, dropout2)\n        out = self.lin3(H2)\n        return out\n    \nnet=Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)\n\n#3 训练和测试\nnum_epochs, lr, batch_size = 10, 0.5, 256\nloss = nn.CrossEntropyLoss(reduction=\"none\")\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\ntrainer = torch.optim.SGD(net.parameters(), lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg)    \n![](img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg)    \n\n\n### 6.1.2 简洁实现\n\n\n\n```python\nnet= nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(784,256),\n    nn.ReLU(), \n    nn.Dropout(dropout1), #dropout\n    nn.Linear(256,256),\n    nn.ReLU(),\n    nn.Dropout(dropout2), #dropout\n    nn.Linear(256,10)\n                   )\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight, std=0.01)\n\nnet.apply(init_weights)\n\n# 训练和测试\ntrainer = torch.optim.SGD(net.parameters(), lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg)\n    \n![](img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/6_deopout.md","raw":"---\ntitle: 3.6 暂退法\ndate: 2024-2-7 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 6 暂退法\n- 模型简单性：\n    - 维度小\n    - 参数泛化\n    - 平滑性\n    \n- 平滑性：函数不应该对其输入的微小变化敏感。例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。具有输入噪声的训练等价于Tikhonov正则化。基于此，提出暂退法：在计算后续层之前向网络的每一层注入噪声。因为当训练一个有多层的深层网络时，注入噪声只会在输入‐输出映射上增强平滑性。从表面上看是在训练过程中丢弃（dropout）一些神经元。\n\n- 需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比：神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。???  \n\n- 做法：\n\n  <span style=\"display:block\">\n  $h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$ \n\n  </span>\n\n- 这样，输出层的计算不能过度依赖于h1, . . . , h5的任何一个元素。通常，我们在测试时不用暂退法。(一些研究人员在测试时使用暂退法，用于估计神经网络预测的“不确定性”：如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。)\n ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png)\n![](img/deeplearning/code/pytorch/3_mlp/6img/1.png)\n\n## 6.1 代码实现\n- 1）从U[0,1]抽样\n- 2）保留大于p的点/(1-p)\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\n#1 定义dropout\ndef dropout_layer(X, dropout):\n    assert 0 <= dropout <= 1\n    if dropout == 1:\n        return torch.zeros_like(X)\n    if dropout == 0:\n        return X\n    mask = (torch.rand(X.shape) > dropout).float() #大于p的元素->1\n    return mask * X / (1.0 - dropout)\n\n#2 测试dropout\nX = torch.arange(16, dtype=torch.float32).reshape((2, 8))\nprint(X)\nprint(dropout_layer(X, 0.))\nprint(dropout_layer(X, 0.5))\nprint(dropout_layer(X, 1.))\n```\n\n    tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n    tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n            [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n    tensor([[ 0.,  2.,  0.,  6.,  0., 10., 12.,  0.],\n            [16.,  0.,  0., 22., 24.,  0.,  0.,  0.]])\n    tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n            [0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n### 6.1.1 dropout应用到模型\n- 将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。\n\n\n```python\n#1 参数\nnum_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\ndropout1, dropout2 = 0.2, 0.5\n\n#2 模型\nclass Net(nn.Module):\n    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,\n                 is_training=True):\n        super(Net, self).__init__()\n        self.num_inputs = num_inputs\n        self.training = is_training\n        self.lin1 = nn.Linear(num_inputs, num_hiddens1)\n        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)\n        self.lin3 = nn.Linear(num_hiddens2, num_outputs)\n        self.relu = nn.ReLU()\n    def forward(self, X):\n        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))\n        if self.training: # 只在训练模型时使用dropout\n            H1 = dropout_layer(H1, dropout1)\n        H2 = self.relu(self.lin2(H1))\n        if self.training: #第二个全连接层后也使用dropout\n            H2 = dropout_layer(H2, dropout2)\n        out = self.lin3(H2)\n        return out\n    \nnet=Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)\n\n#3 训练和测试\nnum_epochs, lr, batch_size = 10, 0.5, 256\nloss = nn.CrossEntropyLoss(reduction=\"none\")\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\ntrainer = torch.optim.SGD(net.parameters(), lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg)    \n![](img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg)    \n\n\n### 6.1.2 简洁实现\n\n\n\n```python\nnet= nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(784,256),\n    nn.ReLU(), \n    nn.Dropout(dropout1), #dropout\n    nn.Linear(256,256),\n    nn.ReLU(),\n    nn.Dropout(dropout2), #dropout\n    nn.Linear(256,10)\n                   )\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight, std=0.01)\n\nnet.apply(init_weights)\n\n# 训练和测试\ntrainer = torch.optim.SGD(net.parameters(), lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)\n```\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg)\n    \n![](img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/6_deopout","published":1,"updated":"2024-03-20T11:13:14.981Z","_id":"clt1985ad00bk7svw8hgr6ppg","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"6-暂退法\"><a href=\"#6-暂退法\" class=\"headerlink\" title=\"6 暂退法\"></a>6 暂退法</h1><ul>\n<li><p>模型简单性：</p>\n<ul>\n<li>维度小</li>\n<li>参数泛化</li>\n<li>平滑性</li>\n</ul>\n</li>\n<li><p>平滑性：函数不应该对其输入的微小变化敏感。例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。具有输入噪声的训练等价于Tikhonov正则化。基于此，提出暂退法：在计算后续层之前向网络的每一层注入噪声。因为当训练一个有多层的深层网络时，注入噪声只会在输入‐输出映射上增强平滑性。从表面上看是在训练过程中丢弃（dropout）一些神经元。</p>\n</li>\n<li><p>需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比：神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。???  </p>\n</li>\n<li><p>做法：</p>\n<span style=\"display:block\">\n$h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$ \n\n</span>\n</li>\n<li><p>这样，输出层的计算不能过度依赖于h1, . . . , h5的任何一个元素。通常，我们在测试时不用暂退法。(一些研究人员在测试时使用暂退法，用于估计神经网络预测的“不确定性”：如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。)<br> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/6img/1.png\"></p>\n</li>\n</ul>\n<h2 id=\"6-1-代码实现\"><a href=\"#6-1-代码实现\" class=\"headerlink\" title=\"6.1 代码实现\"></a>6.1 代码实现</h2><ul>\n<li>1）从U[0,1]抽样</li>\n<li>2）保留大于p的点&#x2F;(1-p)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 定义dropout</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">dropout_layer</span>(<span class=\"params\">X, dropout</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> <span class=\"number\">0</span> &lt;= dropout &lt;= <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> dropout == <span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> dropout == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\">    mask = (torch.rand(X.shape) &gt; dropout).<span class=\"built_in\">float</span>() <span class=\"comment\">#大于p的元素-&gt;1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> mask * X / (<span class=\"number\">1.0</span> - dropout)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 测试dropout</span></span><br><span class=\"line\">X = torch.arange(<span class=\"number\">16</span>, dtype=torch.float32).reshape((<span class=\"number\">2</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">0.</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">0.5</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">1.</span>))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\ntensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\ntensor([[ 0.,  2.,  0.,  6.,  0., 10., 12.,  0.],\n        [16.,  0.,  0., 22., 24.,  0.,  0.,  0.]])\ntensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.]])\n</code></pre>\n<h3 id=\"6-1-1-dropout应用到模型\"><a href=\"#6-1-1-dropout应用到模型\" class=\"headerlink\" title=\"6.1.1 dropout应用到模型\"></a>6.1.1 dropout应用到模型</h3><ul>\n<li>将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 参数</span></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens1, num_hiddens2 = <span class=\"number\">784</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span></span><br><span class=\"line\">dropout1, dropout2 = <span class=\"number\">0.2</span>, <span class=\"number\">0.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 模型</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Net</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,</span></span><br><span class=\"line\"><span class=\"params\">                 is_training=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Net, self).__init__()</span><br><span class=\"line\">        self.num_inputs = num_inputs</span><br><span class=\"line\">        self.training = is_training</span><br><span class=\"line\">        self.lin1 = nn.Linear(num_inputs, num_hiddens1)</span><br><span class=\"line\">        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)</span><br><span class=\"line\">        self.lin3 = nn.Linear(num_hiddens2, num_outputs)</span><br><span class=\"line\">        self.relu = nn.ReLU()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        H1 = self.relu(self.lin1(X.reshape((-<span class=\"number\">1</span>, self.num_inputs))))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training: <span class=\"comment\"># 只在训练模型时使用dropout</span></span><br><span class=\"line\">            H1 = dropout_layer(H1, dropout1)</span><br><span class=\"line\">        H2 = self.relu(self.lin2(H1))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training: <span class=\"comment\">#第二个全连接层后也使用dropout</span></span><br><span class=\"line\">            H2 = dropout_layer(H2, dropout2)</span><br><span class=\"line\">        out = self.lin3(H2)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\">    </span><br><span class=\"line\">net=Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 训练和测试</span></span><br><span class=\"line\">num_epochs, lr, batch_size = <span class=\"number\">10</span>, <span class=\"number\">0.5</span>, <span class=\"number\">256</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&quot;none&quot;</span>)</span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg\">    </p>\n<h3 id=\"6-1-2-简洁实现\"><a href=\"#6-1-2-简洁实现\" class=\"headerlink\" title=\"6.1.2 简洁实现\"></a>6.1.2 简洁实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net= nn.Sequential(</span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">784</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(), </span><br><span class=\"line\">    nn.Dropout(dropout1), <span class=\"comment\">#dropout</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(),</span><br><span class=\"line\">    nn.Dropout(dropout2), <span class=\"comment\">#dropout</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">                   )</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练和测试</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"6-暂退法\"><a href=\"#6-暂退法\" class=\"headerlink\" title=\"6 暂退法\"></a>6 暂退法</h1><ul>\n<li><p>模型简单性：</p>\n<ul>\n<li>维度小</li>\n<li>参数泛化</li>\n<li>平滑性</li>\n</ul>\n</li>\n<li><p>平滑性：函数不应该对其输入的微小变化敏感。例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。具有输入噪声的训练等价于Tikhonov正则化。基于此，提出暂退法：在计算后续层之前向网络的每一层注入噪声。因为当训练一个有多层的深层网络时，注入噪声只会在输入‐输出映射上增强平滑性。从表面上看是在训练过程中丢弃（dropout）一些神经元。</p>\n</li>\n<li><p>需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比：神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。???  </p>\n</li>\n<li><p>做法：</p>\n<span style=\"display:block\">\n$h ^\\prime =\\begin{cases}0 &p \\\\ \\frac{h}{1-p} &1-p \\\\ \\end{cases}.$ \n\n</span>\n</li>\n<li><p>这样，输出层的计算不能过度依赖于h1, . . . , h5的任何一个元素。通常，我们在测试时不用暂退法。(一些研究人员在测试时使用暂退法，用于估计神经网络预测的“不确定性”：如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。)<br> <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6img/1.png\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/6img/1.png\"></p>\n</li>\n</ul>\n<h2 id=\"6-1-代码实现\"><a href=\"#6-1-代码实现\" class=\"headerlink\" title=\"6.1 代码实现\"></a>6.1 代码实现</h2><ul>\n<li>1）从U[0,1]抽样</li>\n<li>2）保留大于p的点&#x2F;(1-p)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#1 定义dropout</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">dropout_layer</span>(<span class=\"params\">X, dropout</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> <span class=\"number\">0</span> &lt;= dropout &lt;= <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> dropout == <span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> dropout == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\">    mask = (torch.rand(X.shape) &gt; dropout).<span class=\"built_in\">float</span>() <span class=\"comment\">#大于p的元素-&gt;1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> mask * X / (<span class=\"number\">1.0</span> - dropout)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 测试dropout</span></span><br><span class=\"line\">X = torch.arange(<span class=\"number\">16</span>, dtype=torch.float32).reshape((<span class=\"number\">2</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">0.</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">0.5</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dropout_layer(X, <span class=\"number\">1.</span>))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\ntensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\ntensor([[ 0.,  2.,  0.,  6.,  0., 10., 12.,  0.],\n        [16.,  0.,  0., 22., 24.,  0.,  0.,  0.]])\ntensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.]])\n</code></pre>\n<h3 id=\"6-1-1-dropout应用到模型\"><a href=\"#6-1-1-dropout应用到模型\" class=\"headerlink\" title=\"6.1.1 dropout应用到模型\"></a>6.1.1 dropout应用到模型</h3><ul>\n<li>将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#1 参数</span></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens1, num_hiddens2 = <span class=\"number\">784</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span></span><br><span class=\"line\">dropout1, dropout2 = <span class=\"number\">0.2</span>, <span class=\"number\">0.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2 模型</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Net</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,</span></span><br><span class=\"line\"><span class=\"params\">                 is_training=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Net, self).__init__()</span><br><span class=\"line\">        self.num_inputs = num_inputs</span><br><span class=\"line\">        self.training = is_training</span><br><span class=\"line\">        self.lin1 = nn.Linear(num_inputs, num_hiddens1)</span><br><span class=\"line\">        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)</span><br><span class=\"line\">        self.lin3 = nn.Linear(num_hiddens2, num_outputs)</span><br><span class=\"line\">        self.relu = nn.ReLU()</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        H1 = self.relu(self.lin1(X.reshape((-<span class=\"number\">1</span>, self.num_inputs))))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training: <span class=\"comment\"># 只在训练模型时使用dropout</span></span><br><span class=\"line\">            H1 = dropout_layer(H1, dropout1)</span><br><span class=\"line\">        H2 = self.relu(self.lin2(H1))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training: <span class=\"comment\">#第二个全连接层后也使用dropout</span></span><br><span class=\"line\">            H2 = dropout_layer(H2, dropout2)</span><br><span class=\"line\">        out = self.lin3(H2)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\">    </span><br><span class=\"line\">net=Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3 训练和测试</span></span><br><span class=\"line\">num_epochs, lr, batch_size = <span class=\"number\">10</span>, <span class=\"number\">0.5</span>, <span class=\"number\">256</span></span><br><span class=\"line\">loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&quot;none&quot;</span>)</span><br><span class=\"line\">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg\" alt=\"svg\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_3_0.svg\">    </p>\n<h3 id=\"6-1-2-简洁实现\"><a href=\"#6-1-2-简洁实现\" class=\"headerlink\" title=\"6.1.2 简洁实现\"></a>6.1.2 简洁实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net= nn.Sequential(</span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">784</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(), </span><br><span class=\"line\">    nn.Dropout(dropout1), <span class=\"comment\">#dropout</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(),</span><br><span class=\"line\">    nn.Dropout(dropout2), <span class=\"comment\">#dropout</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\">                   )</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练和测试</span></span><br><span class=\"line\">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class=\"line\">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>\n\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/6_deopout_files/6_deopout_5_0.svg\"></p>"},{"title":"生产实习-1 系统结构搭建","date":"2024-03-02T00:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 1. 系统结构搭建\n\n## 1.1 下载项目\n\n1. 查看项目规范文档中的工具版本：\n   - 使用spring boot3.1.0\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/1.png)\n\n![](img/java/produce_practice/1.png)\n\n2. [进入网址](https://start.spring.io)\n\n   - 按文档选择，其中spring boot没有这个版本，后面再改。\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/3.png)\n\n     ![](img/java/produce_practice/3.png)\n\n     点击`生成`,网站就会帮我们下载一个工程源文件。将该文件夹解压后就是你的项目文件夹。\n\n3. 打开里面的pom.xml文件，将里面的spring boot版本改成文档需要的3.1.0版本\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/4.png)\n\n   ![](img/java/produce_practice/4.png)\n\n4. 这些基础依赖里只有mybatis明确指定了版本号。我们调低了框架的主版本号，为了防止不兼容，我们需要调整mybatis版本号。\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/5.png)\n\n   ![](img/java/produce_practice/5.png)\n\n5. 访问之前的[第三方依赖仓库](https://mvnrepository.com)查看主框架的依赖版本号。\n\n   搜索spring boot的依赖版本\n\n   - 搜索：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/6.png)\n\n   ![](img/java/produce_practice/6.png)\n\n   - 点击3.1.0版本：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/7.png)\n\n   ![](img/java/produce_practice/7.png)\n\n   - 发现依赖的spring web版本为6.0.9：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/8.png)\n\n   ![](img/java/produce_practice/8.png)\n\n   \n\n   搜索mybatis starter查询他的依赖版本\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/9.png)\n\n    ![](img/java/produce_practice/9.png)\n\n   - 搜索\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/10.png)\n\n      ![](img/java/produce_practice/10.png)\n\n   - 点击上面看到的版本：3.0.3\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/11.png)\n\n      ![](img/java/produce_practice/11.png)\n\n   - 点击对应版本：\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/12.png)\n\n      ![](img/java/produce_practice/12.png)\n\n     发现对应的spring context版本是6.1.0，与之前主框架的6.0.9不一致。\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/13.png)\n\n      ![](img/java/produce_practice/13.png)\n\n   - 需要将mybatis starter版本降低，经查询3.0.2版本依赖的spring context也是6.0.9，因此可以将pom.xml中对应版本改为3.0.2\n\n## 1.2 运行项目\n\n- 用idea打开刚刚下载的项目会自动下载依赖。可以看到下面有很多依赖项：\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/14.png)\n\n![](img/java/produce_practice/14.png)\n\n- 现在暂时不连接数据库，需要注释掉mybatis和mysql连接器，否则会出错。\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/15.png)\n\n![](img/java/produce_practice/15.png)\n\n- 刷新maven后依赖更新：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/16.png)\n\n![](img/java/produce_practice/16.png)\n\n- 找到主程序，运行，记住程序端口：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/17.png)\n\n![](img/java/produce_practice/17.png)\n\n- 在static下新建一个index.html测试一下：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/18.png)\n\n![](img/java/produce_practice/18.png)\n\n- 重新运行，输入网址，测试成功：\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/19.png)\n\n ![](img/java/produce_practice/19.png)  \n\n## 1.3 连接数据库\n\n- 使用阿里云服务器的mysql，第二天发现被攻击了，数据库丢失，所以要做好备份，或者即使关闭端口。可以参考[数据库恢复部分](##1.4)不一定有用。\n\n- 解除之前的注释，刷新maven\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/21.png)\n\n   ![](img/java/produce_practice/21.png)\n\n- 将resources/application.properties重命名：application.yml，配置数据库信息：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/20.png)\n\n   ![](img/java/produce_practice/20.png)\n\n- 注意：如果你将数据库配置那一段删掉，那么运行的时候会出错，但是就算你数据库配置写错了，运行也不会报错，你需要通过一个测试单元来尝试连接一下数据库才能发现是否能够连接成功。\n\n- 在数据库中创建test表，test1列，写入数据：`hello`，在src/test/java/下面有个测试文件，写入如下代码后运行：\n\n  ```java\n  package com.lyingedu.questionnaire;\n  \n  import org.junit.jupiter.api.Test;\n  import org.springframework.beans.factory.annotation.Autowired;\n  import org.springframework.boot.test.context.SpringBootTest;\n  import org.springframework.jdbc.core.JdbcTemplate;\n  import org.springframework.jdbc.core.RowMapper;\n  \n  import java.sql.ResultSet;\n  import java.sql.SQLException;\n  \n  @SpringBootTest\n  class QuestionnaireApplicationTests {\n  \n  \t@Autowired\n  \tprivate JdbcTemplate jdbcTemplate;\n  \n  \t@Test\n  \tvoid contextLoads() {\n  \t\t// 定义一个RowMapper来处理查询结果\n  \t\tRowMapper<String> rowMapper = new RowMapper<String>() {\n  \t\t\t@Override\n  \t\t\tpublic String mapRow(ResultSet rs, int rowNum) throws SQLException {\n  \t\t\t\t// 获取test1列的值\n  \t\t\t\treturn rs.getString(\"test1\");\n  \t\t\t}\n  \t\t};\n  \n  \t\t// 执行查询并获取结果\n  \t\tString result = jdbcTemplate.queryForObject(\"SELECT test1 FROM test LIMIT 1\", rowMapper);\n  \n  \t\t// 打印结果\n  \t\tSystem.out.println(\"查询结果: \" + result);\n  \t}\n  }\n  \n  ```\n\n  如果能够输出结果，说明连接成功。\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/23.png)\n\n   ![](img/java/produce_practice/23.png)\n\n  \n\n## 1.4 数据库修复\n\n- 如果你的远程数据库被攻击了或者被删了，你可以参考以下操作（不一定有用）\n\n  - 查找mysql的binlog文件：连接数据库后执行sql语句\n\n    ```sql\n    SHOW BINARY LOGS;\n    ```\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/35.png)\n\n    ![](img/java/produce_practice/35.png)\n\n    发现有多个日志文件\n\n  - 使用sql语句查看日志信息\n\n    ```sql\n    show binlog events in 'binlog.000002';\n    ```\n\n  - 根据日志文件名查找所在目录：在服务器中运行（root用户）\n\n    ```bash\n    find / -name \"binlog.000001\"\n    ```\n\n    然后cd打开目录\n\n  - 将日志文件变成sql文件：\n\n    ```bash\n    mysqlbinlog binlog.000001 > binlog1.sql\n    ```\n\n    如果提示没有mysqlbinlog，你需要根据提示下载：\n\n    ```\n    apt install mysql-server-core-8.0\n    ```\n\n    显示的带*的就是已经有的功能，选择那个前面是空的带log的功能\n\n  - 将转换好的sql文件复制到docker中\n\n    ```bash\n    docker cp binlog1.sql 容器名:/路径\n    ```\n\n    容器名通过以下命令查看\n\n    ```bash\n    docker ps -a\n    ```\n\n  - 进入docker：\n\n    ```\n    docker exec -it 容器名 bash\n    mysql -u 数据库用户名 -p < sql文件路径\n    ```\n\n  - [参考](https://developer.aliyun.com/article/515402)\n\n    ","source":"_posts/java/produce_practice/1_setup.md","raw":"---\ntitle: 生产实习-1 系统结构搭建\n\ndate: 2024-3-2 08:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n# 1. 系统结构搭建\n\n## 1.1 下载项目\n\n1. 查看项目规范文档中的工具版本：\n   - 使用spring boot3.1.0\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/1.png)\n\n![](img/java/produce_practice/1.png)\n\n2. [进入网址](https://start.spring.io)\n\n   - 按文档选择，其中spring boot没有这个版本，后面再改。\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/3.png)\n\n     ![](img/java/produce_practice/3.png)\n\n     点击`生成`,网站就会帮我们下载一个工程源文件。将该文件夹解压后就是你的项目文件夹。\n\n3. 打开里面的pom.xml文件，将里面的spring boot版本改成文档需要的3.1.0版本\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/4.png)\n\n   ![](img/java/produce_practice/4.png)\n\n4. 这些基础依赖里只有mybatis明确指定了版本号。我们调低了框架的主版本号，为了防止不兼容，我们需要调整mybatis版本号。\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/5.png)\n\n   ![](img/java/produce_practice/5.png)\n\n5. 访问之前的[第三方依赖仓库](https://mvnrepository.com)查看主框架的依赖版本号。\n\n   搜索spring boot的依赖版本\n\n   - 搜索：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/6.png)\n\n   ![](img/java/produce_practice/6.png)\n\n   - 点击3.1.0版本：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/7.png)\n\n   ![](img/java/produce_practice/7.png)\n\n   - 发现依赖的spring web版本为6.0.9：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/8.png)\n\n   ![](img/java/produce_practice/8.png)\n\n   \n\n   搜索mybatis starter查询他的依赖版本\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/9.png)\n\n    ![](img/java/produce_practice/9.png)\n\n   - 搜索\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/10.png)\n\n      ![](img/java/produce_practice/10.png)\n\n   - 点击上面看到的版本：3.0.3\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/11.png)\n\n      ![](img/java/produce_practice/11.png)\n\n   - 点击对应版本：\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/12.png)\n\n      ![](img/java/produce_practice/12.png)\n\n     发现对应的spring context版本是6.1.0，与之前主框架的6.0.9不一致。\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/13.png)\n\n      ![](img/java/produce_practice/13.png)\n\n   - 需要将mybatis starter版本降低，经查询3.0.2版本依赖的spring context也是6.0.9，因此可以将pom.xml中对应版本改为3.0.2\n\n## 1.2 运行项目\n\n- 用idea打开刚刚下载的项目会自动下载依赖。可以看到下面有很多依赖项：\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/14.png)\n\n![](img/java/produce_practice/14.png)\n\n- 现在暂时不连接数据库，需要注释掉mybatis和mysql连接器，否则会出错。\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/15.png)\n\n![](img/java/produce_practice/15.png)\n\n- 刷新maven后依赖更新：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/16.png)\n\n![](img/java/produce_practice/16.png)\n\n- 找到主程序，运行，记住程序端口：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/17.png)\n\n![](img/java/produce_practice/17.png)\n\n- 在static下新建一个index.html测试一下：\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/18.png)\n\n![](img/java/produce_practice/18.png)\n\n- 重新运行，输入网址，测试成功：\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/19.png)\n\n ![](img/java/produce_practice/19.png)  \n\n## 1.3 连接数据库\n\n- 使用阿里云服务器的mysql，第二天发现被攻击了，数据库丢失，所以要做好备份，或者即使关闭端口。可以参考[数据库恢复部分](##1.4)不一定有用。\n\n- 解除之前的注释，刷新maven\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/21.png)\n\n   ![](img/java/produce_practice/21.png)\n\n- 将resources/application.properties重命名：application.yml，配置数据库信息：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/20.png)\n\n   ![](img/java/produce_practice/20.png)\n\n- 注意：如果你将数据库配置那一段删掉，那么运行的时候会出错，但是就算你数据库配置写错了，运行也不会报错，你需要通过一个测试单元来尝试连接一下数据库才能发现是否能够连接成功。\n\n- 在数据库中创建test表，test1列，写入数据：`hello`，在src/test/java/下面有个测试文件，写入如下代码后运行：\n\n  ```java\n  package com.lyingedu.questionnaire;\n  \n  import org.junit.jupiter.api.Test;\n  import org.springframework.beans.factory.annotation.Autowired;\n  import org.springframework.boot.test.context.SpringBootTest;\n  import org.springframework.jdbc.core.JdbcTemplate;\n  import org.springframework.jdbc.core.RowMapper;\n  \n  import java.sql.ResultSet;\n  import java.sql.SQLException;\n  \n  @SpringBootTest\n  class QuestionnaireApplicationTests {\n  \n  \t@Autowired\n  \tprivate JdbcTemplate jdbcTemplate;\n  \n  \t@Test\n  \tvoid contextLoads() {\n  \t\t// 定义一个RowMapper来处理查询结果\n  \t\tRowMapper<String> rowMapper = new RowMapper<String>() {\n  \t\t\t@Override\n  \t\t\tpublic String mapRow(ResultSet rs, int rowNum) throws SQLException {\n  \t\t\t\t// 获取test1列的值\n  \t\t\t\treturn rs.getString(\"test1\");\n  \t\t\t}\n  \t\t};\n  \n  \t\t// 执行查询并获取结果\n  \t\tString result = jdbcTemplate.queryForObject(\"SELECT test1 FROM test LIMIT 1\", rowMapper);\n  \n  \t\t// 打印结果\n  \t\tSystem.out.println(\"查询结果: \" + result);\n  \t}\n  }\n  \n  ```\n\n  如果能够输出结果，说明连接成功。\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/23.png)\n\n   ![](img/java/produce_practice/23.png)\n\n  \n\n## 1.4 数据库修复\n\n- 如果你的远程数据库被攻击了或者被删了，你可以参考以下操作（不一定有用）\n\n  - 查找mysql的binlog文件：连接数据库后执行sql语句\n\n    ```sql\n    SHOW BINARY LOGS;\n    ```\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/35.png)\n\n    ![](img/java/produce_practice/35.png)\n\n    发现有多个日志文件\n\n  - 使用sql语句查看日志信息\n\n    ```sql\n    show binlog events in 'binlog.000002';\n    ```\n\n  - 根据日志文件名查找所在目录：在服务器中运行（root用户）\n\n    ```bash\n    find / -name \"binlog.000001\"\n    ```\n\n    然后cd打开目录\n\n  - 将日志文件变成sql文件：\n\n    ```bash\n    mysqlbinlog binlog.000001 > binlog1.sql\n    ```\n\n    如果提示没有mysqlbinlog，你需要根据提示下载：\n\n    ```\n    apt install mysql-server-core-8.0\n    ```\n\n    显示的带*的就是已经有的功能，选择那个前面是空的带log的功能\n\n  - 将转换好的sql文件复制到docker中\n\n    ```bash\n    docker cp binlog1.sql 容器名:/路径\n    ```\n\n    容器名通过以下命令查看\n\n    ```bash\n    docker ps -a\n    ```\n\n  - 进入docker：\n\n    ```\n    docker exec -it 容器名 bash\n    mysql -u 数据库用户名 -p < sql文件路径\n    ```\n\n  - [参考](https://developer.aliyun.com/article/515402)\n\n    ","slug":"java/produce_practice/1_setup","published":1,"updated":"2024-03-06T10:35:54.176Z","_id":"clt8fmx0e0000mkvw4n8t3fts","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"1-系统结构搭建\"><a href=\"#1-系统结构搭建\" class=\"headerlink\" title=\"1. 系统结构搭建\"></a>1. 系统结构搭建</h1><h2 id=\"1-1-下载项目\"><a href=\"#1-1-下载项目\" class=\"headerlink\" title=\"1.1 下载项目\"></a>1.1 下载项目</h2><ol>\n<li>查看项目规范文档中的工具版本：<ul>\n<li>使用spring boot3.1.0</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/1.png\"></p>\n<ol start=\"2\">\n<li><p><a href=\"https://start.spring.io/\">进入网址</a></p>\n<ul>\n<li><p>按文档选择，其中spring boot没有这个版本，后面再改。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/3.png\"></p>\n<p>点击<code>生成</code>,网站就会帮我们下载一个工程源文件。将该文件夹解压后就是你的项目文件夹。</p>\n</li>\n</ul>\n</li>\n<li><p>打开里面的pom.xml文件，将里面的spring boot版本改成文档需要的3.1.0版本</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/4.png\"></p>\n</li>\n<li><p>这些基础依赖里只有mybatis明确指定了版本号。我们调低了框架的主版本号，为了防止不兼容，我们需要调整mybatis版本号。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/5.png\"></p>\n</li>\n<li><p>访问之前的<a href=\"https://mvnrepository.com/\">第三方依赖仓库</a>查看主框架的依赖版本号。</p>\n<p>搜索spring boot的依赖版本</p>\n<ul>\n<li>搜索：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/6.png\"></p>\n<ul>\n<li>点击3.1.0版本：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/7.png\"></p>\n<ul>\n<li>发现依赖的spring web版本为6.0.9：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/8.png\"></p>\n<p>搜索mybatis starter查询他的依赖版本</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/9.png\"></p>\n<p> <img src=\"/img/java/produce_practice/9.png\"></p>\n<ul>\n<li><p>搜索</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/10.png\"></p>\n<p> <img src=\"/img/java/produce_practice/10.png\"></p>\n</li>\n<li><p>点击上面看到的版本：3.0.3</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/11.png\"></p>\n<p> <img src=\"/img/java/produce_practice/11.png\"></p>\n</li>\n<li><p>点击对应版本：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/12.png\"></p>\n<p> <img src=\"/img/java/produce_practice/12.png\"></p>\n<p>发现对应的spring context版本是6.1.0，与之前主框架的6.0.9不一致。</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/13.png\"></p>\n<p> <img src=\"/img/java/produce_practice/13.png\"></p>\n</li>\n<li><p>需要将mybatis starter版本降低，经查询3.0.2版本依赖的spring context也是6.0.9，因此可以将pom.xml中对应版本改为3.0.2</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"1-2-运行项目\"><a href=\"#1-2-运行项目\" class=\"headerlink\" title=\"1.2 运行项目\"></a>1.2 运行项目</h2><ul>\n<li>用idea打开刚刚下载的项目会自动下载依赖。可以看到下面有很多依赖项：</li>\n</ul>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/14.png\"></p>\n<p><img src=\"/img/java/produce_practice/14.png\"></p>\n<ul>\n<li>现在暂时不连接数据库，需要注释掉mybatis和mysql连接器，否则会出错。</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/15.png\"></p>\n<p><img src=\"/img/java/produce_practice/15.png\"></p>\n<ul>\n<li>刷新maven后依赖更新：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/16.png\"></p>\n<p><img src=\"/img/java/produce_practice/16.png\"></p>\n<ul>\n<li>找到主程序，运行，记住程序端口：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/17.png\"></p>\n<p><img src=\"/img/java/produce_practice/17.png\"></p>\n<ul>\n<li>在static下新建一个index.html测试一下：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/18.png\"></p>\n<p><img src=\"/img/java/produce_practice/18.png\"></p>\n<ul>\n<li>重新运行，输入网址，测试成功：</li>\n</ul>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/19.png\"></p>\n<p> <img src=\"/img/java/produce_practice/19.png\">  </p>\n<h2 id=\"1-3-连接数据库\"><a href=\"#1-3-连接数据库\" class=\"headerlink\" title=\"1.3 连接数据库\"></a>1.3 连接数据库</h2><ul>\n<li><p>使用阿里云服务器的mysql，第二天发现被攻击了，数据库丢失，所以要做好备份，或者即使关闭端口。可以参考<a href=\"##1.4\">数据库恢复部分</a>不一定有用。</p>\n</li>\n<li><p>解除之前的注释，刷新maven</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/21.png\"></p>\n<p> <img src=\"/img/java/produce_practice/21.png\"></p>\n</li>\n<li><p>将resources&#x2F;application.properties重命名：application.yml，配置数据库信息：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/20.png\"></p>\n<p> <img src=\"/img/java/produce_practice/20.png\"></p>\n</li>\n<li><p>注意：如果你将数据库配置那一段删掉，那么运行的时候会出错，但是就算你数据库配置写错了，运行也不会报错，你需要通过一个测试单元来尝试连接一下数据库才能发现是否能够连接成功。</p>\n</li>\n<li><p>在数据库中创建test表，test1列，写入数据：<code>hello</code>，在src&#x2F;test&#x2F;java&#x2F;下面有个测试文件，写入如下代码后运行：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.jupiter.api.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.jdbc.core.JdbcTemplate;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.jdbc.core.RowMapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.ResultSet;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.SQLException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@SpringBootTest</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">QuestionnaireApplicationTests</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Autowired</span></span><br><span class=\"line\">\t<span class=\"keyword\">private</span> JdbcTemplate jdbcTemplate;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Test</span></span><br><span class=\"line\">\t<span class=\"keyword\">void</span> <span class=\"title function_\">contextLoads</span><span class=\"params\">()</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// 定义一个RowMapper来处理查询结果</span></span><br><span class=\"line\">\t\tRowMapper&lt;String&gt; rowMapper = <span class=\"keyword\">new</span> <span class=\"title class_\">RowMapper</span>&lt;String&gt;() &#123;</span><br><span class=\"line\">\t\t\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">public</span> String <span class=\"title function_\">mapRow</span><span class=\"params\">(ResultSet rs, <span class=\"type\">int</span> rowNum)</span> <span class=\"keyword\">throws</span> SQLException &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// 获取test1列的值</span></span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> rs.getString(<span class=\"string\">&quot;test1&quot;</span>);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">// 执行查询并获取结果</span></span><br><span class=\"line\">\t\t<span class=\"type\">String</span> <span class=\"variable\">result</span> <span class=\"operator\">=</span> jdbcTemplate.queryForObject(<span class=\"string\">&quot;SELECT test1 FROM test LIMIT 1&quot;</span>, rowMapper);</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">// 打印结果</span></span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">&quot;查询结果: &quot;</span> + result);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>如果能够输出结果，说明连接成功。</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/23.png\"></p>\n<p> <img src=\"/img/java/produce_practice/23.png\"></p>\n</li>\n</ul>\n<h2 id=\"1-4-数据库修复\"><a href=\"#1-4-数据库修复\" class=\"headerlink\" title=\"1.4 数据库修复\"></a>1.4 数据库修复</h2><ul>\n<li><p>如果你的远程数据库被攻击了或者被删了，你可以参考以下操作（不一定有用）</p>\n<ul>\n<li><p>查找mysql的binlog文件：连接数据库后执行sql语句</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SHOW</span> <span class=\"type\">BINARY</span> LOGS;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/35.png\"></p>\n<p><img src=\"/img/java/produce_practice/35.png\"></p>\n<p>发现有多个日志文件</p>\n</li>\n<li><p>使用sql语句查看日志信息</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> binlog events <span class=\"keyword\">in</span> <span class=\"string\">&#x27;binlog.000002&#x27;</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>根据日志文件名查找所在目录：在服务器中运行（root用户）</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find / -name <span class=\"string\">&quot;binlog.000001&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>然后cd打开目录</p>\n</li>\n<li><p>将日志文件变成sql文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqlbinlog binlog.000001 &gt; binlog1.sql</span><br></pre></td></tr></table></figure>\n\n<p>如果提示没有mysqlbinlog，你需要根据提示下载：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt install mysql-server-core-8.0</span><br></pre></td></tr></table></figure>\n\n<p>显示的带*的就是已经有的功能，选择那个前面是空的带log的功能</p>\n</li>\n<li><p>将转换好的sql文件复制到docker中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">cp</span> binlog1.sql 容器名:/路径</span><br></pre></td></tr></table></figure>\n\n<p>容器名通过以下命令查看</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps -a</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>进入docker：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it 容器名 bash</span><br><span class=\"line\">mysql -u 数据库用户名 -p &lt; sql文件路径</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><a href=\"https://developer.aliyun.com/article/515402\">参考</a></p>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-系统结构搭建\"><a href=\"#1-系统结构搭建\" class=\"headerlink\" title=\"1. 系统结构搭建\"></a>1. 系统结构搭建</h1><h2 id=\"1-1-下载项目\"><a href=\"#1-1-下载项目\" class=\"headerlink\" title=\"1.1 下载项目\"></a>1.1 下载项目</h2><ol>\n<li>查看项目规范文档中的工具版本：<ul>\n<li>使用spring boot3.1.0</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/1.png\"></p>\n<ol start=\"2\">\n<li><p><a href=\"https://start.spring.io/\">进入网址</a></p>\n<ul>\n<li><p>按文档选择，其中spring boot没有这个版本，后面再改。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/3.png\"></p>\n<p>点击<code>生成</code>,网站就会帮我们下载一个工程源文件。将该文件夹解压后就是你的项目文件夹。</p>\n</li>\n</ul>\n</li>\n<li><p>打开里面的pom.xml文件，将里面的spring boot版本改成文档需要的3.1.0版本</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/4.png\"></p>\n</li>\n<li><p>这些基础依赖里只有mybatis明确指定了版本号。我们调低了框架的主版本号，为了防止不兼容，我们需要调整mybatis版本号。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/5.png\"></p>\n</li>\n<li><p>访问之前的<a href=\"https://mvnrepository.com/\">第三方依赖仓库</a>查看主框架的依赖版本号。</p>\n<p>搜索spring boot的依赖版本</p>\n<ul>\n<li>搜索：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/6.png\"></p>\n<ul>\n<li>点击3.1.0版本：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/7.png\"></p>\n<ul>\n<li>发现依赖的spring web版本为6.0.9：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/8.png\"></p>\n<p>搜索mybatis starter查询他的依赖版本</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/9.png\"></p>\n<p> <img src=\"/img/java/produce_practice/9.png\"></p>\n<ul>\n<li><p>搜索</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/10.png\"></p>\n<p> <img src=\"/img/java/produce_practice/10.png\"></p>\n</li>\n<li><p>点击上面看到的版本：3.0.3</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/11.png\"></p>\n<p> <img src=\"/img/java/produce_practice/11.png\"></p>\n</li>\n<li><p>点击对应版本：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/12.png\"></p>\n<p> <img src=\"/img/java/produce_practice/12.png\"></p>\n<p>发现对应的spring context版本是6.1.0，与之前主框架的6.0.9不一致。</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/13.png\"></p>\n<p> <img src=\"/img/java/produce_practice/13.png\"></p>\n</li>\n<li><p>需要将mybatis starter版本降低，经查询3.0.2版本依赖的spring context也是6.0.9，因此可以将pom.xml中对应版本改为3.0.2</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"1-2-运行项目\"><a href=\"#1-2-运行项目\" class=\"headerlink\" title=\"1.2 运行项目\"></a>1.2 运行项目</h2><ul>\n<li>用idea打开刚刚下载的项目会自动下载依赖。可以看到下面有很多依赖项：</li>\n</ul>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/14.png\"></p>\n<p><img src=\"/img/java/produce_practice/14.png\"></p>\n<ul>\n<li>现在暂时不连接数据库，需要注释掉mybatis和mysql连接器，否则会出错。</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/15.png\"></p>\n<p><img src=\"/img/java/produce_practice/15.png\"></p>\n<ul>\n<li>刷新maven后依赖更新：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/16.png\"></p>\n<p><img src=\"/img/java/produce_practice/16.png\"></p>\n<ul>\n<li>找到主程序，运行，记住程序端口：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/17.png\"></p>\n<p><img src=\"/img/java/produce_practice/17.png\"></p>\n<ul>\n<li>在static下新建一个index.html测试一下：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/18.png\"></p>\n<p><img src=\"/img/java/produce_practice/18.png\"></p>\n<ul>\n<li>重新运行，输入网址，测试成功：</li>\n</ul>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/19.png\"></p>\n<p> <img src=\"/img/java/produce_practice/19.png\">  </p>\n<h2 id=\"1-3-连接数据库\"><a href=\"#1-3-连接数据库\" class=\"headerlink\" title=\"1.3 连接数据库\"></a>1.3 连接数据库</h2><ul>\n<li><p>使用阿里云服务器的mysql，第二天发现被攻击了，数据库丢失，所以要做好备份，或者即使关闭端口。可以参考<a href=\"##1.4\">数据库恢复部分</a>不一定有用。</p>\n</li>\n<li><p>解除之前的注释，刷新maven</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/21.png\"></p>\n<p> <img src=\"/img/java/produce_practice/21.png\"></p>\n</li>\n<li><p>将resources&#x2F;application.properties重命名：application.yml，配置数据库信息：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/20.png\"></p>\n<p> <img src=\"/img/java/produce_practice/20.png\"></p>\n</li>\n<li><p>注意：如果你将数据库配置那一段删掉，那么运行的时候会出错，但是就算你数据库配置写错了，运行也不会报错，你需要通过一个测试单元来尝试连接一下数据库才能发现是否能够连接成功。</p>\n</li>\n<li><p>在数据库中创建test表，test1列，写入数据：<code>hello</code>，在src&#x2F;test&#x2F;java&#x2F;下面有个测试文件，写入如下代码后运行：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.jupiter.api.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.jdbc.core.JdbcTemplate;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.jdbc.core.RowMapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.ResultSet;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.sql.SQLException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@SpringBootTest</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">QuestionnaireApplicationTests</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Autowired</span></span><br><span class=\"line\">\t<span class=\"keyword\">private</span> JdbcTemplate jdbcTemplate;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Test</span></span><br><span class=\"line\">\t<span class=\"keyword\">void</span> <span class=\"title function_\">contextLoads</span><span class=\"params\">()</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// 定义一个RowMapper来处理查询结果</span></span><br><span class=\"line\">\t\tRowMapper&lt;String&gt; rowMapper = <span class=\"keyword\">new</span> <span class=\"title class_\">RowMapper</span>&lt;String&gt;() &#123;</span><br><span class=\"line\">\t\t\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">public</span> String <span class=\"title function_\">mapRow</span><span class=\"params\">(ResultSet rs, <span class=\"type\">int</span> rowNum)</span> <span class=\"keyword\">throws</span> SQLException &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// 获取test1列的值</span></span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> rs.getString(<span class=\"string\">&quot;test1&quot;</span>);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">// 执行查询并获取结果</span></span><br><span class=\"line\">\t\t<span class=\"type\">String</span> <span class=\"variable\">result</span> <span class=\"operator\">=</span> jdbcTemplate.queryForObject(<span class=\"string\">&quot;SELECT test1 FROM test LIMIT 1&quot;</span>, rowMapper);</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">// 打印结果</span></span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">&quot;查询结果: &quot;</span> + result);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>如果能够输出结果，说明连接成功。</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/23.png\"></p>\n<p> <img src=\"/img/java/produce_practice/23.png\"></p>\n</li>\n</ul>\n<h2 id=\"1-4-数据库修复\"><a href=\"#1-4-数据库修复\" class=\"headerlink\" title=\"1.4 数据库修复\"></a>1.4 数据库修复</h2><ul>\n<li><p>如果你的远程数据库被攻击了或者被删了，你可以参考以下操作（不一定有用）</p>\n<ul>\n<li><p>查找mysql的binlog文件：连接数据库后执行sql语句</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SHOW</span> <span class=\"type\">BINARY</span> LOGS;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/35.png\"></p>\n<p><img src=\"/img/java/produce_practice/35.png\"></p>\n<p>发现有多个日志文件</p>\n</li>\n<li><p>使用sql语句查看日志信息</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> binlog events <span class=\"keyword\">in</span> <span class=\"string\">&#x27;binlog.000002&#x27;</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>根据日志文件名查找所在目录：在服务器中运行（root用户）</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find / -name <span class=\"string\">&quot;binlog.000001&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>然后cd打开目录</p>\n</li>\n<li><p>将日志文件变成sql文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqlbinlog binlog.000001 &gt; binlog1.sql</span><br></pre></td></tr></table></figure>\n\n<p>如果提示没有mysqlbinlog，你需要根据提示下载：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt install mysql-server-core-8.0</span><br></pre></td></tr></table></figure>\n\n<p>显示的带*的就是已经有的功能，选择那个前面是空的带log的功能</p>\n</li>\n<li><p>将转换好的sql文件复制到docker中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">cp</span> binlog1.sql 容器名:/路径</span><br></pre></td></tr></table></figure>\n\n<p>容器名通过以下命令查看</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps -a</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>进入docker：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it 容器名 bash</span><br><span class=\"line\">mysql -u 数据库用户名 -p &lt; sql文件路径</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><a href=\"https://developer.aliyun.com/article/515402\">参考</a></p>\n</li>\n</ul>\n</li>\n</ul>"},{"title":"Linux入门-0配置","date":"2021-03-01T12:00:00.000Z","toc":true,"_content":"#\n\n<!-- more -->\n\n## 0. 安装\n\n\n\n### 0.1 虚拟机\n\n### 0.2 [下载finalshell](https://www.hostbuf.com/downloads/finalshell_install.exe)\n\n### 0.3 连接finalshell\n\n1. 在linux中右键，打开终端\n\n2. 输入：ifconfig ,找到ens下的inet后面的数字，复制![](./img/linux/install/1.png)\n\n   ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\1.png)\n1. 打开finalshell点击左上文件图标，点击新串口左上带加号的文件图标，点击ssh连接，输入自定义的名称，主机输入刚刚的复制的一串数字，用户名、密码为linux用户的，点击确定\n  ![](./img/linux/install/2.png)\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\2.png)\n### 0.4（windows中使用ubuntu）\n\n1. windows中搜索：windows功能，点击：启动或关闭windows功能，将：适用于Linux的子系统勾选并重启\n\n2. 微软应用商店搜索ubuntu并下载，win10还需下载terminal\n\n3. 在terminal中点击向下箭头，选择Ubuntu\n  ![](./img/linux/install/3.png)\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\3.png)\n\n4. 如果显示Error: 0x800701bc WSL 2 ?????????????????? 则返回windows命令行输入wsl --update\n\n5. 完成后打开Ubuntu窗口，输入用户名，密码，密码\n\n","source":"_posts/linux/Linux_0install.md","raw":"---\ntitle: Linux入门-0配置\ndate: 2021-03-01 20:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n---\n#\n\n<!-- more -->\n\n## 0. 安装\n\n\n\n### 0.1 虚拟机\n\n### 0.2 [下载finalshell](https://www.hostbuf.com/downloads/finalshell_install.exe)\n\n### 0.3 连接finalshell\n\n1. 在linux中右键，打开终端\n\n2. 输入：ifconfig ,找到ens下的inet后面的数字，复制![](./img/linux/install/1.png)\n\n   ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\1.png)\n1. 打开finalshell点击左上文件图标，点击新串口左上带加号的文件图标，点击ssh连接，输入自定义的名称，主机输入刚刚的复制的一串数字，用户名、密码为linux用户的，点击确定\n  ![](./img/linux/install/2.png)\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\2.png)\n### 0.4（windows中使用ubuntu）\n\n1. windows中搜索：windows功能，点击：启动或关闭windows功能，将：适用于Linux的子系统勾选并重启\n\n2. 微软应用商店搜索ubuntu并下载，win10还需下载terminal\n\n3. 在terminal中点击向下箭头，选择Ubuntu\n  ![](./img/linux/install/3.png)\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\3.png)\n\n4. 如果显示Error: 0x800701bc WSL 2 ?????????????????? 则返回windows命令行输入wsl --update\n\n5. 完成后打开Ubuntu窗口，输入用户名，密码，密码\n\n","slug":"linux/Linux_0install","published":1,"updated":"2024-03-02T02:44:18.204Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clta2pezx0000zovw6hix76mc","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h2 id=\"0-安装\"><a href=\"#0-安装\" class=\"headerlink\" title=\"0. 安装\"></a>0. 安装</h2><h3 id=\"0-1-虚拟机\"><a href=\"#0-1-虚拟机\" class=\"headerlink\" title=\"0.1 虚拟机\"></a>0.1 虚拟机</h3><h3 id=\"0-2-下载finalshell\"><a href=\"#0-2-下载finalshell\" class=\"headerlink\" title=\"0.2 下载finalshell\"></a>0.2 <a href=\"https://www.hostbuf.com/downloads/finalshell_install.exe\">下载finalshell</a></h3><h3 id=\"0-3-连接finalshell\"><a href=\"#0-3-连接finalshell\" class=\"headerlink\" title=\"0.3 连接finalshell\"></a>0.3 连接finalshell</h3><ol>\n<li><p>在linux中右键，打开终端</p>\n</li>\n<li><p>输入：ifconfig ,找到ens下的inet后面的数字，复制<img src=\"/./img/linux/install/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\1.png\"></p>\n</li>\n<li><p>打开finalshell点击左上文件图标，点击新串口左上带加号的文件图标，点击ssh连接，输入自定义的名称，主机输入刚刚的复制的一串数字，用户名、密码为linux用户的，点击确定<br>  <img src=\"/./img/linux/install/2.png\"></p>\n</li>\n</ol>\n<p>  <img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\2.png\"></p>\n<h3 id=\"0-4（windows中使用ubuntu）\"><a href=\"#0-4（windows中使用ubuntu）\" class=\"headerlink\" title=\"0.4（windows中使用ubuntu）\"></a>0.4（windows中使用ubuntu）</h3><ol>\n<li><p>windows中搜索：windows功能，点击：启动或关闭windows功能，将：适用于Linux的子系统勾选并重启</p>\n</li>\n<li><p>微软应用商店搜索ubuntu并下载，win10还需下载terminal</p>\n</li>\n<li><p>在terminal中点击向下箭头，选择Ubuntu<br>  <img src=\"/./img/linux/install/3.png\"></p>\n</li>\n</ol>\n<p>  <img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\3.png\"></p>\n<ol start=\"4\">\n<li><p>如果显示Error: 0x800701bc WSL 2 ?????????????????? 则返回windows命令行输入wsl –update</p>\n</li>\n<li><p>完成后打开Ubuntu窗口，输入用户名，密码，密码</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h2 id=\"0-安装\"><a href=\"#0-安装\" class=\"headerlink\" title=\"0. 安装\"></a>0. 安装</h2><h3 id=\"0-1-虚拟机\"><a href=\"#0-1-虚拟机\" class=\"headerlink\" title=\"0.1 虚拟机\"></a>0.1 虚拟机</h3><h3 id=\"0-2-下载finalshell\"><a href=\"#0-2-下载finalshell\" class=\"headerlink\" title=\"0.2 下载finalshell\"></a>0.2 <a href=\"https://www.hostbuf.com/downloads/finalshell_install.exe\">下载finalshell</a></h3><h3 id=\"0-3-连接finalshell\"><a href=\"#0-3-连接finalshell\" class=\"headerlink\" title=\"0.3 连接finalshell\"></a>0.3 连接finalshell</h3><ol>\n<li><p>在linux中右键，打开终端</p>\n</li>\n<li><p>输入：ifconfig ,找到ens下的inet后面的数字，复制<img src=\"/./img/linux/install/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\1.png\"></p>\n</li>\n<li><p>打开finalshell点击左上文件图标，点击新串口左上带加号的文件图标，点击ssh连接，输入自定义的名称，主机输入刚刚的复制的一串数字，用户名、密码为linux用户的，点击确定<br>  <img src=\"/./img/linux/install/2.png\"></p>\n</li>\n</ol>\n<p>  <img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\2.png\"></p>\n<h3 id=\"0-4（windows中使用ubuntu）\"><a href=\"#0-4（windows中使用ubuntu）\" class=\"headerlink\" title=\"0.4（windows中使用ubuntu）\"></a>0.4（windows中使用ubuntu）</h3><ol>\n<li><p>windows中搜索：windows功能，点击：启动或关闭windows功能，将：适用于Linux的子系统勾选并重启</p>\n</li>\n<li><p>微软应用商店搜索ubuntu并下载，win10还需下载terminal</p>\n</li>\n<li><p>在terminal中点击向下箭头，选择Ubuntu<br>  <img src=\"/./img/linux/install/3.png\"></p>\n</li>\n</ol>\n<p>  <img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\install\\3.png\"></p>\n<ol start=\"4\">\n<li><p>如果显示Error: 0x800701bc WSL 2 ?????????????????? 则返回windows命令行输入wsl –update</p>\n</li>\n<li><p>完成后打开Ubuntu窗口，输入用户名，密码，密码</p>\n</li>\n</ol>"},{"title":"Linux入门-1基础命令","date":"2021-03-02T12:00:00.000Z","toc":true,"_content":"#\n\n<!--more-->\n\n# 1 基础命令\n\n| 显示                   | ls -alh 路径                             |\n| ---------------------- | ---------------------------------------- |\n| 打开路径               | <a href='#cd'>cd 路径</a>                |\n| 显示工作路径           | <a href='#pwd'>pwd</a>                    |\n| 创建文件夹             | <a href='#mkdir'>mkdir -p 路径</a>          |\n| 创建文件               | <a href='#touch'>touch 路径</a>             |\n| 查看文件               | <a href='#cat'>cat 路径</a>               |\n| 分页查看               | <a href='#more'>more 路径  </a>            |\n| 复制                   | <a href='#cp'>cp -r 源 目的  </a>        |\n| 移动文件               | <a href='#mv'>mv 源 目的（可重命名</a>） |\n| 删除文件               | <a href='#rm'>rm -rf 路径</a>            |\n| 文件中通过关键字搜索行 | <a href='#grep'>grep -n 关键字 路径 </a>   |\n| 文件内容统计           | <a href='#wc'>wc -cmlw 路径   </a>       |\n| 查看命令源文件         | <a href='#which'>which 命令 </a>            |\n| 搜索文件               | <a href='#find'>find 起始路径 -name \"test\"  </a> |\n| 打印                   | <a href='#echo'>echo</a>                   |\n| 从尾部查看             | <a href='#tail'>tail -f -数字 路径  </a>   |\n| 编辑文件               | <a href='#vi'>vi 路径</a>                |\n\n\n\n## 1. 目录结构\n\n根目录：/\n/home/hellow/test.txt\n\n## 2. 小tip\n\n### 2-1 特殊符号\n\n- . 当前目录\n\n- .. 上级目录\n\n- ~ home\n- `作为命令执行\n### 2-2 进入root用户\n\n- 进入\n\nsu - root\n\n123456\n\n- 退出\nexit\n### 2-3管道符\n\n|\ncat 1.txt | grep \"hello\"\n\n- 左边结果作为右边的输入\n\n### 2-4重定向符\n\\>：右边文件内容清空，左边内容写入文件\n\n\\>>：追加\n## 3. 命令\n命令 [选项] [参数]\n### <span id='ls'>1. ls命令（显示内容）</span>\n\nls [-a -l -h] [路径]\n- a: all，列出全部文件（包括隐藏文件）\n- l: list，以列表展现（权限，用户和用户组，大小，创建日期）\n- h: 以易于阅读的形式，列出文件大小（搭配-l)\n- 组合使用：如-la\n\n### 2. <span id='cd'>cd命令（change directory）</span>\n\ncd [路径]\n\n- cd 回到用户HOME目录\n- cd ../.. 返回上两级\n- cd 路径\n### <span id='pwd'>3. pwd命令（print work directory）</span>\n\npwd\n### 4. <span id='mkdir'>mkdir命令（make directory）</span>\n\nmkdir [-p] 路径\n\n- 多层创建\n### 5. <span id='touch'>touch命令（创建文件）</span>\n\ntouch 路径\n### 6. <span id='cat'>cat命令（查看文件）</span>\n\ncat 路径\n### <span id='more'>7. more命令（查看文件）</span>\n\nmore 路径（分页看，空格下一页，q退出）\n### 8. <span id='cp'>cp命令（copy）</span>\n\ncp [-r] 源路径 目的地\n- r 递归，用于文件夹的复制\n### 9. <span id='mv'>mv命令（move）</span>\n\nmv 源路径 目的地/（可重命名）\n### 10. <span id='rm'>rm命令（remove）</span>\n\nrm [-r -f] 参数1 参数2...\n\n- r 递归，用于删除文件夹\n- f (force)强制删除\n- 支持通配符：test* 表示以test开头\n### 11. <span id='grep'>grep命令（文件中通过关键字搜索行）</span>\n\ngrep [-n] \"关键字\" 文件路径\n\n- n：结果中显示行号\n- 关键字：用于查找\n- 路径：可做输入端口\n### 12. <span id='wc'>wc命令（文件内容统计）</span>\n\nwc [-cmlw] 文件路径\n- c：统计bytes数量\n- m：统计字符数量\n- l：统计行数\n- w：统计单词数\n- 路径：可做输入端口\n### 13. <span id='which'>which命令（查看命令的源文件）</span>\n\nwhich Linux命令\n### 14. <span id='find'>find命令（文件搜索）</span>\n\nfind 起始路径 -name \"test*\"\nfind 起始路径 -size +100k(大于100kb)\n\n### 15. <span id='echo'>echo命令（打印）</span>\n\necho 输出内容\n- echo `pwd：'的作用：将pwd作为命令执行\n### 16. <span id='tail'>tail命令（从尾部查看）</span>\n\ntail [-f -数字] 路径\n- f 持续跟踪(会实时刷新)\n- 数字 查看多少行（默认10）\n\n## 4. <span id='vi'>vim编辑器</span>\n\nvi 文件路径\n\nvim 文件路径\n\n- vim是vi的升级版  \n\n![](./img/linux/commend/4.png)\n![](./img/linux/commend/5.png)\n![](./img/linux/commend/6.png)\n![](./img/linux/commend/7.png)\n![](../../../themes/yilia/source/img/linux/commend/4.png)\n![](../../../themes/yilia/source/img/linux/commend/5.png)\n![](../../../themes/yilia/source/img/linux/commend/6.png)\n![](../../../themes/yilia/source/img/linux/commend/7.png)\n\n## 5. <span id='help'>帮助</span>\n\n命令 --help\n- 查看用法\n\nman 命令\n\n- 操作手册","source":"_posts/linux/Linux_1.command.md","raw":"---\ntitle: Linux入门-1基础命令\ndate: 2021-03-02 20:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n---\n#\n\n<!--more-->\n\n# 1 基础命令\n\n| 显示                   | ls -alh 路径                             |\n| ---------------------- | ---------------------------------------- |\n| 打开路径               | <a href='#cd'>cd 路径</a>                |\n| 显示工作路径           | <a href='#pwd'>pwd</a>                    |\n| 创建文件夹             | <a href='#mkdir'>mkdir -p 路径</a>          |\n| 创建文件               | <a href='#touch'>touch 路径</a>             |\n| 查看文件               | <a href='#cat'>cat 路径</a>               |\n| 分页查看               | <a href='#more'>more 路径  </a>            |\n| 复制                   | <a href='#cp'>cp -r 源 目的  </a>        |\n| 移动文件               | <a href='#mv'>mv 源 目的（可重命名</a>） |\n| 删除文件               | <a href='#rm'>rm -rf 路径</a>            |\n| 文件中通过关键字搜索行 | <a href='#grep'>grep -n 关键字 路径 </a>   |\n| 文件内容统计           | <a href='#wc'>wc -cmlw 路径   </a>       |\n| 查看命令源文件         | <a href='#which'>which 命令 </a>            |\n| 搜索文件               | <a href='#find'>find 起始路径 -name \"test\"  </a> |\n| 打印                   | <a href='#echo'>echo</a>                   |\n| 从尾部查看             | <a href='#tail'>tail -f -数字 路径  </a>   |\n| 编辑文件               | <a href='#vi'>vi 路径</a>                |\n\n\n\n## 1. 目录结构\n\n根目录：/\n/home/hellow/test.txt\n\n## 2. 小tip\n\n### 2-1 特殊符号\n\n- . 当前目录\n\n- .. 上级目录\n\n- ~ home\n- `作为命令执行\n### 2-2 进入root用户\n\n- 进入\n\nsu - root\n\n123456\n\n- 退出\nexit\n### 2-3管道符\n\n|\ncat 1.txt | grep \"hello\"\n\n- 左边结果作为右边的输入\n\n### 2-4重定向符\n\\>：右边文件内容清空，左边内容写入文件\n\n\\>>：追加\n## 3. 命令\n命令 [选项] [参数]\n### <span id='ls'>1. ls命令（显示内容）</span>\n\nls [-a -l -h] [路径]\n- a: all，列出全部文件（包括隐藏文件）\n- l: list，以列表展现（权限，用户和用户组，大小，创建日期）\n- h: 以易于阅读的形式，列出文件大小（搭配-l)\n- 组合使用：如-la\n\n### 2. <span id='cd'>cd命令（change directory）</span>\n\ncd [路径]\n\n- cd 回到用户HOME目录\n- cd ../.. 返回上两级\n- cd 路径\n### <span id='pwd'>3. pwd命令（print work directory）</span>\n\npwd\n### 4. <span id='mkdir'>mkdir命令（make directory）</span>\n\nmkdir [-p] 路径\n\n- 多层创建\n### 5. <span id='touch'>touch命令（创建文件）</span>\n\ntouch 路径\n### 6. <span id='cat'>cat命令（查看文件）</span>\n\ncat 路径\n### <span id='more'>7. more命令（查看文件）</span>\n\nmore 路径（分页看，空格下一页，q退出）\n### 8. <span id='cp'>cp命令（copy）</span>\n\ncp [-r] 源路径 目的地\n- r 递归，用于文件夹的复制\n### 9. <span id='mv'>mv命令（move）</span>\n\nmv 源路径 目的地/（可重命名）\n### 10. <span id='rm'>rm命令（remove）</span>\n\nrm [-r -f] 参数1 参数2...\n\n- r 递归，用于删除文件夹\n- f (force)强制删除\n- 支持通配符：test* 表示以test开头\n### 11. <span id='grep'>grep命令（文件中通过关键字搜索行）</span>\n\ngrep [-n] \"关键字\" 文件路径\n\n- n：结果中显示行号\n- 关键字：用于查找\n- 路径：可做输入端口\n### 12. <span id='wc'>wc命令（文件内容统计）</span>\n\nwc [-cmlw] 文件路径\n- c：统计bytes数量\n- m：统计字符数量\n- l：统计行数\n- w：统计单词数\n- 路径：可做输入端口\n### 13. <span id='which'>which命令（查看命令的源文件）</span>\n\nwhich Linux命令\n### 14. <span id='find'>find命令（文件搜索）</span>\n\nfind 起始路径 -name \"test*\"\nfind 起始路径 -size +100k(大于100kb)\n\n### 15. <span id='echo'>echo命令（打印）</span>\n\necho 输出内容\n- echo `pwd：'的作用：将pwd作为命令执行\n### 16. <span id='tail'>tail命令（从尾部查看）</span>\n\ntail [-f -数字] 路径\n- f 持续跟踪(会实时刷新)\n- 数字 查看多少行（默认10）\n\n## 4. <span id='vi'>vim编辑器</span>\n\nvi 文件路径\n\nvim 文件路径\n\n- vim是vi的升级版  \n\n![](./img/linux/commend/4.png)\n![](./img/linux/commend/5.png)\n![](./img/linux/commend/6.png)\n![](./img/linux/commend/7.png)\n![](../../../themes/yilia/source/img/linux/commend/4.png)\n![](../../../themes/yilia/source/img/linux/commend/5.png)\n![](../../../themes/yilia/source/img/linux/commend/6.png)\n![](../../../themes/yilia/source/img/linux/commend/7.png)\n\n## 5. <span id='help'>帮助</span>\n\n命令 --help\n- 查看用法\n\nman 命令\n\n- 操作手册","slug":"linux/Linux_1.command","published":1,"updated":"2024-03-02T05:42:41.789Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clta2pf020001zovw9w1nf0iw","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"1-基础命令\"><a href=\"#1-基础命令\" class=\"headerlink\" title=\"1 基础命令\"></a>1 基础命令</h1><table>\n<thead>\n<tr>\n<th>显示</th>\n<th>ls -alh 路径</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>打开路径</td>\n<td><a href='#cd'>cd 路径</a></td>\n</tr>\n<tr>\n<td>显示工作路径</td>\n<td><a href='#pwd'>pwd</a></td>\n</tr>\n<tr>\n<td>创建文件夹</td>\n<td><a href='#mkdir'>mkdir -p 路径</a></td>\n</tr>\n<tr>\n<td>创建文件</td>\n<td><a href='#touch'>touch 路径</a></td>\n</tr>\n<tr>\n<td>查看文件</td>\n<td><a href='#cat'>cat 路径</a></td>\n</tr>\n<tr>\n<td>分页查看</td>\n<td><a href='#more'>more 路径  </a></td>\n</tr>\n<tr>\n<td>复制</td>\n<td><a href='#cp'>cp -r 源 目的  </a></td>\n</tr>\n<tr>\n<td>移动文件</td>\n<td><a href='#mv'>mv 源 目的（可重命名</a>）</td>\n</tr>\n<tr>\n<td>删除文件</td>\n<td><a href='#rm'>rm -rf 路径</a></td>\n</tr>\n<tr>\n<td>文件中通过关键字搜索行</td>\n<td><a href='#grep'>grep -n 关键字 路径 </a></td>\n</tr>\n<tr>\n<td>文件内容统计</td>\n<td><a href='#wc'>wc -cmlw 路径   </a></td>\n</tr>\n<tr>\n<td>查看命令源文件</td>\n<td><a href='#which'>which 命令 </a></td>\n</tr>\n<tr>\n<td>搜索文件</td>\n<td><a href='#find'>find 起始路径 -name “test”  </a></td>\n</tr>\n<tr>\n<td>打印</td>\n<td><a href='#echo'>echo</a></td>\n</tr>\n<tr>\n<td>从尾部查看</td>\n<td><a href='#tail'>tail -f -数字 路径  </a></td>\n</tr>\n<tr>\n<td>编辑文件</td>\n<td><a href='#vi'>vi 路径</a></td>\n</tr>\n</tbody></table>\n<h2 id=\"1-目录结构\"><a href=\"#1-目录结构\" class=\"headerlink\" title=\"1. 目录结构\"></a>1. 目录结构</h2><p>根目录：&#x2F;<br>&#x2F;home&#x2F;hellow&#x2F;test.txt</p>\n<h2 id=\"2-小tip\"><a href=\"#2-小tip\" class=\"headerlink\" title=\"2. 小tip\"></a>2. 小tip</h2><h3 id=\"2-1-特殊符号\"><a href=\"#2-1-特殊符号\" class=\"headerlink\" title=\"2-1 特殊符号\"></a>2-1 特殊符号</h3><ul>\n<li><p>. 当前目录</p>\n</li>\n<li><p>.. 上级目录</p>\n</li>\n<li><p>~ home</p>\n</li>\n<li><p>&#96;作为命令执行</p>\n</li>\n</ul>\n<h3 id=\"2-2-进入root用户\"><a href=\"#2-2-进入root用户\" class=\"headerlink\" title=\"2-2 进入root用户\"></a>2-2 进入root用户</h3><ul>\n<li>进入</li>\n</ul>\n<p>su - root</p>\n<p>123456</p>\n<ul>\n<li>退出<br>exit</li>\n</ul>\n<h3 id=\"2-3管道符\"><a href=\"#2-3管道符\" class=\"headerlink\" title=\"2-3管道符\"></a>2-3管道符</h3><p>|<br>cat 1.txt | grep “hello”</p>\n<ul>\n<li>左边结果作为右边的输入</li>\n</ul>\n<h3 id=\"2-4重定向符\"><a href=\"#2-4重定向符\" class=\"headerlink\" title=\"2-4重定向符\"></a>2-4重定向符</h3><p>&gt;：右边文件内容清空，左边内容写入文件</p>\n<p>&gt;&gt;：追加</p>\n<h2 id=\"3-命令\"><a href=\"#3-命令\" class=\"headerlink\" title=\"3. 命令\"></a>3. 命令</h2><p>命令 [选项] [参数]</p>\n<h3 id=\"1-ls命令（显示内容）\"><a href=\"#1-ls命令（显示内容）\" class=\"headerlink\" title=\"1. ls命令（显示内容）\"></a><span id='ls'>1. ls命令（显示内容）</span></h3><p>ls [-a -l -h] [路径]</p>\n<ul>\n<li>a: all，列出全部文件（包括隐藏文件）</li>\n<li>l: list，以列表展现（权限，用户和用户组，大小，创建日期）</li>\n<li>h: 以易于阅读的形式，列出文件大小（搭配-l)</li>\n<li>组合使用：如-la</li>\n</ul>\n<h3 id=\"2-cd命令（change-directory）\"><a href=\"#2-cd命令（change-directory）\" class=\"headerlink\" title=\"2. cd命令（change directory）\"></a>2. <span id='cd'>cd命令（change directory）</span></h3><p>cd [路径]</p>\n<ul>\n<li>cd 回到用户HOME目录</li>\n<li>cd ..&#x2F;.. 返回上两级</li>\n<li>cd 路径</li>\n</ul>\n<h3 id=\"3-pwd命令（print-work-directory）\"><a href=\"#3-pwd命令（print-work-directory）\" class=\"headerlink\" title=\"3. pwd命令（print work directory）\"></a><span id='pwd'>3. pwd命令（print work directory）</span></h3><p>pwd</p>\n<h3 id=\"4-mkdir命令（make-directory）\"><a href=\"#4-mkdir命令（make-directory）\" class=\"headerlink\" title=\"4. mkdir命令（make directory）\"></a>4. <span id='mkdir'>mkdir命令（make directory）</span></h3><p>mkdir [-p] 路径</p>\n<ul>\n<li>多层创建</li>\n</ul>\n<h3 id=\"5-touch命令（创建文件）\"><a href=\"#5-touch命令（创建文件）\" class=\"headerlink\" title=\"5. touch命令（创建文件）\"></a>5. <span id='touch'>touch命令（创建文件）</span></h3><p>touch 路径</p>\n<h3 id=\"6-cat命令（查看文件）\"><a href=\"#6-cat命令（查看文件）\" class=\"headerlink\" title=\"6. cat命令（查看文件）\"></a>6. <span id='cat'>cat命令（查看文件）</span></h3><p>cat 路径</p>\n<h3 id=\"7-more命令（查看文件）\"><a href=\"#7-more命令（查看文件）\" class=\"headerlink\" title=\"7. more命令（查看文件）\"></a><span id='more'>7. more命令（查看文件）</span></h3><p>more 路径（分页看，空格下一页，q退出）</p>\n<h3 id=\"8-cp命令（copy）\"><a href=\"#8-cp命令（copy）\" class=\"headerlink\" title=\"8. cp命令（copy）\"></a>8. <span id='cp'>cp命令（copy）</span></h3><p>cp [-r] 源路径 目的地</p>\n<ul>\n<li>r 递归，用于文件夹的复制</li>\n</ul>\n<h3 id=\"9-mv命令（move）\"><a href=\"#9-mv命令（move）\" class=\"headerlink\" title=\"9. mv命令（move）\"></a>9. <span id='mv'>mv命令（move）</span></h3><p>mv 源路径 目的地&#x2F;（可重命名）</p>\n<h3 id=\"10-rm命令（remove）\"><a href=\"#10-rm命令（remove）\" class=\"headerlink\" title=\"10. rm命令（remove）\"></a>10. <span id='rm'>rm命令（remove）</span></h3><p>rm [-r -f] 参数1 参数2…</p>\n<ul>\n<li>r 递归，用于删除文件夹</li>\n<li>f (force)强制删除</li>\n<li>支持通配符：test* 表示以test开头</li>\n</ul>\n<h3 id=\"11-grep命令（文件中通过关键字搜索行）\"><a href=\"#11-grep命令（文件中通过关键字搜索行）\" class=\"headerlink\" title=\"11. grep命令（文件中通过关键字搜索行）\"></a>11. <span id='grep'>grep命令（文件中通过关键字搜索行）</span></h3><p>grep [-n] “关键字” 文件路径</p>\n<ul>\n<li>n：结果中显示行号</li>\n<li>关键字：用于查找</li>\n<li>路径：可做输入端口</li>\n</ul>\n<h3 id=\"12-wc命令（文件内容统计）\"><a href=\"#12-wc命令（文件内容统计）\" class=\"headerlink\" title=\"12. wc命令（文件内容统计）\"></a>12. <span id='wc'>wc命令（文件内容统计）</span></h3><p>wc [-cmlw] 文件路径</p>\n<ul>\n<li>c：统计bytes数量</li>\n<li>m：统计字符数量</li>\n<li>l：统计行数</li>\n<li>w：统计单词数</li>\n<li>路径：可做输入端口</li>\n</ul>\n<h3 id=\"13-which命令（查看命令的源文件）\"><a href=\"#13-which命令（查看命令的源文件）\" class=\"headerlink\" title=\"13. which命令（查看命令的源文件）\"></a>13. <span id='which'>which命令（查看命令的源文件）</span></h3><p>which Linux命令</p>\n<h3 id=\"14-find命令（文件搜索）\"><a href=\"#14-find命令（文件搜索）\" class=\"headerlink\" title=\"14. find命令（文件搜索）\"></a>14. <span id='find'>find命令（文件搜索）</span></h3><p>find 起始路径 -name “test*”<br>find 起始路径 -size +100k(大于100kb)</p>\n<h3 id=\"15-echo命令（打印）\"><a href=\"#15-echo命令（打印）\" class=\"headerlink\" title=\"15. echo命令（打印）\"></a>15. <span id='echo'>echo命令（打印）</span></h3><p>echo 输出内容</p>\n<ul>\n<li>echo &#96;pwd：’的作用：将pwd作为命令执行</li>\n</ul>\n<h3 id=\"16-tail命令（从尾部查看）\"><a href=\"#16-tail命令（从尾部查看）\" class=\"headerlink\" title=\"16. tail命令（从尾部查看）\"></a>16. <span id='tail'>tail命令（从尾部查看）</span></h3><p>tail [-f -数字] 路径</p>\n<ul>\n<li>f 持续跟踪(会实时刷新)</li>\n<li>数字 查看多少行（默认10）</li>\n</ul>\n<h2 id=\"4-vim编辑器\"><a href=\"#4-vim编辑器\" class=\"headerlink\" title=\"4. vim编辑器\"></a>4. <span id='vi'>vim编辑器</span></h2><p>vi 文件路径</p>\n<p>vim 文件路径</p>\n<ul>\n<li>vim是vi的升级版</li>\n</ul>\n<p><img src=\"/./img/linux/commend/4.png\"><br><img src=\"/./img/linux/commend/5.png\"><br><img src=\"/./img/linux/commend/6.png\"><br><img src=\"/./img/linux/commend/7.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/4.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/5.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/6.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/7.png\"></p>\n<h2 id=\"5-帮助\"><a href=\"#5-帮助\" class=\"headerlink\" title=\"5. 帮助\"></a>5. <span id='help'>帮助</span></h2><p>命令 –help</p>\n<ul>\n<li>查看用法</li>\n</ul>\n<p>man 命令</p>\n<ul>\n<li>操作手册</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-基础命令\"><a href=\"#1-基础命令\" class=\"headerlink\" title=\"1 基础命令\"></a>1 基础命令</h1><table>\n<thead>\n<tr>\n<th>显示</th>\n<th>ls -alh 路径</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>打开路径</td>\n<td><a href='#cd'>cd 路径</a></td>\n</tr>\n<tr>\n<td>显示工作路径</td>\n<td><a href='#pwd'>pwd</a></td>\n</tr>\n<tr>\n<td>创建文件夹</td>\n<td><a href='#mkdir'>mkdir -p 路径</a></td>\n</tr>\n<tr>\n<td>创建文件</td>\n<td><a href='#touch'>touch 路径</a></td>\n</tr>\n<tr>\n<td>查看文件</td>\n<td><a href='#cat'>cat 路径</a></td>\n</tr>\n<tr>\n<td>分页查看</td>\n<td><a href='#more'>more 路径  </a></td>\n</tr>\n<tr>\n<td>复制</td>\n<td><a href='#cp'>cp -r 源 目的  </a></td>\n</tr>\n<tr>\n<td>移动文件</td>\n<td><a href='#mv'>mv 源 目的（可重命名</a>）</td>\n</tr>\n<tr>\n<td>删除文件</td>\n<td><a href='#rm'>rm -rf 路径</a></td>\n</tr>\n<tr>\n<td>文件中通过关键字搜索行</td>\n<td><a href='#grep'>grep -n 关键字 路径 </a></td>\n</tr>\n<tr>\n<td>文件内容统计</td>\n<td><a href='#wc'>wc -cmlw 路径   </a></td>\n</tr>\n<tr>\n<td>查看命令源文件</td>\n<td><a href='#which'>which 命令 </a></td>\n</tr>\n<tr>\n<td>搜索文件</td>\n<td><a href='#find'>find 起始路径 -name “test”  </a></td>\n</tr>\n<tr>\n<td>打印</td>\n<td><a href='#echo'>echo</a></td>\n</tr>\n<tr>\n<td>从尾部查看</td>\n<td><a href='#tail'>tail -f -数字 路径  </a></td>\n</tr>\n<tr>\n<td>编辑文件</td>\n<td><a href='#vi'>vi 路径</a></td>\n</tr>\n</tbody></table>\n<h2 id=\"1-目录结构\"><a href=\"#1-目录结构\" class=\"headerlink\" title=\"1. 目录结构\"></a>1. 目录结构</h2><p>根目录：&#x2F;<br>&#x2F;home&#x2F;hellow&#x2F;test.txt</p>\n<h2 id=\"2-小tip\"><a href=\"#2-小tip\" class=\"headerlink\" title=\"2. 小tip\"></a>2. 小tip</h2><h3 id=\"2-1-特殊符号\"><a href=\"#2-1-特殊符号\" class=\"headerlink\" title=\"2-1 特殊符号\"></a>2-1 特殊符号</h3><ul>\n<li><p>. 当前目录</p>\n</li>\n<li><p>.. 上级目录</p>\n</li>\n<li><p>~ home</p>\n</li>\n<li><p>&#96;作为命令执行</p>\n</li>\n</ul>\n<h3 id=\"2-2-进入root用户\"><a href=\"#2-2-进入root用户\" class=\"headerlink\" title=\"2-2 进入root用户\"></a>2-2 进入root用户</h3><ul>\n<li>进入</li>\n</ul>\n<p>su - root</p>\n<p>123456</p>\n<ul>\n<li>退出<br>exit</li>\n</ul>\n<h3 id=\"2-3管道符\"><a href=\"#2-3管道符\" class=\"headerlink\" title=\"2-3管道符\"></a>2-3管道符</h3><p>|<br>cat 1.txt | grep “hello”</p>\n<ul>\n<li>左边结果作为右边的输入</li>\n</ul>\n<h3 id=\"2-4重定向符\"><a href=\"#2-4重定向符\" class=\"headerlink\" title=\"2-4重定向符\"></a>2-4重定向符</h3><p>&gt;：右边文件内容清空，左边内容写入文件</p>\n<p>&gt;&gt;：追加</p>\n<h2 id=\"3-命令\"><a href=\"#3-命令\" class=\"headerlink\" title=\"3. 命令\"></a>3. 命令</h2><p>命令 [选项] [参数]</p>\n<h3 id=\"1-ls命令（显示内容）\"><a href=\"#1-ls命令（显示内容）\" class=\"headerlink\" title=\"1. ls命令（显示内容）\"></a><span id='ls'>1. ls命令（显示内容）</span></h3><p>ls [-a -l -h] [路径]</p>\n<ul>\n<li>a: all，列出全部文件（包括隐藏文件）</li>\n<li>l: list，以列表展现（权限，用户和用户组，大小，创建日期）</li>\n<li>h: 以易于阅读的形式，列出文件大小（搭配-l)</li>\n<li>组合使用：如-la</li>\n</ul>\n<h3 id=\"2-cd命令（change-directory）\"><a href=\"#2-cd命令（change-directory）\" class=\"headerlink\" title=\"2. cd命令（change directory）\"></a>2. <span id='cd'>cd命令（change directory）</span></h3><p>cd [路径]</p>\n<ul>\n<li>cd 回到用户HOME目录</li>\n<li>cd ..&#x2F;.. 返回上两级</li>\n<li>cd 路径</li>\n</ul>\n<h3 id=\"3-pwd命令（print-work-directory）\"><a href=\"#3-pwd命令（print-work-directory）\" class=\"headerlink\" title=\"3. pwd命令（print work directory）\"></a><span id='pwd'>3. pwd命令（print work directory）</span></h3><p>pwd</p>\n<h3 id=\"4-mkdir命令（make-directory）\"><a href=\"#4-mkdir命令（make-directory）\" class=\"headerlink\" title=\"4. mkdir命令（make directory）\"></a>4. <span id='mkdir'>mkdir命令（make directory）</span></h3><p>mkdir [-p] 路径</p>\n<ul>\n<li>多层创建</li>\n</ul>\n<h3 id=\"5-touch命令（创建文件）\"><a href=\"#5-touch命令（创建文件）\" class=\"headerlink\" title=\"5. touch命令（创建文件）\"></a>5. <span id='touch'>touch命令（创建文件）</span></h3><p>touch 路径</p>\n<h3 id=\"6-cat命令（查看文件）\"><a href=\"#6-cat命令（查看文件）\" class=\"headerlink\" title=\"6. cat命令（查看文件）\"></a>6. <span id='cat'>cat命令（查看文件）</span></h3><p>cat 路径</p>\n<h3 id=\"7-more命令（查看文件）\"><a href=\"#7-more命令（查看文件）\" class=\"headerlink\" title=\"7. more命令（查看文件）\"></a><span id='more'>7. more命令（查看文件）</span></h3><p>more 路径（分页看，空格下一页，q退出）</p>\n<h3 id=\"8-cp命令（copy）\"><a href=\"#8-cp命令（copy）\" class=\"headerlink\" title=\"8. cp命令（copy）\"></a>8. <span id='cp'>cp命令（copy）</span></h3><p>cp [-r] 源路径 目的地</p>\n<ul>\n<li>r 递归，用于文件夹的复制</li>\n</ul>\n<h3 id=\"9-mv命令（move）\"><a href=\"#9-mv命令（move）\" class=\"headerlink\" title=\"9. mv命令（move）\"></a>9. <span id='mv'>mv命令（move）</span></h3><p>mv 源路径 目的地&#x2F;（可重命名）</p>\n<h3 id=\"10-rm命令（remove）\"><a href=\"#10-rm命令（remove）\" class=\"headerlink\" title=\"10. rm命令（remove）\"></a>10. <span id='rm'>rm命令（remove）</span></h3><p>rm [-r -f] 参数1 参数2…</p>\n<ul>\n<li>r 递归，用于删除文件夹</li>\n<li>f (force)强制删除</li>\n<li>支持通配符：test* 表示以test开头</li>\n</ul>\n<h3 id=\"11-grep命令（文件中通过关键字搜索行）\"><a href=\"#11-grep命令（文件中通过关键字搜索行）\" class=\"headerlink\" title=\"11. grep命令（文件中通过关键字搜索行）\"></a>11. <span id='grep'>grep命令（文件中通过关键字搜索行）</span></h3><p>grep [-n] “关键字” 文件路径</p>\n<ul>\n<li>n：结果中显示行号</li>\n<li>关键字：用于查找</li>\n<li>路径：可做输入端口</li>\n</ul>\n<h3 id=\"12-wc命令（文件内容统计）\"><a href=\"#12-wc命令（文件内容统计）\" class=\"headerlink\" title=\"12. wc命令（文件内容统计）\"></a>12. <span id='wc'>wc命令（文件内容统计）</span></h3><p>wc [-cmlw] 文件路径</p>\n<ul>\n<li>c：统计bytes数量</li>\n<li>m：统计字符数量</li>\n<li>l：统计行数</li>\n<li>w：统计单词数</li>\n<li>路径：可做输入端口</li>\n</ul>\n<h3 id=\"13-which命令（查看命令的源文件）\"><a href=\"#13-which命令（查看命令的源文件）\" class=\"headerlink\" title=\"13. which命令（查看命令的源文件）\"></a>13. <span id='which'>which命令（查看命令的源文件）</span></h3><p>which Linux命令</p>\n<h3 id=\"14-find命令（文件搜索）\"><a href=\"#14-find命令（文件搜索）\" class=\"headerlink\" title=\"14. find命令（文件搜索）\"></a>14. <span id='find'>find命令（文件搜索）</span></h3><p>find 起始路径 -name “test*”<br>find 起始路径 -size +100k(大于100kb)</p>\n<h3 id=\"15-echo命令（打印）\"><a href=\"#15-echo命令（打印）\" class=\"headerlink\" title=\"15. echo命令（打印）\"></a>15. <span id='echo'>echo命令（打印）</span></h3><p>echo 输出内容</p>\n<ul>\n<li>echo &#96;pwd：’的作用：将pwd作为命令执行</li>\n</ul>\n<h3 id=\"16-tail命令（从尾部查看）\"><a href=\"#16-tail命令（从尾部查看）\" class=\"headerlink\" title=\"16. tail命令（从尾部查看）\"></a>16. <span id='tail'>tail命令（从尾部查看）</span></h3><p>tail [-f -数字] 路径</p>\n<ul>\n<li>f 持续跟踪(会实时刷新)</li>\n<li>数字 查看多少行（默认10）</li>\n</ul>\n<h2 id=\"4-vim编辑器\"><a href=\"#4-vim编辑器\" class=\"headerlink\" title=\"4. vim编辑器\"></a>4. <span id='vi'>vim编辑器</span></h2><p>vi 文件路径</p>\n<p>vim 文件路径</p>\n<ul>\n<li>vim是vi的升级版</li>\n</ul>\n<p><img src=\"/./img/linux/commend/4.png\"><br><img src=\"/./img/linux/commend/5.png\"><br><img src=\"/./img/linux/commend/6.png\"><br><img src=\"/./img/linux/commend/7.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/4.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/5.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/6.png\"><br><img src=\"/../../../themes/yilia/source/img/linux/commend/7.png\"></p>\n<h2 id=\"5-帮助\"><a href=\"#5-帮助\" class=\"headerlink\" title=\"5. 帮助\"></a>5. <span id='help'>帮助</span></h2><p>命令 –help</p>\n<ul>\n<li>查看用法</li>\n</ul>\n<p>man 命令</p>\n<ul>\n<li>操作手册</li>\n</ul>"},{"title":"Linux入门-2用户和权限","date":"2021-03-03T12:00:00.000Z","toc":true,"_content":"#\n\n<!--more-->\n\n# 2 用户和权限\n\n| <a href='#su'>切换用户</a>             | su 用户名                                 |\n| -------------------------------------- | ----------------------------------------- |\n| <a href='#sudo'>管理员运行</a>         | sudo 命令                                 |\n| <a href='#groupadd'>创建用户组</a>     | groupadd 组名                             |\n| <a href='#groupdel'>删除用户组</a>     | groupdel 组名                             |\n| <a href='#useradd'>创建用户</a>        | useradd 用户名 -g 组名 -d 用户家目录      |\n| <a href='#userdel'>删除用户</a>        | userdel -r 用户名                         |\n| <a href='#id'>查看用户所属组</a>       | id 用户名                                 |\n| <a href='#usermod'>修改用户所属组</a>  | usermod -aG 组名 用户名                   |\n| <a href='#getent'>查看系统用户(组)</a> | getent passwd或group                      |\n| <a href='#chmod'>修改权限</a>          | chmod [-R] 权限 文件或文件夹              |\n| <a href='#chown'>修改所属用户</a>      | `chown [-R] [用户][:用户组] 文件或文件夹` |\n\n\n\n### 1. su（switch user）<span id='su'>命令</span>\n\nsu [-] [用户名]\n\n- 退出用户：exit或ctrl+d\n\n### 2. sudo<span id='sudo'>命令</span>（以管理员身份运行）\n\nsudo Linux命令\n\n- 需要先为用户配置sudo认证  \n  - 先进入root用户\n  - 再visudo，G到最后一行，o到末尾，再末尾输入：用户名 ALL=(ALL)      NOPASSWD: ALL\n  - 再esc，:wq退出 \n\n### 3. 用户组\n- 创建：<span id='groupadd'>groupadd</span> 组名\n- 删除：<span id='groupdel'>groupdel</span> 组名\n\n### 4. 用户\n#### 4-1创建用户\n<span id='useradd'>useradd [-g -d] 用户名</span>\n（useradd 用户名 -g 组名 -d 目录）\n\n- g 指定用户的组，不写则组与用户名同\n- d指定用户home目录位置\n#### 4-2 删除用户\n<span id='userdel'>userdel [-r] 用户名</span>\n\n- r 删除home目录\n#### 4-3 查看用户所属组<span id='id'> </span>\n\nid [用户名]\n\n#### 4-4 修改用户所属组<span id='usermod'> </span>\n\nusermod -aG 组名 用户名\n\n#### 4-5 查看系统用户(组)<span id='getent'></span>\n\ngetent passwd或group\n- 用户显示的信息：用户名:密码:用户组:描述信息:HOME目录:执行终端（默认bash)\n- 组显示信息：组名:组认证:组ID\n\n### 5 权限\n\n#### 5.1 权限信息\n\n![](./img/linux/user/8.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\linux\\user\\8.png)\n\n- 权限信息（序号1）\n\n  总共10位：\n\n  | 类型                              | 所属用户权限 |      |      | 所属用户组权限 |      |      | 其他用户权限 |      |      |\n  | --------------------------------- | ------------ | ---- | ---- | -------------- | ---- | ---- | ------------ | ---- | ---- |\n  | -/d/l                             | r/-          | w/-  | x/-  | r/-            | w/-  | x/-  | r/-          | w/-  | x/-  |\n  | -：文件<br>d：文件夹<br>l：软连接 | 读           | 写   | 执行 |                |      |      |              |      |      |\n\n  对于文件夹：\n\n  - r：可ls里面的内容\n  - w：可以在里面创建、删除、改名\n  - x：可cd到此\n\n#### 5.2 <span id='chmod'>修改权限</span>\n\n- chmod命令\n\n  ```bash\n  chmod [-R] 权限 文件或文件夹\n  ```\n\n  - -R：递归\n\n  - 例子：\n\n    ```bash\n    chmod u=rwx,g=rx,o=x test.txt\n    chmod 751 test.txt\n    ```\n    \n    \n\n#### 5.3 <span id='chown'>修改所属用户</span>\n\n- chown命令\n\n```bash\nchown [-R] [用户][:用户组] 文件或文件夹\n```\n\n  \n\n","source":"_posts/linux/Linux_2.user.md","raw":"---\ntitle: Linux入门-2用户和权限\ndate: 2021-03-03 20:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n---\n#\n\n<!--more-->\n\n# 2 用户和权限\n\n| <a href='#su'>切换用户</a>             | su 用户名                                 |\n| -------------------------------------- | ----------------------------------------- |\n| <a href='#sudo'>管理员运行</a>         | sudo 命令                                 |\n| <a href='#groupadd'>创建用户组</a>     | groupadd 组名                             |\n| <a href='#groupdel'>删除用户组</a>     | groupdel 组名                             |\n| <a href='#useradd'>创建用户</a>        | useradd 用户名 -g 组名 -d 用户家目录      |\n| <a href='#userdel'>删除用户</a>        | userdel -r 用户名                         |\n| <a href='#id'>查看用户所属组</a>       | id 用户名                                 |\n| <a href='#usermod'>修改用户所属组</a>  | usermod -aG 组名 用户名                   |\n| <a href='#getent'>查看系统用户(组)</a> | getent passwd或group                      |\n| <a href='#chmod'>修改权限</a>          | chmod [-R] 权限 文件或文件夹              |\n| <a href='#chown'>修改所属用户</a>      | `chown [-R] [用户][:用户组] 文件或文件夹` |\n\n\n\n### 1. su（switch user）<span id='su'>命令</span>\n\nsu [-] [用户名]\n\n- 退出用户：exit或ctrl+d\n\n### 2. sudo<span id='sudo'>命令</span>（以管理员身份运行）\n\nsudo Linux命令\n\n- 需要先为用户配置sudo认证  \n  - 先进入root用户\n  - 再visudo，G到最后一行，o到末尾，再末尾输入：用户名 ALL=(ALL)      NOPASSWD: ALL\n  - 再esc，:wq退出 \n\n### 3. 用户组\n- 创建：<span id='groupadd'>groupadd</span> 组名\n- 删除：<span id='groupdel'>groupdel</span> 组名\n\n### 4. 用户\n#### 4-1创建用户\n<span id='useradd'>useradd [-g -d] 用户名</span>\n（useradd 用户名 -g 组名 -d 目录）\n\n- g 指定用户的组，不写则组与用户名同\n- d指定用户home目录位置\n#### 4-2 删除用户\n<span id='userdel'>userdel [-r] 用户名</span>\n\n- r 删除home目录\n#### 4-3 查看用户所属组<span id='id'> </span>\n\nid [用户名]\n\n#### 4-4 修改用户所属组<span id='usermod'> </span>\n\nusermod -aG 组名 用户名\n\n#### 4-5 查看系统用户(组)<span id='getent'></span>\n\ngetent passwd或group\n- 用户显示的信息：用户名:密码:用户组:描述信息:HOME目录:执行终端（默认bash)\n- 组显示信息：组名:组认证:组ID\n\n### 5 权限\n\n#### 5.1 权限信息\n\n![](./img/linux/user/8.png)\n\n![](D:\\blog\\themes\\yilia\\source\\img\\linux\\user\\8.png)\n\n- 权限信息（序号1）\n\n  总共10位：\n\n  | 类型                              | 所属用户权限 |      |      | 所属用户组权限 |      |      | 其他用户权限 |      |      |\n  | --------------------------------- | ------------ | ---- | ---- | -------------- | ---- | ---- | ------------ | ---- | ---- |\n  | -/d/l                             | r/-          | w/-  | x/-  | r/-            | w/-  | x/-  | r/-          | w/-  | x/-  |\n  | -：文件<br>d：文件夹<br>l：软连接 | 读           | 写   | 执行 |                |      |      |              |      |      |\n\n  对于文件夹：\n\n  - r：可ls里面的内容\n  - w：可以在里面创建、删除、改名\n  - x：可cd到此\n\n#### 5.2 <span id='chmod'>修改权限</span>\n\n- chmod命令\n\n  ```bash\n  chmod [-R] 权限 文件或文件夹\n  ```\n\n  - -R：递归\n\n  - 例子：\n\n    ```bash\n    chmod u=rwx,g=rx,o=x test.txt\n    chmod 751 test.txt\n    ```\n    \n    \n\n#### 5.3 <span id='chown'>修改所属用户</span>\n\n- chown命令\n\n```bash\nchown [-R] [用户][:用户组] 文件或文件夹\n```\n\n  \n\n","slug":"linux/Linux_2.user","published":1,"updated":"2024-03-02T06:15:44.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clta2pf040003zovw0vqq7bqr","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"2-用户和权限\"><a href=\"#2-用户和权限\" class=\"headerlink\" title=\"2 用户和权限\"></a>2 用户和权限</h1><table>\n<thead>\n<tr>\n<th><a href='#su'>切换用户</a></th>\n<th>su 用户名</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><a href='#sudo'>管理员运行</a></td>\n<td>sudo 命令</td>\n</tr>\n<tr>\n<td><a href='#groupadd'>创建用户组</a></td>\n<td>groupadd 组名</td>\n</tr>\n<tr>\n<td><a href='#groupdel'>删除用户组</a></td>\n<td>groupdel 组名</td>\n</tr>\n<tr>\n<td><a href='#useradd'>创建用户</a></td>\n<td>useradd 用户名 -g 组名 -d 用户家目录</td>\n</tr>\n<tr>\n<td><a href='#userdel'>删除用户</a></td>\n<td>userdel -r 用户名</td>\n</tr>\n<tr>\n<td><a href='#id'>查看用户所属组</a></td>\n<td>id 用户名</td>\n</tr>\n<tr>\n<td><a href='#usermod'>修改用户所属组</a></td>\n<td>usermod -aG 组名 用户名</td>\n</tr>\n<tr>\n<td><a href='#getent'>查看系统用户(组)</a></td>\n<td>getent passwd或group</td>\n</tr>\n<tr>\n<td><a href='#chmod'>修改权限</a></td>\n<td>chmod [-R] 权限 文件或文件夹</td>\n</tr>\n<tr>\n<td><a href='#chown'>修改所属用户</a></td>\n<td><code>chown [-R] [用户][:用户组] 文件或文件夹</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"1-su（switch-user）命令\"><a href=\"#1-su（switch-user）命令\" class=\"headerlink\" title=\"1. su（switch user）命令\"></a>1. su（switch user）<span id='su'>命令</span></h3><p>su [-] [用户名]</p>\n<ul>\n<li>退出用户：exit或ctrl+d</li>\n</ul>\n<h3 id=\"2-sudo命令（以管理员身份运行）\"><a href=\"#2-sudo命令（以管理员身份运行）\" class=\"headerlink\" title=\"2. sudo命令（以管理员身份运行）\"></a>2. sudo<span id='sudo'>命令</span>（以管理员身份运行）</h3><p>sudo Linux命令</p>\n<ul>\n<li>需要先为用户配置sudo认证  <ul>\n<li>先进入root用户</li>\n<li>再visudo，G到最后一行，o到末尾，再末尾输入：用户名 ALL&#x3D;(ALL)      NOPASSWD: ALL</li>\n<li>再esc，:wq退出</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-用户组\"><a href=\"#3-用户组\" class=\"headerlink\" title=\"3. 用户组\"></a>3. 用户组</h3><ul>\n<li>创建：<span id='groupadd'>groupadd</span> 组名</li>\n<li>删除：<span id='groupdel'>groupdel</span> 组名</li>\n</ul>\n<h3 id=\"4-用户\"><a href=\"#4-用户\" class=\"headerlink\" title=\"4. 用户\"></a>4. 用户</h3><h4 id=\"4-1创建用户\"><a href=\"#4-1创建用户\" class=\"headerlink\" title=\"4-1创建用户\"></a>4-1创建用户</h4><p><span id='useradd'>useradd [-g -d] 用户名</span><br>（useradd 用户名 -g 组名 -d 目录）</p>\n<ul>\n<li>g 指定用户的组，不写则组与用户名同</li>\n<li>d指定用户home目录位置</li>\n</ul>\n<h4 id=\"4-2-删除用户\"><a href=\"#4-2-删除用户\" class=\"headerlink\" title=\"4-2 删除用户\"></a>4-2 删除用户</h4><p><span id='userdel'>userdel [-r] 用户名</span></p>\n<ul>\n<li>r 删除home目录</li>\n</ul>\n<h4 id=\"4-3-查看用户所属组\"><a href=\"#4-3-查看用户所属组\" class=\"headerlink\" title=\"4-3 查看用户所属组 \"></a>4-3 查看用户所属组<span id='id'> </span></h4><p>id [用户名]</p>\n<h4 id=\"4-4-修改用户所属组\"><a href=\"#4-4-修改用户所属组\" class=\"headerlink\" title=\"4-4 修改用户所属组 \"></a>4-4 修改用户所属组<span id='usermod'> </span></h4><p>usermod -aG 组名 用户名</p>\n<h4 id=\"4-5-查看系统用户-组\"><a href=\"#4-5-查看系统用户-组\" class=\"headerlink\" title=\"4-5 查看系统用户(组)\"></a>4-5 查看系统用户(组)<span id='getent'></span></h4><p>getent passwd或group</p>\n<ul>\n<li>用户显示的信息：用户名:密码:用户组:描述信息:HOME目录:执行终端（默认bash)</li>\n<li>组显示信息：组名:组认证:组ID</li>\n</ul>\n<h3 id=\"5-权限\"><a href=\"#5-权限\" class=\"headerlink\" title=\"5 权限\"></a>5 权限</h3><h4 id=\"5-1-权限信息\"><a href=\"#5-1-权限信息\" class=\"headerlink\" title=\"5.1 权限信息\"></a>5.1 权限信息</h4><p><img src=\"/./img/linux/user/8.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\user\\8.png\"></p>\n<ul>\n<li><p>权限信息（序号1）</p>\n<p>总共10位：</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>所属用户权限</th>\n<th></th>\n<th></th>\n<th>所属用户组权限</th>\n<th></th>\n<th></th>\n<th>其他用户权限</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-&#x2F;d&#x2F;l</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n</tr>\n<tr>\n<td>-：文件<br>d：文件夹<br>l：软连接</td>\n<td>读</td>\n<td>写</td>\n<td>执行</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>对于文件夹：</p>\n<ul>\n<li>r：可ls里面的内容</li>\n<li>w：可以在里面创建、删除、改名</li>\n<li>x：可cd到此</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"5-2-修改权限\"><a href=\"#5-2-修改权限\" class=\"headerlink\" title=\"5.2 修改权限\"></a>5.2 <span id='chmod'>修改权限</span></h4><ul>\n<li><p>chmod命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> [-R] 权限 文件或文件夹</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-R：递归</p>\n</li>\n<li><p>例子：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> u=rwx,g=rx,o=x test.txt</span><br><span class=\"line\"><span class=\"built_in\">chmod</span> 751 test.txt</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"5-3-修改所属用户\"><a href=\"#5-3-修改所属用户\" class=\"headerlink\" title=\"5.3 修改所属用户\"></a>5.3 <span id='chown'>修改所属用户</span></h4><ul>\n<li>chown命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chown</span> [-R] [用户][:用户组] 文件或文件夹</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"2-用户和权限\"><a href=\"#2-用户和权限\" class=\"headerlink\" title=\"2 用户和权限\"></a>2 用户和权限</h1><table>\n<thead>\n<tr>\n<th><a href='#su'>切换用户</a></th>\n<th>su 用户名</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><a href='#sudo'>管理员运行</a></td>\n<td>sudo 命令</td>\n</tr>\n<tr>\n<td><a href='#groupadd'>创建用户组</a></td>\n<td>groupadd 组名</td>\n</tr>\n<tr>\n<td><a href='#groupdel'>删除用户组</a></td>\n<td>groupdel 组名</td>\n</tr>\n<tr>\n<td><a href='#useradd'>创建用户</a></td>\n<td>useradd 用户名 -g 组名 -d 用户家目录</td>\n</tr>\n<tr>\n<td><a href='#userdel'>删除用户</a></td>\n<td>userdel -r 用户名</td>\n</tr>\n<tr>\n<td><a href='#id'>查看用户所属组</a></td>\n<td>id 用户名</td>\n</tr>\n<tr>\n<td><a href='#usermod'>修改用户所属组</a></td>\n<td>usermod -aG 组名 用户名</td>\n</tr>\n<tr>\n<td><a href='#getent'>查看系统用户(组)</a></td>\n<td>getent passwd或group</td>\n</tr>\n<tr>\n<td><a href='#chmod'>修改权限</a></td>\n<td>chmod [-R] 权限 文件或文件夹</td>\n</tr>\n<tr>\n<td><a href='#chown'>修改所属用户</a></td>\n<td><code>chown [-R] [用户][:用户组] 文件或文件夹</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"1-su（switch-user）命令\"><a href=\"#1-su（switch-user）命令\" class=\"headerlink\" title=\"1. su（switch user）命令\"></a>1. su（switch user）<span id='su'>命令</span></h3><p>su [-] [用户名]</p>\n<ul>\n<li>退出用户：exit或ctrl+d</li>\n</ul>\n<h3 id=\"2-sudo命令（以管理员身份运行）\"><a href=\"#2-sudo命令（以管理员身份运行）\" class=\"headerlink\" title=\"2. sudo命令（以管理员身份运行）\"></a>2. sudo<span id='sudo'>命令</span>（以管理员身份运行）</h3><p>sudo Linux命令</p>\n<ul>\n<li>需要先为用户配置sudo认证  <ul>\n<li>先进入root用户</li>\n<li>再visudo，G到最后一行，o到末尾，再末尾输入：用户名 ALL&#x3D;(ALL)      NOPASSWD: ALL</li>\n<li>再esc，:wq退出</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-用户组\"><a href=\"#3-用户组\" class=\"headerlink\" title=\"3. 用户组\"></a>3. 用户组</h3><ul>\n<li>创建：<span id='groupadd'>groupadd</span> 组名</li>\n<li>删除：<span id='groupdel'>groupdel</span> 组名</li>\n</ul>\n<h3 id=\"4-用户\"><a href=\"#4-用户\" class=\"headerlink\" title=\"4. 用户\"></a>4. 用户</h3><h4 id=\"4-1创建用户\"><a href=\"#4-1创建用户\" class=\"headerlink\" title=\"4-1创建用户\"></a>4-1创建用户</h4><p><span id='useradd'>useradd [-g -d] 用户名</span><br>（useradd 用户名 -g 组名 -d 目录）</p>\n<ul>\n<li>g 指定用户的组，不写则组与用户名同</li>\n<li>d指定用户home目录位置</li>\n</ul>\n<h4 id=\"4-2-删除用户\"><a href=\"#4-2-删除用户\" class=\"headerlink\" title=\"4-2 删除用户\"></a>4-2 删除用户</h4><p><span id='userdel'>userdel [-r] 用户名</span></p>\n<ul>\n<li>r 删除home目录</li>\n</ul>\n<h4 id=\"4-3-查看用户所属组\"><a href=\"#4-3-查看用户所属组\" class=\"headerlink\" title=\"4-3 查看用户所属组 \"></a>4-3 查看用户所属组<span id='id'> </span></h4><p>id [用户名]</p>\n<h4 id=\"4-4-修改用户所属组\"><a href=\"#4-4-修改用户所属组\" class=\"headerlink\" title=\"4-4 修改用户所属组 \"></a>4-4 修改用户所属组<span id='usermod'> </span></h4><p>usermod -aG 组名 用户名</p>\n<h4 id=\"4-5-查看系统用户-组\"><a href=\"#4-5-查看系统用户-组\" class=\"headerlink\" title=\"4-5 查看系统用户(组)\"></a>4-5 查看系统用户(组)<span id='getent'></span></h4><p>getent passwd或group</p>\n<ul>\n<li>用户显示的信息：用户名:密码:用户组:描述信息:HOME目录:执行终端（默认bash)</li>\n<li>组显示信息：组名:组认证:组ID</li>\n</ul>\n<h3 id=\"5-权限\"><a href=\"#5-权限\" class=\"headerlink\" title=\"5 权限\"></a>5 权限</h3><h4 id=\"5-1-权限信息\"><a href=\"#5-1-权限信息\" class=\"headerlink\" title=\"5.1 权限信息\"></a>5.1 权限信息</h4><p><img src=\"/./img/linux/user/8.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\user\\8.png\"></p>\n<ul>\n<li><p>权限信息（序号1）</p>\n<p>总共10位：</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>所属用户权限</th>\n<th></th>\n<th></th>\n<th>所属用户组权限</th>\n<th></th>\n<th></th>\n<th>其他用户权限</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-&#x2F;d&#x2F;l</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n<td>r&#x2F;-</td>\n<td>w&#x2F;-</td>\n<td>x&#x2F;-</td>\n</tr>\n<tr>\n<td>-：文件<br>d：文件夹<br>l：软连接</td>\n<td>读</td>\n<td>写</td>\n<td>执行</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>对于文件夹：</p>\n<ul>\n<li>r：可ls里面的内容</li>\n<li>w：可以在里面创建、删除、改名</li>\n<li>x：可cd到此</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"5-2-修改权限\"><a href=\"#5-2-修改权限\" class=\"headerlink\" title=\"5.2 修改权限\"></a>5.2 <span id='chmod'>修改权限</span></h4><ul>\n<li><p>chmod命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> [-R] 权限 文件或文件夹</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-R：递归</p>\n</li>\n<li><p>例子：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> u=rwx,g=rx,o=x test.txt</span><br><span class=\"line\"><span class=\"built_in\">chmod</span> 751 test.txt</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"5-3-修改所属用户\"><a href=\"#5-3-修改所属用户\" class=\"headerlink\" title=\"5.3 修改所属用户\"></a>5.3 <span id='chown'>修改所属用户</span></h4><ul>\n<li>chown命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chown</span> [-R] [用户][:用户组] 文件或文件夹</span><br></pre></td></tr></table></figure>"},{"title":"Linux入门-3实用操作1","date":"2024-03-02T12:00:00.000Z","toc":true,"_content":"\n#\n\n<!--more-->\n\n# 3 Linux实用操作\n\n## 3.1 快捷键\n\n| 快捷键    | 说明                                   |\n| --------- | -------------------------------------- |\n| ctrl + c  | 停止程序<br>重新输入命令               |\n| ctrl + d  | 退出账户<br>退出程序界面               |\n| history   | 历史命令                               |\n| !命令前缀 | 执行上一次匹配前缀的命令               |\n| ctrl + r  | 搜索历史命令（回车执行，左右键不执行） |\n| ctrl + l  | 清空终端（clear）                      |\n\n| 移动光标  |              |\n| --------- | ------------ |\n| ctrl + a  | 跳到命令开头 |\n| ctrl + e  | 跳到命令结尾 |\n| ctrl + 左 | 左跳一个单词 |\n\n## 3.2 软件安装\n\n### 3.2.1 yum（centos）\n\n- RPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。相当于Linux应用商店\n\n```bash\nyum [-y] [install | remove |search] 软件名\n```\n\n| 选项    | 解释     |\n| ------- | -------- |\n| -y      | 自动确认 |\n| install | 安装     |\n| remove  | 卸载     |\n| search  | 搜索     |\n\n- ubuntu中用apt\n\n\n\n## 3.3 服务管理\n\n- systemctl命令\n\n```bash\nsystemctl start | stop | status | enable |disable 服务名\n```\n\n|                | 说明       |\n| -------------- | ---------- |\n| status         | 查看状态   |\n| enable         | 开机自启动 |\n| NetworkManager | 主网络服务 |\n| network        | 副网络服务 |\n| firewalld      | 防火墙服务 |\n| sshd，ssh      |            |\n\n- 部分软件安装后没有自动集成到systemctl中，我们可以手动添加  \n\n## 3.4 软链接\n\n- 类似快捷方式\n\n```bash\nln -s 起点 终点 \n```\n\n## 3.5 时间\n\n- date命令\n\n```bash\ndate [-d] [+格式化字符串]\n```\n\n| 格式 | 说明                               |\n| ---- | ---------------------------------- |\n| %Y   | 年                                 |\n| %y   | 两位数字的年                       |\n| %m   | 月                                 |\n| %d   | 日                                 |\n| %H   | 小时                               |\n| %M   | 分钟                               |\n| %S   | 秒                                 |\n| %s   | 从1970-01-01 0:0:0到现在过了多少秒 |\n\n​\t例子\n\n```bash\ndate \"+%Y-%m-%d %H:%M:%S\"\ndate -d \"+1day\" +%Y%m%d #后一天\n```\n\n- 修改时区\n\n```bash\nrm -f /etc/localtime #删除文件\nsudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #将该文件链接为localtime\n```\n\n- ntp程序\n\n  通过ntp程序自动校准时间\n\n```bash\nyum -y install ntp #安装\nsystemctl start ntpd #启动服务\nsystemctl enable ntpd #开机自启动\n```\n\n​\t\t手动校准\n\n```bash\nntpdate -u ntp.aliyun.com\n```\n\n","source":"_posts/linux/Linux_3.usage.md","raw":"---\ntitle: Linux入门-3实用操作1\ndate: 2024-03-02 20:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n---\n\n#\n\n<!--more-->\n\n# 3 Linux实用操作\n\n## 3.1 快捷键\n\n| 快捷键    | 说明                                   |\n| --------- | -------------------------------------- |\n| ctrl + c  | 停止程序<br>重新输入命令               |\n| ctrl + d  | 退出账户<br>退出程序界面               |\n| history   | 历史命令                               |\n| !命令前缀 | 执行上一次匹配前缀的命令               |\n| ctrl + r  | 搜索历史命令（回车执行，左右键不执行） |\n| ctrl + l  | 清空终端（clear）                      |\n\n| 移动光标  |              |\n| --------- | ------------ |\n| ctrl + a  | 跳到命令开头 |\n| ctrl + e  | 跳到命令结尾 |\n| ctrl + 左 | 左跳一个单词 |\n\n## 3.2 软件安装\n\n### 3.2.1 yum（centos）\n\n- RPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。相当于Linux应用商店\n\n```bash\nyum [-y] [install | remove |search] 软件名\n```\n\n| 选项    | 解释     |\n| ------- | -------- |\n| -y      | 自动确认 |\n| install | 安装     |\n| remove  | 卸载     |\n| search  | 搜索     |\n\n- ubuntu中用apt\n\n\n\n## 3.3 服务管理\n\n- systemctl命令\n\n```bash\nsystemctl start | stop | status | enable |disable 服务名\n```\n\n|                | 说明       |\n| -------------- | ---------- |\n| status         | 查看状态   |\n| enable         | 开机自启动 |\n| NetworkManager | 主网络服务 |\n| network        | 副网络服务 |\n| firewalld      | 防火墙服务 |\n| sshd，ssh      |            |\n\n- 部分软件安装后没有自动集成到systemctl中，我们可以手动添加  \n\n## 3.4 软链接\n\n- 类似快捷方式\n\n```bash\nln -s 起点 终点 \n```\n\n## 3.5 时间\n\n- date命令\n\n```bash\ndate [-d] [+格式化字符串]\n```\n\n| 格式 | 说明                               |\n| ---- | ---------------------------------- |\n| %Y   | 年                                 |\n| %y   | 两位数字的年                       |\n| %m   | 月                                 |\n| %d   | 日                                 |\n| %H   | 小时                               |\n| %M   | 分钟                               |\n| %S   | 秒                                 |\n| %s   | 从1970-01-01 0:0:0到现在过了多少秒 |\n\n​\t例子\n\n```bash\ndate \"+%Y-%m-%d %H:%M:%S\"\ndate -d \"+1day\" +%Y%m%d #后一天\n```\n\n- 修改时区\n\n```bash\nrm -f /etc/localtime #删除文件\nsudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #将该文件链接为localtime\n```\n\n- ntp程序\n\n  通过ntp程序自动校准时间\n\n```bash\nyum -y install ntp #安装\nsystemctl start ntpd #启动服务\nsystemctl enable ntpd #开机自启动\n```\n\n​\t\t手动校准\n\n```bash\nntpdate -u ntp.aliyun.com\n```\n\n","slug":"linux/Linux_3.usage","published":1,"updated":"2024-03-02T11:54:59.742Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clta2pf050005zovw7hhnb1r6","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-1-快捷键\"><a href=\"#3-1-快捷键\" class=\"headerlink\" title=\"3.1 快捷键\"></a>3.1 快捷键</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ctrl + c</td>\n<td>停止程序<br>重新输入命令</td>\n</tr>\n<tr>\n<td>ctrl + d</td>\n<td>退出账户<br>退出程序界面</td>\n</tr>\n<tr>\n<td>history</td>\n<td>历史命令</td>\n</tr>\n<tr>\n<td>!命令前缀</td>\n<td>执行上一次匹配前缀的命令</td>\n</tr>\n<tr>\n<td>ctrl + r</td>\n<td>搜索历史命令（回车执行，左右键不执行）</td>\n</tr>\n<tr>\n<td>ctrl + l</td>\n<td>清空终端（clear）</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>移动光标</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ctrl + a</td>\n<td>跳到命令开头</td>\n</tr>\n<tr>\n<td>ctrl + e</td>\n<td>跳到命令结尾</td>\n</tr>\n<tr>\n<td>ctrl + 左</td>\n<td>左跳一个单词</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-软件安装\"><a href=\"#3-2-软件安装\" class=\"headerlink\" title=\"3.2 软件安装\"></a>3.2 软件安装</h2><h3 id=\"3-2-1-yum（centos）\"><a href=\"#3-2-1-yum（centos）\" class=\"headerlink\" title=\"3.2.1 yum（centos）\"></a>3.2.1 yum（centos）</h3><ul>\n<li>RPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。相当于Linux应用商店</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum [-y] [install | remove |search] 软件名</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-y</td>\n<td>自动确认</td>\n</tr>\n<tr>\n<td>install</td>\n<td>安装</td>\n</tr>\n<tr>\n<td>remove</td>\n<td>卸载</td>\n</tr>\n<tr>\n<td>search</td>\n<td>搜索</td>\n</tr>\n</tbody></table>\n<ul>\n<li>ubuntu中用apt</li>\n</ul>\n<h2 id=\"3-3-服务管理\"><a href=\"#3-3-服务管理\" class=\"headerlink\" title=\"3.3 服务管理\"></a>3.3 服务管理</h2><ul>\n<li>systemctl命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start | stop | status | <span class=\"built_in\">enable</span> |<span class=\"built_in\">disable</span> 服务名</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th></th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>status</td>\n<td>查看状态</td>\n</tr>\n<tr>\n<td>enable</td>\n<td>开机自启动</td>\n</tr>\n<tr>\n<td>NetworkManager</td>\n<td>主网络服务</td>\n</tr>\n<tr>\n<td>network</td>\n<td>副网络服务</td>\n</tr>\n<tr>\n<td>firewalld</td>\n<td>防火墙服务</td>\n</tr>\n<tr>\n<td>sshd，ssh</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>部分软件安装后没有自动集成到systemctl中，我们可以手动添加</li>\n</ul>\n<h2 id=\"3-4-软链接\"><a href=\"#3-4-软链接\" class=\"headerlink\" title=\"3.4 软链接\"></a>3.4 软链接</h2><ul>\n<li>类似快捷方式</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">ln</span> -s 起点 终点 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-5-时间\"><a href=\"#3-5-时间\" class=\"headerlink\" title=\"3.5 时间\"></a>3.5 时间</h2><ul>\n<li>date命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">date</span> [-d] [+格式化字符串]</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>%Y</td>\n<td>年</td>\n</tr>\n<tr>\n<td>%y</td>\n<td>两位数字的年</td>\n</tr>\n<tr>\n<td>%m</td>\n<td>月</td>\n</tr>\n<tr>\n<td>%d</td>\n<td>日</td>\n</tr>\n<tr>\n<td>%H</td>\n<td>小时</td>\n</tr>\n<tr>\n<td>%M</td>\n<td>分钟</td>\n</tr>\n<tr>\n<td>%S</td>\n<td>秒</td>\n</tr>\n<tr>\n<td>%s</td>\n<td>从1970-01-01 0:0:0到现在过了多少秒</td>\n</tr>\n</tbody></table>\n<p>​\t例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">date</span> <span class=\"string\">&quot;+%Y-%m-%d %H:%M:%S&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">date</span> -d <span class=\"string\">&quot;+1day&quot;</span> +%Y%m%d <span class=\"comment\">#后一天</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>修改时区</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">rm</span> -f /etc/localtime <span class=\"comment\">#删除文件</span></span><br><span class=\"line\">sudo <span class=\"built_in\">ln</span> -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime <span class=\"comment\">#将该文件链接为localtime</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>ntp程序</p>\n<p>通过ntp程序自动校准时间</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install ntp <span class=\"comment\">#安装</span></span><br><span class=\"line\">systemctl start ntpd <span class=\"comment\">#启动服务</span></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> ntpd <span class=\"comment\">#开机自启动</span></span><br></pre></td></tr></table></figure>\n\n<p>​\t\t手动校准</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ntpdate -u ntp.aliyun.com</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-1-快捷键\"><a href=\"#3-1-快捷键\" class=\"headerlink\" title=\"3.1 快捷键\"></a>3.1 快捷键</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ctrl + c</td>\n<td>停止程序<br>重新输入命令</td>\n</tr>\n<tr>\n<td>ctrl + d</td>\n<td>退出账户<br>退出程序界面</td>\n</tr>\n<tr>\n<td>history</td>\n<td>历史命令</td>\n</tr>\n<tr>\n<td>!命令前缀</td>\n<td>执行上一次匹配前缀的命令</td>\n</tr>\n<tr>\n<td>ctrl + r</td>\n<td>搜索历史命令（回车执行，左右键不执行）</td>\n</tr>\n<tr>\n<td>ctrl + l</td>\n<td>清空终端（clear）</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>移动光标</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ctrl + a</td>\n<td>跳到命令开头</td>\n</tr>\n<tr>\n<td>ctrl + e</td>\n<td>跳到命令结尾</td>\n</tr>\n<tr>\n<td>ctrl + 左</td>\n<td>左跳一个单词</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-软件安装\"><a href=\"#3-2-软件安装\" class=\"headerlink\" title=\"3.2 软件安装\"></a>3.2 软件安装</h2><h3 id=\"3-2-1-yum（centos）\"><a href=\"#3-2-1-yum（centos）\" class=\"headerlink\" title=\"3.2.1 yum（centos）\"></a>3.2.1 yum（centos）</h3><ul>\n<li>RPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。相当于Linux应用商店</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum [-y] [install | remove |search] 软件名</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-y</td>\n<td>自动确认</td>\n</tr>\n<tr>\n<td>install</td>\n<td>安装</td>\n</tr>\n<tr>\n<td>remove</td>\n<td>卸载</td>\n</tr>\n<tr>\n<td>search</td>\n<td>搜索</td>\n</tr>\n</tbody></table>\n<ul>\n<li>ubuntu中用apt</li>\n</ul>\n<h2 id=\"3-3-服务管理\"><a href=\"#3-3-服务管理\" class=\"headerlink\" title=\"3.3 服务管理\"></a>3.3 服务管理</h2><ul>\n<li>systemctl命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start | stop | status | <span class=\"built_in\">enable</span> |<span class=\"built_in\">disable</span> 服务名</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th></th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>status</td>\n<td>查看状态</td>\n</tr>\n<tr>\n<td>enable</td>\n<td>开机自启动</td>\n</tr>\n<tr>\n<td>NetworkManager</td>\n<td>主网络服务</td>\n</tr>\n<tr>\n<td>network</td>\n<td>副网络服务</td>\n</tr>\n<tr>\n<td>firewalld</td>\n<td>防火墙服务</td>\n</tr>\n<tr>\n<td>sshd，ssh</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>部分软件安装后没有自动集成到systemctl中，我们可以手动添加</li>\n</ul>\n<h2 id=\"3-4-软链接\"><a href=\"#3-4-软链接\" class=\"headerlink\" title=\"3.4 软链接\"></a>3.4 软链接</h2><ul>\n<li>类似快捷方式</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">ln</span> -s 起点 终点 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-5-时间\"><a href=\"#3-5-时间\" class=\"headerlink\" title=\"3.5 时间\"></a>3.5 时间</h2><ul>\n<li>date命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">date</span> [-d] [+格式化字符串]</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>%Y</td>\n<td>年</td>\n</tr>\n<tr>\n<td>%y</td>\n<td>两位数字的年</td>\n</tr>\n<tr>\n<td>%m</td>\n<td>月</td>\n</tr>\n<tr>\n<td>%d</td>\n<td>日</td>\n</tr>\n<tr>\n<td>%H</td>\n<td>小时</td>\n</tr>\n<tr>\n<td>%M</td>\n<td>分钟</td>\n</tr>\n<tr>\n<td>%S</td>\n<td>秒</td>\n</tr>\n<tr>\n<td>%s</td>\n<td>从1970-01-01 0:0:0到现在过了多少秒</td>\n</tr>\n</tbody></table>\n<p>​\t例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">date</span> <span class=\"string\">&quot;+%Y-%m-%d %H:%M:%S&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">date</span> -d <span class=\"string\">&quot;+1day&quot;</span> +%Y%m%d <span class=\"comment\">#后一天</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>修改时区</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">rm</span> -f /etc/localtime <span class=\"comment\">#删除文件</span></span><br><span class=\"line\">sudo <span class=\"built_in\">ln</span> -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime <span class=\"comment\">#将该文件链接为localtime</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>ntp程序</p>\n<p>通过ntp程序自动校准时间</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install ntp <span class=\"comment\">#安装</span></span><br><span class=\"line\">systemctl start ntpd <span class=\"comment\">#启动服务</span></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> ntpd <span class=\"comment\">#开机自启动</span></span><br></pre></td></tr></table></figure>\n\n<p>​\t\t手动校准</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ntpdate -u ntp.aliyun.com</span><br></pre></td></tr></table></figure>"},{"title":"Linux入门-3使用操作2","date":"2024-03-02T13:00:00.000Z","toc":true,"_content":"\n#\n\n<!--more-->\n\n\n\n# 3 Linux实用操作\n\n## 3.6 ip与主机\n\n- 查看ip\n\n```bash\nifconfig #查看ip\nyum -y install net-tools #如果无法使用ifconfig\n```\n\n- 查看主机名\n\n```bash\nhostname #查看主机名\nhostnamectl set-hostname 主机名 #修改主机名\n```\n\n通过修改`     C:\\Windows\\System32\\drivers\\etc\\hosts  `（linux在`/etc/hosts`）中的配置就可以实现通过主机名访问-\n\n- 在VMware中设置固定ip\n\n  1. 在vmware中配置ip地址网关和网段\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\1.png)\n\n     ![](img/linux/usage/1.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\2.png)\n\n     ![](img/linux/usage/2.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\3.png)\n\n     ![](img/linux/usage/3.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\4.png)\n\n     ![](img/linux/usage/4.png)\n\n  2. 在linux中手动修改配置文件\n\n     ```bash\n     vim /etc/sysconfig/network-scripts/ifcfg-ens33\n     ```\n\n     做如下修改：\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\5.png)\n\n     ![](img/linux/usage/5.png)\n\n     ```bash\n     systemctl restart network #重启网卡\n     ```\n\n## 3.7 网络传输\n\n  - ping命令\n\n    ```bash\n    ping [-c 数字] ip或主机名 #检查指定服务器是否可联通\n    ```\n\n    - -c：检查次数\n\n  - wget命令\n\n    ```bash\n    wget [-b] url #文件下载\n    tail -f wget-log #监控后台下载进度\n    ```\n\n    - -b：后台下载，会将日志写入当前工作目录的wget-log文件\n\n    - 如果下载未完成，请及时清理未完成的不可用文件\n\n  - curl命令\n\n    发送http网络请求，可用于下载文件、获取信息等\n\n    ```bash\n    curl [-O] url\n    ```\n\n    - -O：下载文件\n\n  - 端口\n\n    | 端口        | 作用                              |\n    | ----------- | --------------------------------- |\n    | 1~1023      | 公认端口                          |\n    | 1024~49151  | 注册端口，松散的绑定一些程序\\服务 |\n    | 49152~65535 | 不绑定固定程序，临时使用          |\n    |             |                                   |\n\n    - 查看端口占用\n\n      - nmap命令\n\n        ```bash\n        yum -y install nmap #安装nmap\n        nmap ip #查看端口占用\n        ```\n\n      - netstat命令\n\n        ```bash\n        yum -y install net-tools #安装netstat\n        netstat -anp | grep 端口号 #查看端口被谁占用\n        ```\n\n## 3.8 进程管理\n\n- 查看进程\n\n  ```bash\n  ps [-e -f] #查看进程信息\n  ```\n\n  - 例子\n\n    ```bash\n    ps -ef | grep tail #查找tail命令的进程信息\n    ```\n\n    \n\n  - -e：全部进程\n\n  - -f：以完全格式化的形式展示信息\n\n    | 列名  | 解释                                          |\n    | ----- | --------------------------------------------- |\n    | UID   | 用户ID                                        |\n    | PID   | 进程号                                        |\n    | PPID  | 父进程                                        |\n    | C     | cpu占用率                                     |\n    | STIME | 启动时间                                      |\n    | TTY   | 启动此进程的终端序号，如显示?，表示非终端启动 |\n    | TIME  | 占用cup时间                                   |\n    | CMD   | 进程名<br>启动路径<br>启动命令                |\n\n  - 关闭进程\n\n    ```bash\n    kill [-9] 进程ID #关闭进程\n    ```\n\n    - -9：强制关闭，不询问进程\n\n  \n\n## 3.9 主机状态\n\n- 查看系统资源占用\n\n  ```bash\n  top [-p -d -c -n -b -i -u] #查看系统资源占用\n  ```\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\6.png)\n\n  ![](img/linux/usage/6.png)\n\n  | 行   | 解释                                                         |\n  | ---- | ------------------------------------------------------------ |\n  | 1    | 时间<br>up：启动了6分钟<br>users：2个用户登录<br>load：1、5、15分钟负载 |\n  | 2    | tasks：175个进程<br>running：1个进程在运行<br>sleeping：174个在睡眠<brL>0个停止进行，0个僵尸进程 |\n  | 3    | cpu：cpu使用率<br>us：用户cpu使用率<br>sy：系统cpu使用率<br>ni：高优先级进程占用CPU时间百分比<br>id：空闲CPU率<br>wa：IO等待CPU占用率<br>hi：CPU硬件中断率<br>si：CPU软件中断率<br>st：强制等待占用CPU率 |\n  | 4    | Kib Mem：物理内存<br>total：总量<br>free：空闲<br/>used：使用<br/>buff/cache：buff和cache占用 |\n  | 5    | KibSwap：虚拟内存（交换空间）<br/>total：总量<br/>free：空闲<br/>used：使用<br/>buff/cache：buff和cache占用 |\n  | 6    | PR：进程优先级，越小越高<br>NI：负值表示高优先级，正表示低优先级<br>VIRT：进程使用虚拟内存，单位KB<br>RES：进程使用物理内存，单位KB<br/>SHR：进程使用共享内存，单位KB<br/>S：进程状态（S休眠，R运行，Z僵死状态，N负数优先级，I空闲状态）<br/>%MEM：进程占用内存率<br/>TIME+：进程使用CPU时间总计，单位10毫秒<br/>COMMAND：进程的命令或名称或程序文件路径 |\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\7.png)\n\n  ![](img/linux/usage/7.png)\n\n  - 在top界面下：\n\n    ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\8.png)\n\n    ![](img/linux/usage/8.png)\n\n- 磁盘信息监控\n\n  - df命令查看磁盘使用\n\n    ```bash\n    df [-h]\n    ```\n\n    - -h显示单位\n\n  - iostat查看cpu、磁盘信息\n\n    ```bash\n    iostat [-x][数字1][数字2]\n    ```\n\n    - -x：显示更多信息\n\n    - 数字1：刷新间隔\n\n    - 数字2：刷新次数\n\n      ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\9.png)\n\n      ![](img/linux/usage/9.png)\n\n      - rrqm/s： 每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge, 提高IO利用率, 避免重复调用）；\n\n      - wrqm/s： 每秒这个设备相关的写入请求有多少被Merge了。\n\n      - rsec/s： 每秒读取的扇区数；sectors\n\n      - wsec/： 每秒写入的扇区数。\n\n      - rKB/s： 每秒发送到设备的读取请求数\n\n      - wKB/s： 每秒发送到设备的写入请求数\n\n      - avgrq-sz  平均请求扇区的大小\n\n      - avgqu-sz  平均请求队列的长度。毫无疑问，队列长度越短越好。  \n\n      - await：  每一个IO请求的处理的平均时间（单位是微秒毫秒）。\n\n      - svctm   表示平均每次设备I/O操作的服务时间（以毫秒为单位）\n\n      - %util：  磁盘利用率\n\n- 网络状态监控\n\n  ```bash\n  sar -n DEV 数字1 数字2\n  ```\n\n  - -n：查看网络\n\n  - DEV：查看网络接口\n\n  - 数字1：刷新间隔\n\n  - 数字2：查看次数\n\n    ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\10.png)\n\n    ![](img/linux/usage/10.png)\n\n    - IFACE 本地网卡接口的名称\n\n    - rxpck/s 每秒钟接受的数据包\n\n    - txpck/s 每秒钟发送的数据包\n\n    - rxKB/S 每秒钟接受的数据包大小，单位为KB\n\n    - txKB/S 每秒钟发送的数据包大小，单位为KB\n\n    - rxcmp/s 每秒钟接受的压缩数据包\n\n    - txcmp/s 每秒钟发送的压缩包\n\n    - rxmcst/s 每秒钟接收的多播数据包","source":"_posts/linux/Linux_4.usage2.md","raw":"---\ntitle: Linux入门-3使用操作2\ndate: 2024-03-02 21:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n---\n\n#\n\n<!--more-->\n\n\n\n# 3 Linux实用操作\n\n## 3.6 ip与主机\n\n- 查看ip\n\n```bash\nifconfig #查看ip\nyum -y install net-tools #如果无法使用ifconfig\n```\n\n- 查看主机名\n\n```bash\nhostname #查看主机名\nhostnamectl set-hostname 主机名 #修改主机名\n```\n\n通过修改`     C:\\Windows\\System32\\drivers\\etc\\hosts  `（linux在`/etc/hosts`）中的配置就可以实现通过主机名访问-\n\n- 在VMware中设置固定ip\n\n  1. 在vmware中配置ip地址网关和网段\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\1.png)\n\n     ![](img/linux/usage/1.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\2.png)\n\n     ![](img/linux/usage/2.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\3.png)\n\n     ![](img/linux/usage/3.png)\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\4.png)\n\n     ![](img/linux/usage/4.png)\n\n  2. 在linux中手动修改配置文件\n\n     ```bash\n     vim /etc/sysconfig/network-scripts/ifcfg-ens33\n     ```\n\n     做如下修改：\n\n     ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\5.png)\n\n     ![](img/linux/usage/5.png)\n\n     ```bash\n     systemctl restart network #重启网卡\n     ```\n\n## 3.7 网络传输\n\n  - ping命令\n\n    ```bash\n    ping [-c 数字] ip或主机名 #检查指定服务器是否可联通\n    ```\n\n    - -c：检查次数\n\n  - wget命令\n\n    ```bash\n    wget [-b] url #文件下载\n    tail -f wget-log #监控后台下载进度\n    ```\n\n    - -b：后台下载，会将日志写入当前工作目录的wget-log文件\n\n    - 如果下载未完成，请及时清理未完成的不可用文件\n\n  - curl命令\n\n    发送http网络请求，可用于下载文件、获取信息等\n\n    ```bash\n    curl [-O] url\n    ```\n\n    - -O：下载文件\n\n  - 端口\n\n    | 端口        | 作用                              |\n    | ----------- | --------------------------------- |\n    | 1~1023      | 公认端口                          |\n    | 1024~49151  | 注册端口，松散的绑定一些程序\\服务 |\n    | 49152~65535 | 不绑定固定程序，临时使用          |\n    |             |                                   |\n\n    - 查看端口占用\n\n      - nmap命令\n\n        ```bash\n        yum -y install nmap #安装nmap\n        nmap ip #查看端口占用\n        ```\n\n      - netstat命令\n\n        ```bash\n        yum -y install net-tools #安装netstat\n        netstat -anp | grep 端口号 #查看端口被谁占用\n        ```\n\n## 3.8 进程管理\n\n- 查看进程\n\n  ```bash\n  ps [-e -f] #查看进程信息\n  ```\n\n  - 例子\n\n    ```bash\n    ps -ef | grep tail #查找tail命令的进程信息\n    ```\n\n    \n\n  - -e：全部进程\n\n  - -f：以完全格式化的形式展示信息\n\n    | 列名  | 解释                                          |\n    | ----- | --------------------------------------------- |\n    | UID   | 用户ID                                        |\n    | PID   | 进程号                                        |\n    | PPID  | 父进程                                        |\n    | C     | cpu占用率                                     |\n    | STIME | 启动时间                                      |\n    | TTY   | 启动此进程的终端序号，如显示?，表示非终端启动 |\n    | TIME  | 占用cup时间                                   |\n    | CMD   | 进程名<br>启动路径<br>启动命令                |\n\n  - 关闭进程\n\n    ```bash\n    kill [-9] 进程ID #关闭进程\n    ```\n\n    - -9：强制关闭，不询问进程\n\n  \n\n## 3.9 主机状态\n\n- 查看系统资源占用\n\n  ```bash\n  top [-p -d -c -n -b -i -u] #查看系统资源占用\n  ```\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\6.png)\n\n  ![](img/linux/usage/6.png)\n\n  | 行   | 解释                                                         |\n  | ---- | ------------------------------------------------------------ |\n  | 1    | 时间<br>up：启动了6分钟<br>users：2个用户登录<br>load：1、5、15分钟负载 |\n  | 2    | tasks：175个进程<br>running：1个进程在运行<br>sleeping：174个在睡眠<brL>0个停止进行，0个僵尸进程 |\n  | 3    | cpu：cpu使用率<br>us：用户cpu使用率<br>sy：系统cpu使用率<br>ni：高优先级进程占用CPU时间百分比<br>id：空闲CPU率<br>wa：IO等待CPU占用率<br>hi：CPU硬件中断率<br>si：CPU软件中断率<br>st：强制等待占用CPU率 |\n  | 4    | Kib Mem：物理内存<br>total：总量<br>free：空闲<br/>used：使用<br/>buff/cache：buff和cache占用 |\n  | 5    | KibSwap：虚拟内存（交换空间）<br/>total：总量<br/>free：空闲<br/>used：使用<br/>buff/cache：buff和cache占用 |\n  | 6    | PR：进程优先级，越小越高<br>NI：负值表示高优先级，正表示低优先级<br>VIRT：进程使用虚拟内存，单位KB<br>RES：进程使用物理内存，单位KB<br/>SHR：进程使用共享内存，单位KB<br/>S：进程状态（S休眠，R运行，Z僵死状态，N负数优先级，I空闲状态）<br/>%MEM：进程占用内存率<br/>TIME+：进程使用CPU时间总计，单位10毫秒<br/>COMMAND：进程的命令或名称或程序文件路径 |\n\n  ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\7.png)\n\n  ![](img/linux/usage/7.png)\n\n  - 在top界面下：\n\n    ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\8.png)\n\n    ![](img/linux/usage/8.png)\n\n- 磁盘信息监控\n\n  - df命令查看磁盘使用\n\n    ```bash\n    df [-h]\n    ```\n\n    - -h显示单位\n\n  - iostat查看cpu、磁盘信息\n\n    ```bash\n    iostat [-x][数字1][数字2]\n    ```\n\n    - -x：显示更多信息\n\n    - 数字1：刷新间隔\n\n    - 数字2：刷新次数\n\n      ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\9.png)\n\n      ![](img/linux/usage/9.png)\n\n      - rrqm/s： 每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge, 提高IO利用率, 避免重复调用）；\n\n      - wrqm/s： 每秒这个设备相关的写入请求有多少被Merge了。\n\n      - rsec/s： 每秒读取的扇区数；sectors\n\n      - wsec/： 每秒写入的扇区数。\n\n      - rKB/s： 每秒发送到设备的读取请求数\n\n      - wKB/s： 每秒发送到设备的写入请求数\n\n      - avgrq-sz  平均请求扇区的大小\n\n      - avgqu-sz  平均请求队列的长度。毫无疑问，队列长度越短越好。  \n\n      - await：  每一个IO请求的处理的平均时间（单位是微秒毫秒）。\n\n      - svctm   表示平均每次设备I/O操作的服务时间（以毫秒为单位）\n\n      - %util：  磁盘利用率\n\n- 网络状态监控\n\n  ```bash\n  sar -n DEV 数字1 数字2\n  ```\n\n  - -n：查看网络\n\n  - DEV：查看网络接口\n\n  - 数字1：刷新间隔\n\n  - 数字2：查看次数\n\n    ![](D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\10.png)\n\n    ![](img/linux/usage/10.png)\n\n    - IFACE 本地网卡接口的名称\n\n    - rxpck/s 每秒钟接受的数据包\n\n    - txpck/s 每秒钟发送的数据包\n\n    - rxKB/S 每秒钟接受的数据包大小，单位为KB\n\n    - txKB/S 每秒钟发送的数据包大小，单位为KB\n\n    - rxcmp/s 每秒钟接受的压缩数据包\n\n    - txcmp/s 每秒钟发送的压缩包\n\n    - rxmcst/s 每秒钟接收的多播数据包","slug":"linux/Linux_4.usage2","published":1,"updated":"2024-03-02T12:47:26.719Z","_id":"clta2pf060008zovw0duzbzc8","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-6-ip与主机\"><a href=\"#3-6-ip与主机\" class=\"headerlink\" title=\"3.6 ip与主机\"></a>3.6 ip与主机</h2><ul>\n<li>查看ip</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ifconfig <span class=\"comment\">#查看ip</span></span><br><span class=\"line\">yum -y install net-tools <span class=\"comment\">#如果无法使用ifconfig</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>查看主机名</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname <span class=\"comment\">#查看主机名</span></span><br><span class=\"line\">hostnamectl set-hostname 主机名 <span class=\"comment\">#修改主机名</span></span><br></pre></td></tr></table></figure>\n\n<p>通过修改<code>    C:\\Windows\\System32\\drivers\\etc\\hosts </code>（linux在<code>/etc/hosts</code>）中的配置就可以实现通过主机名访问-</p>\n<ul>\n<li><p>在VMware中设置固定ip</p>\n<ol>\n<li><p>在vmware中配置ip地址网关和网段</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\1.png\"></p>\n<p><img src=\"/img/linux/usage/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\2.png\"></p>\n<p><img src=\"/img/linux/usage/2.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\3.png\"></p>\n<p><img src=\"/img/linux/usage/3.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\4.png\"></p>\n<p><img src=\"/img/linux/usage/4.png\"></p>\n</li>\n<li><p>在linux中手动修改配置文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>\n\n<p>做如下修改：</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\5.png\"></p>\n<p><img src=\"/img/linux/usage/5.png\"></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart network <span class=\"comment\">#重启网卡</span></span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n</ul>\n<h2 id=\"3-7-网络传输\"><a href=\"#3-7-网络传输\" class=\"headerlink\" title=\"3.7 网络传输\"></a>3.7 网络传输</h2><ul>\n<li><p>ping命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ping [-c 数字] ip或主机名 <span class=\"comment\">#检查指定服务器是否可联通</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-c：检查次数</li>\n</ul>\n</li>\n<li><p>wget命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget [-b] url <span class=\"comment\">#文件下载</span></span><br><span class=\"line\"><span class=\"built_in\">tail</span> -f wget-log <span class=\"comment\">#监控后台下载进度</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-b：后台下载，会将日志写入当前工作目录的wget-log文件</p>\n</li>\n<li><p>如果下载未完成，请及时清理未完成的不可用文件</p>\n</li>\n</ul>\n</li>\n<li><p>curl命令</p>\n<p>发送http网络请求，可用于下载文件、获取信息等</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl [-O] url</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-O：下载文件</li>\n</ul>\n</li>\n<li><p>端口</p>\n<table>\n<thead>\n<tr>\n<th>端口</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1~1023</td>\n<td>公认端口</td>\n</tr>\n<tr>\n<td>1024~49151</td>\n<td>注册端口，松散的绑定一些程序\\服务</td>\n</tr>\n<tr>\n<td>49152~65535</td>\n<td>不绑定固定程序，临时使用</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>查看端口占用</p>\n<ul>\n<li><p>nmap命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install nmap <span class=\"comment\">#安装nmap</span></span><br><span class=\"line\">nmap ip <span class=\"comment\">#查看端口占用</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>netstat命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install net-tools <span class=\"comment\">#安装netstat</span></span><br><span class=\"line\">netstat -anp | grep 端口号 <span class=\"comment\">#查看端口被谁占用</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-8-进程管理\"><a href=\"#3-8-进程管理\" class=\"headerlink\" title=\"3.8 进程管理\"></a>3.8 进程管理</h2><ul>\n<li><p>查看进程</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps [-e -f] <span class=\"comment\">#查看进程信息</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef | grep <span class=\"built_in\">tail</span> <span class=\"comment\">#查找tail命令的进程信息</span></span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>-e：全部进程</p>\n</li>\n<li><p>-f：以完全格式化的形式展示信息</p>\n<table>\n<thead>\n<tr>\n<th>列名</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>UID</td>\n<td>用户ID</td>\n</tr>\n<tr>\n<td>PID</td>\n<td>进程号</td>\n</tr>\n<tr>\n<td>PPID</td>\n<td>父进程</td>\n</tr>\n<tr>\n<td>C</td>\n<td>cpu占用率</td>\n</tr>\n<tr>\n<td>STIME</td>\n<td>启动时间</td>\n</tr>\n<tr>\n<td>TTY</td>\n<td>启动此进程的终端序号，如显示?，表示非终端启动</td>\n</tr>\n<tr>\n<td>TIME</td>\n<td>占用cup时间</td>\n</tr>\n<tr>\n<td>CMD</td>\n<td>进程名<br>启动路径<br>启动命令</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>关闭进程</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">kill</span> [-9] 进程ID <span class=\"comment\">#关闭进程</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-9：强制关闭，不询问进程</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-9-主机状态\"><a href=\"#3-9-主机状态\" class=\"headerlink\" title=\"3.9 主机状态\"></a>3.9 主机状态</h2><ul>\n<li><p>查看系统资源占用</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top [-p -d -c -n -b -i -u] <span class=\"comment\">#查看系统资源占用</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\6.png\"></p>\n<p><img src=\"/img/linux/usage/6.png\"></p>\n<table>\n<thead>\n<tr>\n<th>行</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>时间<br>up：启动了6分钟<br>users：2个用户登录<br>load：1、5、15分钟负载</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tasks：175个进程<br>running：1个进程在运行<br>sleeping：174个在睡眠<brL>0个停止进行，0个僵尸进程</td>\n</tr>\n<tr>\n<td>3</td>\n<td>cpu：cpu使用率<br>us：用户cpu使用率<br>sy：系统cpu使用率<br>ni：高优先级进程占用CPU时间百分比<br>id：空闲CPU率<br>wa：IO等待CPU占用率<br>hi：CPU硬件中断率<br>si：CPU软件中断率<br>st：强制等待占用CPU率</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Kib Mem：物理内存<br>total：总量<br>free：空闲<br/>used：使用<br/>buff&#x2F;cache：buff和cache占用</td>\n</tr>\n<tr>\n<td>5</td>\n<td>KibSwap：虚拟内存（交换空间）<br/>total：总量<br/>free：空闲<br/>used：使用<br/>buff&#x2F;cache：buff和cache占用</td>\n</tr>\n<tr>\n<td>6</td>\n<td>PR：进程优先级，越小越高<br>NI：负值表示高优先级，正表示低优先级<br>VIRT：进程使用虚拟内存，单位KB<br>RES：进程使用物理内存，单位KB<br/>SHR：进程使用共享内存，单位KB<br/>S：进程状态（S休眠，R运行，Z僵死状态，N负数优先级，I空闲状态）<br/>%MEM：进程占用内存率<br/>TIME+：进程使用CPU时间总计，单位10毫秒<br/>COMMAND：进程的命令或名称或程序文件路径</td>\n</tr>\n</tbody></table>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\7.png\"></p>\n<p><img src=\"/img/linux/usage/7.png\"></p>\n<ul>\n<li><p>在top界面下：</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\8.png\"></p>\n<p><img src=\"/img/linux/usage/8.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>磁盘信息监控</p>\n<ul>\n<li><p>df命令查看磁盘使用</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">df</span> [-h]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-h显示单位</li>\n</ul>\n</li>\n<li><p>iostat查看cpu、磁盘信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat [-x][数字1][数字2]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-x：显示更多信息</p>\n</li>\n<li><p>数字1：刷新间隔</p>\n</li>\n<li><p>数字2：刷新次数</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\9.png\"></p>\n<p><img src=\"/img/linux/usage/9.png\"></p>\n<ul>\n<li><p>rrqm&#x2F;s： 每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge, 提高IO利用率, 避免重复调用）；</p>\n</li>\n<li><p>wrqm&#x2F;s： 每秒这个设备相关的写入请求有多少被Merge了。</p>\n</li>\n<li><p>rsec&#x2F;s： 每秒读取的扇区数；sectors</p>\n</li>\n<li><p>wsec&#x2F;： 每秒写入的扇区数。</p>\n</li>\n<li><p>rKB&#x2F;s： 每秒发送到设备的读取请求数</p>\n</li>\n<li><p>wKB&#x2F;s： 每秒发送到设备的写入请求数</p>\n</li>\n<li><p>avgrq-sz  平均请求扇区的大小</p>\n</li>\n<li><p>avgqu-sz  平均请求队列的长度。毫无疑问，队列长度越短越好。  </p>\n</li>\n<li><p>await：  每一个IO请求的处理的平均时间（单位是微秒毫秒）。</p>\n</li>\n<li><p>svctm   表示平均每次设备I&#x2F;O操作的服务时间（以毫秒为单位）</p>\n</li>\n<li><p>%util：  磁盘利用率</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>网络状态监控</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sar -n DEV 数字1 数字2</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-n：查看网络</p>\n</li>\n<li><p>DEV：查看网络接口</p>\n</li>\n<li><p>数字1：刷新间隔</p>\n</li>\n<li><p>数字2：查看次数</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\10.png\"></p>\n<p><img src=\"/img/linux/usage/10.png\"></p>\n<ul>\n<li><p>IFACE 本地网卡接口的名称</p>\n</li>\n<li><p>rxpck&#x2F;s 每秒钟接受的数据包</p>\n</li>\n<li><p>txpck&#x2F;s 每秒钟发送的数据包</p>\n</li>\n<li><p>rxKB&#x2F;S 每秒钟接受的数据包大小，单位为KB</p>\n</li>\n<li><p>txKB&#x2F;S 每秒钟发送的数据包大小，单位为KB</p>\n</li>\n<li><p>rxcmp&#x2F;s 每秒钟接受的压缩数据包</p>\n</li>\n<li><p>txcmp&#x2F;s 每秒钟发送的压缩包</p>\n</li>\n<li><p>rxmcst&#x2F;s 每秒钟接收的多播数据包</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-6-ip与主机\"><a href=\"#3-6-ip与主机\" class=\"headerlink\" title=\"3.6 ip与主机\"></a>3.6 ip与主机</h2><ul>\n<li>查看ip</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ifconfig <span class=\"comment\">#查看ip</span></span><br><span class=\"line\">yum -y install net-tools <span class=\"comment\">#如果无法使用ifconfig</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>查看主机名</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname <span class=\"comment\">#查看主机名</span></span><br><span class=\"line\">hostnamectl set-hostname 主机名 <span class=\"comment\">#修改主机名</span></span><br></pre></td></tr></table></figure>\n\n<p>通过修改<code>    C:\\Windows\\System32\\drivers\\etc\\hosts </code>（linux在<code>/etc/hosts</code>）中的配置就可以实现通过主机名访问-</p>\n<ul>\n<li><p>在VMware中设置固定ip</p>\n<ol>\n<li><p>在vmware中配置ip地址网关和网段</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\1.png\"></p>\n<p><img src=\"/img/linux/usage/1.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\2.png\"></p>\n<p><img src=\"/img/linux/usage/2.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\3.png\"></p>\n<p><img src=\"/img/linux/usage/3.png\"></p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\4.png\"></p>\n<p><img src=\"/img/linux/usage/4.png\"></p>\n</li>\n<li><p>在linux中手动修改配置文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>\n\n<p>做如下修改：</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\5.png\"></p>\n<p><img src=\"/img/linux/usage/5.png\"></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart network <span class=\"comment\">#重启网卡</span></span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n</ul>\n<h2 id=\"3-7-网络传输\"><a href=\"#3-7-网络传输\" class=\"headerlink\" title=\"3.7 网络传输\"></a>3.7 网络传输</h2><ul>\n<li><p>ping命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ping [-c 数字] ip或主机名 <span class=\"comment\">#检查指定服务器是否可联通</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-c：检查次数</li>\n</ul>\n</li>\n<li><p>wget命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget [-b] url <span class=\"comment\">#文件下载</span></span><br><span class=\"line\"><span class=\"built_in\">tail</span> -f wget-log <span class=\"comment\">#监控后台下载进度</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-b：后台下载，会将日志写入当前工作目录的wget-log文件</p>\n</li>\n<li><p>如果下载未完成，请及时清理未完成的不可用文件</p>\n</li>\n</ul>\n</li>\n<li><p>curl命令</p>\n<p>发送http网络请求，可用于下载文件、获取信息等</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl [-O] url</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-O：下载文件</li>\n</ul>\n</li>\n<li><p>端口</p>\n<table>\n<thead>\n<tr>\n<th>端口</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1~1023</td>\n<td>公认端口</td>\n</tr>\n<tr>\n<td>1024~49151</td>\n<td>注册端口，松散的绑定一些程序\\服务</td>\n</tr>\n<tr>\n<td>49152~65535</td>\n<td>不绑定固定程序，临时使用</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>查看端口占用</p>\n<ul>\n<li><p>nmap命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install nmap <span class=\"comment\">#安装nmap</span></span><br><span class=\"line\">nmap ip <span class=\"comment\">#查看端口占用</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>netstat命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install net-tools <span class=\"comment\">#安装netstat</span></span><br><span class=\"line\">netstat -anp | grep 端口号 <span class=\"comment\">#查看端口被谁占用</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-8-进程管理\"><a href=\"#3-8-进程管理\" class=\"headerlink\" title=\"3.8 进程管理\"></a>3.8 进程管理</h2><ul>\n<li><p>查看进程</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps [-e -f] <span class=\"comment\">#查看进程信息</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef | grep <span class=\"built_in\">tail</span> <span class=\"comment\">#查找tail命令的进程信息</span></span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>-e：全部进程</p>\n</li>\n<li><p>-f：以完全格式化的形式展示信息</p>\n<table>\n<thead>\n<tr>\n<th>列名</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>UID</td>\n<td>用户ID</td>\n</tr>\n<tr>\n<td>PID</td>\n<td>进程号</td>\n</tr>\n<tr>\n<td>PPID</td>\n<td>父进程</td>\n</tr>\n<tr>\n<td>C</td>\n<td>cpu占用率</td>\n</tr>\n<tr>\n<td>STIME</td>\n<td>启动时间</td>\n</tr>\n<tr>\n<td>TTY</td>\n<td>启动此进程的终端序号，如显示?，表示非终端启动</td>\n</tr>\n<tr>\n<td>TIME</td>\n<td>占用cup时间</td>\n</tr>\n<tr>\n<td>CMD</td>\n<td>进程名<br>启动路径<br>启动命令</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>关闭进程</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">kill</span> [-9] 进程ID <span class=\"comment\">#关闭进程</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-9：强制关闭，不询问进程</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-9-主机状态\"><a href=\"#3-9-主机状态\" class=\"headerlink\" title=\"3.9 主机状态\"></a>3.9 主机状态</h2><ul>\n<li><p>查看系统资源占用</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top [-p -d -c -n -b -i -u] <span class=\"comment\">#查看系统资源占用</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\6.png\"></p>\n<p><img src=\"/img/linux/usage/6.png\"></p>\n<table>\n<thead>\n<tr>\n<th>行</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>时间<br>up：启动了6分钟<br>users：2个用户登录<br>load：1、5、15分钟负载</td>\n</tr>\n<tr>\n<td>2</td>\n<td>tasks：175个进程<br>running：1个进程在运行<br>sleeping：174个在睡眠<brL>0个停止进行，0个僵尸进程</td>\n</tr>\n<tr>\n<td>3</td>\n<td>cpu：cpu使用率<br>us：用户cpu使用率<br>sy：系统cpu使用率<br>ni：高优先级进程占用CPU时间百分比<br>id：空闲CPU率<br>wa：IO等待CPU占用率<br>hi：CPU硬件中断率<br>si：CPU软件中断率<br>st：强制等待占用CPU率</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Kib Mem：物理内存<br>total：总量<br>free：空闲<br/>used：使用<br/>buff&#x2F;cache：buff和cache占用</td>\n</tr>\n<tr>\n<td>5</td>\n<td>KibSwap：虚拟内存（交换空间）<br/>total：总量<br/>free：空闲<br/>used：使用<br/>buff&#x2F;cache：buff和cache占用</td>\n</tr>\n<tr>\n<td>6</td>\n<td>PR：进程优先级，越小越高<br>NI：负值表示高优先级，正表示低优先级<br>VIRT：进程使用虚拟内存，单位KB<br>RES：进程使用物理内存，单位KB<br/>SHR：进程使用共享内存，单位KB<br/>S：进程状态（S休眠，R运行，Z僵死状态，N负数优先级，I空闲状态）<br/>%MEM：进程占用内存率<br/>TIME+：进程使用CPU时间总计，单位10毫秒<br/>COMMAND：进程的命令或名称或程序文件路径</td>\n</tr>\n</tbody></table>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\7.png\"></p>\n<p><img src=\"/img/linux/usage/7.png\"></p>\n<ul>\n<li><p>在top界面下：</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\8.png\"></p>\n<p><img src=\"/img/linux/usage/8.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>磁盘信息监控</p>\n<ul>\n<li><p>df命令查看磁盘使用</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">df</span> [-h]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-h显示单位</li>\n</ul>\n</li>\n<li><p>iostat查看cpu、磁盘信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat [-x][数字1][数字2]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-x：显示更多信息</p>\n</li>\n<li><p>数字1：刷新间隔</p>\n</li>\n<li><p>数字2：刷新次数</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\9.png\"></p>\n<p><img src=\"/img/linux/usage/9.png\"></p>\n<ul>\n<li><p>rrqm&#x2F;s： 每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge, 提高IO利用率, 避免重复调用）；</p>\n</li>\n<li><p>wrqm&#x2F;s： 每秒这个设备相关的写入请求有多少被Merge了。</p>\n</li>\n<li><p>rsec&#x2F;s： 每秒读取的扇区数；sectors</p>\n</li>\n<li><p>wsec&#x2F;： 每秒写入的扇区数。</p>\n</li>\n<li><p>rKB&#x2F;s： 每秒发送到设备的读取请求数</p>\n</li>\n<li><p>wKB&#x2F;s： 每秒发送到设备的写入请求数</p>\n</li>\n<li><p>avgrq-sz  平均请求扇区的大小</p>\n</li>\n<li><p>avgqu-sz  平均请求队列的长度。毫无疑问，队列长度越短越好。  </p>\n</li>\n<li><p>await：  每一个IO请求的处理的平均时间（单位是微秒毫秒）。</p>\n</li>\n<li><p>svctm   表示平均每次设备I&#x2F;O操作的服务时间（以毫秒为单位）</p>\n</li>\n<li><p>%util：  磁盘利用率</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>网络状态监控</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sar -n DEV 数字1 数字2</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>-n：查看网络</p>\n</li>\n<li><p>DEV：查看网络接口</p>\n</li>\n<li><p>数字1：刷新间隔</p>\n</li>\n<li><p>数字2：查看次数</p>\n<p><img src=\"D:\\blog\\themes\\yilia\\source\\img\\linux\\usage\\10.png\"></p>\n<p><img src=\"/img/linux/usage/10.png\"></p>\n<ul>\n<li><p>IFACE 本地网卡接口的名称</p>\n</li>\n<li><p>rxpck&#x2F;s 每秒钟接受的数据包</p>\n</li>\n<li><p>txpck&#x2F;s 每秒钟发送的数据包</p>\n</li>\n<li><p>rxKB&#x2F;S 每秒钟接受的数据包大小，单位为KB</p>\n</li>\n<li><p>txKB&#x2F;S 每秒钟发送的数据包大小，单位为KB</p>\n</li>\n<li><p>rxcmp&#x2F;s 每秒钟接受的压缩数据包</p>\n</li>\n<li><p>txcmp&#x2F;s 每秒钟发送的压缩包</p>\n</li>\n<li><p>rxmcst&#x2F;s 每秒钟接收的多播数据包</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>"},{"title":"Linux入门-3使用操作3","date":"2024-03-02T14:00:00.000Z","toc":true,"_content":"\n#\n\n<!--more-->\n\n# 3 Linux实用操作\n\n## 3.9 环境变量\n\n### 3.9.1 查看环境变量\n\n```bash\nenv\n```\n\n- 查看PATH变量\n\n  ```bash\n  env | grep PATH\n  ```\n\n  - PATH记录了系统执行任何命令的搜索路径，当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体。比如执行cd命令，就从第二个目录/usr/bin中搜索到了cd命令，并执行\n\n### 3.9.2 获取环境变量值\n\n```bash\n$变量名\n```\n\n- 例子\n\n  ```bash\n  echo ${PATH}abc\n  ```\n\n### 3.9.3 设置环境变量\n\n- 临时设置\n\n  ```bash\n  export 变量名=变量值\n  ```\n\n- 永久设置\n\n  | 作用         | 文件                          |\n  | ------------ | ----------------------------- |\n  | 针对当前用户 | ~/.bashrc                     |\n  | 所有用户     | /etc/profile                  |\n  |              | 使用`source 配置文件`立刻生效 |\n\n  - 例子\n\n    ```bash\n    export PATH=$PATH:目标文件\n    ```\n\n## 3.10 上传下载\n\n- rz、sz命令\n\n```bash\nyum -y install lrzsz #下载rz、sz\nrz #上传\nsz 文件 #下载\n```\n\n## 3.11 压缩解压\n\n### 1. tar命令\n\n```bash\ntar [-c -v -x -f -z -C] 参1 参2...\n```\n\n- 可解压\n\n  | 格式 | 说明                                                         |\n  | ---- | ------------------------------------------------------------ |\n  | .tar | tarball，归档文件，     简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装 |\n  | .gz  | •也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积 |\n\n- 参数\n\n  | 参数 | 说明                       |\n  | ---- | -------------------------- |\n  | c    | 创建压缩文件               |\n  | v    | 查看进度                   |\n  | x    | 解压模式                   |\n  | f    | 目标文件，必须放在最后一个 |\n  | z    | gzip模式，一般放在第一个   |\n  | C    | 解压目的地，单独使用       |\n\n- 压缩\n\n  ```bash\n  tar -cvf test.tar 文件1 文件2 #tar压缩\n  tar -zcvf test.tar.gz 文件1 文件2 #gzip压缩\n  ```\n\n- 解压\n\n  ```bash\n  tar -xvf 文件\n  tar -xvf 文件 -C 目标路径 #指定目录\n  tar -zxvf 文件 -C 目标路径 #解压.gz\n  ```\n\n### 2. zip命令\n\n```bash\nzip [-r] 文件1 文件2\n```\n\n### 3. unzip命令\n\n```bash\nunzip 文件 [-d 目标路径]\n```\n\n\n\n","source":"_posts/linux/Linux_5.usage3.md","raw":"---\ntitle: Linux入门-3使用操作3\ndate: 2024-03-02 22:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n\n---\n\n#\n\n<!--more-->\n\n# 3 Linux实用操作\n\n## 3.9 环境变量\n\n### 3.9.1 查看环境变量\n\n```bash\nenv\n```\n\n- 查看PATH变量\n\n  ```bash\n  env | grep PATH\n  ```\n\n  - PATH记录了系统执行任何命令的搜索路径，当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体。比如执行cd命令，就从第二个目录/usr/bin中搜索到了cd命令，并执行\n\n### 3.9.2 获取环境变量值\n\n```bash\n$变量名\n```\n\n- 例子\n\n  ```bash\n  echo ${PATH}abc\n  ```\n\n### 3.9.3 设置环境变量\n\n- 临时设置\n\n  ```bash\n  export 变量名=变量值\n  ```\n\n- 永久设置\n\n  | 作用         | 文件                          |\n  | ------------ | ----------------------------- |\n  | 针对当前用户 | ~/.bashrc                     |\n  | 所有用户     | /etc/profile                  |\n  |              | 使用`source 配置文件`立刻生效 |\n\n  - 例子\n\n    ```bash\n    export PATH=$PATH:目标文件\n    ```\n\n## 3.10 上传下载\n\n- rz、sz命令\n\n```bash\nyum -y install lrzsz #下载rz、sz\nrz #上传\nsz 文件 #下载\n```\n\n## 3.11 压缩解压\n\n### 1. tar命令\n\n```bash\ntar [-c -v -x -f -z -C] 参1 参2...\n```\n\n- 可解压\n\n  | 格式 | 说明                                                         |\n  | ---- | ------------------------------------------------------------ |\n  | .tar | tarball，归档文件，     简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装 |\n  | .gz  | •也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积 |\n\n- 参数\n\n  | 参数 | 说明                       |\n  | ---- | -------------------------- |\n  | c    | 创建压缩文件               |\n  | v    | 查看进度                   |\n  | x    | 解压模式                   |\n  | f    | 目标文件，必须放在最后一个 |\n  | z    | gzip模式，一般放在第一个   |\n  | C    | 解压目的地，单独使用       |\n\n- 压缩\n\n  ```bash\n  tar -cvf test.tar 文件1 文件2 #tar压缩\n  tar -zcvf test.tar.gz 文件1 文件2 #gzip压缩\n  ```\n\n- 解压\n\n  ```bash\n  tar -xvf 文件\n  tar -xvf 文件 -C 目标路径 #指定目录\n  tar -zxvf 文件 -C 目标路径 #解压.gz\n  ```\n\n### 2. zip命令\n\n```bash\nzip [-r] 文件1 文件2\n```\n\n### 3. unzip命令\n\n```bash\nunzip 文件 [-d 目标路径]\n```\n\n\n\n","slug":"linux/Linux_5.usage3","published":1,"updated":"2024-03-02T12:47:39.959Z","_id":"clta2pf07000bzovwe05igf5i","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-9-环境变量\"><a href=\"#3-9-环境变量\" class=\"headerlink\" title=\"3.9 环境变量\"></a>3.9 环境变量</h2><h3 id=\"3-9-1-查看环境变量\"><a href=\"#3-9-1-查看环境变量\" class=\"headerlink\" title=\"3.9.1 查看环境变量\"></a>3.9.1 查看环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">env</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>查看PATH变量</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">env</span> | grep PATH</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>PATH记录了系统执行任何命令的搜索路径，当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体。比如执行cd命令，就从第二个目录&#x2F;usr&#x2F;bin中搜索到了cd命令，并执行</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-9-2-获取环境变量值\"><a href=\"#3-9-2-获取环境变量值\" class=\"headerlink\" title=\"3.9.2 获取环境变量值\"></a>3.9.2 获取环境变量值</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$变量名</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;PATH&#125;</span>abc</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"3-9-3-设置环境变量\"><a href=\"#3-9-3-设置环境变量\" class=\"headerlink\" title=\"3.9.3 设置环境变量\"></a>3.9.3 设置环境变量</h3><ul>\n<li><p>临时设置</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> 变量名=变量值</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>永久设置</p>\n<table>\n<thead>\n<tr>\n<th>作用</th>\n<th>文件</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>针对当前用户</td>\n<td>~&#x2F;.bashrc</td>\n</tr>\n<tr>\n<td>所有用户</td>\n<td>&#x2F;etc&#x2F;profile</td>\n</tr>\n<tr>\n<td></td>\n<td>使用<code>source 配置文件</code>立刻生效</td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:目标文件</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-10-上传下载\"><a href=\"#3-10-上传下载\" class=\"headerlink\" title=\"3.10 上传下载\"></a>3.10 上传下载</h2><ul>\n<li>rz、sz命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install lrzsz <span class=\"comment\">#下载rz、sz</span></span><br><span class=\"line\">rz <span class=\"comment\">#上传</span></span><br><span class=\"line\">sz 文件 <span class=\"comment\">#下载</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-11-压缩解压\"><a href=\"#3-11-压缩解压\" class=\"headerlink\" title=\"3.11 压缩解压\"></a>3.11 压缩解压</h2><h3 id=\"1-tar命令\"><a href=\"#1-tar命令\" class=\"headerlink\" title=\"1. tar命令\"></a>1. tar命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar [-c -v -x -f -z -C] 参1 参2...</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>可解压</p>\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>.tar</td>\n<td>tarball，归档文件，     简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装</td>\n</tr>\n<tr>\n<td>.gz</td>\n<td>•也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>参数</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>c</td>\n<td>创建压缩文件</td>\n</tr>\n<tr>\n<td>v</td>\n<td>查看进度</td>\n</tr>\n<tr>\n<td>x</td>\n<td>解压模式</td>\n</tr>\n<tr>\n<td>f</td>\n<td>目标文件，必须放在最后一个</td>\n</tr>\n<tr>\n<td>z</td>\n<td>gzip模式，一般放在第一个</td>\n</tr>\n<tr>\n<td>C</td>\n<td>解压目的地，单独使用</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>压缩</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -cvf test.tar 文件1 文件2 <span class=\"comment\">#tar压缩</span></span><br><span class=\"line\">tar -zcvf test.tar.gz 文件1 文件2 <span class=\"comment\">#gzip压缩</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>解压</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -xvf 文件</span><br><span class=\"line\">tar -xvf 文件 -C 目标路径 <span class=\"comment\">#指定目录</span></span><br><span class=\"line\">tar -zxvf 文件 -C 目标路径 <span class=\"comment\">#解压.gz</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"2-zip命令\"><a href=\"#2-zip命令\" class=\"headerlink\" title=\"2. zip命令\"></a>2. zip命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zip [-r] 文件1 文件2</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-unzip命令\"><a href=\"#3-unzip命令\" class=\"headerlink\" title=\"3. unzip命令\"></a>3. unzip命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unzip 文件 [-d 目标路径]</span><br></pre></td></tr></table></figure>\n\n\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-Linux实用操作\"><a href=\"#3-Linux实用操作\" class=\"headerlink\" title=\"3 Linux实用操作\"></a>3 Linux实用操作</h1><h2 id=\"3-9-环境变量\"><a href=\"#3-9-环境变量\" class=\"headerlink\" title=\"3.9 环境变量\"></a>3.9 环境变量</h2><h3 id=\"3-9-1-查看环境变量\"><a href=\"#3-9-1-查看环境变量\" class=\"headerlink\" title=\"3.9.1 查看环境变量\"></a>3.9.1 查看环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">env</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>查看PATH变量</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">env</span> | grep PATH</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>PATH记录了系统执行任何命令的搜索路径，当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体。比如执行cd命令，就从第二个目录&#x2F;usr&#x2F;bin中搜索到了cd命令，并执行</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-9-2-获取环境变量值\"><a href=\"#3-9-2-获取环境变量值\" class=\"headerlink\" title=\"3.9.2 获取环境变量值\"></a>3.9.2 获取环境变量值</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$变量名</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;PATH&#125;</span>abc</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"3-9-3-设置环境变量\"><a href=\"#3-9-3-设置环境变量\" class=\"headerlink\" title=\"3.9.3 设置环境变量\"></a>3.9.3 设置环境变量</h3><ul>\n<li><p>临时设置</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> 变量名=变量值</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>永久设置</p>\n<table>\n<thead>\n<tr>\n<th>作用</th>\n<th>文件</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>针对当前用户</td>\n<td>~&#x2F;.bashrc</td>\n</tr>\n<tr>\n<td>所有用户</td>\n<td>&#x2F;etc&#x2F;profile</td>\n</tr>\n<tr>\n<td></td>\n<td>使用<code>source 配置文件</code>立刻生效</td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:目标文件</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-10-上传下载\"><a href=\"#3-10-上传下载\" class=\"headerlink\" title=\"3.10 上传下载\"></a>3.10 上传下载</h2><ul>\n<li>rz、sz命令</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install lrzsz <span class=\"comment\">#下载rz、sz</span></span><br><span class=\"line\">rz <span class=\"comment\">#上传</span></span><br><span class=\"line\">sz 文件 <span class=\"comment\">#下载</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-11-压缩解压\"><a href=\"#3-11-压缩解压\" class=\"headerlink\" title=\"3.11 压缩解压\"></a>3.11 压缩解压</h2><h3 id=\"1-tar命令\"><a href=\"#1-tar命令\" class=\"headerlink\" title=\"1. tar命令\"></a>1. tar命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar [-c -v -x -f -z -C] 参1 参2...</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>可解压</p>\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>.tar</td>\n<td>tarball，归档文件，     简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装</td>\n</tr>\n<tr>\n<td>.gz</td>\n<td>•也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>参数</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>c</td>\n<td>创建压缩文件</td>\n</tr>\n<tr>\n<td>v</td>\n<td>查看进度</td>\n</tr>\n<tr>\n<td>x</td>\n<td>解压模式</td>\n</tr>\n<tr>\n<td>f</td>\n<td>目标文件，必须放在最后一个</td>\n</tr>\n<tr>\n<td>z</td>\n<td>gzip模式，一般放在第一个</td>\n</tr>\n<tr>\n<td>C</td>\n<td>解压目的地，单独使用</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>压缩</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -cvf test.tar 文件1 文件2 <span class=\"comment\">#tar压缩</span></span><br><span class=\"line\">tar -zcvf test.tar.gz 文件1 文件2 <span class=\"comment\">#gzip压缩</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>解压</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -xvf 文件</span><br><span class=\"line\">tar -xvf 文件 -C 目标路径 <span class=\"comment\">#指定目录</span></span><br><span class=\"line\">tar -zxvf 文件 -C 目标路径 <span class=\"comment\">#解压.gz</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"2-zip命令\"><a href=\"#2-zip命令\" class=\"headerlink\" title=\"2. zip命令\"></a>2. zip命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zip [-r] 文件1 文件2</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-unzip命令\"><a href=\"#3-unzip命令\" class=\"headerlink\" title=\"3. unzip命令\"></a>3. unzip命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unzip 文件 [-d 目标路径]</span><br></pre></td></tr></table></figure>"},{"title":"生产实习-3 用户模块基础代码","date":"2024-03-04T03:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 3. 用户模块基础代码\n\n- spring boot运行总体流程：前端发起请求 -> 后端controller -> 后端service -> mapper -> sql\n- 我们从后往前写，先写service\n\n## 3.1 实现service\n\n- service层是一个接口，实现类的形式。\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/3/1.png)\n\n  ![](img/java/produce_practice/3/1.png)\n\n  1. 首先在biz/user/service下创建UserService。然后根据文档中表格信息实现接口：\n\n     ```java\n     package com.lyingedu.questionnaire.biz.user.service;\n     \n     import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n     \n     import java.util.List;\n     \n     public interface UserService {\n     \n         /**\n          * 增加用户\n          * @param userInfo\n          * @return\n          */\n         int addUserInfo(UserInfo userInfo);\n     \n         /**\n          * 修改用户\n          * @param userInfo\n          * @return\n          */\n         int modifyUserInfo(UserInfo userInfo);\n     \n     \n         /**\n          * 删除用户\n          * @param id\n          * @return\n          */\n         int deleteUserById(String id);\n     \n         /**\n          * 查询用户列表\n          * @return\n          */\n         List<UserInfo> queryUserList(UserInfo userInfo);\n     }\n     \n     ```\n\n  2. 在biz/user/service下创建UserServiceImpl。编写service实现类\n\n     - 先写public class UserServiceImpl implements UserService然后鼠标放到下划线，点击实现）\n     - 然后在类上面写注释：@Service让springboot知道这是一个操作数据库的service\n- 写入UserInfoMapper属性，属性需要在实现类里面说明。@resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到\n  \n     ```java\n     package com.lyingedu.questionnaire.biz.user.service;\n     \n     import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n     import com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;\n     import jakarta.annotation.Resource;\n     import org.springframework.stereotype.Service;\n     \n     import java.util.List;\n     \n     @Service //让spring boot知道这是操作数据库的service\n     public class UserServiceImpl implements UserService{\n     \n         @Resource //resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到\n         private UserInfoMapper userInfoMapper; //属性需要在实现类中说明\n     \n         @Override\n         public int addUserInfo(UserInfo userInfo) {\n             //TODO\n             return 0;\n         }\n     \n         @Override\n         public int modifyUserInfo(UserInfo userInfo) {\n             return 0;\n         }\n     \n         @Override\n         public int deleteUserById(String id) {\n             return 0;\n         }\n     \n    @Override\n         public List<UserInfo> queryUserList(UserInfo userInfo) {\n             return null;\n         }\n     }\n     \n    ```\n    \n     \n\n## 3.２ 实现controller\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/3/2.png)![](D:/blog/themes/yilia/source/img/java/produce_practice/3/3.png)\n\n![](img/java/produce_practice/3/2.png)\n\n![](img/java/produce_practice/3/3.png)\n\n1. 在biz/user/controller下创建UserController类，并注解@RestController，使用rest的接口风格；注解@RequestMapping(\"/admin\")，使用request请求\n\n2. HttpResponseEntity是一个通用的给前端返回结果的类，因此我们在questionnaire目录下创建一个beans目录存放一些通用的bean，在beans里面创建HttpResponseEntity.java\n\n   ```java\n   package com.lyingedu.questionnaire.beans;\n   \n   import lombok.Data;\n   \n   import java.io.Serializable;\n   \n   @Data //lombook的data注解可以省略get set方法\n   public class HttpResponseEntity implements Serializable {\n       private String code;//状态码\n       private Object data;//返回数据\n       private String message;//状态消息\n   \n       public HttpResponseEntity(){ //默认初始信息\n           this.code=\"0\";\n           this.message=\"操作失败\";\n       }\n   \n   \n   }\n   \n   ```\n\n   - 注意：由于代码中使用了lombok，你需要在idea中下载lombok插件并启用其注解处理（一般idea会提示你）\n\n3. 继续完善controller：\n\n   ```java\n   package com.lyingedu.questionnaire.biz.user.controller;\n   \n   import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n   import com.lyingedu.questionnaire.biz.user.service.UserService;\n   import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n   import com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;\n   import jakarta.annotation.Resource;\n   import org.springframework.web.bind.annotation.RequestMapping;\n   import org.springframework.web.bind.annotation.RestController;\n   \n   @RestController //rest的接口风格\n   @RequestMapping(\"/admin\") //使用request请求\n   public class UserController {\n   \n       @Resource\n       private UserService userService;\n   \n       /**\n        * 用户列表\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity queryUserList(UserInfo userInfo){\n   \n           //TODO\n           return null;\n       }\n   \n       /**\n        * 增加用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity addUserInfo(UserInfo userInfo) {\n           //TODO\n           return null;\n       }\n   \n       /**\n        * 修改用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity modifyUserInfo(UserInfo userInfo) {\n   \n           //TODO\n           return null;\n       }\n   \n       /**\n        * 删除用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity deleteUserById(UserInfo userInfo) {\n           //TODO\n           return null;\n       }\n   \n       /**\n        * 用户登录\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity userLogin(UserInfo userInfo) {\n   \n           //TODO\n           return null;\n       }\n   }\n   \n   ```\n\n   ","source":"_posts/java/produce_practice/3_userbase.md","raw":"---\ntitle: 生产实习-3 用户模块基础代码\n\ndate: 2024-3-4 11:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n\n\n---\n\n#\n<!--more-->\n\n# 3. 用户模块基础代码\n\n- spring boot运行总体流程：前端发起请求 -> 后端controller -> 后端service -> mapper -> sql\n- 我们从后往前写，先写service\n\n## 3.1 实现service\n\n- service层是一个接口，实现类的形式。\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/3/1.png)\n\n  ![](img/java/produce_practice/3/1.png)\n\n  1. 首先在biz/user/service下创建UserService。然后根据文档中表格信息实现接口：\n\n     ```java\n     package com.lyingedu.questionnaire.biz.user.service;\n     \n     import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n     \n     import java.util.List;\n     \n     public interface UserService {\n     \n         /**\n          * 增加用户\n          * @param userInfo\n          * @return\n          */\n         int addUserInfo(UserInfo userInfo);\n     \n         /**\n          * 修改用户\n          * @param userInfo\n          * @return\n          */\n         int modifyUserInfo(UserInfo userInfo);\n     \n     \n         /**\n          * 删除用户\n          * @param id\n          * @return\n          */\n         int deleteUserById(String id);\n     \n         /**\n          * 查询用户列表\n          * @return\n          */\n         List<UserInfo> queryUserList(UserInfo userInfo);\n     }\n     \n     ```\n\n  2. 在biz/user/service下创建UserServiceImpl。编写service实现类\n\n     - 先写public class UserServiceImpl implements UserService然后鼠标放到下划线，点击实现）\n     - 然后在类上面写注释：@Service让springboot知道这是一个操作数据库的service\n- 写入UserInfoMapper属性，属性需要在实现类里面说明。@resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到\n  \n     ```java\n     package com.lyingedu.questionnaire.biz.user.service;\n     \n     import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n     import com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;\n     import jakarta.annotation.Resource;\n     import org.springframework.stereotype.Service;\n     \n     import java.util.List;\n     \n     @Service //让spring boot知道这是操作数据库的service\n     public class UserServiceImpl implements UserService{\n     \n         @Resource //resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到\n         private UserInfoMapper userInfoMapper; //属性需要在实现类中说明\n     \n         @Override\n         public int addUserInfo(UserInfo userInfo) {\n             //TODO\n             return 0;\n         }\n     \n         @Override\n         public int modifyUserInfo(UserInfo userInfo) {\n             return 0;\n         }\n     \n         @Override\n         public int deleteUserById(String id) {\n             return 0;\n         }\n     \n    @Override\n         public List<UserInfo> queryUserList(UserInfo userInfo) {\n             return null;\n         }\n     }\n     \n    ```\n    \n     \n\n## 3.２ 实现controller\n\n ![](D:/blog/themes/yilia/source/img/java/produce_practice/3/2.png)![](D:/blog/themes/yilia/source/img/java/produce_practice/3/3.png)\n\n![](img/java/produce_practice/3/2.png)\n\n![](img/java/produce_practice/3/3.png)\n\n1. 在biz/user/controller下创建UserController类，并注解@RestController，使用rest的接口风格；注解@RequestMapping(\"/admin\")，使用request请求\n\n2. HttpResponseEntity是一个通用的给前端返回结果的类，因此我们在questionnaire目录下创建一个beans目录存放一些通用的bean，在beans里面创建HttpResponseEntity.java\n\n   ```java\n   package com.lyingedu.questionnaire.beans;\n   \n   import lombok.Data;\n   \n   import java.io.Serializable;\n   \n   @Data //lombook的data注解可以省略get set方法\n   public class HttpResponseEntity implements Serializable {\n       private String code;//状态码\n       private Object data;//返回数据\n       private String message;//状态消息\n   \n       public HttpResponseEntity(){ //默认初始信息\n           this.code=\"0\";\n           this.message=\"操作失败\";\n       }\n   \n   \n   }\n   \n   ```\n\n   - 注意：由于代码中使用了lombok，你需要在idea中下载lombok插件并启用其注解处理（一般idea会提示你）\n\n3. 继续完善controller：\n\n   ```java\n   package com.lyingedu.questionnaire.biz.user.controller;\n   \n   import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n   import com.lyingedu.questionnaire.biz.user.service.UserService;\n   import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n   import com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;\n   import jakarta.annotation.Resource;\n   import org.springframework.web.bind.annotation.RequestMapping;\n   import org.springframework.web.bind.annotation.RestController;\n   \n   @RestController //rest的接口风格\n   @RequestMapping(\"/admin\") //使用request请求\n   public class UserController {\n   \n       @Resource\n       private UserService userService;\n   \n       /**\n        * 用户列表\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity queryUserList(UserInfo userInfo){\n   \n           //TODO\n           return null;\n       }\n   \n       /**\n        * 增加用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity addUserInfo(UserInfo userInfo) {\n           //TODO\n           return null;\n       }\n   \n       /**\n        * 修改用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity modifyUserInfo(UserInfo userInfo) {\n   \n           //TODO\n           return null;\n       }\n   \n       /**\n        * 删除用户\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity deleteUserById(UserInfo userInfo) {\n           //TODO\n           return null;\n       }\n   \n       /**\n        * 用户登录\n        * @param userInfo\n        * @return\n        */\n       public HttpResponseEntity userLogin(UserInfo userInfo) {\n   \n           //TODO\n           return null;\n       }\n   }\n   \n   ```\n\n   ","slug":"java/produce_practice/3_userbase","published":1,"updated":"2024-03-08T05:48:35.083Z","_id":"cltfntnsz0000ccvw41iu1cn9","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"3-用户模块基础代码\"><a href=\"#3-用户模块基础代码\" class=\"headerlink\" title=\"3. 用户模块基础代码\"></a>3. 用户模块基础代码</h1><ul>\n<li>spring boot运行总体流程：前端发起请求 -&gt; 后端controller -&gt; 后端service -&gt; mapper -&gt; sql</li>\n<li>我们从后往前写，先写service</li>\n</ul>\n<h2 id=\"3-1-实现service\"><a href=\"#3-1-实现service\" class=\"headerlink\" title=\"3.1 实现service\"></a>3.1 实现service</h2><ul>\n<li><p>service层是一个接口，实现类的形式。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/1.png\"></p>\n<ol>\n<li><p>首先在biz&#x2F;user&#x2F;service下创建UserService。然后根据文档中表格信息实现接口：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">UserService</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> id</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在biz&#x2F;user&#x2F;service下创建UserServiceImpl。编写service实现类</p>\n<ul>\n<li>先写public class UserServiceImpl implements UserService然后鼠标放到下划线，点击实现）</li>\n<li>然后在类上面写注释：@Service让springboot知道这是一个操作数据库的service</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>写入UserInfoMapper属性，属性需要在实现类里面说明。@resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到</p>\n   <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> org.springframework.stereotype.Service;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"meta\">@Service</span> <span class=\"comment\">//让spring boot知道这是操作数据库的service</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UserServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">UserService</span>&#123;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Resource</span> <span class=\"comment\">//resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到</span></span><br><span class=\"line\">     <span class=\"keyword\">private</span> UserInfoMapper userInfoMapper; <span class=\"comment\">//属性需要在实现类中说明</span></span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"comment\">//TODO</span></span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> </span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"3-２-实现controller\"><a href=\"#3-２-实现controller\" class=\"headerlink\" title=\"3.２ 实现controller\"></a>3.２ 实现controller</h2><p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/2.png\"><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/3.png\"></p>\n<ol>\n<li><p>在biz&#x2F;user&#x2F;controller下创建UserController类，并注解@RestController，使用rest的接口风格；注解@RequestMapping(“&#x2F;admin”)，使用request请求</p>\n</li>\n<li><p>HttpResponseEntity是一个通用的给前端返回结果的类，因此我们在questionnaire目录下创建一个beans目录存放一些通用的bean，在beans里面创建HttpResponseEntity.java</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.beans;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.Data;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.Serializable;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Data</span> <span class=\"comment\">//lombook的data注解可以省略get set方法</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">HttpResponseEntity</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">Serializable</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String code;<span class=\"comment\">//状态码</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object data;<span class=\"comment\">//返回数据</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> String message;<span class=\"comment\">//状态消息</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"title function_\">HttpResponseEntity</span><span class=\"params\">()</span>&#123; <span class=\"comment\">//默认初始信息</span></span><br><span class=\"line\">        <span class=\"built_in\">this</span>.code=<span class=\"string\">&quot;0&quot;</span>;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.message=<span class=\"string\">&quot;操作失败&quot;</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>注意：由于代码中使用了lombok，你需要在idea中下载lombok插件并启用其注解处理（一般idea会提示你）</li>\n</ul>\n</li>\n<li><p>继续完善controller：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.controller;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.service.UserService;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RestController</span> <span class=\"comment\">//rest的接口风格</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping(&quot;/admin&quot;)</span> <span class=\"comment\">//使用request请求</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UserController</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> UserService userService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteUserById</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 用户登录</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-用户模块基础代码\"><a href=\"#3-用户模块基础代码\" class=\"headerlink\" title=\"3. 用户模块基础代码\"></a>3. 用户模块基础代码</h1><ul>\n<li>spring boot运行总体流程：前端发起请求 -&gt; 后端controller -&gt; 后端service -&gt; mapper -&gt; sql</li>\n<li>我们从后往前写，先写service</li>\n</ul>\n<h2 id=\"3-1-实现service\"><a href=\"#3-1-实现service\" class=\"headerlink\" title=\"3.1 实现service\"></a>3.1 实现service</h2><ul>\n<li><p>service层是一个接口，实现类的形式。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/1.png\"></p>\n<ol>\n<li><p>首先在biz&#x2F;user&#x2F;service下创建UserService。然后根据文档中表格信息实现接口：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">UserService</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> id</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在biz&#x2F;user&#x2F;service下创建UserServiceImpl。编写service实现类</p>\n<ul>\n<li>先写public class UserServiceImpl implements UserService然后鼠标放到下划线，点击实现）</li>\n<li>然后在类上面写注释：@Service让springboot知道这是一个操作数据库的service</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>写入UserInfoMapper属性，属性需要在实现类里面说明。@resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到</p>\n   <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"> <span class=\"keyword\">import</span> org.springframework.stereotype.Service;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"meta\">@Service</span> <span class=\"comment\">//让spring boot知道这是操作数据库的service</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UserServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">UserService</span>&#123;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Resource</span> <span class=\"comment\">//resource注解可以让springboot自动给他注入依赖，否则UserInfoMapper找不到</span></span><br><span class=\"line\">     <span class=\"keyword\">private</span> UserInfoMapper userInfoMapper; <span class=\"comment\">//属性需要在实现类中说明</span></span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"comment\">//TODO</span></span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">     <span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\">     <span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> </span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"3-２-实现controller\"><a href=\"#3-２-实现controller\" class=\"headerlink\" title=\"3.２ 实现controller\"></a>3.２ 实现controller</h2><p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/2.png\"><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/3/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/3/3.png\"></p>\n<ol>\n<li><p>在biz&#x2F;user&#x2F;controller下创建UserController类，并注解@RestController，使用rest的接口风格；注解@RequestMapping(“&#x2F;admin”)，使用request请求</p>\n</li>\n<li><p>HttpResponseEntity是一个通用的给前端返回结果的类，因此我们在questionnaire目录下创建一个beans目录存放一些通用的bean，在beans里面创建HttpResponseEntity.java</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.beans;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.Data;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.Serializable;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Data</span> <span class=\"comment\">//lombook的data注解可以省略get set方法</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">HttpResponseEntity</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">Serializable</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String code;<span class=\"comment\">//状态码</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object data;<span class=\"comment\">//返回数据</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> String message;<span class=\"comment\">//状态消息</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"title function_\">HttpResponseEntity</span><span class=\"params\">()</span>&#123; <span class=\"comment\">//默认初始信息</span></span><br><span class=\"line\">        <span class=\"built_in\">this</span>.code=<span class=\"string\">&quot;0&quot;</span>;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.message=<span class=\"string\">&quot;操作失败&quot;</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>注意：由于代码中使用了lombok，你需要在idea中下载lombok插件并启用其注解处理（一般idea会提示你）</li>\n</ul>\n</li>\n<li><p>继续完善controller：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.controller;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.service.UserService;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.UserInfoMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RestController</span> <span class=\"comment\">//rest的接口风格</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping(&quot;/admin&quot;)</span> <span class=\"comment\">//使用request请求</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UserController</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> UserService userService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteUserById</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 用户登录</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//TODO</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ol>"},{"title":"生产实习-4 登录及创建用户功能开发","date":"2024-03-05T01:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n\n\n# 4. 登录及创建用户功能开发\n\n## 4.1 登录功能\n\n### 4.1.1 查看前端代码\n\n- 首先在resources/static/pages/login/index.html查看登录按钮的动作：发现是调用了onLogin函数。\n\n- 进入./index.js查看该函数：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/1.png)\n\n  ![](img/java/produce_practice/4/1.png)\n\n### 4.1.2 编写UserController.userLogin方法（control层）\n\n- 然后我们到biz/user/controller/UserController，其中有\n\n  ```java\n  @RequestMapping(\"/admin\") //使用request请求\n  ```\n\n  对应/admin路径。然后我们找到其中的userLogin方法，进行编写：\n\n  ```java\n      @PostMapping(\"/userLogin\")\n      public HttpResponseEntity userLogin(@RequestBody UserInfo userInfo) { //requestbody注解，将请求的json数据转换为对象\n  \n          HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n          //TODO\n          List<UserInfo> userInfos = userService.queryUserList(userInfo); //使用service层的方法查询用户信息\n  \n          if(userInfos.size() != 0) {//如果查询到用户信息则状态码为666，否则为默认值\n              httpResponseEntity.setCode(\"666\");\n              httpResponseEntity.setData(userInfos.get(0));\n          }\n          return httpResponseEntity;//传给前端\n      }\n  ```\n\n- 然后进行调试，可以先在该方法内打个断点，然后调试，进入 http://127.0.0.1:8085/pages/login/index.html，输入用户名密码，确认后可以看到代码运行到了断点处，可以查看一下userInfo变量是否能获得。\n\n  - 注意：如果你输入了localhost而非127.0.0.1你可能会发现代码没有运行到断点处，无法查看变量。在浏览器打开检查页面。\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/2.png)\n\n    ![](img/java/produce_practice/4/2.png)\n\n### 4.1.3 编写userserviceImpl.queryUserList方法（service层）\n\n- 具体查询是在userserviceImpl.queryUserList中实现的：\n\n  ```java\n      /**\n       * 查询用户列表\n       * @param userInfo\n       * @return\n       */\n      @Override\n      public List<UserInfo> queryUserList(UserInfo userInfo) {//1. 用userInof查询数据库\n  \n          UserInfoExample userInfoExample = new UserInfoExample(); //3 在dbmap/entities里面是有userinfoexample的\n          UserInfoExample.Criteria userInfoCriteria = userInfoExample.createCriteria(); //4 然后用这个example创建一个条件\n          userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) //根据这两个条件进行查询\n                          .andPasswordEqualTo(userInfo.getPassword());\n  \n  \n          return userInfoMapper.selectByExample(userInfoExample);//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询\n      }\n  }\n  ```\n\n### 4.1.4 调试结果\n\n- 然后继续在usercontroller的返回那一行打个断点，继续调试，发现确认用户名密码后发生错误，调试终止。这是因为一些xml文件放在了java包下面，无法编译到工程中，需要在项目根目录的pom.xml的<build>中加入以下代码：\n\n  ```xml\n  \t<resources>\n  \t\t\t<resource>\n  \t\t\t\t<directory>src/main/java</directory>\n  \t\t\t\t<includes>\n  \t\t\t\t\t<include>**/*.xml</include>\n  \t\t\t\t</includes>\n  \t\t\t\t<filtering>false</filtering>\n  \t\t\t</resource>\n  \t\t\t<resource>\n  \t\t\t\t<directory>src/main/resources</directory>\n  \t\t\t</resource>\n  \t\t</resources>\n  ```\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/3.png)\n\n  ![](img/java/produce_practice/4/3.png)\n\n  然后刷新maven即可。\n\n- 此时发现userInfos的id是0，说明查询数据库成功了（id值来自数据库）\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/4.png)\n\n  ![](img/java/produce_practice/4/4.png)\n\n  - 然后点击调试控制台的恢复程序按钮\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/5.png)\n\n    ![](img/java/produce_practice/4/5.png) \n\n    发现前端页面跳转：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/6.png)\n\n    ![](img/java/produce_practice/4/6.png)\n\n## 4.2 创建用户功能\n\n### 4.2.1 查看前端代码\n\n- 发现路径是admin/addUserInfo，参照4.1的经验，我们接下来要找control层的addUserInfo方法\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/7.png)\n\n  ![](img/java/produce_practice/4/7.png) \n\n\n\n### 4.2.2 编写UserController.userLogin方法（control层）\n\n```java\n    public HttpResponseEntity addUserInfo(@RequestBody UserInfo userInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        int count = userService.addUserInfo(userInfo); //返回受影响的行数\n        if(count > 0) { //插入成功则状态码为666，否则为默认错误值\n            httpResponseEntity.setCode(\"666\");\n        }\n        return httpResponseEntity;\n    }\n```\n\n### 4.2.3 编写userserviceImpl.addUserInfo方法（service层）\n\n- 由于数据库设计问题，每次插入数据都需要一个userid，userid不是自动编号的，需要自己写入，而前端没有写入，因此我们还需要一个在后端生成userid的方法在后端。为此我们创建src/main/java/com/lyingedu/questionnaire/common/utils/UUIDUtil.java:\n\n  ```java\n  package com.lyingedu.questionnaire.common.utils;\n  \n  \n  import java.util.UUID;\n  \n  public class UUIDUtil {\n  \n      /**\n       *获取一个UUID\n       */\n      public static String getOneUUID(){\n          //获取UUID\n          String s = UUID.randomUUID().toString();\n          //去掉“-”符号\n          return s.substring(0,8)+s.substring(9,13)+s.substring(14,18)+s.substring(19,23)+s.substring(24);\n      }\n      /**\n       * 获得指定数目的UUID\n       * @param number int 需要获得的UUID数量\n       * @return String[] UUID数组\n       */\n      public static String[] getUUID(int number){\n          if(number < 1){\n              return null;\n          }\n          String[] ss = new String[number];\n          for(int i=0;i<number;i++){\n              ss[i] = getOneUUID();\n          }\n          return ss;\n      }\n  }\n  \n  ```\n\n- 然后我们再来编写userserviceImpl.addUserInfo方法：\n\n  ```java\n      public int addUserInfo(UserInfo userInfo) {\n  \n          userInfo.setId(UUIDUtil.getOneUUID());\n          userInfo.setStatus(\"1\");//1有效，0无效\n          \n          return userInfoMapper.insert(userInfo);\n      }\n  ```\n\n- 最后还需要将index.js里面的两句判断状态码从1改成自己的666：\n\n  ```js\n  if (res.code === \"666\") {\n  ```\n\n  ","source":"_posts/java/produce_practice/4_login.md","raw":"---\ntitle: 生产实习-4 登录及创建用户功能开发\n\ndate: 2024-3-5 09:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n\n\n# 4. 登录及创建用户功能开发\n\n## 4.1 登录功能\n\n### 4.1.1 查看前端代码\n\n- 首先在resources/static/pages/login/index.html查看登录按钮的动作：发现是调用了onLogin函数。\n\n- 进入./index.js查看该函数：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/1.png)\n\n  ![](img/java/produce_practice/4/1.png)\n\n### 4.1.2 编写UserController.userLogin方法（control层）\n\n- 然后我们到biz/user/controller/UserController，其中有\n\n  ```java\n  @RequestMapping(\"/admin\") //使用request请求\n  ```\n\n  对应/admin路径。然后我们找到其中的userLogin方法，进行编写：\n\n  ```java\n      @PostMapping(\"/userLogin\")\n      public HttpResponseEntity userLogin(@RequestBody UserInfo userInfo) { //requestbody注解，将请求的json数据转换为对象\n  \n          HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n          //TODO\n          List<UserInfo> userInfos = userService.queryUserList(userInfo); //使用service层的方法查询用户信息\n  \n          if(userInfos.size() != 0) {//如果查询到用户信息则状态码为666，否则为默认值\n              httpResponseEntity.setCode(\"666\");\n              httpResponseEntity.setData(userInfos.get(0));\n          }\n          return httpResponseEntity;//传给前端\n      }\n  ```\n\n- 然后进行调试，可以先在该方法内打个断点，然后调试，进入 http://127.0.0.1:8085/pages/login/index.html，输入用户名密码，确认后可以看到代码运行到了断点处，可以查看一下userInfo变量是否能获得。\n\n  - 注意：如果你输入了localhost而非127.0.0.1你可能会发现代码没有运行到断点处，无法查看变量。在浏览器打开检查页面。\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/2.png)\n\n    ![](img/java/produce_practice/4/2.png)\n\n### 4.1.3 编写userserviceImpl.queryUserList方法（service层）\n\n- 具体查询是在userserviceImpl.queryUserList中实现的：\n\n  ```java\n      /**\n       * 查询用户列表\n       * @param userInfo\n       * @return\n       */\n      @Override\n      public List<UserInfo> queryUserList(UserInfo userInfo) {//1. 用userInof查询数据库\n  \n          UserInfoExample userInfoExample = new UserInfoExample(); //3 在dbmap/entities里面是有userinfoexample的\n          UserInfoExample.Criteria userInfoCriteria = userInfoExample.createCriteria(); //4 然后用这个example创建一个条件\n          userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) //根据这两个条件进行查询\n                          .andPasswordEqualTo(userInfo.getPassword());\n  \n  \n          return userInfoMapper.selectByExample(userInfoExample);//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询\n      }\n  }\n  ```\n\n### 4.1.4 调试结果\n\n- 然后继续在usercontroller的返回那一行打个断点，继续调试，发现确认用户名密码后发生错误，调试终止。这是因为一些xml文件放在了java包下面，无法编译到工程中，需要在项目根目录的pom.xml的<build>中加入以下代码：\n\n  ```xml\n  \t<resources>\n  \t\t\t<resource>\n  \t\t\t\t<directory>src/main/java</directory>\n  \t\t\t\t<includes>\n  \t\t\t\t\t<include>**/*.xml</include>\n  \t\t\t\t</includes>\n  \t\t\t\t<filtering>false</filtering>\n  \t\t\t</resource>\n  \t\t\t<resource>\n  \t\t\t\t<directory>src/main/resources</directory>\n  \t\t\t</resource>\n  \t\t</resources>\n  ```\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/3.png)\n\n  ![](img/java/produce_practice/4/3.png)\n\n  然后刷新maven即可。\n\n- 此时发现userInfos的id是0，说明查询数据库成功了（id值来自数据库）\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/4.png)\n\n  ![](img/java/produce_practice/4/4.png)\n\n  - 然后点击调试控制台的恢复程序按钮\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/5.png)\n\n    ![](img/java/produce_practice/4/5.png) \n\n    发现前端页面跳转：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/6.png)\n\n    ![](img/java/produce_practice/4/6.png)\n\n## 4.2 创建用户功能\n\n### 4.2.1 查看前端代码\n\n- 发现路径是admin/addUserInfo，参照4.1的经验，我们接下来要找control层的addUserInfo方法\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/4/7.png)\n\n  ![](img/java/produce_practice/4/7.png) \n\n\n\n### 4.2.2 编写UserController.userLogin方法（control层）\n\n```java\n    public HttpResponseEntity addUserInfo(@RequestBody UserInfo userInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        int count = userService.addUserInfo(userInfo); //返回受影响的行数\n        if(count > 0) { //插入成功则状态码为666，否则为默认错误值\n            httpResponseEntity.setCode(\"666\");\n        }\n        return httpResponseEntity;\n    }\n```\n\n### 4.2.3 编写userserviceImpl.addUserInfo方法（service层）\n\n- 由于数据库设计问题，每次插入数据都需要一个userid，userid不是自动编号的，需要自己写入，而前端没有写入，因此我们还需要一个在后端生成userid的方法在后端。为此我们创建src/main/java/com/lyingedu/questionnaire/common/utils/UUIDUtil.java:\n\n  ```java\n  package com.lyingedu.questionnaire.common.utils;\n  \n  \n  import java.util.UUID;\n  \n  public class UUIDUtil {\n  \n      /**\n       *获取一个UUID\n       */\n      public static String getOneUUID(){\n          //获取UUID\n          String s = UUID.randomUUID().toString();\n          //去掉“-”符号\n          return s.substring(0,8)+s.substring(9,13)+s.substring(14,18)+s.substring(19,23)+s.substring(24);\n      }\n      /**\n       * 获得指定数目的UUID\n       * @param number int 需要获得的UUID数量\n       * @return String[] UUID数组\n       */\n      public static String[] getUUID(int number){\n          if(number < 1){\n              return null;\n          }\n          String[] ss = new String[number];\n          for(int i=0;i<number;i++){\n              ss[i] = getOneUUID();\n          }\n          return ss;\n      }\n  }\n  \n  ```\n\n- 然后我们再来编写userserviceImpl.addUserInfo方法：\n\n  ```java\n      public int addUserInfo(UserInfo userInfo) {\n  \n          userInfo.setId(UUIDUtil.getOneUUID());\n          userInfo.setStatus(\"1\");//1有效，0无效\n          \n          return userInfoMapper.insert(userInfo);\n      }\n  ```\n\n- 最后还需要将index.js里面的两句判断状态码从1改成自己的666：\n\n  ```js\n  if (res.code === \"666\") {\n  ```\n\n  ","slug":"java/produce_practice/4_login","published":1,"updated":"2024-03-05T11:39:22.574Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltfntnt00001ccvwb6an9pjh","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<h1 id=\"4-登录及创建用户功能开发\"><a href=\"#4-登录及创建用户功能开发\" class=\"headerlink\" title=\"4. 登录及创建用户功能开发\"></a>4. 登录及创建用户功能开发</h1><h2 id=\"4-1-登录功能\"><a href=\"#4-1-登录功能\" class=\"headerlink\" title=\"4.1 登录功能\"></a>4.1 登录功能</h2><h3 id=\"4-1-1-查看前端代码\"><a href=\"#4-1-1-查看前端代码\" class=\"headerlink\" title=\"4.1.1 查看前端代码\"></a>4.1.1 查看前端代码</h3><ul>\n<li><p>首先在resources&#x2F;static&#x2F;pages&#x2F;login&#x2F;index.html查看登录按钮的动作：发现是调用了onLogin函数。</p>\n</li>\n<li><p>进入.&#x2F;index.js查看该函数：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/1.png\"></p>\n</li>\n</ul>\n<h3 id=\"4-1-2-编写UserController-userLogin方法（control层）\"><a href=\"#4-1-2-编写UserController-userLogin方法（control层）\" class=\"headerlink\" title=\"4.1.2 编写UserController.userLogin方法（control层）\"></a>4.1.2 编写UserController.userLogin方法（control层）</h3><ul>\n<li><p>然后我们到biz&#x2F;user&#x2F;controller&#x2F;UserController，其中有</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping(&quot;/admin&quot;)</span> <span class=\"comment\">//使用request请求</span></span><br></pre></td></tr></table></figure>\n\n<p>对应&#x2F;admin路径。然后我们找到其中的userLogin方法，进行编写：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/userLogin&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123; <span class=\"comment\">//requestbody注解，将请求的json数据转换为对象</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"comment\">//TODO</span></span><br><span class=\"line\">    List&lt;UserInfo&gt; userInfos = userService.queryUserList(userInfo); <span class=\"comment\">//使用service层的方法查询用户信息</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(userInfos.size() != <span class=\"number\">0</span>) &#123;<span class=\"comment\">//如果查询到用户信息则状态码为666，否则为默认值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">        httpResponseEntity.setData(userInfos.get(<span class=\"number\">0</span>));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;<span class=\"comment\">//传给前端</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后进行调试，可以先在该方法内打个断点，然后调试，进入 <a href=\"http://127.0.0.1:8085/pages/login/index.html%EF%BC%8C%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%EF%BC%8C%E7%A1%AE%E8%AE%A4%E5%90%8E%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C%E5%88%B0%E4%BA%86%E6%96%AD%E7%82%B9%E5%A4%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%8BuserInfo%E5%8F%98%E9%87%8F%E6%98%AF%E5%90%A6%E8%83%BD%E8%8E%B7%E5%BE%97%E3%80%82\">http://127.0.0.1:8085/pages/login/index.html，输入用户名密码，确认后可以看到代码运行到了断点处，可以查看一下userInfo变量是否能获得。</a></p>\n<ul>\n<li><p>注意：如果你输入了localhost而非127.0.0.1你可能会发现代码没有运行到断点处，无法查看变量。在浏览器打开检查页面。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/2.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-1-3-编写userserviceImpl-queryUserList方法（service层）\"><a href=\"#4-1-3-编写userserviceImpl-queryUserList方法（service层）\" class=\"headerlink\" title=\"4.1.3 编写userserviceImpl.queryUserList方法（service层）\"></a>4.1.3 编写userserviceImpl.queryUserList方法（service层）</h3><ul>\n<li><p>具体查询是在userserviceImpl.queryUserList中实现的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;<span class=\"comment\">//1. 用userInof查询数据库</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">UserInfoExample</span> <span class=\"variable\">userInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfoExample</span>(); <span class=\"comment\">//3 在dbmap/entities里面是有userinfoexample的</span></span><br><span class=\"line\">        UserInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">userInfoCriteria</span> <span class=\"operator\">=</span> userInfoExample.createCriteria(); <span class=\"comment\">//4 然后用这个example创建一个条件</span></span><br><span class=\"line\">        userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) <span class=\"comment\">//根据这两个条件进行查询</span></span><br><span class=\"line\">                        .andPasswordEqualTo(userInfo.getPassword());</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> userInfoMapper.selectByExample(userInfoExample);<span class=\"comment\">//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"4-1-4-调试结果\"><a href=\"#4-1-4-调试结果\" class=\"headerlink\" title=\"4.1.4 调试结果\"></a>4.1.4 调试结果</h3><ul>\n<li><p>然后继续在usercontroller的返回那一行打个断点，继续调试，发现确认用户名密码后发生错误，调试终止。这是因为一些xml文件放在了java包下面，无法编译到工程中，需要在项目根目录的pom.xml的<build>中加入以下代码：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/3.png\"></p>\n<p>然后刷新maven即可。</p>\n</li>\n<li><p>此时发现userInfos的id是0，说明查询数据库成功了（id值来自数据库）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/4.png\"></p>\n<ul>\n<li><p>然后点击调试控制台的恢复程序按钮</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/5.png\"> </p>\n<p>发现前端页面跳转：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/6.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-2-创建用户功能\"><a href=\"#4-2-创建用户功能\" class=\"headerlink\" title=\"4.2 创建用户功能\"></a>4.2 创建用户功能</h2><h3 id=\"4-2-1-查看前端代码\"><a href=\"#4-2-1-查看前端代码\" class=\"headerlink\" title=\"4.2.1 查看前端代码\"></a>4.2.1 查看前端代码</h3><ul>\n<li><p>发现路径是admin&#x2F;addUserInfo，参照4.1的经验，我们接下来要找control层的addUserInfo方法</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/7.png\"></p>\n</li>\n</ul>\n<h3 id=\"4-2-2-编写UserController-userLogin方法（control层）\"><a href=\"#4-2-2-编写UserController-userLogin方法（control层）\" class=\"headerlink\" title=\"4.2.2 编写UserController.userLogin方法（control层）\"></a>4.2.2 编写UserController.userLogin方法（control层）</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addUserInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">count</span> <span class=\"operator\">=</span> userService.addUserInfo(userInfo); <span class=\"comment\">//返回受影响的行数</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(count &gt; <span class=\"number\">0</span>) &#123; <span class=\"comment\">//插入成功则状态码为666，否则为默认错误值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-2-3-编写userserviceImpl-addUserInfo方法（service层）\"><a href=\"#4-2-3-编写userserviceImpl-addUserInfo方法（service层）\" class=\"headerlink\" title=\"4.2.3 编写userserviceImpl.addUserInfo方法（service层）\"></a>4.2.3 编写userserviceImpl.addUserInfo方法（service层）</h3><ul>\n<li><p>由于数据库设计问题，每次插入数据都需要一个userid，userid不是自动编号的，需要自己写入，而前端没有写入，因此我们还需要一个在后端生成userid的方法在后端。为此我们创建src&#x2F;main&#x2F;java&#x2F;com&#x2F;lyingedu&#x2F;questionnaire&#x2F;common&#x2F;utils&#x2F;UUIDUtil.java:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.common.utils;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.UUID;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UUIDUtil</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     *获取一个UUID</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title function_\">getOneUUID</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//获取UUID</span></span><br><span class=\"line\">        <span class=\"type\">String</span> <span class=\"variable\">s</span> <span class=\"operator\">=</span> UUID.randomUUID().toString();</span><br><span class=\"line\">        <span class=\"comment\">//去掉“-”符号</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> s.substring(<span class=\"number\">0</span>,<span class=\"number\">8</span>)+s.substring(<span class=\"number\">9</span>,<span class=\"number\">13</span>)+s.substring(<span class=\"number\">14</span>,<span class=\"number\">18</span>)+s.substring(<span class=\"number\">19</span>,<span class=\"number\">23</span>)+s.substring(<span class=\"number\">24</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获得指定数目的UUID</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> number int 需要获得的UUID数量</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> String[] UUID数组</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String[] getUUID(<span class=\"type\">int</span> number)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number &lt; <span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        String[] ss = <span class=\"keyword\">new</span> <span class=\"title class_\">String</span>[number];</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;number;i++)&#123;</span><br><span class=\"line\">            ss[i] = getOneUUID();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ss;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后我们再来编写userserviceImpl.addUserInfo方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">    userInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">    userInfo.setStatus(<span class=\"string\">&quot;1&quot;</span>);<span class=\"comment\">//1有效，0无效</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.insert(userInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>最后还需要将index.js里面的两句判断状态码从1改成自己的666：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (res.<span class=\"property\">code</span> === <span class=\"string\">&quot;666&quot;</span>) &#123;</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"4-登录及创建用户功能开发\"><a href=\"#4-登录及创建用户功能开发\" class=\"headerlink\" title=\"4. 登录及创建用户功能开发\"></a>4. 登录及创建用户功能开发</h1><h2 id=\"4-1-登录功能\"><a href=\"#4-1-登录功能\" class=\"headerlink\" title=\"4.1 登录功能\"></a>4.1 登录功能</h2><h3 id=\"4-1-1-查看前端代码\"><a href=\"#4-1-1-查看前端代码\" class=\"headerlink\" title=\"4.1.1 查看前端代码\"></a>4.1.1 查看前端代码</h3><ul>\n<li><p>首先在resources&#x2F;static&#x2F;pages&#x2F;login&#x2F;index.html查看登录按钮的动作：发现是调用了onLogin函数。</p>\n</li>\n<li><p>进入.&#x2F;index.js查看该函数：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/1.png\"></p>\n</li>\n</ul>\n<h3 id=\"4-1-2-编写UserController-userLogin方法（control层）\"><a href=\"#4-1-2-编写UserController-userLogin方法（control层）\" class=\"headerlink\" title=\"4.1.2 编写UserController.userLogin方法（control层）\"></a>4.1.2 编写UserController.userLogin方法（control层）</h3><ul>\n<li><p>然后我们到biz&#x2F;user&#x2F;controller&#x2F;UserController，其中有</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping(&quot;/admin&quot;)</span> <span class=\"comment\">//使用request请求</span></span><br></pre></td></tr></table></figure>\n\n<p>对应&#x2F;admin路径。然后我们找到其中的userLogin方法，进行编写：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/userLogin&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123; <span class=\"comment\">//requestbody注解，将请求的json数据转换为对象</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"comment\">//TODO</span></span><br><span class=\"line\">    List&lt;UserInfo&gt; userInfos = userService.queryUserList(userInfo); <span class=\"comment\">//使用service层的方法查询用户信息</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(userInfos.size() != <span class=\"number\">0</span>) &#123;<span class=\"comment\">//如果查询到用户信息则状态码为666，否则为默认值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">        httpResponseEntity.setData(userInfos.get(<span class=\"number\">0</span>));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;<span class=\"comment\">//传给前端</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后进行调试，可以先在该方法内打个断点，然后调试，进入 <a href=\"http://127.0.0.1:8085/pages/login/index.html%EF%BC%8C%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%EF%BC%8C%E7%A1%AE%E8%AE%A4%E5%90%8E%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C%E5%88%B0%E4%BA%86%E6%96%AD%E7%82%B9%E5%A4%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%8BuserInfo%E5%8F%98%E9%87%8F%E6%98%AF%E5%90%A6%E8%83%BD%E8%8E%B7%E5%BE%97%E3%80%82\">http://127.0.0.1:8085/pages/login/index.html，输入用户名密码，确认后可以看到代码运行到了断点处，可以查看一下userInfo变量是否能获得。</a></p>\n<ul>\n<li><p>注意：如果你输入了localhost而非127.0.0.1你可能会发现代码没有运行到断点处，无法查看变量。在浏览器打开检查页面。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/2.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4-1-3-编写userserviceImpl-queryUserList方法（service层）\"><a href=\"#4-1-3-编写userserviceImpl-queryUserList方法（service层）\" class=\"headerlink\" title=\"4.1.3 编写userserviceImpl.queryUserList方法（service层）\"></a>4.1.3 编写userserviceImpl.queryUserList方法（service层）</h3><ul>\n<li><p>具体查询是在userserviceImpl.queryUserList中实现的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询用户列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> userInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;<span class=\"comment\">//1. 用userInof查询数据库</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">UserInfoExample</span> <span class=\"variable\">userInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfoExample</span>(); <span class=\"comment\">//3 在dbmap/entities里面是有userinfoexample的</span></span><br><span class=\"line\">        UserInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">userInfoCriteria</span> <span class=\"operator\">=</span> userInfoExample.createCriteria(); <span class=\"comment\">//4 然后用这个example创建一个条件</span></span><br><span class=\"line\">        userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) <span class=\"comment\">//根据这两个条件进行查询</span></span><br><span class=\"line\">                        .andPasswordEqualTo(userInfo.getPassword());</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> userInfoMapper.selectByExample(userInfoExample);<span class=\"comment\">//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"4-1-4-调试结果\"><a href=\"#4-1-4-调试结果\" class=\"headerlink\" title=\"4.1.4 调试结果\"></a>4.1.4 调试结果</h3><ul>\n<li><p>然后继续在usercontroller的返回那一行打个断点，继续调试，发现确认用户名密码后发生错误，调试终止。这是因为一些xml文件放在了java包下面，无法编译到工程中，需要在项目根目录的pom.xml的<build>中加入以下代码：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">filtering</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">filtering</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>src/main/resources<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/3.png\"></p>\n<p>然后刷新maven即可。</p>\n</li>\n<li><p>此时发现userInfos的id是0，说明查询数据库成功了（id值来自数据库）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/4.png\"></p>\n<ul>\n<li><p>然后点击调试控制台的恢复程序按钮</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/5.png\"> </p>\n<p>发现前端页面跳转：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/6.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-2-创建用户功能\"><a href=\"#4-2-创建用户功能\" class=\"headerlink\" title=\"4.2 创建用户功能\"></a>4.2 创建用户功能</h2><h3 id=\"4-2-1-查看前端代码\"><a href=\"#4-2-1-查看前端代码\" class=\"headerlink\" title=\"4.2.1 查看前端代码\"></a>4.2.1 查看前端代码</h3><ul>\n<li><p>发现路径是admin&#x2F;addUserInfo，参照4.1的经验，我们接下来要找control层的addUserInfo方法</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/4/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/4/7.png\"></p>\n</li>\n</ul>\n<h3 id=\"4-2-2-编写UserController-userLogin方法（control层）\"><a href=\"#4-2-2-编写UserController-userLogin方法（control层）\" class=\"headerlink\" title=\"4.2.2 编写UserController.userLogin方法（control层）\"></a>4.2.2 编写UserController.userLogin方法（control层）</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addUserInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">count</span> <span class=\"operator\">=</span> userService.addUserInfo(userInfo); <span class=\"comment\">//返回受影响的行数</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(count &gt; <span class=\"number\">0</span>) &#123; <span class=\"comment\">//插入成功则状态码为666，否则为默认错误值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-2-3-编写userserviceImpl-addUserInfo方法（service层）\"><a href=\"#4-2-3-编写userserviceImpl-addUserInfo方法（service层）\" class=\"headerlink\" title=\"4.2.3 编写userserviceImpl.addUserInfo方法（service层）\"></a>4.2.3 编写userserviceImpl.addUserInfo方法（service层）</h3><ul>\n<li><p>由于数据库设计问题，每次插入数据都需要一个userid，userid不是自动编号的，需要自己写入，而前端没有写入，因此我们还需要一个在后端生成userid的方法在后端。为此我们创建src&#x2F;main&#x2F;java&#x2F;com&#x2F;lyingedu&#x2F;questionnaire&#x2F;common&#x2F;utils&#x2F;UUIDUtil.java:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.common.utils;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.UUID;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">UUIDUtil</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     *获取一个UUID</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title function_\">getOneUUID</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//获取UUID</span></span><br><span class=\"line\">        <span class=\"type\">String</span> <span class=\"variable\">s</span> <span class=\"operator\">=</span> UUID.randomUUID().toString();</span><br><span class=\"line\">        <span class=\"comment\">//去掉“-”符号</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> s.substring(<span class=\"number\">0</span>,<span class=\"number\">8</span>)+s.substring(<span class=\"number\">9</span>,<span class=\"number\">13</span>)+s.substring(<span class=\"number\">14</span>,<span class=\"number\">18</span>)+s.substring(<span class=\"number\">19</span>,<span class=\"number\">23</span>)+s.substring(<span class=\"number\">24</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获得指定数目的UUID</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> number int 需要获得的UUID数量</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> String[] UUID数组</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String[] getUUID(<span class=\"type\">int</span> number)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number &lt; <span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        String[] ss = <span class=\"keyword\">new</span> <span class=\"title class_\">String</span>[number];</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;number;i++)&#123;</span><br><span class=\"line\">            ss[i] = getOneUUID();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ss;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后我们再来编写userserviceImpl.addUserInfo方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">    userInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">    userInfo.setStatus(<span class=\"string\">&quot;1&quot;</span>);<span class=\"comment\">//1有效，0无效</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.insert(userInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>最后还需要将index.js里面的两句判断状态码从1改成自己的666：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (res.<span class=\"property\">code</span> === <span class=\"string\">&quot;666&quot;</span>) &#123;</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"生产实习-2 引入静态资源","date":"2024-03-04T00:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 2. 引入静态资源\n\n## 2.1 引入静态资源\n\n1. 将静态文件粘贴到static目录\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/1.png)\n\n   ![](img/java/produce_practice/2/1.png)\n\n2. 查看程序访问路径：8085端口\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/2.png)\n\n   ![](img/java/produce_practice/2/2.png)\n\n3. 修改程序配置文件的端口配置为8085\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/3.png)\n\n   ![](img/java/produce_practice/2/3.png)\n\n4. 运行并访问 ：http://127.0.0.1:8085/pages/login/index.html，能显示登录页面就ok\n\n   \n\n## 2.2 连接数据库\n\n1. 创建数据库myweb并创建两个表并插入一条数据\n\n   ```sql\n   CREATE TABLE IF NOT EXISTS `myweb`.`user_info` (\n     `id` VARCHAR(40) NOT NULL,\n     `username` VARCHAR(255) NULL,\n     `password` VARCHAR(255) NULL,\n     `start_time` DATETIME NULL,\n     `stop_time` DATETIME NULL,\n     `status` VARCHAR(255) NULL,\n     `created_by` VARCHAR(255) NULL,\n     `creation_date` DATETIME NULL,\n     `last_update_by` VARCHAR(255) NULL,\n     `last_update_date` DATETIME NULL,\n     PRIMARY KEY (`id`))\n   ENGINE = InnoDB\n   \n   INSERT INTO user_info (id, username,password)\n   VALUES ('0', 'admin', '1');\n   ```\n   \n2. 更改配置文件中数据库名：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/4.png)\n\n   ![](img/java/produce_practice/2/4.png) \n\n3. 所有工程文件都在main/java/com/lyingedu.questionnaire下。在这里创建如下目录结构：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/5.png)\n\n   ![](img/java/produce_practice/2/5.png)\n\n4. 使用dbgen工具将数据库导入工程：\n\n  - 用idea打开dbgen工具\n  \n  - 对myweb.xml做如下修改：\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/6.png)\n  \n    ![](img/java/produce_practice/2/6.png)\n  \n  - 修改配置文件，运行（注意数据库地址端口用户名密码都不能错）\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/7.png)\n  \n    ![](img/java/produce_practice/2/7.png)\n  \n  - 运行完成后会发现在主项目的questionnaire下多出了一个dbmap文件夹：\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/8.png)\n  \n    ![](img/java/produce_practice/2/8.png)\n\n5. 数据库实体用户在生成后需要对这些对实体映射进行一些配置（不然无法在开发过程中引用）\n\n   - 指定数据库配置文件的位置：（注意不要把路径中的com/lyingedu写成了com.lyingedu ！\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/9.png)\n\n     ![](img/java/produce_practice/2/9.png)\n\n   - 在主入口映射接口文件，运行成功则配置ok\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/10.png)\n\n      ![](img/java/produce_practice/2/10.png)  ","source":"_posts/java/produce_practice/2_static.md","raw":"---\ntitle: 生产实习-2 引入静态资源\n\ndate: 2024-3-4 08:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n\n---\n\n#\n<!--more-->\n\n# 2. 引入静态资源\n\n## 2.1 引入静态资源\n\n1. 将静态文件粘贴到static目录\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/1.png)\n\n   ![](img/java/produce_practice/2/1.png)\n\n2. 查看程序访问路径：8085端口\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/2.png)\n\n   ![](img/java/produce_practice/2/2.png)\n\n3. 修改程序配置文件的端口配置为8085\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/3.png)\n\n   ![](img/java/produce_practice/2/3.png)\n\n4. 运行并访问 ：http://127.0.0.1:8085/pages/login/index.html，能显示登录页面就ok\n\n   \n\n## 2.2 连接数据库\n\n1. 创建数据库myweb并创建两个表并插入一条数据\n\n   ```sql\n   CREATE TABLE IF NOT EXISTS `myweb`.`user_info` (\n     `id` VARCHAR(40) NOT NULL,\n     `username` VARCHAR(255) NULL,\n     `password` VARCHAR(255) NULL,\n     `start_time` DATETIME NULL,\n     `stop_time` DATETIME NULL,\n     `status` VARCHAR(255) NULL,\n     `created_by` VARCHAR(255) NULL,\n     `creation_date` DATETIME NULL,\n     `last_update_by` VARCHAR(255) NULL,\n     `last_update_date` DATETIME NULL,\n     PRIMARY KEY (`id`))\n   ENGINE = InnoDB\n   \n   INSERT INTO user_info (id, username,password)\n   VALUES ('0', 'admin', '1');\n   ```\n   \n2. 更改配置文件中数据库名：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/4.png)\n\n   ![](img/java/produce_practice/2/4.png) \n\n3. 所有工程文件都在main/java/com/lyingedu.questionnaire下。在这里创建如下目录结构：\n\n   ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/5.png)\n\n   ![](img/java/produce_practice/2/5.png)\n\n4. 使用dbgen工具将数据库导入工程：\n\n  - 用idea打开dbgen工具\n  \n  - 对myweb.xml做如下修改：\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/6.png)\n  \n    ![](img/java/produce_practice/2/6.png)\n  \n  - 修改配置文件，运行（注意数据库地址端口用户名密码都不能错）\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/7.png)\n  \n    ![](img/java/produce_practice/2/7.png)\n  \n  - 运行完成后会发现在主项目的questionnaire下多出了一个dbmap文件夹：\n  \n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/8.png)\n  \n    ![](img/java/produce_practice/2/8.png)\n\n5. 数据库实体用户在生成后需要对这些对实体映射进行一些配置（不然无法在开发过程中引用）\n\n   - 指定数据库配置文件的位置：（注意不要把路径中的com/lyingedu写成了com.lyingedu ！\n\n     ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/9.png)\n\n     ![](img/java/produce_practice/2/9.png)\n\n   - 在主入口映射接口文件，运行成功则配置ok\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/2/10.png)\n\n      ![](img/java/produce_practice/2/10.png)  ","slug":"java/produce_practice/2_static","published":1,"updated":"2024-03-08T02:13:24.383Z","_id":"cltfntnt10003ccvwfyr14vy1","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"2-引入静态资源\"><a href=\"#2-引入静态资源\" class=\"headerlink\" title=\"2. 引入静态资源\"></a>2. 引入静态资源</h1><h2 id=\"2-1-引入静态资源\"><a href=\"#2-1-引入静态资源\" class=\"headerlink\" title=\"2.1 引入静态资源\"></a>2.1 引入静态资源</h2><ol>\n<li><p>将静态文件粘贴到static目录</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/1.png\"></p>\n</li>\n<li><p>查看程序访问路径：8085端口</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/2.png\"></p>\n</li>\n<li><p>修改程序配置文件的端口配置为8085</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/3.png\"></p>\n</li>\n<li><p>运行并访问 ：<a href=\"http://127.0.0.1:8085/pages/login/index.html%EF%BC%8C%E8%83%BD%E6%98%BE%E7%A4%BA%E7%99%BB%E5%BD%95%E9%A1%B5%E9%9D%A2%E5%B0%B1ok\">http://127.0.0.1:8085/pages/login/index.html，能显示登录页面就ok</a></p>\n</li>\n</ol>\n<h2 id=\"2-2-连接数据库\"><a href=\"#2-2-连接数据库\" class=\"headerlink\" title=\"2.2 连接数据库\"></a>2.2 连接数据库</h2><ol>\n<li><p>创建数据库myweb并创建两个表并插入一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> `myweb`.`user_info` (</span><br><span class=\"line\">  `id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">40</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `username` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `password` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `start_time` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `stop_time` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `status` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `created_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `creation_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`))</span><br><span class=\"line\">ENGINE <span class=\"operator\">=</span> InnoDB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> user_info (id, username,password)</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"string\">&#x27;0&#x27;</span>, <span class=\"string\">&#x27;admin&#x27;</span>, <span class=\"string\">&#x27;1&#x27;</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>更改配置文件中数据库名：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/4.png\"> </p>\n</li>\n<li><p>所有工程文件都在main&#x2F;java&#x2F;com&#x2F;lyingedu.questionnaire下。在这里创建如下目录结构：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/5.png\"></p>\n</li>\n<li><p>使用dbgen工具将数据库导入工程：</p>\n</li>\n</ol>\n<ul>\n<li><p>用idea打开dbgen工具</p>\n</li>\n<li><p>对myweb.xml做如下修改：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/6.png\"></p>\n</li>\n<li><p>修改配置文件，运行（注意数据库地址端口用户名密码都不能错）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/7.png\"></p>\n</li>\n<li><p>运行完成后会发现在主项目的questionnaire下多出了一个dbmap文件夹：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/8.png\"></p>\n</li>\n</ul>\n<ol start=\"5\">\n<li><p>数据库实体用户在生成后需要对这些对实体映射进行一些配置（不然无法在开发过程中引用）</p>\n<ul>\n<li><p>指定数据库配置文件的位置：（注意不要把路径中的com&#x2F;lyingedu写成了com.lyingedu ！</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/9.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/9.png\"></p>\n</li>\n<li><p>在主入口映射接口文件，运行成功则配置ok</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/10.png\"></p>\n<p> <img src=\"/img/java/produce_practice/2/10.png\"></p>\n</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"2-引入静态资源\"><a href=\"#2-引入静态资源\" class=\"headerlink\" title=\"2. 引入静态资源\"></a>2. 引入静态资源</h1><h2 id=\"2-1-引入静态资源\"><a href=\"#2-1-引入静态资源\" class=\"headerlink\" title=\"2.1 引入静态资源\"></a>2.1 引入静态资源</h2><ol>\n<li><p>将静态文件粘贴到static目录</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/1.png\"></p>\n</li>\n<li><p>查看程序访问路径：8085端口</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/2.png\"></p>\n</li>\n<li><p>修改程序配置文件的端口配置为8085</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/3.png\"></p>\n</li>\n<li><p>运行并访问 ：<a href=\"http://127.0.0.1:8085/pages/login/index.html%EF%BC%8C%E8%83%BD%E6%98%BE%E7%A4%BA%E7%99%BB%E5%BD%95%E9%A1%B5%E9%9D%A2%E5%B0%B1ok\">http://127.0.0.1:8085/pages/login/index.html，能显示登录页面就ok</a></p>\n</li>\n</ol>\n<h2 id=\"2-2-连接数据库\"><a href=\"#2-2-连接数据库\" class=\"headerlink\" title=\"2.2 连接数据库\"></a>2.2 连接数据库</h2><ol>\n<li><p>创建数据库myweb并创建两个表并插入一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> `myweb`.`user_info` (</span><br><span class=\"line\">  `id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">40</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `username` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `password` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `start_time` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `stop_time` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `status` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `created_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `creation_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">255</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`))</span><br><span class=\"line\">ENGINE <span class=\"operator\">=</span> InnoDB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> user_info (id, username,password)</span><br><span class=\"line\"><span class=\"keyword\">VALUES</span> (<span class=\"string\">&#x27;0&#x27;</span>, <span class=\"string\">&#x27;admin&#x27;</span>, <span class=\"string\">&#x27;1&#x27;</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>更改配置文件中数据库名：</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/4.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/4.png\"> </p>\n</li>\n<li><p>所有工程文件都在main&#x2F;java&#x2F;com&#x2F;lyingedu.questionnaire下。在这里创建如下目录结构：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/5.png\"></p>\n</li>\n<li><p>使用dbgen工具将数据库导入工程：</p>\n</li>\n</ol>\n<ul>\n<li><p>用idea打开dbgen工具</p>\n</li>\n<li><p>对myweb.xml做如下修改：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/6.png\"></p>\n</li>\n<li><p>修改配置文件，运行（注意数据库地址端口用户名密码都不能错）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/7.png\"></p>\n</li>\n<li><p>运行完成后会发现在主项目的questionnaire下多出了一个dbmap文件夹：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/8.png\"></p>\n</li>\n</ul>\n<ol start=\"5\">\n<li><p>数据库实体用户在生成后需要对这些对实体映射进行一些配置（不然无法在开发过程中引用）</p>\n<ul>\n<li><p>指定数据库配置文件的位置：（注意不要把路径中的com&#x2F;lyingedu写成了com.lyingedu ！</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/9.png\"></p>\n<p><img src=\"/img/java/produce_practice/2/9.png\"></p>\n</li>\n<li><p>在主入口映射接口文件，运行成功则配置ok</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/2/10.png\"></p>\n<p> <img src=\"/img/java/produce_practice/2/10.png\"></p>\n</li>\n</ul>\n</li>\n</ol>"},{"title":"生产实习-5 用户管理功能","date":"2024-03-05T03:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n\n\n# 5. 用户管理功能\n\n## 5.1 用户列表功能\n\n- 查看pages/user/index.js可以看到需要完成的函数是：queryUserList\n\n### 5.1.1 control层queryUserList\n\n```java\n    @PostMapping(\"/queryUserList\")\n    public HttpResponseEntity queryUserList(@RequestBody UserInfo userInfo){\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n\n        List<UserInfo> userInfos = userService.queryUserList(userInfo);\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setData(userInfos);\n\n        return httpResponseEntity;\n    }\n```\n\n### 5.1.2 server层queryUserList\n\n```java\n    public List<UserInfo> queryUserList(UserInfo userInfo) {//1. 用userInof查询数据库\n\n        UserInfoExample userInfoExample = new UserInfoExample(); //3 在dbmap/entities里面是有userinfoexample的\n\n        if(userInfo.getUsername()!=null){//登录\n            UserInfoExample.Criteria userInfoCriteria = userInfoExample.createCriteria(); //4 然后用这个example创建一个条件\n            userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) //根据这两个条件进行查询\n                    .andPasswordEqualTo(userInfo.getPassword());\n        }\n        //没有条件的就是全查\n\n        return userInfoMapper.selectByExample(userInfoExample);//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询\n    }\n```\n\n## 5.2 用户编辑\n\n- 首先在浏览器检查源码，查看编辑用户按钮调用的是哪个函数（handleEdit)：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/1.png)\n\n  ![](img/java/produce_practice/5/1.png)\n\n  - 在pages/user/index.js里面也可以看到编辑按钮对应的是handleEdit，然后在handleEdit里面发现又跳转到创建用户页。\n  - 然后去createUser/index.html里面看到创建用户按钮对应index.js下的handleCreateUser函数，在handleCreateUser函数里面判断，如果传入了user.id说明是要修改，没传入则是要新建，在修改部分找到路径：/admin/modifyUserInfo。\n\n### 5.2.1 control层modifyUserInfo\n\n```java\n    @PostMapping(\"/modifyUserInfo\")\n    public HttpResponseEntity modifyUserInfo(@RequestBody UserInfo userInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        userService.modifyUserInfo(userInfo);\n        httpResponseEntity.setCode(\"666\");\n        return httpResponseEntity;\n    }\n```\n\n### 5.2.2 service层modifyUserInfo\n\n```java\n    public int modifyUserInfo(UserInfo userInfo) {\n        //根据主键修改，只修改提供的部分，不提供的部分不修改，不带selective的方法对于不提供的部分默认改成null\n        return userInfoMapper.updateByPrimaryKeySelective(userInfo);\n    }\n```\n\n## 5.3 删除用户\n\n- 同理，在user/index.js里面找到删除按钮，对应deleteUser函数，在deleteUser函数中找到路径admin/deleteUserinfo，所以要写deleteUserinfo函数\n\n### 5.3.1 control层deleteUserinfo\n\n```java\n    @PostMapping(\"/deleteUserinfo\")\n    public HttpResponseEntity deleteUserById(@RequestBody UserInfo userInfo) {\n        \n        userService.deleteUserById(userInfo.getId());\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        httpResponseEntity.setCode(\"666\");\n        \n        return httpResponseEntity;\n    }\n```\n\n\n\n### 5.3.2 server层deleteUserinfo\n\n```java\n    public int deleteUserById(String id) {\n        return userInfoMapper.deleteByPrimaryKey(id);\n        \n    }\n```","source":"_posts/java/produce_practice/5_usermanage.md","raw":"---\ntitle: 生产实习-5 用户管理功能\n\ndate: 2024-3-5 11:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n\n\n# 5. 用户管理功能\n\n## 5.1 用户列表功能\n\n- 查看pages/user/index.js可以看到需要完成的函数是：queryUserList\n\n### 5.1.1 control层queryUserList\n\n```java\n    @PostMapping(\"/queryUserList\")\n    public HttpResponseEntity queryUserList(@RequestBody UserInfo userInfo){\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n\n        List<UserInfo> userInfos = userService.queryUserList(userInfo);\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setData(userInfos);\n\n        return httpResponseEntity;\n    }\n```\n\n### 5.1.2 server层queryUserList\n\n```java\n    public List<UserInfo> queryUserList(UserInfo userInfo) {//1. 用userInof查询数据库\n\n        UserInfoExample userInfoExample = new UserInfoExample(); //3 在dbmap/entities里面是有userinfoexample的\n\n        if(userInfo.getUsername()!=null){//登录\n            UserInfoExample.Criteria userInfoCriteria = userInfoExample.createCriteria(); //4 然后用这个example创建一个条件\n            userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) //根据这两个条件进行查询\n                    .andPasswordEqualTo(userInfo.getPassword());\n        }\n        //没有条件的就是全查\n\n        return userInfoMapper.selectByExample(userInfoExample);//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询\n    }\n```\n\n## 5.2 用户编辑\n\n- 首先在浏览器检查源码，查看编辑用户按钮调用的是哪个函数（handleEdit)：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/1.png)\n\n  ![](img/java/produce_practice/5/1.png)\n\n  - 在pages/user/index.js里面也可以看到编辑按钮对应的是handleEdit，然后在handleEdit里面发现又跳转到创建用户页。\n  - 然后去createUser/index.html里面看到创建用户按钮对应index.js下的handleCreateUser函数，在handleCreateUser函数里面判断，如果传入了user.id说明是要修改，没传入则是要新建，在修改部分找到路径：/admin/modifyUserInfo。\n\n### 5.2.1 control层modifyUserInfo\n\n```java\n    @PostMapping(\"/modifyUserInfo\")\n    public HttpResponseEntity modifyUserInfo(@RequestBody UserInfo userInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        userService.modifyUserInfo(userInfo);\n        httpResponseEntity.setCode(\"666\");\n        return httpResponseEntity;\n    }\n```\n\n### 5.2.2 service层modifyUserInfo\n\n```java\n    public int modifyUserInfo(UserInfo userInfo) {\n        //根据主键修改，只修改提供的部分，不提供的部分不修改，不带selective的方法对于不提供的部分默认改成null\n        return userInfoMapper.updateByPrimaryKeySelective(userInfo);\n    }\n```\n\n## 5.3 删除用户\n\n- 同理，在user/index.js里面找到删除按钮，对应deleteUser函数，在deleteUser函数中找到路径admin/deleteUserinfo，所以要写deleteUserinfo函数\n\n### 5.3.1 control层deleteUserinfo\n\n```java\n    @PostMapping(\"/deleteUserinfo\")\n    public HttpResponseEntity deleteUserById(@RequestBody UserInfo userInfo) {\n        \n        userService.deleteUserById(userInfo.getId());\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        httpResponseEntity.setCode(\"666\");\n        \n        return httpResponseEntity;\n    }\n```\n\n\n\n### 5.3.2 server层deleteUserinfo\n\n```java\n    public int deleteUserById(String id) {\n        return userInfoMapper.deleteByPrimaryKey(id);\n        \n    }\n```","slug":"java/produce_practice/5_usermanage","published":1,"updated":"2024-03-05T12:16:12.394Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltfntnt20005ccvwetgrbrzt","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<h1 id=\"5-用户管理功能\"><a href=\"#5-用户管理功能\" class=\"headerlink\" title=\"5. 用户管理功能\"></a>5. 用户管理功能</h1><h2 id=\"5-1-用户列表功能\"><a href=\"#5-1-用户列表功能\" class=\"headerlink\" title=\"5.1 用户列表功能\"></a>5.1 用户列表功能</h2><ul>\n<li>查看pages&#x2F;user&#x2F;index.js可以看到需要完成的函数是：queryUserList</li>\n</ul>\n<h3 id=\"5-1-1-control层queryUserList\"><a href=\"#5-1-1-control层queryUserList\" class=\"headerlink\" title=\"5.1.1 control层queryUserList\"></a>5.1.1 control层queryUserList</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/queryUserList&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryUserList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;UserInfo&gt; userInfos = userService.queryUserList(userInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setData(userInfos);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-1-2-server层queryUserList\"><a href=\"#5-1-2-server层queryUserList\" class=\"headerlink\" title=\"5.1.2 server层queryUserList\"></a>5.1.2 server层queryUserList</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;<span class=\"comment\">//1. 用userInof查询数据库</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">UserInfoExample</span> <span class=\"variable\">userInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfoExample</span>(); <span class=\"comment\">//3 在dbmap/entities里面是有userinfoexample的</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(userInfo.getUsername()!=<span class=\"literal\">null</span>)&#123;<span class=\"comment\">//登录</span></span><br><span class=\"line\">        UserInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">userInfoCriteria</span> <span class=\"operator\">=</span> userInfoExample.createCriteria(); <span class=\"comment\">//4 然后用这个example创建一个条件</span></span><br><span class=\"line\">        userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) <span class=\"comment\">//根据这两个条件进行查询</span></span><br><span class=\"line\">                .andPasswordEqualTo(userInfo.getPassword());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//没有条件的就是全查</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.selectByExample(userInfoExample);<span class=\"comment\">//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-用户编辑\"><a href=\"#5-2-用户编辑\" class=\"headerlink\" title=\"5.2 用户编辑\"></a>5.2 用户编辑</h2><ul>\n<li><p>首先在浏览器检查源码，查看编辑用户按钮调用的是哪个函数（handleEdit)：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/5/1.png\"></p>\n<ul>\n<li>在pages&#x2F;user&#x2F;index.js里面也可以看到编辑按钮对应的是handleEdit，然后在handleEdit里面发现又跳转到创建用户页。</li>\n<li>然后去createUser&#x2F;index.html里面看到创建用户按钮对应index.js下的handleCreateUser函数，在handleCreateUser函数里面判断，如果传入了user.id说明是要修改，没传入则是要新建，在修改部分找到路径：&#x2F;admin&#x2F;modifyUserInfo。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"5-2-1-control层modifyUserInfo\"><a href=\"#5-2-1-control层modifyUserInfo\" class=\"headerlink\" title=\"5.2.1 control层modifyUserInfo\"></a>5.2.1 control层modifyUserInfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/modifyUserInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    userService.modifyUserInfo(userInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-2-service层modifyUserInfo\"><a href=\"#5-2-2-service层modifyUserInfo\" class=\"headerlink\" title=\"5.2.2 service层modifyUserInfo\"></a>5.2.2 service层modifyUserInfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">//根据主键修改，只修改提供的部分，不提供的部分不修改，不带selective的方法对于不提供的部分默认改成null</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.updateByPrimaryKeySelective(userInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-3-删除用户\"><a href=\"#5-3-删除用户\" class=\"headerlink\" title=\"5.3 删除用户\"></a>5.3 删除用户</h2><ul>\n<li>同理，在user&#x2F;index.js里面找到删除按钮，对应deleteUser函数，在deleteUser函数中找到路径admin&#x2F;deleteUserinfo，所以要写deleteUserinfo函数</li>\n</ul>\n<h3 id=\"5-3-1-control层deleteUserinfo\"><a href=\"#5-3-1-control层deleteUserinfo\" class=\"headerlink\" title=\"5.3.1 control层deleteUserinfo\"></a>5.3.1 control层deleteUserinfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/deleteUserinfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteUserById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    userService.deleteUserById(userInfo.getId());</span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"5-3-2-server层deleteUserinfo\"><a href=\"#5-3-2-server层deleteUserinfo\" class=\"headerlink\" title=\"5.3.2 server层deleteUserinfo\"></a>5.3.2 server层deleteUserinfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.deleteByPrimaryKey(id);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"5-用户管理功能\"><a href=\"#5-用户管理功能\" class=\"headerlink\" title=\"5. 用户管理功能\"></a>5. 用户管理功能</h1><h2 id=\"5-1-用户列表功能\"><a href=\"#5-1-用户列表功能\" class=\"headerlink\" title=\"5.1 用户列表功能\"></a>5.1 用户列表功能</h2><ul>\n<li>查看pages&#x2F;user&#x2F;index.js可以看到需要完成的函数是：queryUserList</li>\n</ul>\n<h3 id=\"5-1-1-control层queryUserList\"><a href=\"#5-1-1-control层queryUserList\" class=\"headerlink\" title=\"5.1.1 control层queryUserList\"></a>5.1.1 control层queryUserList</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/queryUserList&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryUserList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;UserInfo&gt; userInfos = userService.queryUserList(userInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setData(userInfos);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-1-2-server层queryUserList\"><a href=\"#5-1-2-server层queryUserList\" class=\"headerlink\" title=\"5.1.2 server层queryUserList\"></a>5.1.2 server层queryUserList</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> List&lt;UserInfo&gt; <span class=\"title function_\">queryUserList</span><span class=\"params\">(UserInfo userInfo)</span> &#123;<span class=\"comment\">//1. 用userInof查询数据库</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">UserInfoExample</span> <span class=\"variable\">userInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfoExample</span>(); <span class=\"comment\">//3 在dbmap/entities里面是有userinfoexample的</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(userInfo.getUsername()!=<span class=\"literal\">null</span>)&#123;<span class=\"comment\">//登录</span></span><br><span class=\"line\">        UserInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">userInfoCriteria</span> <span class=\"operator\">=</span> userInfoExample.createCriteria(); <span class=\"comment\">//4 然后用这个example创建一个条件</span></span><br><span class=\"line\">        userInfoCriteria.andUsernameEqualTo(userInfo.getUsername()) <span class=\"comment\">//根据这两个条件进行查询</span></span><br><span class=\"line\">                .andPasswordEqualTo(userInfo.getPassword());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//没有条件的就是全查</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.selectByExample(userInfoExample);<span class=\"comment\">//2 使用userInfoMapper里面自带一些方法，使用里面的selectbyexample查询</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-用户编辑\"><a href=\"#5-2-用户编辑\" class=\"headerlink\" title=\"5.2 用户编辑\"></a>5.2 用户编辑</h2><ul>\n<li><p>首先在浏览器检查源码，查看编辑用户按钮调用的是哪个函数（handleEdit)：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/5/1.png\"></p>\n<ul>\n<li>在pages&#x2F;user&#x2F;index.js里面也可以看到编辑按钮对应的是handleEdit，然后在handleEdit里面发现又跳转到创建用户页。</li>\n<li>然后去createUser&#x2F;index.html里面看到创建用户按钮对应index.js下的handleCreateUser函数，在handleCreateUser函数里面判断，如果传入了user.id说明是要修改，没传入则是要新建，在修改部分找到路径：&#x2F;admin&#x2F;modifyUserInfo。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"5-2-1-control层modifyUserInfo\"><a href=\"#5-2-1-control层modifyUserInfo\" class=\"headerlink\" title=\"5.2.1 control层modifyUserInfo\"></a>5.2.1 control层modifyUserInfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/modifyUserInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    userService.modifyUserInfo(userInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-2-service层modifyUserInfo\"><a href=\"#5-2-2-service层modifyUserInfo\" class=\"headerlink\" title=\"5.2.2 service层modifyUserInfo\"></a>5.2.2 service层modifyUserInfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyUserInfo</span><span class=\"params\">(UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">//根据主键修改，只修改提供的部分，不提供的部分不修改，不带selective的方法对于不提供的部分默认改成null</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.updateByPrimaryKeySelective(userInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5-3-删除用户\"><a href=\"#5-3-删除用户\" class=\"headerlink\" title=\"5.3 删除用户\"></a>5.3 删除用户</h2><ul>\n<li>同理，在user&#x2F;index.js里面找到删除按钮，对应deleteUser函数，在deleteUser函数中找到路径admin&#x2F;deleteUserinfo，所以要写deleteUserinfo函数</li>\n</ul>\n<h3 id=\"5-3-1-control层deleteUserinfo\"><a href=\"#5-3-1-control层deleteUserinfo\" class=\"headerlink\" title=\"5.3.1 control层deleteUserinfo\"></a>5.3.1 control层deleteUserinfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/deleteUserinfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteUserById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    userService.deleteUserById(userInfo.getId());</span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"5-3-2-server层deleteUserinfo\"><a href=\"#5-3-2-server层deleteUserinfo\" class=\"headerlink\" title=\"5.3.2 server层deleteUserinfo\"></a>5.3.2 server层deleteUserinfo</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteUserById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> userInfoMapper.deleteByPrimaryKey(id);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"生产实习-6 单元测试与log日志输出","date":"2024-03-05T04:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n\n\n# 6. 单元测试与log日志输出\n\n\n\n## 6.1 配置日志文件\n\n- 将logback-spring.xml放到resources下，做如下修改：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/2.png)\n\n  ![](img/java/produce_practice/5/2.png)\n\n- 假设你需要在每次登录的时候都记录日志，那在controller中找到登录方法所在的类，然后在类上面加上@Slf4j的注释，可以发现结构中多了一个log：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/3.png)\n\n    ![](img/java/produce_practice/5/3.png)\n\n- 在登录方法中加入日志记录：\n\n  ```java\n      public HttpResponseEntity userLogin(@RequestBody UserInfo userInfo) { //requestbody注解，将请求的json数据转换为对象\n  \n          log.info(\"用户\" + userInfo.getUsername() + \"登录\");\n  ```\n\n  然后运行项目，登录后可以看到控制台有输出登录信息，并且log目录下也会有日志记录。\n\n## 6.2 单元测试\n\n- 在src/test下可以找到测试类\n\n- 在pom.xml的dependences标签下加入依赖：（记得刷新maven）这样就可以使用@RunWith注解，它可以使用springboot的依赖注入\n\n  ```xml\n  \t\t<dependency>\n  \t\t\t<groupId>junit</groupId>\n  \t\t\t<artifactId>junit</artifactId>\n  \t\t\t<version>4.12</version>\n  \t\t</dependency>\n  ```\n\n- 测试代码：\n\n  ```java\n  package com.lyingedu.questionnaire;\n  \n  import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n  import com.lyingedu.questionnaire.biz.user.controller.UserController;\n  import com.lyingedu.questionnaire.common.utils.UUIDUtil;\n  import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n  import jakarta.annotation.Resource;\n  import lombok.extern.slf4j.Slf4j;\n  import org.junit.Test;\n  import org.junit.runner.RunWith;\n  import org.springframework.boot.test.context.SpringBootTest;\n  import org.springframework.test.context.junit4.SpringRunner;\n  \n  import java.util.Date;\n  import java.util.List;\n  \n  @Slf4j\n  @RunWith(SpringRunner.class) //这样可以用springboot的依赖注入\n  @SpringBootTest\n  public class QuestionnaireApplicationTests {\n      @Resource\n      private UserController userController;\n  \n      /*\n      * 测试查询功能\n       */\n      @Test //注意使用junit，而不是junit.api\n      public void testQueryUserInfoList(){\n          UserInfo userInfo = new UserInfo();\n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n          if (\"666\".equals(httpResponseEntity.getCode())) {\n              log.info(\">>queryUserList用户列表查询测试成功\");\n          }\n      }\n  \n      /*\n      * 测试用户登录\n       */\n      @Test\n      public void testUserLogin(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"admin\");\n          userInfo.setPassword(\"12\");\n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n          if (\"666\".equals(httpResponseEntity.getCode())) {\n              log.info(\">>selectUserInfo用户\"+userInfo.getUsername()+\"登录测试成功\");\n          }else {\n              log.info(\">>selectUserInfo用户登录测试失败\");\n          }\n      }\n  \n      /*\n      * 测试创建用户\n       */\n      @Test\n      public void testCreateUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setId(UUIDUtil.getOneUUID());\n          userInfo.setUsername(\"test005\");\n          userInfo.setPassword(\"123\");\n          userInfo.setStatus(\"1\");\n          userInfo.setCreatedBy(\"anyone\");\n          userInfo.setCreationDate(new Date());\n          userInfo.setStartTime(new Date());\n          userInfo.setStopTime(new Date());\n          userInfo.setLastUpdateBy(\"anyone\");\n          userInfo.setLastUpdateDate(new Date());\n  \n          HttpResponseEntity httpResponseEntity = userController.addUserInfo(userInfo);\n          if(\"666\".equals(httpResponseEntity.getCode())){\n              log.info(\">>adduserinfo插入用户测试成功\");\n          }\n  \n      }\n  \n      /*\n      * 测试修改用户\n       */\n      @Test\n      public void testUpdUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"test005\");\n          userInfo.setPassword(\"123\");\n  \n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n  \n          if(\"666\".equals(httpResponseEntity.getCode())){//查询成功\n              List list=(List) httpResponseEntity.getData();\n              if(list.size() !=0){\n                  UserInfo data = (UserInfo) list.get(0);\n                  data.setUsername(\"test006\");\n                  HttpResponseEntity httpResponseEntity1 = userController.modifyUserInfo(data);\n                  if(\"666\".equals(httpResponseEntity1.getCode())){\n                      log.info(\">>update修改用户更新测试成功\");\n                  }\n              }\n  \n          }\n      }\n  \n      /*\n      * 测试删除用户\n       */\n      @Test\n      public void testDeleteUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"test006\");\n          userInfo.setPassword(\"123\");\n  \n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n  \n          if(\"666\".equals(httpResponseEntity.getCode())){//查询成功\n              List list=(List) httpResponseEntity.getData();\n              if(list.size() !=0){\n                  UserInfo data = (UserInfo) list.get(0);\n  \n                  HttpResponseEntity httpResponseEntity1 = userController.deleteUserById(data);\n                  if(\"666\".equals(httpResponseEntity1.getCode())){\n                      log.info(\">>delete用户删除测试成功\");\n                  }\n              }\n  \n          }\n      }\n  }\n  \n  ```\n\n  ","source":"_posts/java/produce_practice/6_testlog.md","raw":"---\ntitle: 生产实习-6 单元测试与log日志输出\n\ndate: 2024-3-5 12:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n\n---\n\n#\n<!--more-->\n\n\n\n# 6. 单元测试与log日志输出\n\n\n\n## 6.1 配置日志文件\n\n- 将logback-spring.xml放到resources下，做如下修改：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/2.png)\n\n  ![](img/java/produce_practice/5/2.png)\n\n- 假设你需要在每次登录的时候都记录日志，那在controller中找到登录方法所在的类，然后在类上面加上@Slf4j的注释，可以发现结构中多了一个log：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/5/3.png)\n\n    ![](img/java/produce_practice/5/3.png)\n\n- 在登录方法中加入日志记录：\n\n  ```java\n      public HttpResponseEntity userLogin(@RequestBody UserInfo userInfo) { //requestbody注解，将请求的json数据转换为对象\n  \n          log.info(\"用户\" + userInfo.getUsername() + \"登录\");\n  ```\n\n  然后运行项目，登录后可以看到控制台有输出登录信息，并且log目录下也会有日志记录。\n\n## 6.2 单元测试\n\n- 在src/test下可以找到测试类\n\n- 在pom.xml的dependences标签下加入依赖：（记得刷新maven）这样就可以使用@RunWith注解，它可以使用springboot的依赖注入\n\n  ```xml\n  \t\t<dependency>\n  \t\t\t<groupId>junit</groupId>\n  \t\t\t<artifactId>junit</artifactId>\n  \t\t\t<version>4.12</version>\n  \t\t</dependency>\n  ```\n\n- 测试代码：\n\n  ```java\n  package com.lyingedu.questionnaire;\n  \n  import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n  import com.lyingedu.questionnaire.biz.user.controller.UserController;\n  import com.lyingedu.questionnaire.common.utils.UUIDUtil;\n  import com.lyingedu.questionnaire.dbmap.entities.UserInfo;\n  import jakarta.annotation.Resource;\n  import lombok.extern.slf4j.Slf4j;\n  import org.junit.Test;\n  import org.junit.runner.RunWith;\n  import org.springframework.boot.test.context.SpringBootTest;\n  import org.springframework.test.context.junit4.SpringRunner;\n  \n  import java.util.Date;\n  import java.util.List;\n  \n  @Slf4j\n  @RunWith(SpringRunner.class) //这样可以用springboot的依赖注入\n  @SpringBootTest\n  public class QuestionnaireApplicationTests {\n      @Resource\n      private UserController userController;\n  \n      /*\n      * 测试查询功能\n       */\n      @Test //注意使用junit，而不是junit.api\n      public void testQueryUserInfoList(){\n          UserInfo userInfo = new UserInfo();\n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n          if (\"666\".equals(httpResponseEntity.getCode())) {\n              log.info(\">>queryUserList用户列表查询测试成功\");\n          }\n      }\n  \n      /*\n      * 测试用户登录\n       */\n      @Test\n      public void testUserLogin(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"admin\");\n          userInfo.setPassword(\"12\");\n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n          if (\"666\".equals(httpResponseEntity.getCode())) {\n              log.info(\">>selectUserInfo用户\"+userInfo.getUsername()+\"登录测试成功\");\n          }else {\n              log.info(\">>selectUserInfo用户登录测试失败\");\n          }\n      }\n  \n      /*\n      * 测试创建用户\n       */\n      @Test\n      public void testCreateUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setId(UUIDUtil.getOneUUID());\n          userInfo.setUsername(\"test005\");\n          userInfo.setPassword(\"123\");\n          userInfo.setStatus(\"1\");\n          userInfo.setCreatedBy(\"anyone\");\n          userInfo.setCreationDate(new Date());\n          userInfo.setStartTime(new Date());\n          userInfo.setStopTime(new Date());\n          userInfo.setLastUpdateBy(\"anyone\");\n          userInfo.setLastUpdateDate(new Date());\n  \n          HttpResponseEntity httpResponseEntity = userController.addUserInfo(userInfo);\n          if(\"666\".equals(httpResponseEntity.getCode())){\n              log.info(\">>adduserinfo插入用户测试成功\");\n          }\n  \n      }\n  \n      /*\n      * 测试修改用户\n       */\n      @Test\n      public void testUpdUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"test005\");\n          userInfo.setPassword(\"123\");\n  \n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n  \n          if(\"666\".equals(httpResponseEntity.getCode())){//查询成功\n              List list=(List) httpResponseEntity.getData();\n              if(list.size() !=0){\n                  UserInfo data = (UserInfo) list.get(0);\n                  data.setUsername(\"test006\");\n                  HttpResponseEntity httpResponseEntity1 = userController.modifyUserInfo(data);\n                  if(\"666\".equals(httpResponseEntity1.getCode())){\n                      log.info(\">>update修改用户更新测试成功\");\n                  }\n              }\n  \n          }\n      }\n  \n      /*\n      * 测试删除用户\n       */\n      @Test\n      public void testDeleteUser(){\n          UserInfo userInfo = new UserInfo();\n          userInfo.setUsername(\"test006\");\n          userInfo.setPassword(\"123\");\n  \n          HttpResponseEntity httpResponseEntity = userController.queryUserList(userInfo);\n  \n          if(\"666\".equals(httpResponseEntity.getCode())){//查询成功\n              List list=(List) httpResponseEntity.getData();\n              if(list.size() !=0){\n                  UserInfo data = (UserInfo) list.get(0);\n  \n                  HttpResponseEntity httpResponseEntity1 = userController.deleteUserById(data);\n                  if(\"666\".equals(httpResponseEntity1.getCode())){\n                      log.info(\">>delete用户删除测试成功\");\n                  }\n              }\n  \n          }\n      }\n  }\n  \n  ```\n\n  ","slug":"java/produce_practice/6_testlog","published":1,"updated":"2024-03-05T14:41:09.469Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltfntnt30008ccvw3vo48p29","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<h1 id=\"6-单元测试与log日志输出\"><a href=\"#6-单元测试与log日志输出\" class=\"headerlink\" title=\"6. 单元测试与log日志输出\"></a>6. 单元测试与log日志输出</h1><h2 id=\"6-1-配置日志文件\"><a href=\"#6-1-配置日志文件\" class=\"headerlink\" title=\"6.1 配置日志文件\"></a>6.1 配置日志文件</h2><ul>\n<li><p>将logback-spring.xml放到resources下，做如下修改：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/5/2.png\"></p>\n</li>\n<li><p>假设你需要在每次登录的时候都记录日志，那在controller中找到登录方法所在的类，然后在类上面加上@Slf4j的注释，可以发现结构中多了一个log：</p>\n<p>  <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/3.png\"></p>\n<p>  <img src=\"/img/java/produce_practice/5/3.png\"></p>\n</li>\n<li><p>在登录方法中加入日志记录：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123; <span class=\"comment\">//requestbody注解，将请求的json数据转换为对象</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    log.info(<span class=\"string\">&quot;用户&quot;</span> + userInfo.getUsername() + <span class=\"string\">&quot;登录&quot;</span>);</span><br></pre></td></tr></table></figure>\n\n<p>然后运行项目，登录后可以看到控制台有输出登录信息，并且log目录下也会有日志记录。</p>\n</li>\n</ul>\n<h2 id=\"6-2-单元测试\"><a href=\"#6-2-单元测试\" class=\"headerlink\" title=\"6.2 单元测试\"></a>6.2 单元测试</h2><ul>\n<li><p>在src&#x2F;test下可以找到测试类</p>\n</li>\n<li><p>在pom.xml的dependences标签下加入依赖：（记得刷新maven）这样就可以使用@RunWith注解，它可以使用springboot的依赖注入</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>4.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>测试代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.controller.UserController;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.common.utils.UUIDUtil;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.runner.RunWith;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.Date;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Slf4j</span></span><br><span class=\"line\"><span class=\"meta\">@RunWith(SpringRunner.class)</span> <span class=\"comment\">//这样可以用springboot的依赖注入</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootTest</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">QuestionnaireApplicationTests</span> &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> UserController userController;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试查询功能</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span> <span class=\"comment\">//注意使用junit，而不是junit.api</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testQueryUserInfoList</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode())) &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;queryUserList用户列表查询测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试用户登录</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testUserLogin</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;admin&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;12&quot;</span>);</span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode())) &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;selectUserInfo用户&quot;</span>+userInfo.getUsername()+<span class=\"string\">&quot;登录测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;selectUserInfo用户登录测试失败&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试创建用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testCreateUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test005&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\">        userInfo.setStatus(<span class=\"string\">&quot;1&quot;</span>);</span><br><span class=\"line\">        userInfo.setCreatedBy(<span class=\"string\">&quot;anyone&quot;</span>);</span><br><span class=\"line\">        userInfo.setCreationDate(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setStartTime(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setStopTime(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setLastUpdateBy(<span class=\"string\">&quot;anyone&quot;</span>);</span><br><span class=\"line\">        userInfo.setLastUpdateDate(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.addUserInfo(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;adduserinfo插入用户测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testUpdUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test005&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;<span class=\"comment\">//查询成功</span></span><br><span class=\"line\">            List list=(List) httpResponseEntity.getData();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(list.size() !=<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">UserInfo</span> <span class=\"variable\">data</span> <span class=\"operator\">=</span> (UserInfo) list.get(<span class=\"number\">0</span>);</span><br><span class=\"line\">                data.setUsername(<span class=\"string\">&quot;test006&quot;</span>);</span><br><span class=\"line\">                <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity1</span> <span class=\"operator\">=</span> userController.modifyUserInfo(data);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity1.getCode()))&#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">&quot;&gt;&gt;update修改用户更新测试成功&quot;</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testDeleteUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test006&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;<span class=\"comment\">//查询成功</span></span><br><span class=\"line\">            List list=(List) httpResponseEntity.getData();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(list.size() !=<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">UserInfo</span> <span class=\"variable\">data</span> <span class=\"operator\">=</span> (UserInfo) list.get(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity1</span> <span class=\"operator\">=</span> userController.deleteUserById(data);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity1.getCode()))&#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">&quot;&gt;&gt;delete用户删除测试成功&quot;</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"6-单元测试与log日志输出\"><a href=\"#6-单元测试与log日志输出\" class=\"headerlink\" title=\"6. 单元测试与log日志输出\"></a>6. 单元测试与log日志输出</h1><h2 id=\"6-1-配置日志文件\"><a href=\"#6-1-配置日志文件\" class=\"headerlink\" title=\"6.1 配置日志文件\"></a>6.1 配置日志文件</h2><ul>\n<li><p>将logback-spring.xml放到resources下，做如下修改：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/5/2.png\"></p>\n</li>\n<li><p>假设你需要在每次登录的时候都记录日志，那在controller中找到登录方法所在的类，然后在类上面加上@Slf4j的注释，可以发现结构中多了一个log：</p>\n<p>  <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/5/3.png\"></p>\n<p>  <img src=\"/img/java/produce_practice/5/3.png\"></p>\n</li>\n<li><p>在登录方法中加入日志记录：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">userLogin</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> UserInfo userInfo)</span> &#123; <span class=\"comment\">//requestbody注解，将请求的json数据转换为对象</span></span><br><span class=\"line\">  </span><br><span class=\"line\">    log.info(<span class=\"string\">&quot;用户&quot;</span> + userInfo.getUsername() + <span class=\"string\">&quot;登录&quot;</span>);</span><br></pre></td></tr></table></figure>\n\n<p>然后运行项目，登录后可以看到控制台有输出登录信息，并且log目录下也会有日志记录。</p>\n</li>\n</ul>\n<h2 id=\"6-2-单元测试\"><a href=\"#6-2-单元测试\" class=\"headerlink\" title=\"6.2 单元测试\"></a>6.2 单元测试</h2><ul>\n<li><p>在src&#x2F;test下可以找到测试类</p>\n</li>\n<li><p>在pom.xml的dependences标签下加入依赖：（记得刷新maven）这样就可以使用@RunWith注解，它可以使用springboot的依赖注入</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>junit<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>4.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>测试代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.controller.UserController;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.common.utils.UUIDUtil;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.UserInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.Test;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.junit.runner.RunWith;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.Date;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Slf4j</span></span><br><span class=\"line\"><span class=\"meta\">@RunWith(SpringRunner.class)</span> <span class=\"comment\">//这样可以用springboot的依赖注入</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootTest</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">QuestionnaireApplicationTests</span> &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> UserController userController;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试查询功能</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span> <span class=\"comment\">//注意使用junit，而不是junit.api</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testQueryUserInfoList</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode())) &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;queryUserList用户列表查询测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试用户登录</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testUserLogin</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;admin&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;12&quot;</span>);</span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode())) &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;selectUserInfo用户&quot;</span>+userInfo.getUsername()+<span class=\"string\">&quot;登录测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;selectUserInfo用户登录测试失败&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试创建用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testCreateUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test005&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\">        userInfo.setStatus(<span class=\"string\">&quot;1&quot;</span>);</span><br><span class=\"line\">        userInfo.setCreatedBy(<span class=\"string\">&quot;anyone&quot;</span>);</span><br><span class=\"line\">        userInfo.setCreationDate(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setStartTime(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setStopTime(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\">        userInfo.setLastUpdateBy(<span class=\"string\">&quot;anyone&quot;</span>);</span><br><span class=\"line\">        userInfo.setLastUpdateDate(<span class=\"keyword\">new</span> <span class=\"title class_\">Date</span>());</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.addUserInfo(userInfo);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;</span><br><span class=\"line\">            log.info(<span class=\"string\">&quot;&gt;&gt;adduserinfo插入用户测试成功&quot;</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试修改用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testUpdUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test005&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;<span class=\"comment\">//查询成功</span></span><br><span class=\"line\">            List list=(List) httpResponseEntity.getData();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(list.size() !=<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">UserInfo</span> <span class=\"variable\">data</span> <span class=\"operator\">=</span> (UserInfo) list.get(<span class=\"number\">0</span>);</span><br><span class=\"line\">                data.setUsername(<span class=\"string\">&quot;test006&quot;</span>);</span><br><span class=\"line\">                <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity1</span> <span class=\"operator\">=</span> userController.modifyUserInfo(data);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity1.getCode()))&#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">&quot;&gt;&gt;update修改用户更新测试成功&quot;</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    * 测试删除用户</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">testDeleteUser</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"type\">UserInfo</span> <span class=\"variable\">userInfo</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">UserInfo</span>();</span><br><span class=\"line\">        userInfo.setUsername(<span class=\"string\">&quot;test006&quot;</span>);</span><br><span class=\"line\">        userInfo.setPassword(<span class=\"string\">&quot;123&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> userController.queryUserList(userInfo);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity.getCode()))&#123;<span class=\"comment\">//查询成功</span></span><br><span class=\"line\">            List list=(List) httpResponseEntity.getData();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(list.size() !=<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">UserInfo</span> <span class=\"variable\">data</span> <span class=\"operator\">=</span> (UserInfo) list.get(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity1</span> <span class=\"operator\">=</span> userController.deleteUserById(data);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"string\">&quot;666&quot;</span>.equals(httpResponseEntity1.getCode()))&#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">&quot;&gt;&gt;delete用户删除测试成功&quot;</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"word笔记","date":"2024-04-13T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 1. 公式\n\n- 使用latex公式\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/1.png)\n\n  ![](img/experience/app/word/1.png)\n\n- 写latex公式\n  \n  - 写/ alt + = / ctrl + =\n\n\n\n# 2. 保存pdf\n\n## 2.1 保存pdf的时候添加导航栏\n\n- word里面ctrl+f打开导航栏\n\n- 另存为 ， 选择类型为pdf, 选项\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/1.png)\n\n  ![](img/experience/app/word/to_pdf/1.png)\n\n- 选择标题\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/2.png)\n  \n  ![](img/experience/app/word/to_pdf/2.png)\n\n\n\n# 3. 页码\n\n## 3.1 分割页码\n\n- 如何将摘要编页码，目录无页码，正文编页码\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/0.png)\n\n  ![](img/experience/app/word/page/0.png)\n\n- 分别在上图箭头处（每一节的结尾插入分节符）（选择分节符/下一页，不要选连续）\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/1.png)\n\n  ![](img/experience/app/word/page/1.png)\n\n- 重复n次插入后，你获得了四个区块。每个区块里面的分页随便你插入何种类型的分页符。\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/2.png)\n\n  ![](img/experience/app/word/page/2.png)\n\n- 双击页脚（假设你在页脚插入页码），在**每**个区块的的第一页**取消链接到前一节**，插入页码。（每个区块的第一页都要点击**取消链接到前一节**斩断联系。）\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/3.png)\n\n   ![](img/experience/app/word/page/3.png)  \n\n- 此时页码不是1，不要慌，点击页码，设置格式。就ok了\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/4.png)\n\n   ![](img/experience/app/word/page/4.png)  \n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/5.png)\n\n    ![](img/experience/app/word/page/5.png) \n\n- 不需要页码的区块直接删除 \n\n\n\n# 4. ","source":"_posts/experience/app/word.md","raw":"---\ntitle: word笔记\n\ndate: 2024-4-14\n\ntags: [经验]\n\ncategories: [经验]\n\ncomment: true\n\ntoc: true\n\n\n\n---\n\n#\n<!--more-->\n\n# 1. 公式\n\n- 使用latex公式\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/1.png)\n\n  ![](img/experience/app/word/1.png)\n\n- 写latex公式\n  \n  - 写/ alt + = / ctrl + =\n\n\n\n# 2. 保存pdf\n\n## 2.1 保存pdf的时候添加导航栏\n\n- word里面ctrl+f打开导航栏\n\n- 另存为 ， 选择类型为pdf, 选项\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/1.png)\n\n  ![](img/experience/app/word/to_pdf/1.png)\n\n- 选择标题\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/2.png)\n  \n  ![](img/experience/app/word/to_pdf/2.png)\n\n\n\n# 3. 页码\n\n## 3.1 分割页码\n\n- 如何将摘要编页码，目录无页码，正文编页码\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/0.png)\n\n  ![](img/experience/app/word/page/0.png)\n\n- 分别在上图箭头处（每一节的结尾插入分节符）（选择分节符/下一页，不要选连续）\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/1.png)\n\n  ![](img/experience/app/word/page/1.png)\n\n- 重复n次插入后，你获得了四个区块。每个区块里面的分页随便你插入何种类型的分页符。\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/word/page/2.png)\n\n  ![](img/experience/app/word/page/2.png)\n\n- 双击页脚（假设你在页脚插入页码），在**每**个区块的的第一页**取消链接到前一节**，插入页码。（每个区块的第一页都要点击**取消链接到前一节**斩断联系。）\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/3.png)\n\n   ![](img/experience/app/word/page/3.png)  \n\n- 此时页码不是1，不要慌，点击页码，设置格式。就ok了\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/4.png)\n\n   ![](img/experience/app/word/page/4.png)  \n\n   ![](D:/blog/themes/yilia/source/img/experience/app/word/page/5.png)\n\n    ![](img/experience/app/word/page/5.png) \n\n- 不需要页码的区块直接删除 \n\n\n\n# 4. ","slug":"experience/app/word","published":1,"updated":"2024-04-14T15:22:42.247Z","_id":"cltfntnt4000bccvwdcwkc2i5","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"1-公式\"><a href=\"#1-公式\" class=\"headerlink\" title=\"1. 公式\"></a>1. 公式</h1><ul>\n<li><p>使用latex公式</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/1.png\"></p>\n<p><img src=\"/img/experience/app/word/1.png\"></p>\n</li>\n<li><p>写latex公式</p>\n<ul>\n<li>写&#x2F; alt + &#x3D; &#x2F; ctrl + &#x3D;</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-保存pdf\"><a href=\"#2-保存pdf\" class=\"headerlink\" title=\"2. 保存pdf\"></a>2. 保存pdf</h1><h2 id=\"2-1-保存pdf的时候添加导航栏\"><a href=\"#2-1-保存pdf的时候添加导航栏\" class=\"headerlink\" title=\"2.1 保存pdf的时候添加导航栏\"></a>2.1 保存pdf的时候添加导航栏</h2><ul>\n<li><p>word里面ctrl+f打开导航栏</p>\n</li>\n<li><p>另存为 ， 选择类型为pdf, 选项</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/1.png\"></p>\n<p><img src=\"/img/experience/app/word/to_pdf/1.png\"></p>\n</li>\n<li><p>选择标题</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/2.png\"></p>\n<p><img src=\"/img/experience/app/word/to_pdf/2.png\"></p>\n</li>\n</ul>\n<h1 id=\"3-页码\"><a href=\"#3-页码\" class=\"headerlink\" title=\"3. 页码\"></a>3. 页码</h1><h2 id=\"3-1-分割页码\"><a href=\"#3-1-分割页码\" class=\"headerlink\" title=\"3.1 分割页码\"></a>3.1 分割页码</h2><ul>\n<li><p>如何将摘要编页码，目录无页码，正文编页码</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/0.png\"></p>\n<p><img src=\"/img/experience/app/word/page/0.png\"></p>\n</li>\n<li><p>分别在上图箭头处（每一节的结尾插入分节符）（选择分节符&#x2F;下一页，不要选连续）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/1.png\"></p>\n<p><img src=\"/img/experience/app/word/page/1.png\"></p>\n</li>\n<li><p>重复n次插入后，你获得了四个区块。每个区块里面的分页随便你插入何种类型的分页符。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/2.png\"></p>\n<p><img src=\"/img/experience/app/word/page/2.png\"></p>\n</li>\n<li><p>双击页脚（假设你在页脚插入页码），在<strong>每</strong>个区块的的第一页<strong>取消链接到前一节</strong>，插入页码。（每个区块的第一页都要点击<strong>取消链接到前一节</strong>斩断联系。）</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/3.png\"></p>\n<p> <img src=\"/img/experience/app/word/page/3.png\">  </p>\n</li>\n<li><p>此时页码不是1，不要慌，点击页码，设置格式。就ok了</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/4.png\"></p>\n<p> <img src=\"/img/experience/app/word/page/4.png\">  </p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/5.png\"></p>\n<p>  <img src=\"/img/experience/app/word/page/5.png\"> </p>\n</li>\n<li><p>不需要页码的区块直接删除</p>\n</li>\n</ul>\n<h1 id=\"4\"><a href=\"#4\" class=\"headerlink\" title=\"4.\"></a>4.</h1>","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-公式\"><a href=\"#1-公式\" class=\"headerlink\" title=\"1. 公式\"></a>1. 公式</h1><ul>\n<li><p>使用latex公式</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/1.png\"></p>\n<p><img src=\"/img/experience/app/word/1.png\"></p>\n</li>\n<li><p>写latex公式</p>\n<ul>\n<li>写&#x2F; alt + &#x3D; &#x2F; ctrl + &#x3D;</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-保存pdf\"><a href=\"#2-保存pdf\" class=\"headerlink\" title=\"2. 保存pdf\"></a>2. 保存pdf</h1><h2 id=\"2-1-保存pdf的时候添加导航栏\"><a href=\"#2-1-保存pdf的时候添加导航栏\" class=\"headerlink\" title=\"2.1 保存pdf的时候添加导航栏\"></a>2.1 保存pdf的时候添加导航栏</h2><ul>\n<li><p>word里面ctrl+f打开导航栏</p>\n</li>\n<li><p>另存为 ， 选择类型为pdf, 选项</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/1.png\"></p>\n<p><img src=\"/img/experience/app/word/to_pdf/1.png\"></p>\n</li>\n<li><p>选择标题</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/to_pdf/2.png\"></p>\n<p><img src=\"/img/experience/app/word/to_pdf/2.png\"></p>\n</li>\n</ul>\n<h1 id=\"3-页码\"><a href=\"#3-页码\" class=\"headerlink\" title=\"3. 页码\"></a>3. 页码</h1><h2 id=\"3-1-分割页码\"><a href=\"#3-1-分割页码\" class=\"headerlink\" title=\"3.1 分割页码\"></a>3.1 分割页码</h2><ul>\n<li><p>如何将摘要编页码，目录无页码，正文编页码</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/0.png\"></p>\n<p><img src=\"/img/experience/app/word/page/0.png\"></p>\n</li>\n<li><p>分别在上图箭头处（每一节的结尾插入分节符）（选择分节符&#x2F;下一页，不要选连续）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/1.png\"></p>\n<p><img src=\"/img/experience/app/word/page/1.png\"></p>\n</li>\n<li><p>重复n次插入后，你获得了四个区块。每个区块里面的分页随便你插入何种类型的分页符。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/2.png\"></p>\n<p><img src=\"/img/experience/app/word/page/2.png\"></p>\n</li>\n<li><p>双击页脚（假设你在页脚插入页码），在<strong>每</strong>个区块的的第一页<strong>取消链接到前一节</strong>，插入页码。（每个区块的第一页都要点击<strong>取消链接到前一节</strong>斩断联系。）</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/3.png\"></p>\n<p> <img src=\"/img/experience/app/word/page/3.png\">  </p>\n</li>\n<li><p>此时页码不是1，不要慌，点击页码，设置格式。就ok了</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/4.png\"></p>\n<p> <img src=\"/img/experience/app/word/page/4.png\">  </p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/word/page/5.png\"></p>\n<p>  <img src=\"/img/experience/app/word/page/5.png\"> </p>\n</li>\n<li><p>不需要页码的区块直接删除</p>\n</li>\n</ul>\n<h1 id=\"4\"><a href=\"#4\" class=\"headerlink\" title=\"4.\"></a>4.</h1>"},{"title":"生产实习-0 开发环境准备","date":"2024-03-01T00:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 0. 开发环境准备\n\n## 0.1 安装java\n\n### 0.1.1 下载安装\n\n- 下载地址： [Archived OpenJDK GA Releases (java.net)](https://jdk.java.net/archive/) \n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/1.png)\n\n  ![](img/java/produce_practice/0/1.png)\n\n- 下载后解压到你想放到的目录（比如我是D:/jdk-17\n\n### 0.1.2 配置环境变量\n\n1. windows搜索：环境变量。选择`编辑系统环境变量`\n\n2. 新建环境变量： ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/2.png)\n\n   ![](img/java/produce_practice/0/2.png) \n\n3. 输入变量名：`JAVA_HOME`，变量值（根据你存放的路径）：`D:\\jdk-17`，确定。\n\n4. 双击path，选择新建，输入`%JAVA_HOME%\\bin`，确定，这样就将java的bin目录放到系统环境变量了，可以直接使用java命令了。（javac命令？？？）\n\n5. 重新启动终端（更新环境变量）输入java回车，可以看到有反应，说明ok了。\n\n\n\n## 0.2 安装docker\n\n| 方案                    | 要求               |\n| ----------------------- | ------------------ |\n| 本地下载mysql           | 本地没下载过数据库 |\n| 虚拟机 + mysql          |                    |\n| 虚拟机 + docker + mysql |                    |\n| 服务器 + docker + mysql |                    |\n\n- 本次实验采用服务器 + docker + mysql\n\n### 0.2.1 下载ubuntu镜像（使用虚拟机）\n\n-  [Get Ubuntu Server | Download | Ubuntu](https://ubuntu.com/download/server) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/4.png)\n\n    ![](img/java/produce_practice/0/4.png) \n\n### 0.2.2 安装虚拟机\n\n- 略\n\n### 0.2.3 安装docker\n\n- 服务器中输入\n\n    ```bash\n    sudo apt install docker.io\n    ```\n\n    如果命令无效，提示用snap安装，则用snap\n\n    ，输入y是确认。安装完成收输入whereis docker可以查看docker位置\n    \n- 服务器中输入\n\n    ```bash\n    - sudo docker search mysql\n    ```\n\n### 0.2.4 安装mysql\n\n- 服务器中输入：\n\n  ```bash\n  sudo docker pull mysql:8.0.34\n  ```\n\n- 查看镜像文件：\n\n  ```bash\n  sudo docker images\n  ```\n\n  可以看到镜像文件中有一个我们刚刚拉取的镜像\n\n- 将镜像封装成容器运行：(这里将docker的3306端口映射到本地的3306，你可以改，数据库密码123456)\n\n  ```bash\n  sudo docker run -itd --name mysql8034 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0.34\n  ```\n\n- 查看容器列表\n\n  ```bash\n  sudo docker ps -a\n  ```\n\n  看到刚刚的容器就说明ok了。\n\n- 可视化工具：navicat、Mysql workbench（使用较低版本的navicat连接的时候可能会发现连接错误，需要更新navicat版本）\n\n## 0.3 安装idea\n\n- 下载地址（划到下面下载社区版）：https://www.jetbrains.com/zh-cn/idea/download\n\n- 配置国内镜像：\n\n  - 设置内搜索：maven\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png)\n\n    ![](img/java/produce_practice/0/5.png) \n\n  - 创建C:\\Users\\123\\.m2\\settings.xml\n\n    ```xml\n    <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n              xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n              xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                                  http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n        <mirrors>\n            <mirror>\n                <id>alimaven</id>\n                <name>aliyun maven</name>\n                <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n                <mirrorOf>central</mirrorOf>\n            </mirror>\n        </mirrors>\n    </settings>\n    ```\n\n  - 重新打开设置，将刚刚的勾勾上\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png)\n\n    ![](img/java/produce_practice/0/5.png) \n\n- 检验国内镜像配置\n\n  - 进入网址（建议收藏）： [Maven Repository: Search/Browse/Explore (mvnrepository.com)](https://mvnrepository.com/) \n\n  - 搜索fastjson2：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/6.png)\n\n    ![](img/java/produce_practice/0/6.png) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/7.png)\n\n    ![](img/java/produce_practice/0/7.png) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/8.png)\n\n    ![](img/java/produce_practice/0/8.png) \n\n    - 复制：\n\n    ```xml\n    <!-- https://mvnrepository.com/artifact/com.alibaba.fastjson2/fastjson2 -->\n    <dependency>\n        <groupId>com.alibaba.fastjson2</groupId>\n        <artifactId>fastjson2</artifactId>\n        <version>2.0.47</version>\n    </dependency>\n    \n    ```\n\n    - 将上面的内容粘贴到项目的pom.xml的<dependences>标签下（无则自己建），更新maven：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/9.png)\n\n    ![](img/java/produce_practice/0/9.png) \n\n    - 此时刚刚粘贴的依赖不是红色字体了，说明下载ok，然后输入json可以看到有代码自动补全：\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/10.png)\n\n      ![](img/java/produce_practice/0/10.png) \n\n- 统一编码：（搜索encoding或编码，还有搜索控制台：编码）\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/11.png)\n\n  ![](img/java/produce_practice/0/11.png) \n\n- 避免其他插件在控制台输出中文乱码：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/12.png)\n\n  ![](img/java/produce_practice/0/12.png) \n\n  输入：\n\n  ```\n  -Xmx4096m\n  -Dfile.encoding=UTF-8\n  ```","source":"_posts/java/produce_practice/0_config.md","raw":"---\ntitle: 生产实习-0 开发环境准备\n\ndate: 2024-3-1 08:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n\n\n\n---\n\n#\n<!--more-->\n\n# 0. 开发环境准备\n\n## 0.1 安装java\n\n### 0.1.1 下载安装\n\n- 下载地址： [Archived OpenJDK GA Releases (java.net)](https://jdk.java.net/archive/) \n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/1.png)\n\n  ![](img/java/produce_practice/0/1.png)\n\n- 下载后解压到你想放到的目录（比如我是D:/jdk-17\n\n### 0.1.2 配置环境变量\n\n1. windows搜索：环境变量。选择`编辑系统环境变量`\n\n2. 新建环境变量： ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/2.png)\n\n   ![](img/java/produce_practice/0/2.png) \n\n3. 输入变量名：`JAVA_HOME`，变量值（根据你存放的路径）：`D:\\jdk-17`，确定。\n\n4. 双击path，选择新建，输入`%JAVA_HOME%\\bin`，确定，这样就将java的bin目录放到系统环境变量了，可以直接使用java命令了。（javac命令？？？）\n\n5. 重新启动终端（更新环境变量）输入java回车，可以看到有反应，说明ok了。\n\n\n\n## 0.2 安装docker\n\n| 方案                    | 要求               |\n| ----------------------- | ------------------ |\n| 本地下载mysql           | 本地没下载过数据库 |\n| 虚拟机 + mysql          |                    |\n| 虚拟机 + docker + mysql |                    |\n| 服务器 + docker + mysql |                    |\n\n- 本次实验采用服务器 + docker + mysql\n\n### 0.2.1 下载ubuntu镜像（使用虚拟机）\n\n-  [Get Ubuntu Server | Download | Ubuntu](https://ubuntu.com/download/server) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/4.png)\n\n    ![](img/java/produce_practice/0/4.png) \n\n### 0.2.2 安装虚拟机\n\n- 略\n\n### 0.2.3 安装docker\n\n- 服务器中输入\n\n    ```bash\n    sudo apt install docker.io\n    ```\n\n    如果命令无效，提示用snap安装，则用snap\n\n    ，输入y是确认。安装完成收输入whereis docker可以查看docker位置\n    \n- 服务器中输入\n\n    ```bash\n    - sudo docker search mysql\n    ```\n\n### 0.2.4 安装mysql\n\n- 服务器中输入：\n\n  ```bash\n  sudo docker pull mysql:8.0.34\n  ```\n\n- 查看镜像文件：\n\n  ```bash\n  sudo docker images\n  ```\n\n  可以看到镜像文件中有一个我们刚刚拉取的镜像\n\n- 将镜像封装成容器运行：(这里将docker的3306端口映射到本地的3306，你可以改，数据库密码123456)\n\n  ```bash\n  sudo docker run -itd --name mysql8034 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0.34\n  ```\n\n- 查看容器列表\n\n  ```bash\n  sudo docker ps -a\n  ```\n\n  看到刚刚的容器就说明ok了。\n\n- 可视化工具：navicat、Mysql workbench（使用较低版本的navicat连接的时候可能会发现连接错误，需要更新navicat版本）\n\n## 0.3 安装idea\n\n- 下载地址（划到下面下载社区版）：https://www.jetbrains.com/zh-cn/idea/download\n\n- 配置国内镜像：\n\n  - 设置内搜索：maven\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png)\n\n    ![](img/java/produce_practice/0/5.png) \n\n  - 创建C:\\Users\\123\\.m2\\settings.xml\n\n    ```xml\n    <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n              xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n              xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                                  http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n        <mirrors>\n            <mirror>\n                <id>alimaven</id>\n                <name>aliyun maven</name>\n                <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n                <mirrorOf>central</mirrorOf>\n            </mirror>\n        </mirrors>\n    </settings>\n    ```\n\n  - 重新打开设置，将刚刚的勾勾上\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png)\n\n    ![](img/java/produce_practice/0/5.png) \n\n- 检验国内镜像配置\n\n  - 进入网址（建议收藏）： [Maven Repository: Search/Browse/Explore (mvnrepository.com)](https://mvnrepository.com/) \n\n  - 搜索fastjson2：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/6.png)\n\n    ![](img/java/produce_practice/0/6.png) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/7.png)\n\n    ![](img/java/produce_practice/0/7.png) \n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/8.png)\n\n    ![](img/java/produce_practice/0/8.png) \n\n    - 复制：\n\n    ```xml\n    <!-- https://mvnrepository.com/artifact/com.alibaba.fastjson2/fastjson2 -->\n    <dependency>\n        <groupId>com.alibaba.fastjson2</groupId>\n        <artifactId>fastjson2</artifactId>\n        <version>2.0.47</version>\n    </dependency>\n    \n    ```\n\n    - 将上面的内容粘贴到项目的pom.xml的<dependences>标签下（无则自己建），更新maven：\n\n    ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/9.png)\n\n    ![](img/java/produce_practice/0/9.png) \n\n    - 此时刚刚粘贴的依赖不是红色字体了，说明下载ok，然后输入json可以看到有代码自动补全：\n\n      ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/10.png)\n\n      ![](img/java/produce_practice/0/10.png) \n\n- 统一编码：（搜索encoding或编码，还有搜索控制台：编码）\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/11.png)\n\n  ![](img/java/produce_practice/0/11.png) \n\n- 避免其他插件在控制台输出中文乱码：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/0/12.png)\n\n  ![](img/java/produce_practice/0/12.png) \n\n  输入：\n\n  ```\n  -Xmx4096m\n  -Dfile.encoding=UTF-8\n  ```","slug":"java/produce_practice/0_config","published":1,"updated":"2024-03-06T12:05:56.798Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltfr696y000054vw667819si","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"0-开发环境准备\"><a href=\"#0-开发环境准备\" class=\"headerlink\" title=\"0. 开发环境准备\"></a>0. 开发环境准备</h1><h2 id=\"0-1-安装java\"><a href=\"#0-1-安装java\" class=\"headerlink\" title=\"0.1 安装java\"></a>0.1 安装java</h2><h3 id=\"0-1-1-下载安装\"><a href=\"#0-1-1-下载安装\" class=\"headerlink\" title=\"0.1.1 下载安装\"></a>0.1.1 下载安装</h3><ul>\n<li><p>下载地址： <a href=\"https://jdk.java.net/archive/\">Archived OpenJDK GA Releases (java.net)</a> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/1.png\"></p>\n</li>\n<li><p>下载后解压到你想放到的目录（比如我是D:&#x2F;jdk-17</p>\n</li>\n</ul>\n<h3 id=\"0-1-2-配置环境变量\"><a href=\"#0-1-2-配置环境变量\" class=\"headerlink\" title=\"0.1.2 配置环境变量\"></a>0.1.2 配置环境变量</h3><ol>\n<li><p>windows搜索：环境变量。选择<code>编辑系统环境变量</code></p>\n</li>\n<li><p>新建环境变量： <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/2.png\"> </p>\n</li>\n<li><p>输入变量名：<code>JAVA_HOME</code>，变量值（根据你存放的路径）：<code>D:\\jdk-17</code>，确定。</p>\n</li>\n<li><p>双击path，选择新建，输入<code>%JAVA_HOME%\\bin</code>，确定，这样就将java的bin目录放到系统环境变量了，可以直接使用java命令了。（javac命令？？？）</p>\n</li>\n<li><p>重新启动终端（更新环境变量）输入java回车，可以看到有反应，说明ok了。</p>\n</li>\n</ol>\n<h2 id=\"0-2-安装docker\"><a href=\"#0-2-安装docker\" class=\"headerlink\" title=\"0.2 安装docker\"></a>0.2 安装docker</h2><table>\n<thead>\n<tr>\n<th>方案</th>\n<th>要求</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>本地下载mysql</td>\n<td>本地没下载过数据库</td>\n</tr>\n<tr>\n<td>虚拟机 + mysql</td>\n<td></td>\n</tr>\n<tr>\n<td>虚拟机 + docker + mysql</td>\n<td></td>\n</tr>\n<tr>\n<td>服务器 + docker + mysql</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>本次实验采用服务器 + docker + mysql</li>\n</ul>\n<h3 id=\"0-2-1-下载ubuntu镜像（使用虚拟机）\"><a href=\"#0-2-1-下载ubuntu镜像（使用虚拟机）\" class=\"headerlink\" title=\"0.2.1 下载ubuntu镜像（使用虚拟机）\"></a>0.2.1 下载ubuntu镜像（使用虚拟机）</h3><ul>\n<li><p><a href=\"https://ubuntu.com/download/server\">Get Ubuntu Server | Download | Ubuntu</a> </p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/4.png\"></p>\n<p> <img src=\"/img/java/produce_practice/0/4.png\"></p>\n</li>\n</ul>\n<h3 id=\"0-2-2-安装虚拟机\"><a href=\"#0-2-2-安装虚拟机\" class=\"headerlink\" title=\"0.2.2 安装虚拟机\"></a>0.2.2 安装虚拟机</h3><ul>\n<li>略</li>\n</ul>\n<h3 id=\"0-2-3-安装docker\"><a href=\"#0-2-3-安装docker\" class=\"headerlink\" title=\"0.2.3 安装docker\"></a>0.2.3 安装docker</h3><ul>\n<li><p>服务器中输入</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install docker.io</span><br></pre></td></tr></table></figure>\n\n<p>  如果命令无效，提示用snap安装，则用snap</p>\n<p>  ，输入y是确认。安装完成收输入whereis docker可以查看docker位置</p>\n</li>\n<li><p>服务器中输入</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- sudo docker search mysql</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"0-2-4-安装mysql\"><a href=\"#0-2-4-安装mysql\" class=\"headerlink\" title=\"0.2.4 安装mysql\"></a>0.2.4 安装mysql</h3><ul>\n<li><p>服务器中输入：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker pull mysql:8.0.34</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看镜像文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker images</span><br></pre></td></tr></table></figure>\n\n<p>可以看到镜像文件中有一个我们刚刚拉取的镜像</p>\n</li>\n<li><p>将镜像封装成容器运行：(这里将docker的3306端口映射到本地的3306，你可以改，数据库密码123456)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker run -itd --name mysql8034 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0.34</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看容器列表</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps -a</span><br></pre></td></tr></table></figure>\n\n<p>看到刚刚的容器就说明ok了。</p>\n</li>\n<li><p>可视化工具：navicat、Mysql workbench（使用较低版本的navicat连接的时候可能会发现连接错误，需要更新navicat版本）</p>\n</li>\n</ul>\n<h2 id=\"0-3-安装idea\"><a href=\"#0-3-安装idea\" class=\"headerlink\" title=\"0.3 安装idea\"></a>0.3 安装idea</h2><ul>\n<li><p>下载地址（划到下面下载社区版）：<a href=\"https://www.jetbrains.com/zh-cn/idea/download\">https://www.jetbrains.com/zh-cn/idea/download</a></p>\n</li>\n<li><p>配置国内镜像：</p>\n<ul>\n<li><p>设置内搜索：maven</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/5.png\"> </p>\n</li>\n<li><p>创建C:\\Users\\123.m2\\settings.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">&quot;http://maven.apache.org/SETTINGS/1.0.0</span></span></span><br><span class=\"line\"><span class=\"string\"><span class=\"tag\">                              http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>alimaven<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>aliyun maven<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>central<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>重新打开设置，将刚刚的勾勾上</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/5.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>检验国内镜像配置</p>\n<ul>\n<li><p>进入网址（建议收藏）： <a href=\"https://mvnrepository.com/\">Maven Repository: Search&#x2F;Browse&#x2F;Explore (mvnrepository.com)</a> </p>\n</li>\n<li><p>搜索fastjson2：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/6.png\"> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/7.png\"> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/8.png\"> </p>\n<ul>\n<li>复制：</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- https://mvnrepository.com/artifact/com.alibaba.fastjson2/fastjson2 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.alibaba.fastjson2<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>fastjson2<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.0.47<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>将上面的内容粘贴到项目的pom.xml的<dependences>标签下（无则自己建），更新maven：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/9.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/9.png\"> </p>\n<ul>\n<li><p>此时刚刚粘贴的依赖不是红色字体了，说明下载ok，然后输入json可以看到有代码自动补全：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/10.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/10.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>统一编码：（搜索encoding或编码，还有搜索控制台：编码）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/11.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/11.png\"> </p>\n</li>\n<li><p>避免其他插件在控制台输出中文乱码：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/12.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/12.png\"> </p>\n<p>输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Xmx4096m</span><br><span class=\"line\">-Dfile.encoding=UTF-8</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"0-开发环境准备\"><a href=\"#0-开发环境准备\" class=\"headerlink\" title=\"0. 开发环境准备\"></a>0. 开发环境准备</h1><h2 id=\"0-1-安装java\"><a href=\"#0-1-安装java\" class=\"headerlink\" title=\"0.1 安装java\"></a>0.1 安装java</h2><h3 id=\"0-1-1-下载安装\"><a href=\"#0-1-1-下载安装\" class=\"headerlink\" title=\"0.1.1 下载安装\"></a>0.1.1 下载安装</h3><ul>\n<li><p>下载地址： <a href=\"https://jdk.java.net/archive/\">Archived OpenJDK GA Releases (java.net)</a> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/1.png\"></p>\n</li>\n<li><p>下载后解压到你想放到的目录（比如我是D:&#x2F;jdk-17</p>\n</li>\n</ul>\n<h3 id=\"0-1-2-配置环境变量\"><a href=\"#0-1-2-配置环境变量\" class=\"headerlink\" title=\"0.1.2 配置环境变量\"></a>0.1.2 配置环境变量</h3><ol>\n<li><p>windows搜索：环境变量。选择<code>编辑系统环境变量</code></p>\n</li>\n<li><p>新建环境变量： <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/2.png\"> </p>\n</li>\n<li><p>输入变量名：<code>JAVA_HOME</code>，变量值（根据你存放的路径）：<code>D:\\jdk-17</code>，确定。</p>\n</li>\n<li><p>双击path，选择新建，输入<code>%JAVA_HOME%\\bin</code>，确定，这样就将java的bin目录放到系统环境变量了，可以直接使用java命令了。（javac命令？？？）</p>\n</li>\n<li><p>重新启动终端（更新环境变量）输入java回车，可以看到有反应，说明ok了。</p>\n</li>\n</ol>\n<h2 id=\"0-2-安装docker\"><a href=\"#0-2-安装docker\" class=\"headerlink\" title=\"0.2 安装docker\"></a>0.2 安装docker</h2><table>\n<thead>\n<tr>\n<th>方案</th>\n<th>要求</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>本地下载mysql</td>\n<td>本地没下载过数据库</td>\n</tr>\n<tr>\n<td>虚拟机 + mysql</td>\n<td></td>\n</tr>\n<tr>\n<td>虚拟机 + docker + mysql</td>\n<td></td>\n</tr>\n<tr>\n<td>服务器 + docker + mysql</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>本次实验采用服务器 + docker + mysql</li>\n</ul>\n<h3 id=\"0-2-1-下载ubuntu镜像（使用虚拟机）\"><a href=\"#0-2-1-下载ubuntu镜像（使用虚拟机）\" class=\"headerlink\" title=\"0.2.1 下载ubuntu镜像（使用虚拟机）\"></a>0.2.1 下载ubuntu镜像（使用虚拟机）</h3><ul>\n<li><p><a href=\"https://ubuntu.com/download/server\">Get Ubuntu Server | Download | Ubuntu</a> </p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/4.png\"></p>\n<p> <img src=\"/img/java/produce_practice/0/4.png\"></p>\n</li>\n</ul>\n<h3 id=\"0-2-2-安装虚拟机\"><a href=\"#0-2-2-安装虚拟机\" class=\"headerlink\" title=\"0.2.2 安装虚拟机\"></a>0.2.2 安装虚拟机</h3><ul>\n<li>略</li>\n</ul>\n<h3 id=\"0-2-3-安装docker\"><a href=\"#0-2-3-安装docker\" class=\"headerlink\" title=\"0.2.3 安装docker\"></a>0.2.3 安装docker</h3><ul>\n<li><p>服务器中输入</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install docker.io</span><br></pre></td></tr></table></figure>\n\n<p>  如果命令无效，提示用snap安装，则用snap</p>\n<p>  ，输入y是确认。安装完成收输入whereis docker可以查看docker位置</p>\n</li>\n<li><p>服务器中输入</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- sudo docker search mysql</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"0-2-4-安装mysql\"><a href=\"#0-2-4-安装mysql\" class=\"headerlink\" title=\"0.2.4 安装mysql\"></a>0.2.4 安装mysql</h3><ul>\n<li><p>服务器中输入：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker pull mysql:8.0.34</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看镜像文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker images</span><br></pre></td></tr></table></figure>\n\n<p>可以看到镜像文件中有一个我们刚刚拉取的镜像</p>\n</li>\n<li><p>将镜像封装成容器运行：(这里将docker的3306端口映射到本地的3306，你可以改，数据库密码123456)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker run -itd --name mysql8034 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0.34</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看容器列表</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps -a</span><br></pre></td></tr></table></figure>\n\n<p>看到刚刚的容器就说明ok了。</p>\n</li>\n<li><p>可视化工具：navicat、Mysql workbench（使用较低版本的navicat连接的时候可能会发现连接错误，需要更新navicat版本）</p>\n</li>\n</ul>\n<h2 id=\"0-3-安装idea\"><a href=\"#0-3-安装idea\" class=\"headerlink\" title=\"0.3 安装idea\"></a>0.3 安装idea</h2><ul>\n<li><p>下载地址（划到下面下载社区版）：<a href=\"https://www.jetbrains.com/zh-cn/idea/download\">https://www.jetbrains.com/zh-cn/idea/download</a></p>\n</li>\n<li><p>配置国内镜像：</p>\n<ul>\n<li><p>设置内搜索：maven</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/5.png\"> </p>\n</li>\n<li><p>创建C:\\Users\\123.m2\\settings.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">&quot;http://maven.apache.org/SETTINGS/1.0.0</span></span></span><br><span class=\"line\"><span class=\"string\"><span class=\"tag\">                              http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>alimaven<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>aliyun maven<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>central<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>重新打开设置，将刚刚的勾勾上</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/5.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/5.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>检验国内镜像配置</p>\n<ul>\n<li><p>进入网址（建议收藏）： <a href=\"https://mvnrepository.com/\">Maven Repository: Search&#x2F;Browse&#x2F;Explore (mvnrepository.com)</a> </p>\n</li>\n<li><p>搜索fastjson2：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/6.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/6.png\"> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/7.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/7.png\"> </p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/8.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/8.png\"> </p>\n<ul>\n<li>复制：</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- https://mvnrepository.com/artifact/com.alibaba.fastjson2/fastjson2 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.alibaba.fastjson2<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>fastjson2<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.0.47<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>将上面的内容粘贴到项目的pom.xml的<dependences>标签下（无则自己建），更新maven：</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/9.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/9.png\"> </p>\n<ul>\n<li><p>此时刚刚粘贴的依赖不是红色字体了，说明下载ok，然后输入json可以看到有代码自动补全：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/10.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/10.png\"></p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>统一编码：（搜索encoding或编码，还有搜索控制台：编码）</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/11.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/11.png\"> </p>\n</li>\n<li><p>避免其他插件在控制台输出中文乱码：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/0/12.png\"></p>\n<p><img src=\"/img/java/produce_practice/0/12.png\"> </p>\n<p>输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Xmx4096m</span><br><span class=\"line\">-Dfile.encoding=UTF-8</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"python tips","date":"2024-03-10T12:00:00.000Z","toc":true,"_content":"\n#\n\n<!-- more -->\n\n\n\n- 导入当前文件夹（建了\\__init__.py）下的包：\n\n    ```python\n    from . import diffusion, unet\n    ```\n\n- 数字前自动补0：\n\n  ```python\n  name=f'{number:05d}.png'\n  ```\n\n  ","source":"_posts/python/tips.md","raw":"---\ntitle: python tips\ndate: 2024-03-10 20:00:00\ntoc: true\ntags: [python]\ncategories: [python]\n\n\n---\n\n#\n\n<!-- more -->\n\n\n\n- 导入当前文件夹（建了\\__init__.py）下的包：\n\n    ```python\n    from . import diffusion, unet\n    ```\n\n- 数字前自动补0：\n\n  ```python\n  name=f'{number:05d}.png'\n  ```\n\n  ","slug":"python/tips","published":1,"updated":"2024-04-01T14:36:47.058Z","_id":"cltmv05yw0000lkvw5mfe7u66","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<ul>\n<li><p>导入当前文件夹（建了_<em>init</em>_.py）下的包：</p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> . <span class=\"keyword\">import</span> diffusion, unet</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>数字前自动补0：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name=<span class=\"string\">f&#x27;<span class=\"subst\">&#123;number:05d&#125;</span>.png&#x27;</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<ul>\n<li><p>导入当前文件夹（建了_<em>init</em>_.py）下的包：</p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> . <span class=\"keyword\">import</span> diffusion, unet</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>数字前自动补0：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name=<span class=\"string\">f&#x27;<span class=\"subst\">&#123;number:05d&#125;</span>.png&#x27;</span></span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"Linux服务器免密登录","date":"2024-03-09T14:00:00.000Z","toc":true,"_content":"\n#\n\n<!--more-->\n\n# Linux服务器免密登录\n\n## 1 生成本地公钥\n\n- 本地运行（可以先到user/.ssh下查看有没有id_rsa.pub文件，有就不用生成了）：\n\n  ```bash\n  ssh-keygen\n  ```\n\n  一直回车就行。\n\n## 2 将生成的公钥上传到服务器\n\n- 在服务器端创建~/.ssh\n\n  ```bash\n  mkdir .ssh\n  ```\n\n  \n\n- 本地cd到：user/用户名/.ssh。将id_rsa.pub复制到服务器的~/.ssh/authorized_keys（root用户的根目录与普通用户的根目录不同）\n\n  ```bash\n  scp -P 端口 id_rsa.pub 用户名@IP:~/.ssh/authorized_keys\n  ```\n\n  ","source":"_posts/linux/Linux_nopassword.md","raw":"---\ntitle: Linux服务器免密登录\ndate: 2024-03-09 22:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n---\n\n#\n\n<!--more-->\n\n# Linux服务器免密登录\n\n## 1 生成本地公钥\n\n- 本地运行（可以先到user/.ssh下查看有没有id_rsa.pub文件，有就不用生成了）：\n\n  ```bash\n  ssh-keygen\n  ```\n\n  一直回车就行。\n\n## 2 将生成的公钥上传到服务器\n\n- 在服务器端创建~/.ssh\n\n  ```bash\n  mkdir .ssh\n  ```\n\n  \n\n- 本地cd到：user/用户名/.ssh。将id_rsa.pub复制到服务器的~/.ssh/authorized_keys（root用户的根目录与普通用户的根目录不同）\n\n  ```bash\n  scp -P 端口 id_rsa.pub 用户名@IP:~/.ssh/authorized_keys\n  ```\n\n  ","slug":"linux/Linux_nopassword","published":1,"updated":"2024-03-11T12:31:15.983Z","_id":"cltmv05yy0001lkvw6f4jcvff","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"Linux服务器免密登录\"><a href=\"#Linux服务器免密登录\" class=\"headerlink\" title=\"Linux服务器免密登录\"></a>Linux服务器免密登录</h1><h2 id=\"1-生成本地公钥\"><a href=\"#1-生成本地公钥\" class=\"headerlink\" title=\"1 生成本地公钥\"></a>1 生成本地公钥</h2><ul>\n<li><p>本地运行（可以先到user&#x2F;.ssh下查看有没有id_rsa.pub文件，有就不用生成了）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n\n<p>一直回车就行。</p>\n</li>\n</ul>\n<h2 id=\"2-将生成的公钥上传到服务器\"><a href=\"#2-将生成的公钥上传到服务器\" class=\"headerlink\" title=\"2 将生成的公钥上传到服务器\"></a>2 将生成的公钥上传到服务器</h2><ul>\n<li><p>在服务器端创建~&#x2F;.ssh</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> .ssh</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>本地cd到：user&#x2F;用户名&#x2F;.ssh。将id_rsa.pub复制到服务器的~&#x2F;.ssh&#x2F;authorized_keys（root用户的根目录与普通用户的根目录不同）</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -P 端口 id_rsa.pub 用户名@IP:~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"Linux服务器免密登录\"><a href=\"#Linux服务器免密登录\" class=\"headerlink\" title=\"Linux服务器免密登录\"></a>Linux服务器免密登录</h1><h2 id=\"1-生成本地公钥\"><a href=\"#1-生成本地公钥\" class=\"headerlink\" title=\"1 生成本地公钥\"></a>1 生成本地公钥</h2><ul>\n<li><p>本地运行（可以先到user&#x2F;.ssh下查看有没有id_rsa.pub文件，有就不用生成了）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen</span><br></pre></td></tr></table></figure>\n\n<p>一直回车就行。</p>\n</li>\n</ul>\n<h2 id=\"2-将生成的公钥上传到服务器\"><a href=\"#2-将生成的公钥上传到服务器\" class=\"headerlink\" title=\"2 将生成的公钥上传到服务器\"></a>2 将生成的公钥上传到服务器</h2><ul>\n<li><p>在服务器端创建~&#x2F;.ssh</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> .ssh</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>本地cd到：user&#x2F;用户名&#x2F;.ssh。将id_rsa.pub复制到服务器的~&#x2F;.ssh&#x2F;authorized_keys（root用户的根目录与普通用户的根目录不同）</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -P 端口 id_rsa.pub 用户名@IP:~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"使用via键盘映射","date":"2024-03-07T00:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 使用via键盘映射\n\n- 键盘的F1键默认是功能键，不是原始的F1，使用F1需要Fn+F1，如何改回原来的。（请确认你的键盘支持这个功能，需要问商家要json文件）\n\n## 1. 下载via\n\n- https://github.com/WestBerryVIA/via-releases/releases\n- 根据你自己的系统下载对应的安装文件\n\n## 2. 连接键盘\n\n### 2.1 显示design\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/1.png)\n\n![](img/experience/keyboard/1.png)\n\n## 2.2 导入配置文件\n\n1. 找商家要json文件\n\n2. 将键盘调到有线模式，连线到电脑，点击load，如果无法导入json文件，可以试试开启`Use V2 definitions`选项。\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/2.png)\n\n   ![](img/experience/keyboard/2.png)\n\n3. 创建一个宏：Fn + F1。需要先进入全屏模式才能录制，点击圆点进行录制，然后按住Fn + F1，再点击圆点完成录制，然后点击傍边的保存按钮。\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/3.png)\n\n   ![](img/experience/keyboard/3.png)\n\n4. 按照如下顺序将F1（我这里因为已经换成M1:\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/4.png)\n\n   ![](img/experience/keyboard/4.png)\n\n## 2.3 其他功能\n\n### 2.3.1 via\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/5.png)\n\n![](img/experience/keyboard/5.png)\n\n### 2.3.2 界面\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/6.png)\n\n![](img/experience/keyboard/6.png)\n\n### 2.3.3 宏\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/7.png)\n\n![](img/experience/keyboard/7.png)\n\n### 2.3.4 层\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/8.png)\n\n![](img/experience/keyboard/8.png)\n\n### 2.3.5 any\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/9.png)\n\n![](img/experience/keyboard/9.png)","source":"_posts/experience/keyboard/keymap.md","raw":"---\ntitle: 使用via键盘映射\n\ndate: 2024-3-7 08:00:00\n\ntags: [键盘]\n\ncategories: [经验]\n\ncomment: true\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n# 使用via键盘映射\n\n- 键盘的F1键默认是功能键，不是原始的F1，使用F1需要Fn+F1，如何改回原来的。（请确认你的键盘支持这个功能，需要问商家要json文件）\n\n## 1. 下载via\n\n- https://github.com/WestBerryVIA/via-releases/releases\n- 根据你自己的系统下载对应的安装文件\n\n## 2. 连接键盘\n\n### 2.1 显示design\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/1.png)\n\n![](img/experience/keyboard/1.png)\n\n## 2.2 导入配置文件\n\n1. 找商家要json文件\n\n2. 将键盘调到有线模式，连线到电脑，点击load，如果无法导入json文件，可以试试开启`Use V2 definitions`选项。\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/2.png)\n\n   ![](img/experience/keyboard/2.png)\n\n3. 创建一个宏：Fn + F1。需要先进入全屏模式才能录制，点击圆点进行录制，然后按住Fn + F1，再点击圆点完成录制，然后点击傍边的保存按钮。\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/3.png)\n\n   ![](img/experience/keyboard/3.png)\n\n4. 按照如下顺序将F1（我这里因为已经换成M1:\n\n   ![](D:/blog/themes/yilia/source/img/experience/keyboard/4.png)\n\n   ![](img/experience/keyboard/4.png)\n\n## 2.3 其他功能\n\n### 2.3.1 via\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/5.png)\n\n![](img/experience/keyboard/5.png)\n\n### 2.3.2 界面\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/6.png)\n\n![](img/experience/keyboard/6.png)\n\n### 2.3.3 宏\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/7.png)\n\n![](img/experience/keyboard/7.png)\n\n### 2.3.4 层\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/8.png)\n\n![](img/experience/keyboard/8.png)\n\n### 2.3.5 any\n\n![](D:/blog/themes/yilia/source/img/experience/keyboard/9.png)\n\n![](img/experience/keyboard/9.png)","slug":"experience/keyboard/keymap","published":1,"updated":"2024-03-07T11:58:26.971Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltmv05z90005lkvwbmmb6maz","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"使用via键盘映射\"><a href=\"#使用via键盘映射\" class=\"headerlink\" title=\"使用via键盘映射\"></a>使用via键盘映射</h1><ul>\n<li>键盘的F1键默认是功能键，不是原始的F1，使用F1需要Fn+F1，如何改回原来的。（请确认你的键盘支持这个功能，需要问商家要json文件）</li>\n</ul>\n<h2 id=\"1-下载via\"><a href=\"#1-下载via\" class=\"headerlink\" title=\"1. 下载via\"></a>1. 下载via</h2><ul>\n<li><a href=\"https://github.com/WestBerryVIA/via-releases/releases\">https://github.com/WestBerryVIA/via-releases/releases</a></li>\n<li>根据你自己的系统下载对应的安装文件</li>\n</ul>\n<h2 id=\"2-连接键盘\"><a href=\"#2-连接键盘\" class=\"headerlink\" title=\"2. 连接键盘\"></a>2. 连接键盘</h2><h3 id=\"2-1-显示design\"><a href=\"#2-1-显示design\" class=\"headerlink\" title=\"2.1 显示design\"></a>2.1 显示design</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/1.png\"></p>\n<p><img src=\"/img/experience/keyboard/1.png\"></p>\n<h2 id=\"2-2-导入配置文件\"><a href=\"#2-2-导入配置文件\" class=\"headerlink\" title=\"2.2 导入配置文件\"></a>2.2 导入配置文件</h2><ol>\n<li><p>找商家要json文件</p>\n</li>\n<li><p>将键盘调到有线模式，连线到电脑，点击load，如果无法导入json文件，可以试试开启<code>Use V2 definitions</code>选项。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/2.png\"></p>\n<p><img src=\"/img/experience/keyboard/2.png\"></p>\n</li>\n<li><p>创建一个宏：Fn + F1。需要先进入全屏模式才能录制，点击圆点进行录制，然后按住Fn + F1，再点击圆点完成录制，然后点击傍边的保存按钮。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/3.png\"></p>\n<p><img src=\"/img/experience/keyboard/3.png\"></p>\n</li>\n<li><p>按照如下顺序将F1（我这里因为已经换成M1:</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/4.png\"></p>\n<p><img src=\"/img/experience/keyboard/4.png\"></p>\n</li>\n</ol>\n<h2 id=\"2-3-其他功能\"><a href=\"#2-3-其他功能\" class=\"headerlink\" title=\"2.3 其他功能\"></a>2.3 其他功能</h2><h3 id=\"2-3-1-via\"><a href=\"#2-3-1-via\" class=\"headerlink\" title=\"2.3.1 via\"></a>2.3.1 via</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/5.png\"></p>\n<p><img src=\"/img/experience/keyboard/5.png\"></p>\n<h3 id=\"2-3-2-界面\"><a href=\"#2-3-2-界面\" class=\"headerlink\" title=\"2.3.2 界面\"></a>2.3.2 界面</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/6.png\"></p>\n<p><img src=\"/img/experience/keyboard/6.png\"></p>\n<h3 id=\"2-3-3-宏\"><a href=\"#2-3-3-宏\" class=\"headerlink\" title=\"2.3.3 宏\"></a>2.3.3 宏</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/7.png\"></p>\n<p><img src=\"/img/experience/keyboard/7.png\"></p>\n<h3 id=\"2-3-4-层\"><a href=\"#2-3-4-层\" class=\"headerlink\" title=\"2.3.4 层\"></a>2.3.4 层</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/8.png\"></p>\n<p><img src=\"/img/experience/keyboard/8.png\"></p>\n<h3 id=\"2-3-5-any\"><a href=\"#2-3-5-any\" class=\"headerlink\" title=\"2.3.5 any\"></a>2.3.5 any</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/9.png\"></p>\n<p><img src=\"/img/experience/keyboard/9.png\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"使用via键盘映射\"><a href=\"#使用via键盘映射\" class=\"headerlink\" title=\"使用via键盘映射\"></a>使用via键盘映射</h1><ul>\n<li>键盘的F1键默认是功能键，不是原始的F1，使用F1需要Fn+F1，如何改回原来的。（请确认你的键盘支持这个功能，需要问商家要json文件）</li>\n</ul>\n<h2 id=\"1-下载via\"><a href=\"#1-下载via\" class=\"headerlink\" title=\"1. 下载via\"></a>1. 下载via</h2><ul>\n<li><a href=\"https://github.com/WestBerryVIA/via-releases/releases\">https://github.com/WestBerryVIA/via-releases/releases</a></li>\n<li>根据你自己的系统下载对应的安装文件</li>\n</ul>\n<h2 id=\"2-连接键盘\"><a href=\"#2-连接键盘\" class=\"headerlink\" title=\"2. 连接键盘\"></a>2. 连接键盘</h2><h3 id=\"2-1-显示design\"><a href=\"#2-1-显示design\" class=\"headerlink\" title=\"2.1 显示design\"></a>2.1 显示design</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/1.png\"></p>\n<p><img src=\"/img/experience/keyboard/1.png\"></p>\n<h2 id=\"2-2-导入配置文件\"><a href=\"#2-2-导入配置文件\" class=\"headerlink\" title=\"2.2 导入配置文件\"></a>2.2 导入配置文件</h2><ol>\n<li><p>找商家要json文件</p>\n</li>\n<li><p>将键盘调到有线模式，连线到电脑，点击load，如果无法导入json文件，可以试试开启<code>Use V2 definitions</code>选项。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/2.png\"></p>\n<p><img src=\"/img/experience/keyboard/2.png\"></p>\n</li>\n<li><p>创建一个宏：Fn + F1。需要先进入全屏模式才能录制，点击圆点进行录制，然后按住Fn + F1，再点击圆点完成录制，然后点击傍边的保存按钮。</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/3.png\"></p>\n<p><img src=\"/img/experience/keyboard/3.png\"></p>\n</li>\n<li><p>按照如下顺序将F1（我这里因为已经换成M1:</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/4.png\"></p>\n<p><img src=\"/img/experience/keyboard/4.png\"></p>\n</li>\n</ol>\n<h2 id=\"2-3-其他功能\"><a href=\"#2-3-其他功能\" class=\"headerlink\" title=\"2.3 其他功能\"></a>2.3 其他功能</h2><h3 id=\"2-3-1-via\"><a href=\"#2-3-1-via\" class=\"headerlink\" title=\"2.3.1 via\"></a>2.3.1 via</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/5.png\"></p>\n<p><img src=\"/img/experience/keyboard/5.png\"></p>\n<h3 id=\"2-3-2-界面\"><a href=\"#2-3-2-界面\" class=\"headerlink\" title=\"2.3.2 界面\"></a>2.3.2 界面</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/6.png\"></p>\n<p><img src=\"/img/experience/keyboard/6.png\"></p>\n<h3 id=\"2-3-3-宏\"><a href=\"#2-3-3-宏\" class=\"headerlink\" title=\"2.3.3 宏\"></a>2.3.3 宏</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/7.png\"></p>\n<p><img src=\"/img/experience/keyboard/7.png\"></p>\n<h3 id=\"2-3-4-层\"><a href=\"#2-3-4-层\" class=\"headerlink\" title=\"2.3.4 层\"></a>2.3.4 层</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/8.png\"></p>\n<p><img src=\"/img/experience/keyboard/8.png\"></p>\n<h3 id=\"2-3-5-any\"><a href=\"#2-3-5-any\" class=\"headerlink\" title=\"2.3.5 any\"></a>2.3.5 any</h3><p><img src=\"D:/blog/themes/yilia/source/img/experience/keyboard/9.png\"></p>\n<p><img src=\"/img/experience/keyboard/9.png\"></p>"},{"title":"Windows卸载ssh","date":"2024-03-10T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n\n <!--more-->\n\n# Windows使用Git的ssh\n\n- 发现Windows的ssh服务版本较低，不好更新，选择使用Git的ssh（前提是你安装过Git），每次更新Git（`git update-git-for-windows`）ssh就会自动更新。\n\n## 1. 卸载windows的ssh服务\n\n- windows搜索：`可选功能`\n- ![](D:/blog/themes/yilia/source/img/experience/windows/ssh/1.png)\n- ![](img/experience/windows/ssh/1.png)\n\n## 2. 将Git的ssh目录加入环境变量\n\n- 通常Git的ssh是在Git/usr/bin下（用\\\\)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/ssh/2.png)\n![](img/experience/windows/ssh/2.png)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/ssh/3.png)\n![](img/experience/windows/ssh/3.png)\n\n \n\n","source":"_posts/experience/windows/ssh.md","raw":"---\ntitle: Windows卸载ssh\n\ndate: 2024-3-11\n\ntags: [windows]\n\ncategories: [windows]\n\ncomment: true\n\ntoc: true\n---\n\n#\n\n <!--more-->\n\n# Windows使用Git的ssh\n\n- 发现Windows的ssh服务版本较低，不好更新，选择使用Git的ssh（前提是你安装过Git），每次更新Git（`git update-git-for-windows`）ssh就会自动更新。\n\n## 1. 卸载windows的ssh服务\n\n- windows搜索：`可选功能`\n- ![](D:/blog/themes/yilia/source/img/experience/windows/ssh/1.png)\n- ![](img/experience/windows/ssh/1.png)\n\n## 2. 将Git的ssh目录加入环境变量\n\n- 通常Git的ssh是在Git/usr/bin下（用\\\\)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/ssh/2.png)\n![](img/experience/windows/ssh/2.png)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/ssh/3.png)\n![](img/experience/windows/ssh/3.png)\n\n \n\n","slug":"experience/windows/ssh","published":1,"updated":"2024-03-12T01:24:26.668Z","_id":"cltmv05zd000dlkvw4nr3cy57","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1> <span id=\"more\"></span>\n\n<h1 id=\"Windows使用Git的ssh\"><a href=\"#Windows使用Git的ssh\" class=\"headerlink\" title=\"Windows使用Git的ssh\"></a>Windows使用Git的ssh</h1><ul>\n<li>发现Windows的ssh服务版本较低，不好更新，选择使用Git的ssh（前提是你安装过Git），每次更新Git（<code>git update-git-for-windows</code>）ssh就会自动更新。</li>\n</ul>\n<h2 id=\"1-卸载windows的ssh服务\"><a href=\"#1-卸载windows的ssh服务\" class=\"headerlink\" title=\"1. 卸载windows的ssh服务\"></a>1. 卸载windows的ssh服务</h2><ul>\n<li>windows搜索：<code>可选功能</code></li>\n<li><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/1.png\"></li>\n<li><img src=\"/img/experience/windows/ssh/1.png\"></li>\n</ul>\n<h2 id=\"2-将Git的ssh目录加入环境变量\"><a href=\"#2-将Git的ssh目录加入环境变量\" class=\"headerlink\" title=\"2. 将Git的ssh目录加入环境变量\"></a>2. 将Git的ssh目录加入环境变量</h2><ul>\n<li>通常Git的ssh是在Git&#x2F;usr&#x2F;bin下（用\\)</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/2.png\"><br><img src=\"/img/experience/windows/ssh/2.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/3.png\"><br><img src=\"/img/experience/windows/ssh/3.png\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"Windows使用Git的ssh\"><a href=\"#Windows使用Git的ssh\" class=\"headerlink\" title=\"Windows使用Git的ssh\"></a>Windows使用Git的ssh</h1><ul>\n<li>发现Windows的ssh服务版本较低，不好更新，选择使用Git的ssh（前提是你安装过Git），每次更新Git（<code>git update-git-for-windows</code>）ssh就会自动更新。</li>\n</ul>\n<h2 id=\"1-卸载windows的ssh服务\"><a href=\"#1-卸载windows的ssh服务\" class=\"headerlink\" title=\"1. 卸载windows的ssh服务\"></a>1. 卸载windows的ssh服务</h2><ul>\n<li>windows搜索：<code>可选功能</code></li>\n<li><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/1.png\"></li>\n<li><img src=\"/img/experience/windows/ssh/1.png\"></li>\n</ul>\n<h2 id=\"2-将Git的ssh目录加入环境变量\"><a href=\"#2-将Git的ssh目录加入环境变量\" class=\"headerlink\" title=\"2. 将Git的ssh目录加入环境变量\"></a>2. 将Git的ssh目录加入环境变量</h2><ul>\n<li>通常Git的ssh是在Git&#x2F;usr&#x2F;bin下（用\\)</li>\n</ul>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/2.png\"><br><img src=\"/img/experience/windows/ssh/2.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/ssh/3.png\"><br><img src=\"/img/experience/windows/ssh/3.png\"></p>"},{"title":"生产实习-7 项目功能开发","date":"2024-03-08T04:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 7 项目功能开发\n![](D:/blog/themes/yilia/source/img/java/produce_practice/6/0.png)\n\n![](img/java/produce_practice/6/0.png)\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/6/1.png)\n\n![](img/java/produce_practice/6/1.png)\n\n## 7.1 项目实体创建\n\n- 创建ProjectInfo（之前用dbgan程序生成过），还需要在数据库创建表：\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS `myweb`.`project_info` (\n    `id` VARCHAR(45) NOT NULL,\n    `user_id` VARCHAR(45) NULL,\n    `project_name` VARCHAR(45) NULL,\n    `project_content` VARCHAR(45) NULL,\n    `created_by` VARCHAR(45) NULL,\n    `creation_date` DATETIME NULL,\n    `last_updated_by` VARCHAR(45) NULL,\n    `last_update_date` DATETIME NULL,\n    PRIMARY KEY (`id`))\n  ENGINE = InnoDB\n  ```\n\n## 7.2 数据库映射创建\n\n- 创建ProjectInfoMapper接口（之前dbgan程序生成过xml文件）\n\n## 7.3 创建功能接口\n\n- 先写service层的接口：ProjectService：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/6/3.png)\n\n  ![](img/java/produce_practice/6/3.png)\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.service;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  \n  import java.util.List;\n  \n  public interface ProjectService {\n      /**\n       * 增加项目\n       * @param projectInfo\n       * @return\n       */\n      int addProjectInfo(ProjectInfo projectInfo, String UserId);\n  \n      /**\n       * 修改项目\n       * @param projectInfo\n       * @return\n       */\n      int modifyProjectInfo(ProjectInfo projectInfo);\n  \n      /**\n       * 删除项目\n       * @param id\n       * @return\n       */\n      int deleteProjectById(String id);\n  \n      /**\n       * 查询项目列表\n       * @return\n       */\n      List<ProjectInfo> queryProjectList(ProjectInfo projectInfo);\n  }\n  \n  ```\n\n- 再写service实现类：ProjectServiceImpl:\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.service;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import com.lyingedu.questionnaire.dbmap.imapper.ProjectInfoMapper;\n  import jakarta.annotation.Resource;\n  import org.springframework.stereotype.Service;\n  \n  import java.util.List;\n  \n  @Service\n  public class ProjectServiceImpl implements ProjectService {\n      \n      @Resource\n      private ProjectInfoMapper projectInfoMapper;\n  \n      @Override\n      public int addProjectInfo(ProjectInfo projectInfo, String UserId) {\n          return 0;\n      }\n  \n      @Override\n      public int modifyProjectInfo(ProjectInfo projectInfo) {\n          return 0;\n      }\n  \n      @Override\n      public int deleteProjectById(String id) {\n          return 0;\n      }\n  \n      @Override\n      public List<ProjectInfo> queryProjectList(ProjectInfo projectInfo) {\n          return null;\n      }\n  \n  \n  }\n  \n  ```\n\n- 最后写control层：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/6/2.png)\n\n  ![](img/java/produce_practice/6/2.png)\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.controller;\n  \n  import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n  import com.lyingedu.questionnaire.biz.user.service.ProjectService;\n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import jakarta.annotation.Resource;\n  import lombok.extern.slf4j.Slf4j;\n  import org.springframework.web.bind.annotation.RequestBody;\n  import org.springframework.web.bind.annotation.RestController;\n  \n  \n  @RestController //rest的接口风格\n  @Slf4j\n  public class ProjectController {\n      @Resource\n      private ProjectService projectService;\n  \n      public HttpResponseEntity queryProjectList(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity addProjectInfo(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity modifyProjectInfo(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity deleteProjectById(@RequestBody String id){\n          return null;\n      }\n  \n  }\n  \n  ```\n\n  \n\n## 7.3 项目列表功能\n\n- 先查看对应的前端代码得到路径\n\n### 7.3.1 control层\n\n- ProjectController.queryProjectList：\n\n```java\n    @PostMapping(\"/queryProjectList\")\n    public HttpResponseEntity queryProjectList(@RequestBody ProjectInfo projectInfo){\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n\n        List<ProjectInfo> projectInfos = projectService.queryProjectList(projectInfo);\n        if(projectInfos.size() == 1) {\n            httpResponseEntity.setCode(\"666\");\n        }\n        httpResponseEntity.setData(projectInfos);\n\n        return httpResponseEntity;\n    }\n```\n\n\n\n### 7.3.2 service层\n\n- ProjectServiceImpl.queryProjectList：\n\n```java\n    public List<ProjectInfo> queryProjectList(ProjectInfo projectInfo) {\n\n        ProjectInfoExample projectInfoExample = new ProjectInfoExample();\n        ProjectInfoExample.Criteria projectInfoCriteria = projectInfoExample.createCriteria();\n        projectInfoCriteria.andCreatedByEqualTo(projectInfo.getCreatedBy());\n        return projectInfoMapper.selectByExample(projectInfoExample);\n    }\n```\n\n### 7.3.3 数据库映射\n\n- 实现selectByEanmple：\n\n- imapper函数接口（已经生成过了）：\n\n  ```java\n  package com.lyingedu.questionnaire.dbmap.imapper;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample;\n  import java.util.List;\n  import org.apache.ibatis.annotations.Param;\n  \n  public interface ProjectInfoMapper {\n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      long countByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int deleteByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int deleteByPrimaryKey(String id);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int insert(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int insertSelective(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      List<ProjectInfo> selectByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      ProjectInfo selectByPrimaryKey(String id);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByExampleSelective(@Param(\"row\") ProjectInfo row, @Param(\"example\") ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByExample(@Param(\"row\") ProjectInfo row, @Param(\"example\") ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByPrimaryKeySelective(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByPrimaryKey(ProjectInfo row);\n  }\n  ```\n\n  \n\n- xmapper执行sql（已经生成过了）：\n\n  ```java\n    <select id=\"selectByExample\" parameterType=\"com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample\" resultMap=\"BaseResultMap\">\n      <!--\n        WARNING - @mbg.generated\n        This element is automatically generated by MyBatis Generator, do not modify.\n        This element was generated on Tue Mar 05 14:17:07 CST 2024.\n      -->\n      select\n      <if test=\"distinct\">\n        distinct\n      </if>\n      <include refid=\"Base_Column_List\" />\n      from project_info\n      <if test=\"_parameter != null\">\n        <include refid=\"Example_Where_Clause\" />\n      </if>\n      <if test=\"orderByClause != null\">\n        order by ${orderByClause}\n      </if>\n    </select>\n  ```\n\n  \n\n### 7.3.3 测试\n\n- 登陆后会显示当前用户创建的问卷\n\n## 7.4 新建项目功能\n\n- 查看前端代码得到路径\n\n### 7.4.1 control层\n\n```java\n    @PostMapping(\"/addProjectInfo\")\n    public HttpResponseEntity addProjectInfo(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        int count = projectService.addProjectInfo(projectInfo, projectInfo.getCreatedBy()); //返回受影响的行数 //用户名要唯一\n        if(count == 1) { //插入成功则状态码为666，否则为默认错误值\n            httpResponseEntity.setCode(\"666\");\n        }\n        return httpResponseEntity;\n    }\n```\n\n### 7.4.2 service层\n\n```java\n    public int addProjectInfo(ProjectInfo projectInfo, String userName) {\n\n        projectInfo.setId(UUIDUtil.getOneUUID());\n        projectInfo.setCreatedBy(userName);\n        return projectInfoMapper.insert(projectInfo);\n    }\n```\n\n\n\n## 7.5 项目修改\n\n### 7.5.1 control层\n\n```java\n    @PostMapping(\"/modifyProjectInfo\")\n    public HttpResponseEntity modifyProjectInfo(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        projectService.modifyProjectInfo(projectInfo);\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setMessage(\"修改成功\");\n        return httpResponseEntity;\n    }\n```\n\n### 7.5.2 service层\n\n```java\n    public int modifyProjectInfo(ProjectInfo projectInfo) {\n        return projectInfoMapper.updateByPrimaryKeySelective(projectInfo)\n    }\n```\n\n\n\n## 7.6 项目删除\n\n### 7.6.1 control层\n\n```java\n    @PostMapping(\"/deleteProjectById\")\n    public HttpResponseEntity deleteProjectById(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        projectService.deleteProjectById(projectInfo.getId());\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setMessage(\"删除成功\");\n        return httpResponseEntity;\n    }\n```\n\n### 7.6.2 service层\n\n```java\n    public int deleteProjectById(String id) {\n        return projectInfoMapper.deleteByPrimaryKey(id);\n    }\n```\n\n","source":"_posts/java/produce_practice/7_project.md","raw":"---\ntitle: 生产实习-7 项目功能开发\n\ndate: 2024-3-8 12:00:00\n\ntags: [生产实习,java,springboot]\n\ncategories: [java]\n\ncomment: true\n\ntoc: true\n---\n\n#\n<!--more-->\n\n# 7 项目功能开发\n![](D:/blog/themes/yilia/source/img/java/produce_practice/6/0.png)\n\n![](img/java/produce_practice/6/0.png)\n\n![](D:/blog/themes/yilia/source/img/java/produce_practice/6/1.png)\n\n![](img/java/produce_practice/6/1.png)\n\n## 7.1 项目实体创建\n\n- 创建ProjectInfo（之前用dbgan程序生成过），还需要在数据库创建表：\n\n  ```sql\n  CREATE TABLE IF NOT EXISTS `myweb`.`project_info` (\n    `id` VARCHAR(45) NOT NULL,\n    `user_id` VARCHAR(45) NULL,\n    `project_name` VARCHAR(45) NULL,\n    `project_content` VARCHAR(45) NULL,\n    `created_by` VARCHAR(45) NULL,\n    `creation_date` DATETIME NULL,\n    `last_updated_by` VARCHAR(45) NULL,\n    `last_update_date` DATETIME NULL,\n    PRIMARY KEY (`id`))\n  ENGINE = InnoDB\n  ```\n\n## 7.2 数据库映射创建\n\n- 创建ProjectInfoMapper接口（之前dbgan程序生成过xml文件）\n\n## 7.3 创建功能接口\n\n- 先写service层的接口：ProjectService：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/6/3.png)\n\n  ![](img/java/produce_practice/6/3.png)\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.service;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  \n  import java.util.List;\n  \n  public interface ProjectService {\n      /**\n       * 增加项目\n       * @param projectInfo\n       * @return\n       */\n      int addProjectInfo(ProjectInfo projectInfo, String UserId);\n  \n      /**\n       * 修改项目\n       * @param projectInfo\n       * @return\n       */\n      int modifyProjectInfo(ProjectInfo projectInfo);\n  \n      /**\n       * 删除项目\n       * @param id\n       * @return\n       */\n      int deleteProjectById(String id);\n  \n      /**\n       * 查询项目列表\n       * @return\n       */\n      List<ProjectInfo> queryProjectList(ProjectInfo projectInfo);\n  }\n  \n  ```\n\n- 再写service实现类：ProjectServiceImpl:\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.service;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import com.lyingedu.questionnaire.dbmap.imapper.ProjectInfoMapper;\n  import jakarta.annotation.Resource;\n  import org.springframework.stereotype.Service;\n  \n  import java.util.List;\n  \n  @Service\n  public class ProjectServiceImpl implements ProjectService {\n      \n      @Resource\n      private ProjectInfoMapper projectInfoMapper;\n  \n      @Override\n      public int addProjectInfo(ProjectInfo projectInfo, String UserId) {\n          return 0;\n      }\n  \n      @Override\n      public int modifyProjectInfo(ProjectInfo projectInfo) {\n          return 0;\n      }\n  \n      @Override\n      public int deleteProjectById(String id) {\n          return 0;\n      }\n  \n      @Override\n      public List<ProjectInfo> queryProjectList(ProjectInfo projectInfo) {\n          return null;\n      }\n  \n  \n  }\n  \n  ```\n\n- 最后写control层：\n\n  ![](D:/blog/themes/yilia/source/img/java/produce_practice/6/2.png)\n\n  ![](img/java/produce_practice/6/2.png)\n\n  ```java\n  package com.lyingedu.questionnaire.biz.user.controller;\n  \n  import com.lyingedu.questionnaire.beans.HttpResponseEntity;\n  import com.lyingedu.questionnaire.biz.user.service.ProjectService;\n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import jakarta.annotation.Resource;\n  import lombok.extern.slf4j.Slf4j;\n  import org.springframework.web.bind.annotation.RequestBody;\n  import org.springframework.web.bind.annotation.RestController;\n  \n  \n  @RestController //rest的接口风格\n  @Slf4j\n  public class ProjectController {\n      @Resource\n      private ProjectService projectService;\n  \n      public HttpResponseEntity queryProjectList(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity addProjectInfo(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity modifyProjectInfo(@RequestBody ProjectInfo projectInfo){\n          return null;\n      }\n  \n      public HttpResponseEntity deleteProjectById(@RequestBody String id){\n          return null;\n      }\n  \n  }\n  \n  ```\n\n  \n\n## 7.3 项目列表功能\n\n- 先查看对应的前端代码得到路径\n\n### 7.3.1 control层\n\n- ProjectController.queryProjectList：\n\n```java\n    @PostMapping(\"/queryProjectList\")\n    public HttpResponseEntity queryProjectList(@RequestBody ProjectInfo projectInfo){\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n\n        List<ProjectInfo> projectInfos = projectService.queryProjectList(projectInfo);\n        if(projectInfos.size() == 1) {\n            httpResponseEntity.setCode(\"666\");\n        }\n        httpResponseEntity.setData(projectInfos);\n\n        return httpResponseEntity;\n    }\n```\n\n\n\n### 7.3.2 service层\n\n- ProjectServiceImpl.queryProjectList：\n\n```java\n    public List<ProjectInfo> queryProjectList(ProjectInfo projectInfo) {\n\n        ProjectInfoExample projectInfoExample = new ProjectInfoExample();\n        ProjectInfoExample.Criteria projectInfoCriteria = projectInfoExample.createCriteria();\n        projectInfoCriteria.andCreatedByEqualTo(projectInfo.getCreatedBy());\n        return projectInfoMapper.selectByExample(projectInfoExample);\n    }\n```\n\n### 7.3.3 数据库映射\n\n- 实现selectByEanmple：\n\n- imapper函数接口（已经生成过了）：\n\n  ```java\n  package com.lyingedu.questionnaire.dbmap.imapper;\n  \n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;\n  import com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample;\n  import java.util.List;\n  import org.apache.ibatis.annotations.Param;\n  \n  public interface ProjectInfoMapper {\n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      long countByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int deleteByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int deleteByPrimaryKey(String id);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int insert(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int insertSelective(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      List<ProjectInfo> selectByExample(ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      ProjectInfo selectByPrimaryKey(String id);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByExampleSelective(@Param(\"row\") ProjectInfo row, @Param(\"example\") ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByExample(@Param(\"row\") ProjectInfo row, @Param(\"example\") ProjectInfoExample example);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByPrimaryKeySelective(ProjectInfo row);\n  \n      /**\n       * This method was generated by MyBatis Generator.\n       * This method corresponds to the database table project_info\n       *\n       * @mbg.generated Tue Mar 05 14:17:07 CST 2024\n       */\n      int updateByPrimaryKey(ProjectInfo row);\n  }\n  ```\n\n  \n\n- xmapper执行sql（已经生成过了）：\n\n  ```java\n    <select id=\"selectByExample\" parameterType=\"com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample\" resultMap=\"BaseResultMap\">\n      <!--\n        WARNING - @mbg.generated\n        This element is automatically generated by MyBatis Generator, do not modify.\n        This element was generated on Tue Mar 05 14:17:07 CST 2024.\n      -->\n      select\n      <if test=\"distinct\">\n        distinct\n      </if>\n      <include refid=\"Base_Column_List\" />\n      from project_info\n      <if test=\"_parameter != null\">\n        <include refid=\"Example_Where_Clause\" />\n      </if>\n      <if test=\"orderByClause != null\">\n        order by ${orderByClause}\n      </if>\n    </select>\n  ```\n\n  \n\n### 7.3.3 测试\n\n- 登陆后会显示当前用户创建的问卷\n\n## 7.4 新建项目功能\n\n- 查看前端代码得到路径\n\n### 7.4.1 control层\n\n```java\n    @PostMapping(\"/addProjectInfo\")\n    public HttpResponseEntity addProjectInfo(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        int count = projectService.addProjectInfo(projectInfo, projectInfo.getCreatedBy()); //返回受影响的行数 //用户名要唯一\n        if(count == 1) { //插入成功则状态码为666，否则为默认错误值\n            httpResponseEntity.setCode(\"666\");\n        }\n        return httpResponseEntity;\n    }\n```\n\n### 7.4.2 service层\n\n```java\n    public int addProjectInfo(ProjectInfo projectInfo, String userName) {\n\n        projectInfo.setId(UUIDUtil.getOneUUID());\n        projectInfo.setCreatedBy(userName);\n        return projectInfoMapper.insert(projectInfo);\n    }\n```\n\n\n\n## 7.5 项目修改\n\n### 7.5.1 control层\n\n```java\n    @PostMapping(\"/modifyProjectInfo\")\n    public HttpResponseEntity modifyProjectInfo(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        projectService.modifyProjectInfo(projectInfo);\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setMessage(\"修改成功\");\n        return httpResponseEntity;\n    }\n```\n\n### 7.5.2 service层\n\n```java\n    public int modifyProjectInfo(ProjectInfo projectInfo) {\n        return projectInfoMapper.updateByPrimaryKeySelective(projectInfo)\n    }\n```\n\n\n\n## 7.6 项目删除\n\n### 7.6.1 control层\n\n```java\n    @PostMapping(\"/deleteProjectById\")\n    public HttpResponseEntity deleteProjectById(@RequestBody ProjectInfo projectInfo) {\n\n        HttpResponseEntity httpResponseEntity = new HttpResponseEntity();\n        projectService.deleteProjectById(projectInfo.getId());\n        httpResponseEntity.setCode(\"666\");\n        httpResponseEntity.setMessage(\"删除成功\");\n        return httpResponseEntity;\n    }\n```\n\n### 7.6.2 service层\n\n```java\n    public int deleteProjectById(String id) {\n        return projectInfoMapper.deleteByPrimaryKey(id);\n    }\n```\n\n","slug":"java/produce_practice/7_project","published":1,"updated":"2024-03-08T09:09:05.970Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltmv05zg000hlkvw3y8h0yn2","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"7-项目功能开发\"><a href=\"#7-项目功能开发\" class=\"headerlink\" title=\"7 项目功能开发\"></a>7 项目功能开发</h1><p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/0.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/0.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/1.png\"></p>\n<h2 id=\"7-1-项目实体创建\"><a href=\"#7-1-项目实体创建\" class=\"headerlink\" title=\"7.1 项目实体创建\"></a>7.1 项目实体创建</h2><ul>\n<li><p>创建ProjectInfo（之前用dbgan程序生成过），还需要在数据库创建表：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> `myweb`.`project_info` (</span><br><span class=\"line\">  `id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `user_id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `project_name` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `project_content` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `created_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `creation_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_updated_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`))</span><br><span class=\"line\">ENGINE <span class=\"operator\">=</span> InnoDB</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"7-2-数据库映射创建\"><a href=\"#7-2-数据库映射创建\" class=\"headerlink\" title=\"7.2 数据库映射创建\"></a>7.2 数据库映射创建</h2><ul>\n<li>创建ProjectInfoMapper接口（之前dbgan程序生成过xml文件）</li>\n</ul>\n<h2 id=\"7-3-创建功能接口\"><a href=\"#7-3-创建功能接口\" class=\"headerlink\" title=\"7.3 创建功能接口\"></a>7.3 创建功能接口</h2><ul>\n<li><p>先写service层的接口：ProjectService：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/3.png\"></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ProjectService</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> projectInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String UserId)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> projectInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> id</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询项目列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>再写service实现类：ProjectServiceImpl:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.ProjectInfoMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.stereotype.Service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Service</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">ProjectServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">ProjectService</span> &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> ProjectInfoMapper projectInfoMapper;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String UserId)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>最后写control层：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/2.png\"></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.controller;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.service.ProjectService;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RequestBody;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RestController</span> <span class=\"comment\">//rest的接口风格</span></span><br><span class=\"line\"><span class=\"meta\">@Slf4j</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">ProjectController</span> &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> ProjectService projectService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryProjectList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> String id)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"7-3-项目列表功能\"><a href=\"#7-3-项目列表功能\" class=\"headerlink\" title=\"7.3 项目列表功能\"></a>7.3 项目列表功能</h2><ul>\n<li>先查看对应的前端代码得到路径</li>\n</ul>\n<h3 id=\"7-3-1-control层\"><a href=\"#7-3-1-control层\" class=\"headerlink\" title=\"7.3.1 control层\"></a>7.3.1 control层</h3><ul>\n<li>ProjectController.queryProjectList：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/queryProjectList&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryProjectList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; projectInfos = projectService.queryProjectList(projectInfo);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(projectInfos.size() == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    httpResponseEntity.setData(projectInfos);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"7-3-2-service层\"><a href=\"#7-3-2-service层\" class=\"headerlink\" title=\"7.3.2 service层\"></a>7.3.2 service层</h3><ul>\n<li>ProjectServiceImpl.queryProjectList：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">ProjectInfoExample</span> <span class=\"variable\">projectInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">ProjectInfoExample</span>();</span><br><span class=\"line\">    ProjectInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">projectInfoCriteria</span> <span class=\"operator\">=</span> projectInfoExample.createCriteria();</span><br><span class=\"line\">    projectInfoCriteria.andCreatedByEqualTo(projectInfo.getCreatedBy());</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.selectByExample(projectInfoExample);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-3-3-数据库映射\"><a href=\"#7-3-3-数据库映射\" class=\"headerlink\" title=\"7.3.3 数据库映射\"></a>7.3.3 数据库映射</h3><ul>\n<li><p>实现selectByEanmple：</p>\n</li>\n<li><p>imapper函数接口（已经生成过了）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.dbmap.imapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.ibatis.annotations.Param;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ProjectInfoMapper</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">long</span> <span class=\"title function_\">countByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteByPrimaryKey</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">insert</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">insertSelective</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; <span class=\"title function_\">selectByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    ProjectInfo <span class=\"title function_\">selectByPrimaryKey</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByExampleSelective</span><span class=\"params\">(<span class=\"meta\">@Param(&quot;row&quot;)</span> ProjectInfo row, <span class=\"meta\">@Param(&quot;example&quot;)</span> ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByExample</span><span class=\"params\">(<span class=\"meta\">@Param(&quot;row&quot;)</span> ProjectInfo row, <span class=\"meta\">@Param(&quot;example&quot;)</span> ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByPrimaryKeySelective</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByPrimaryKey</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>xmapper执行sql（已经生成过了）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;select id=<span class=\"string\">&quot;selectByExample&quot;</span> parameterType=<span class=\"string\">&quot;com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample&quot;</span> resultMap=<span class=\"string\">&quot;BaseResultMap&quot;</span>&gt;</span><br><span class=\"line\">  &lt;!--</span><br><span class=\"line\">    WARNING - <span class=\"meta\">@mbg</span>.generated</span><br><span class=\"line\">    This element is automatically generated by MyBatis Generator, <span class=\"keyword\">do</span> not modify.</span><br><span class=\"line\">    This element was generated on Tue Mar <span class=\"number\">05</span> <span class=\"number\">14</span>:<span class=\"number\">17</span>:<span class=\"number\">07</span> CST <span class=\"number\">2024.</span></span><br><span class=\"line\">  --&gt;</span><br><span class=\"line\">  select</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;distinct&quot;</span>&gt;</span><br><span class=\"line\">    distinct</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">  &lt;include refid=<span class=\"string\">&quot;Base_Column_List&quot;</span> /&gt;</span><br><span class=\"line\">  from project_info</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;_parameter != null&quot;</span>&gt;</span><br><span class=\"line\">    &lt;include refid=<span class=\"string\">&quot;Example_Where_Clause&quot;</span> /&gt;</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;orderByClause != null&quot;</span>&gt;</span><br><span class=\"line\">    order by $&#123;orderByClause&#125;</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">&lt;/select&gt;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"7-3-3-测试\"><a href=\"#7-3-3-测试\" class=\"headerlink\" title=\"7.3.3 测试\"></a>7.3.3 测试</h3><ul>\n<li>登陆后会显示当前用户创建的问卷</li>\n</ul>\n<h2 id=\"7-4-新建项目功能\"><a href=\"#7-4-新建项目功能\" class=\"headerlink\" title=\"7.4 新建项目功能\"></a>7.4 新建项目功能</h2><ul>\n<li>查看前端代码得到路径</li>\n</ul>\n<h3 id=\"7-4-1-control层\"><a href=\"#7-4-1-control层\" class=\"headerlink\" title=\"7.4.1 control层\"></a>7.4.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/addProjectInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">count</span> <span class=\"operator\">=</span> projectService.addProjectInfo(projectInfo, projectInfo.getCreatedBy()); <span class=\"comment\">//返回受影响的行数 //用户名要唯一</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(count == <span class=\"number\">1</span>) &#123; <span class=\"comment\">//插入成功则状态码为666，否则为默认错误值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-4-2-service层\"><a href=\"#7-4-2-service层\" class=\"headerlink\" title=\"7.4.2 service层\"></a>7.4.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String userName)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    projectInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">    projectInfo.setCreatedBy(userName);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.insert(projectInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"7-5-项目修改\"><a href=\"#7-5-项目修改\" class=\"headerlink\" title=\"7.5 项目修改\"></a>7.5 项目修改</h2><h3 id=\"7-5-1-control层\"><a href=\"#7-5-1-control层\" class=\"headerlink\" title=\"7.5.1 control层\"></a>7.5.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/modifyProjectInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    projectService.modifyProjectInfo(projectInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setMessage(<span class=\"string\">&quot;修改成功&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-5-2-service层\"><a href=\"#7-5-2-service层\" class=\"headerlink\" title=\"7.5.2 service层\"></a>7.5.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.updateByPrimaryKeySelective(projectInfo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"7-6-项目删除\"><a href=\"#7-6-项目删除\" class=\"headerlink\" title=\"7.6 项目删除\"></a>7.6 项目删除</h2><h3 id=\"7-6-1-control层\"><a href=\"#7-6-1-control层\" class=\"headerlink\" title=\"7.6.1 control层\"></a>7.6.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/deleteProjectById&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    projectService.deleteProjectById(projectInfo.getId());</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setMessage(<span class=\"string\">&quot;删除成功&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-6-2-service层\"><a href=\"#7-6-2-service层\" class=\"headerlink\" title=\"7.6.2 service层\"></a>7.6.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.deleteByPrimaryKey(id);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"7-项目功能开发\"><a href=\"#7-项目功能开发\" class=\"headerlink\" title=\"7 项目功能开发\"></a>7 项目功能开发</h1><p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/0.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/0.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/1.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/1.png\"></p>\n<h2 id=\"7-1-项目实体创建\"><a href=\"#7-1-项目实体创建\" class=\"headerlink\" title=\"7.1 项目实体创建\"></a>7.1 项目实体创建</h2><ul>\n<li><p>创建ProjectInfo（之前用dbgan程序生成过），还需要在数据库创建表：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> IF <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> `myweb`.`project_info` (</span><br><span class=\"line\">  `id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `user_id` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `project_name` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `project_content` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `created_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `creation_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_updated_by` <span class=\"type\">VARCHAR</span>(<span class=\"number\">45</span>) <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `last_update_date` DATETIME <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`))</span><br><span class=\"line\">ENGINE <span class=\"operator\">=</span> InnoDB</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"7-2-数据库映射创建\"><a href=\"#7-2-数据库映射创建\" class=\"headerlink\" title=\"7.2 数据库映射创建\"></a>7.2 数据库映射创建</h2><ul>\n<li>创建ProjectInfoMapper接口（之前dbgan程序生成过xml文件）</li>\n</ul>\n<h2 id=\"7-3-创建功能接口\"><a href=\"#7-3-创建功能接口\" class=\"headerlink\" title=\"7.3 创建功能接口\"></a>7.3 创建功能接口</h2><ul>\n<li><p>先写service层的接口：ProjectService：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/3.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/3.png\"></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ProjectService</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 增加项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> projectInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String UserId)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 修改项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> projectInfo</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 删除项目</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> id</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 查询项目列表</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>再写service实现类：ProjectServiceImpl:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.imapper.ProjectInfoMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.stereotype.Service;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Service</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">ProjectServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">ProjectService</span> &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> ProjectInfoMapper projectInfoMapper;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String UserId)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>最后写control层：</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/java/produce_practice/6/2.png\"></p>\n<p><img src=\"/img/java/produce_practice/6/2.png\"></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.biz.user.controller;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.beans.HttpResponseEntity;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.biz.user.service.ProjectService;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> jakarta.annotation.Resource;</span><br><span class=\"line\"><span class=\"keyword\">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RequestBody;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@RestController</span> <span class=\"comment\">//rest的接口风格</span></span><br><span class=\"line\"><span class=\"meta\">@Slf4j</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">ProjectController</span> &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Resource</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> ProjectService projectService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryProjectList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> String id)</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"7-3-项目列表功能\"><a href=\"#7-3-项目列表功能\" class=\"headerlink\" title=\"7.3 项目列表功能\"></a>7.3 项目列表功能</h2><ul>\n<li>先查看对应的前端代码得到路径</li>\n</ul>\n<h3 id=\"7-3-1-control层\"><a href=\"#7-3-1-control层\" class=\"headerlink\" title=\"7.3.1 control层\"></a>7.3.1 control层</h3><ul>\n<li>ProjectController.queryProjectList：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/queryProjectList&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">queryProjectList</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; projectInfos = projectService.queryProjectList(projectInfo);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(projectInfos.size() == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    httpResponseEntity.setData(projectInfos);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"7-3-2-service层\"><a href=\"#7-3-2-service层\" class=\"headerlink\" title=\"7.3.2 service层\"></a>7.3.2 service层</h3><ul>\n<li>ProjectServiceImpl.queryProjectList：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> List&lt;ProjectInfo&gt; <span class=\"title function_\">queryProjectList</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">ProjectInfoExample</span> <span class=\"variable\">projectInfoExample</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">ProjectInfoExample</span>();</span><br><span class=\"line\">    ProjectInfoExample.<span class=\"type\">Criteria</span> <span class=\"variable\">projectInfoCriteria</span> <span class=\"operator\">=</span> projectInfoExample.createCriteria();</span><br><span class=\"line\">    projectInfoCriteria.andCreatedByEqualTo(projectInfo.getCreatedBy());</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.selectByExample(projectInfoExample);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-3-3-数据库映射\"><a href=\"#7-3-3-数据库映射\" class=\"headerlink\" title=\"7.3.3 数据库映射\"></a>7.3.3 数据库映射</h3><ul>\n<li><p>实现selectByEanmple：</p>\n</li>\n<li><p>imapper函数接口（已经生成过了）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.lyingedu.questionnaire.dbmap.imapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfo;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.List;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.ibatis.annotations.Param;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ProjectInfoMapper</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">long</span> <span class=\"title function_\">countByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">deleteByPrimaryKey</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">insert</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">insertSelective</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    List&lt;ProjectInfo&gt; <span class=\"title function_\">selectByExample</span><span class=\"params\">(ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    ProjectInfo <span class=\"title function_\">selectByPrimaryKey</span><span class=\"params\">(String id)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByExampleSelective</span><span class=\"params\">(<span class=\"meta\">@Param(&quot;row&quot;)</span> ProjectInfo row, <span class=\"meta\">@Param(&quot;example&quot;)</span> ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByExample</span><span class=\"params\">(<span class=\"meta\">@Param(&quot;row&quot;)</span> ProjectInfo row, <span class=\"meta\">@Param(&quot;example&quot;)</span> ProjectInfoExample example)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByPrimaryKeySelective</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * This method was generated by MyBatis Generator.</span></span><br><span class=\"line\"><span class=\"comment\">     * This method corresponds to the database table project_info</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@mbg</span>.generated Tue Mar 05 14:17:07 CST 2024</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"title function_\">updateByPrimaryKey</span><span class=\"params\">(ProjectInfo row)</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>xmapper执行sql（已经生成过了）：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;select id=<span class=\"string\">&quot;selectByExample&quot;</span> parameterType=<span class=\"string\">&quot;com.lyingedu.questionnaire.dbmap.entities.ProjectInfoExample&quot;</span> resultMap=<span class=\"string\">&quot;BaseResultMap&quot;</span>&gt;</span><br><span class=\"line\">  &lt;!--</span><br><span class=\"line\">    WARNING - <span class=\"meta\">@mbg</span>.generated</span><br><span class=\"line\">    This element is automatically generated by MyBatis Generator, <span class=\"keyword\">do</span> not modify.</span><br><span class=\"line\">    This element was generated on Tue Mar <span class=\"number\">05</span> <span class=\"number\">14</span>:<span class=\"number\">17</span>:<span class=\"number\">07</span> CST <span class=\"number\">2024.</span></span><br><span class=\"line\">  --&gt;</span><br><span class=\"line\">  select</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;distinct&quot;</span>&gt;</span><br><span class=\"line\">    distinct</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">  &lt;include refid=<span class=\"string\">&quot;Base_Column_List&quot;</span> /&gt;</span><br><span class=\"line\">  from project_info</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;_parameter != null&quot;</span>&gt;</span><br><span class=\"line\">    &lt;include refid=<span class=\"string\">&quot;Example_Where_Clause&quot;</span> /&gt;</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">  &lt;<span class=\"keyword\">if</span> test=<span class=\"string\">&quot;orderByClause != null&quot;</span>&gt;</span><br><span class=\"line\">    order by $&#123;orderByClause&#125;</span><br><span class=\"line\">  &lt;/<span class=\"keyword\">if</span>&gt;</span><br><span class=\"line\">&lt;/select&gt;</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"7-3-3-测试\"><a href=\"#7-3-3-测试\" class=\"headerlink\" title=\"7.3.3 测试\"></a>7.3.3 测试</h3><ul>\n<li>登陆后会显示当前用户创建的问卷</li>\n</ul>\n<h2 id=\"7-4-新建项目功能\"><a href=\"#7-4-新建项目功能\" class=\"headerlink\" title=\"7.4 新建项目功能\"></a>7.4 新建项目功能</h2><ul>\n<li>查看前端代码得到路径</li>\n</ul>\n<h3 id=\"7-4-1-control层\"><a href=\"#7-4-1-control层\" class=\"headerlink\" title=\"7.4.1 control层\"></a>7.4.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/addProjectInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">count</span> <span class=\"operator\">=</span> projectService.addProjectInfo(projectInfo, projectInfo.getCreatedBy()); <span class=\"comment\">//返回受影响的行数 //用户名要唯一</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(count == <span class=\"number\">1</span>) &#123; <span class=\"comment\">//插入成功则状态码为666，否则为默认错误值</span></span><br><span class=\"line\">        httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-4-2-service层\"><a href=\"#7-4-2-service层\" class=\"headerlink\" title=\"7.4.2 service层\"></a>7.4.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">addProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo, String userName)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    projectInfo.setId(UUIDUtil.getOneUUID());</span><br><span class=\"line\">    projectInfo.setCreatedBy(userName);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.insert(projectInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"7-5-项目修改\"><a href=\"#7-5-项目修改\" class=\"headerlink\" title=\"7.5 项目修改\"></a>7.5 项目修改</h2><h3 id=\"7-5-1-control层\"><a href=\"#7-5-1-control层\" class=\"headerlink\" title=\"7.5.1 control层\"></a>7.5.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/modifyProjectInfo&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    projectService.modifyProjectInfo(projectInfo);</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setMessage(<span class=\"string\">&quot;修改成功&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-5-2-service层\"><a href=\"#7-5-2-service层\" class=\"headerlink\" title=\"7.5.2 service层\"></a>7.5.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">modifyProjectInfo</span><span class=\"params\">(ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.updateByPrimaryKeySelective(projectInfo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"7-6-项目删除\"><a href=\"#7-6-项目删除\" class=\"headerlink\" title=\"7.6 项目删除\"></a>7.6 项目删除</h2><h3 id=\"7-6-1-control层\"><a href=\"#7-6-1-control层\" class=\"headerlink\" title=\"7.6.1 control层\"></a>7.6.1 control层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping(&quot;/deleteProjectById&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> HttpResponseEntity <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(<span class=\"meta\">@RequestBody</span> ProjectInfo projectInfo)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">HttpResponseEntity</span> <span class=\"variable\">httpResponseEntity</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">HttpResponseEntity</span>();</span><br><span class=\"line\">    projectService.deleteProjectById(projectInfo.getId());</span><br><span class=\"line\">    httpResponseEntity.setCode(<span class=\"string\">&quot;666&quot;</span>);</span><br><span class=\"line\">    httpResponseEntity.setMessage(<span class=\"string\">&quot;删除成功&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> httpResponseEntity;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-6-2-service层\"><a href=\"#7-6-2-service层\" class=\"headerlink\" title=\"7.6.2 service层\"></a>7.6.2 service层</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">deleteProjectById</span><span class=\"params\">(String id)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> projectInfoMapper.deleteByPrimaryKey(id);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"tmux使用","date":"2024-03-11T14:00:00.000Z","toc":true,"_content":"\n#\n\n<!--more-->\n\n\n\n# Linux中使用tmux\n\n-  假设你在本地windows powershell中连接了远端服务器，然后打开了服务器的tmux，然后在tmux中运行了一个python代码，代码还没跑完就将本地的windows powershell关掉了，但是你的服务器还能接着跑代码。\n\n\n\n- \n\n  |              |                                 |\n  | ------------ | ------------------------------- |\n  | 查看会话     | tmux ls                         |\n  | 删除会话     | tmux kill-session -t 会话名或id |\n  | 激活会话     | tmux attach -t 会话名或id       |\n  | 退出当前会话 | ctrl+d                          |\n\n- \n\n  |                  |                         |\n  | ---------------- | ----------------------- |\n  | 向左打开一个窗口 | ctrl+b %                |\n  | 向下打开一个窗口 | ctrl+b \"                |\n  | 调整窗口大小     | ctrl+b+方向（狂按方向） |\n|                  |                         |\n  \n  ","source":"_posts/linux/tmux.md","raw":"---\ntitle: tmux使用\ndate: 2024-03-11 22:00:00\ntoc: true\ntags: [Linux]\ncategories: [Linux]\n\n\n---\n\n#\n\n<!--more-->\n\n\n\n# Linux中使用tmux\n\n-  假设你在本地windows powershell中连接了远端服务器，然后打开了服务器的tmux，然后在tmux中运行了一个python代码，代码还没跑完就将本地的windows powershell关掉了，但是你的服务器还能接着跑代码。\n\n\n\n- \n\n  |              |                                 |\n  | ------------ | ------------------------------- |\n  | 查看会话     | tmux ls                         |\n  | 删除会话     | tmux kill-session -t 会话名或id |\n  | 激活会话     | tmux attach -t 会话名或id       |\n  | 退出当前会话 | ctrl+d                          |\n\n- \n\n  |                  |                         |\n  | ---------------- | ----------------------- |\n  | 向左打开一个窗口 | ctrl+b %                |\n  | 向下打开一个窗口 | ctrl+b \"                |\n  | 调整窗口大小     | ctrl+b+方向（狂按方向） |\n|                  |                         |\n  \n  ","slug":"linux/tmux","published":1,"updated":"2024-03-11T14:19:08.051Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltod2agt000050vwd1rrfdto","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n\n\n<h1 id=\"Linux中使用tmux\"><a href=\"#Linux中使用tmux\" class=\"headerlink\" title=\"Linux中使用tmux\"></a>Linux中使用tmux</h1><ul>\n<li><p>假设你在本地windows powershell中连接了远端服务器，然后打开了服务器的tmux，然后在tmux中运行了一个python代码，代码还没跑完就将本地的windows powershell关掉了，但是你的服务器还能接着跑代码。</p>\n</li>\n<li><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>查看会话</td>\n<td>tmux ls</td>\n</tr>\n<tr>\n<td>删除会话</td>\n<td>tmux kill-session -t 会话名或id</td>\n</tr>\n<tr>\n<td>激活会话</td>\n<td>tmux attach -t 会话名或id</td>\n</tr>\n<tr>\n<td>退出当前会话</td>\n<td>ctrl+d</td>\n</tr>\n</tbody></table>\n</li>\n<li><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>向左打开一个窗口</td>\n<td>ctrl+b %</td>\n</tr>\n<tr>\n<td>向下打开一个窗口</td>\n<td>ctrl+b “</td>\n</tr>\n<tr>\n<td>调整窗口大小</td>\n<td>ctrl+b+方向（狂按方向）</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>|                  |                         |</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"Linux中使用tmux\"><a href=\"#Linux中使用tmux\" class=\"headerlink\" title=\"Linux中使用tmux\"></a>Linux中使用tmux</h1><ul>\n<li><p>假设你在本地windows powershell中连接了远端服务器，然后打开了服务器的tmux，然后在tmux中运行了一个python代码，代码还没跑完就将本地的windows powershell关掉了，但是你的服务器还能接着跑代码。</p>\n</li>\n<li><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>查看会话</td>\n<td>tmux ls</td>\n</tr>\n<tr>\n<td>删除会话</td>\n<td>tmux kill-session -t 会话名或id</td>\n</tr>\n<tr>\n<td>激活会话</td>\n<td>tmux attach -t 会话名或id</td>\n</tr>\n<tr>\n<td>退出当前会话</td>\n<td>ctrl+d</td>\n</tr>\n</tbody></table>\n</li>\n<li><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>向左打开一个窗口</td>\n<td>ctrl+b %</td>\n</tr>\n<tr>\n<td>向下打开一个窗口</td>\n<td>ctrl+b “</td>\n</tr>\n<tr>\n<td>调整窗口大小</td>\n<td>ctrl+b+方向（狂按方向）</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>|                  |                         |</p>"},{"title":"Windows powershell美化","date":"2024-03-11T16:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n\n <!--more-->\n\n# Windows powershell美化\n\n- windows powershell编辑文件时颜色看不清（比如写python文件时，import语句看不见）\n\n## 1. 微软商店下载windows terminal\n\n![](D:/blog/themes/yilia/source/img/experience/windows/powershell/1.png)\n\n![](img/experience/windows/powershell/1.png)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/powershell/2.png)\n\n![](img/experience/windows/powershell/2.png)","source":"_posts/experience/windows/powershell.md","raw":"---\ntitle: Windows powershell美化\n\ndate: 2024-3-12\n\ntags: [windows]\n\ncategories: [windows]\n\ncomment: true\n\ntoc: true\n\n---\n\n#\n\n <!--more-->\n\n# Windows powershell美化\n\n- windows powershell编辑文件时颜色看不清（比如写python文件时，import语句看不见）\n\n## 1. 微软商店下载windows terminal\n\n![](D:/blog/themes/yilia/source/img/experience/windows/powershell/1.png)\n\n![](img/experience/windows/powershell/1.png)\n\n![](D:/blog/themes/yilia/source/img/experience/windows/powershell/2.png)\n\n![](img/experience/windows/powershell/2.png)","slug":"experience/windows/powershell","published":1,"updated":"2024-03-12T01:57:25.668Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltod2ah7000750vwfj9o5gdr","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1> <span id=\"more\"></span>\n\n<h1 id=\"Windows-powershell美化\"><a href=\"#Windows-powershell美化\" class=\"headerlink\" title=\"Windows powershell美化\"></a>Windows powershell美化</h1><ul>\n<li>windows powershell编辑文件时颜色看不清（比如写python文件时，import语句看不见）</li>\n</ul>\n<h2 id=\"1-微软商店下载windows-terminal\"><a href=\"#1-微软商店下载windows-terminal\" class=\"headerlink\" title=\"1. 微软商店下载windows terminal\"></a>1. 微软商店下载windows terminal</h2><p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/powershell/1.png\"></p>\n<p><img src=\"/img/experience/windows/powershell/1.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/powershell/2.png\"></p>\n<p><img src=\"/img/experience/windows/powershell/2.png\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"Windows-powershell美化\"><a href=\"#Windows-powershell美化\" class=\"headerlink\" title=\"Windows powershell美化\"></a>Windows powershell美化</h1><ul>\n<li>windows powershell编辑文件时颜色看不清（比如写python文件时，import语句看不见）</li>\n</ul>\n<h2 id=\"1-微软商店下载windows-terminal\"><a href=\"#1-微软商店下载windows-terminal\" class=\"headerlink\" title=\"1. 微软商店下载windows terminal\"></a>1. 微软商店下载windows terminal</h2><p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/powershell/1.png\"></p>\n<p><img src=\"/img/experience/windows/powershell/1.png\"></p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/windows/powershell/2.png\"></p>\n<p><img src=\"/img/experience/windows/powershell/2.png\"></p>"},{"title":"1-2 归并排序","date":"2023-10-01T16:00:00.000Z","comment":false,"toc":true,"_content":"\n#\n<!--more-->\n\n## 2 归并排序\n\n### 2.1 思想\n\n```\n1. 确定分界点 a[(l+r)/2]\n2. 递归排序左右\n3. 归并，合二为一（*）\n```\n\n### 2.2 算法模板\n```c\n#include<iostream>\n\nusing namespace std;\n\nint a[100010];\nint temp[100010];\nint n=0;\n\nvoid msort(int a[],int l,int r){\n    if(l>=r) return;\n    int mid=((r-l)>>1)+l;\n    msort(a,l,mid);\n    msort(a,mid+1,r);\n    \n    //merge\n    int i=l,j=mid+1,k=0;\n    while(i<=mid && j<=r){\n        temp[k++]=(a[i]<=a[j]?a[i++]:a[j++]);\n    }\n    while(i<=mid) temp[k++]=a[i++];\n    while(j<=r) temp[k++]=a[j++];\n    //\n    for(i=l,j=0;i<=r;i++,j++) a[i]=temp[j];\n}\n\nint main(){\n    scanf(\"%d\",&n);\n    for(int i=0;i<n;i++) scanf(\"%d\",&a[i]);\n    msort(a,0,n-1);\n    for(int i=0;i<n;i++) printf(\"%d \",a[i]);\n    return 0;\n}\n```\n\n```c++\n//测试\n5\n5 4 3 2 1\n```\n\n","source":"_posts/algorithm/1_base/2_mergesort.md","raw":"---\ntitle: 1-2 归并排序\n\ndate: 2023-10-02\n\ntags: [算法，排序]\n\ncategories: [算法]\n\ncomment: false\n\ntoc: true\n\n---\n\n#\n<!--more-->\n\n## 2 归并排序\n\n### 2.1 思想\n\n```\n1. 确定分界点 a[(l+r)/2]\n2. 递归排序左右\n3. 归并，合二为一（*）\n```\n\n### 2.2 算法模板\n```c\n#include<iostream>\n\nusing namespace std;\n\nint a[100010];\nint temp[100010];\nint n=0;\n\nvoid msort(int a[],int l,int r){\n    if(l>=r) return;\n    int mid=((r-l)>>1)+l;\n    msort(a,l,mid);\n    msort(a,mid+1,r);\n    \n    //merge\n    int i=l,j=mid+1,k=0;\n    while(i<=mid && j<=r){\n        temp[k++]=(a[i]<=a[j]?a[i++]:a[j++]);\n    }\n    while(i<=mid) temp[k++]=a[i++];\n    while(j<=r) temp[k++]=a[j++];\n    //\n    for(i=l,j=0;i<=r;i++,j++) a[i]=temp[j];\n}\n\nint main(){\n    scanf(\"%d\",&n);\n    for(int i=0;i<n;i++) scanf(\"%d\",&a[i]);\n    msort(a,0,n-1);\n    for(int i=0;i<n;i++) printf(\"%d \",a[i]);\n    return 0;\n}\n```\n\n```c++\n//测试\n5\n5 4 3 2 1\n```\n\n","slug":"algorithm/1_base/2_mergesort","published":1,"updated":"2024-04-18T05:33:39.799Z","_id":"cltwpq3va000038vw2mf7bg3v","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h2 id=\"2-归并排序\"><a href=\"#2-归并排序\" class=\"headerlink\" title=\"2 归并排序\"></a>2 归并排序</h2><h3 id=\"2-1-思想\"><a href=\"#2-1-思想\" class=\"headerlink\" title=\"2.1 思想\"></a>2.1 思想</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 确定分界点 a[(l+r)/2]</span><br><span class=\"line\">2. 递归排序左右</span><br><span class=\"line\">3. 归并，合二为一（*）</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-2-算法模板\"><a href=\"#2-2-算法模板\" class=\"headerlink\" title=\"2.2 算法模板\"></a>2.2 算法模板</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">using namespace <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> temp[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> n=<span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">msort</span><span class=\"params\">(<span class=\"type\">int</span> a[],<span class=\"type\">int</span> l,<span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(l&gt;=r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> mid=((r-l)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">    msort(a,l,mid);</span><br><span class=\"line\">    msort(a,mid+<span class=\"number\">1</span>,r);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//merge</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=l,j=mid+<span class=\"number\">1</span>,k=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=mid &amp;&amp; j&lt;=r)&#123;</span><br><span class=\"line\">        temp[k++]=(a[i]&lt;=a[j]?a[i++]:a[j++]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=mid) temp[k++]=a[i++];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j&lt;=r) temp[k++]=a[j++];</span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=l,j=<span class=\"number\">0</span>;i&lt;=r;i++,j++) a[i]=temp[j];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;n);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">    msort(a,<span class=\"number\">0</span>,n<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,a[i]);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//测试</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">5</span> <span class=\"number\">4</span> <span class=\"number\">3</span> <span class=\"number\">2</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h2 id=\"2-归并排序\"><a href=\"#2-归并排序\" class=\"headerlink\" title=\"2 归并排序\"></a>2 归并排序</h2><h3 id=\"2-1-思想\"><a href=\"#2-1-思想\" class=\"headerlink\" title=\"2.1 思想\"></a>2.1 思想</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 确定分界点 a[(l+r)/2]</span><br><span class=\"line\">2. 递归排序左右</span><br><span class=\"line\">3. 归并，合二为一（*）</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-2-算法模板\"><a href=\"#2-2-算法模板\" class=\"headerlink\" title=\"2.2 算法模板\"></a>2.2 算法模板</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">using namespace <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> temp[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> n=<span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">msort</span><span class=\"params\">(<span class=\"type\">int</span> a[],<span class=\"type\">int</span> l,<span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(l&gt;=r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> mid=((r-l)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">    msort(a,l,mid);</span><br><span class=\"line\">    msort(a,mid+<span class=\"number\">1</span>,r);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//merge</span></span><br><span class=\"line\">    <span class=\"type\">int</span> i=l,j=mid+<span class=\"number\">1</span>,k=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=mid &amp;&amp; j&lt;=r)&#123;</span><br><span class=\"line\">        temp[k++]=(a[i]&lt;=a[j]?a[i++]:a[j++]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;=mid) temp[k++]=a[i++];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j&lt;=r) temp[k++]=a[j++];</span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=l,j=<span class=\"number\">0</span>;i&lt;=r;i++,j++) a[i]=temp[j];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;n);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">    msort(a,<span class=\"number\">0</span>,n<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,a[i]);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//测试</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">5</span> <span class=\"number\">4</span> <span class=\"number\">3</span> <span class=\"number\">2</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>"},{"title":"鼠标侧键更改","date":"2024-03-18T00:00:00.000Z","comment":true,"toc":true,"_content":"\n#\n<!--more-->\n\n# 更改鼠标侧键\n\n- 原始的鼠标侧键是在浏览器/文件资源管理器中上一页下一页，想将其修改为其他快捷键。\n\n## 1. X-Mouse Button Control\n\n- [下载X-Mouse Button Control](https://www.highrez.co.uk/scripts/download.asp?package=XMouse)\n\n- 找到侧键位置，更改即可\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/mouse/1.png)\n\n  ![](img/experience/app/mouse/1.png)\n\n  - 此外还可以自己设置不同的方案等。\n\n## 2. autohotkey\n\n- [下载](https://www.autohotkey.com/)(两个都要下载)\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/mouse/2.png)\n\n  ![](img/experience/app/mouse/2.png) \n\n- 新建一个文件：\n\n     ![](D:/blog/themes/yilia/source/img/experience/app/mouse/3.png)\n\n    ![](img/experience/app/mouse/3.png) \n\n- 写入如下内容，实现短按、长按不同功能：\n\n  ```ahk\n  #Persistent\n  #UseHook\n  \n  XButton1::\n  KeyWait, XButton1, T0.2\n  If ErrorLevel ; 表示按键被长按\n      Send, #{v} ; 模拟按下 Win+V\n  Else\n      Send, ^{z} ; 模拟按下 Ctrl+Z\n  Return\n  \n  XButton2::\n  KeyWait, XButton2, T0.2\n  If ErrorLevel ; 表示按键被长按\n      Send, ^{v} ; 模拟按下 Ctrl+V\n  Else\n      Send, ^{c} ; 模拟按下 Ctrl+C\n  Return\n  ```\n\n  双击运行即可。\n  \n- 将该文件放到：`C:\\Users\\123\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup`开机自启动。","source":"_posts/experience/app/mouse.md","raw":"---\ntitle: 鼠标侧键更改\n\ndate: 2024-3-18 08:00:00\n\ntags: [鼠标]\n\ncategories: [经验]\n\ncomment: true\n\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n# 更改鼠标侧键\n\n- 原始的鼠标侧键是在浏览器/文件资源管理器中上一页下一页，想将其修改为其他快捷键。\n\n## 1. X-Mouse Button Control\n\n- [下载X-Mouse Button Control](https://www.highrez.co.uk/scripts/download.asp?package=XMouse)\n\n- 找到侧键位置，更改即可\n\n  ![](D:/blog/themes/yilia/source/img/experience/app/mouse/1.png)\n\n  ![](img/experience/app/mouse/1.png)\n\n  - 此外还可以自己设置不同的方案等。\n\n## 2. autohotkey\n\n- [下载](https://www.autohotkey.com/)(两个都要下载)\n\n   ![](D:/blog/themes/yilia/source/img/experience/app/mouse/2.png)\n\n  ![](img/experience/app/mouse/2.png) \n\n- 新建一个文件：\n\n     ![](D:/blog/themes/yilia/source/img/experience/app/mouse/3.png)\n\n    ![](img/experience/app/mouse/3.png) \n\n- 写入如下内容，实现短按、长按不同功能：\n\n  ```ahk\n  #Persistent\n  #UseHook\n  \n  XButton1::\n  KeyWait, XButton1, T0.2\n  If ErrorLevel ; 表示按键被长按\n      Send, #{v} ; 模拟按下 Win+V\n  Else\n      Send, ^{z} ; 模拟按下 Ctrl+Z\n  Return\n  \n  XButton2::\n  KeyWait, XButton2, T0.2\n  If ErrorLevel ; 表示按键被长按\n      Send, ^{v} ; 模拟按下 Ctrl+V\n  Else\n      Send, ^{c} ; 模拟按下 Ctrl+C\n  Return\n  ```\n\n  双击运行即可。\n  \n- 将该文件放到：`C:\\Users\\123\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup`开机自启动。","slug":"experience/app/mouse","published":1,"updated":"2024-03-18T08:55:28.271Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cltwpq3ve000138vw3rl5awse","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"更改鼠标侧键\"><a href=\"#更改鼠标侧键\" class=\"headerlink\" title=\"更改鼠标侧键\"></a>更改鼠标侧键</h1><ul>\n<li>原始的鼠标侧键是在浏览器&#x2F;文件资源管理器中上一页下一页，想将其修改为其他快捷键。</li>\n</ul>\n<h2 id=\"1-X-Mouse-Button-Control\"><a href=\"#1-X-Mouse-Button-Control\" class=\"headerlink\" title=\"1. X-Mouse Button Control\"></a>1. X-Mouse Button Control</h2><ul>\n<li><p><a href=\"https://www.highrez.co.uk/scripts/download.asp?package=XMouse\">下载X-Mouse Button Control</a></p>\n</li>\n<li><p>找到侧键位置，更改即可</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/1.png\"></p>\n<p><img src=\"/img/experience/app/mouse/1.png\"></p>\n<ul>\n<li>此外还可以自己设置不同的方案等。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-autohotkey\"><a href=\"#2-autohotkey\" class=\"headerlink\" title=\"2. autohotkey\"></a>2. autohotkey</h2><ul>\n<li><p><a href=\"https://www.autohotkey.com/\">下载</a>(两个都要下载)</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/2.png\"></p>\n<p><img src=\"/img/experience/app/mouse/2.png\"> </p>\n</li>\n<li><p>新建一个文件：</p>\n<p>   <img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/3.png\"></p>\n<p>  <img src=\"/img/experience/app/mouse/3.png\"> </p>\n</li>\n<li><p>写入如下内容，实现短按、长按不同功能：</p>\n<figure class=\"highlight ahk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#Persistent</span></span><br><span class=\"line\"><span class=\"meta\">#UseHook</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title\">XButton1::</span></span><br><span class=\"line\"><span class=\"built_in\">KeyWait,</span> XButton1, T0.<span class=\"number\">2</span></span><br><span class=\"line\">If <span class=\"built_in\">ErrorLevel</span> <span class=\"comment\">; 表示按键被长按</span></span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> #&#123;v&#125; <span class=\"comment\">; 模拟按下 Win+V</span></span><br><span class=\"line\">Else</span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;z&#125; <span class=\"comment\">; 模拟按下 Ctrl+Z</span></span><br><span class=\"line\"><span class=\"keyword\">Return</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title\">XButton2::</span></span><br><span class=\"line\"><span class=\"built_in\">KeyWait,</span> XButton2, T0.<span class=\"number\">2</span></span><br><span class=\"line\">If <span class=\"built_in\">ErrorLevel</span> <span class=\"comment\">; 表示按键被长按</span></span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;v&#125; <span class=\"comment\">; 模拟按下 Ctrl+V</span></span><br><span class=\"line\">Else</span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;c&#125; <span class=\"comment\">; 模拟按下 Ctrl+C</span></span><br><span class=\"line\"><span class=\"keyword\">Return</span></span><br></pre></td></tr></table></figure>\n\n<p>双击运行即可。</p>\n</li>\n<li><p>将该文件放到：<code>C:\\Users\\123\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup</code>开机自启动。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"更改鼠标侧键\"><a href=\"#更改鼠标侧键\" class=\"headerlink\" title=\"更改鼠标侧键\"></a>更改鼠标侧键</h1><ul>\n<li>原始的鼠标侧键是在浏览器&#x2F;文件资源管理器中上一页下一页，想将其修改为其他快捷键。</li>\n</ul>\n<h2 id=\"1-X-Mouse-Button-Control\"><a href=\"#1-X-Mouse-Button-Control\" class=\"headerlink\" title=\"1. X-Mouse Button Control\"></a>1. X-Mouse Button Control</h2><ul>\n<li><p><a href=\"https://www.highrez.co.uk/scripts/download.asp?package=XMouse\">下载X-Mouse Button Control</a></p>\n</li>\n<li><p>找到侧键位置，更改即可</p>\n<p><img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/1.png\"></p>\n<p><img src=\"/img/experience/app/mouse/1.png\"></p>\n<ul>\n<li>此外还可以自己设置不同的方案等。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-autohotkey\"><a href=\"#2-autohotkey\" class=\"headerlink\" title=\"2. autohotkey\"></a>2. autohotkey</h2><ul>\n<li><p><a href=\"https://www.autohotkey.com/\">下载</a>(两个都要下载)</p>\n<p> <img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/2.png\"></p>\n<p><img src=\"/img/experience/app/mouse/2.png\"> </p>\n</li>\n<li><p>新建一个文件：</p>\n<p>   <img src=\"D:/blog/themes/yilia/source/img/experience/app/mouse/3.png\"></p>\n<p>  <img src=\"/img/experience/app/mouse/3.png\"> </p>\n</li>\n<li><p>写入如下内容，实现短按、长按不同功能：</p>\n<figure class=\"highlight ahk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#Persistent</span></span><br><span class=\"line\"><span class=\"meta\">#UseHook</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title\">XButton1::</span></span><br><span class=\"line\"><span class=\"built_in\">KeyWait,</span> XButton1, T0.<span class=\"number\">2</span></span><br><span class=\"line\">If <span class=\"built_in\">ErrorLevel</span> <span class=\"comment\">; 表示按键被长按</span></span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> #&#123;v&#125; <span class=\"comment\">; 模拟按下 Win+V</span></span><br><span class=\"line\">Else</span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;z&#125; <span class=\"comment\">; 模拟按下 Ctrl+Z</span></span><br><span class=\"line\"><span class=\"keyword\">Return</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title\">XButton2::</span></span><br><span class=\"line\"><span class=\"built_in\">KeyWait,</span> XButton2, T0.<span class=\"number\">2</span></span><br><span class=\"line\">If <span class=\"built_in\">ErrorLevel</span> <span class=\"comment\">; 表示按键被长按</span></span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;v&#125; <span class=\"comment\">; 模拟按下 Ctrl+V</span></span><br><span class=\"line\">Else</span><br><span class=\"line\"><span class=\"built_in\">    Send,</span> ^&#123;c&#125; <span class=\"comment\">; 模拟按下 Ctrl+C</span></span><br><span class=\"line\"><span class=\"keyword\">Return</span></span><br></pre></td></tr></table></figure>\n\n<p>双击运行即可。</p>\n</li>\n<li><p>将该文件放到：<code>C:\\Users\\123\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup</code>开机自启动。</p>\n</li>\n</ul>"},{"title":"1-1. 快速排序","date":"2023-10-01T16:00:00.000Z","comment":false,"toc":true,"_content":"#\n<!--more-->\n\n# 1 快速排序\n\n### 1. 1 思想\n\n```\n1. 确定分界点\n\t- q[l]\n\t- q[r]\n\t- q[(l+r)/2]\n\t- q[random]\n2. 调整区间（*）\n\t- 左边<=x x0 右边>=x\n\t- x不一定在x0位置\n3. 递归两端\n```\n```\n1. 暴力求解\n\ta[], b[], c[],对c进行排序，<=x的放到a，>=x的放到b。放完后先将a放到c，再将b放到c.\n\t\n2. 优化空间\n\t定义左右指针i,j当c[i]>x时停，当c[j]<x时停。两个都停之后交换。\n```\n### 1.2 算法模板\n```c\n#include<iostream>\nusing namespace std;\nint a[100000];\nvoid qsort(int a[],int l, int r){\n    if(l>=r) return;\n    int i=l-1,j=r+1;\n    int x=a[((r-l)>>1)+l];\n    while(i<j){\n        do i++; while(a[i]<x);\n        do j--; while(a[j]>x);\n        if(i<j) swap(a[i],a[j]);\n    }\n    qsort(a,l,j);\n    qsort(a,j+1,r);\n}\n\nint main(){\n    int n;\n    scanf(\"%d\",&n);\n    for(int i=0;i<n;i++) scanf(\"%d\",&a[i]);\n    qsort(a,0,n-1);\n    for(int i=0;i<n;i++) printf(\"%d \",a[i]);\n}\n```\n```\n//输入\n5\n5 4 3 2 1\n```\n\n\n\n- 可以考虑使用i或j\n- 可以考虑使用while(a[i++])\n\n- 快排不稳定，如果要变成稳定的，可以变成<a[i], i>\n\n\n","source":"_posts/algorithm/1_base/1_qsort.md","raw":"---\ntitle: 1-1. 快速排序\n\ndate: 2023-10-02\n\ntags: [算法，排序]\n\ncategories: [算法]\n\ncomment: false\n\ntoc: true\n---\n#\n<!--more-->\n\n# 1 快速排序\n\n### 1. 1 思想\n\n```\n1. 确定分界点\n\t- q[l]\n\t- q[r]\n\t- q[(l+r)/2]\n\t- q[random]\n2. 调整区间（*）\n\t- 左边<=x x0 右边>=x\n\t- x不一定在x0位置\n3. 递归两端\n```\n```\n1. 暴力求解\n\ta[], b[], c[],对c进行排序，<=x的放到a，>=x的放到b。放完后先将a放到c，再将b放到c.\n\t\n2. 优化空间\n\t定义左右指针i,j当c[i]>x时停，当c[j]<x时停。两个都停之后交换。\n```\n### 1.2 算法模板\n```c\n#include<iostream>\nusing namespace std;\nint a[100000];\nvoid qsort(int a[],int l, int r){\n    if(l>=r) return;\n    int i=l-1,j=r+1;\n    int x=a[((r-l)>>1)+l];\n    while(i<j){\n        do i++; while(a[i]<x);\n        do j--; while(a[j]>x);\n        if(i<j) swap(a[i],a[j]);\n    }\n    qsort(a,l,j);\n    qsort(a,j+1,r);\n}\n\nint main(){\n    int n;\n    scanf(\"%d\",&n);\n    for(int i=0;i<n;i++) scanf(\"%d\",&a[i]);\n    qsort(a,0,n-1);\n    for(int i=0;i<n;i++) printf(\"%d \",a[i]);\n}\n```\n```\n//输入\n5\n5 4 3 2 1\n```\n\n\n\n- 可以考虑使用i或j\n- 可以考虑使用while(a[i++])\n\n- 快排不稳定，如果要变成稳定的，可以变成<a[i], i>\n\n\n","slug":"algorithm/1_base/1_qsort","published":1,"updated":"2024-04-18T05:31:36.551Z","_id":"cltwpq3vg000338vw0lct49bb","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"1-快速排序\"><a href=\"#1-快速排序\" class=\"headerlink\" title=\"1 快速排序\"></a>1 快速排序</h1><h3 id=\"1-1-思想\"><a href=\"#1-1-思想\" class=\"headerlink\" title=\"1. 1 思想\"></a>1. 1 思想</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 确定分界点</span><br><span class=\"line\">\t- q[l]</span><br><span class=\"line\">\t- q[r]</span><br><span class=\"line\">\t- q[(l+r)/2]</span><br><span class=\"line\">\t- q[random]</span><br><span class=\"line\">2. 调整区间（*）</span><br><span class=\"line\">\t- 左边&lt;=x x0 右边&gt;=x</span><br><span class=\"line\">\t- x不一定在x0位置</span><br><span class=\"line\">3. 递归两端</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 暴力求解</span><br><span class=\"line\">\ta[], b[], c[],对c进行排序，&lt;=x的放到a，&gt;=x的放到b。放完后先将a放到c，再将b放到c.</span><br><span class=\"line\">\t</span><br><span class=\"line\">2. 优化空间</span><br><span class=\"line\">\t定义左右指针i,j当c[i]&gt;x时停，当c[j]&lt;x时停。两个都停之后交换。</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-算法模板\"><a href=\"#1-2-算法模板\" class=\"headerlink\" title=\"1.2 算法模板\"></a>1.2 算法模板</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\">using namespace <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100000</span>];</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">qsort</span><span class=\"params\">(<span class=\"type\">int</span> a[],<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(l&gt;=r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=l<span class=\"number\">-1</span>,j=r+<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> x=a[((r-l)&gt;&gt;<span class=\"number\">1</span>)+l];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;j)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> i++; <span class=\"keyword\">while</span>(a[i]&lt;x);</span><br><span class=\"line\">        <span class=\"keyword\">do</span> j--; <span class=\"keyword\">while</span>(a[j]&gt;x);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(i&lt;j) swap(a[i],a[j]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    qsort(a,l,j);</span><br><span class=\"line\">    qsort(a,j+<span class=\"number\">1</span>,r);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> n;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;n);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">    qsort(a,<span class=\"number\">0</span>,n<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,a[i]);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//输入</span><br><span class=\"line\">5</span><br><span class=\"line\">5 4 3 2 1</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li><p>可以考虑使用i或j</p>\n</li>\n<li><p>可以考虑使用while(a[i++])</p>\n</li>\n<li><p>快排不稳定，如果要变成稳定的，可以变成&lt;a[i], i&gt;</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-快速排序\"><a href=\"#1-快速排序\" class=\"headerlink\" title=\"1 快速排序\"></a>1 快速排序</h1><h3 id=\"1-1-思想\"><a href=\"#1-1-思想\" class=\"headerlink\" title=\"1. 1 思想\"></a>1. 1 思想</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 确定分界点</span><br><span class=\"line\">\t- q[l]</span><br><span class=\"line\">\t- q[r]</span><br><span class=\"line\">\t- q[(l+r)/2]</span><br><span class=\"line\">\t- q[random]</span><br><span class=\"line\">2. 调整区间（*）</span><br><span class=\"line\">\t- 左边&lt;=x x0 右边&gt;=x</span><br><span class=\"line\">\t- x不一定在x0位置</span><br><span class=\"line\">3. 递归两端</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 暴力求解</span><br><span class=\"line\">\ta[], b[], c[],对c进行排序，&lt;=x的放到a，&gt;=x的放到b。放完后先将a放到c，再将b放到c.</span><br><span class=\"line\">\t</span><br><span class=\"line\">2. 优化空间</span><br><span class=\"line\">\t定义左右指针i,j当c[i]&gt;x时停，当c[j]&lt;x时停。两个都停之后交换。</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-算法模板\"><a href=\"#1-2-算法模板\" class=\"headerlink\" title=\"1.2 算法模板\"></a>1.2 算法模板</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\">using namespace <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100000</span>];</span><br><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">qsort</span><span class=\"params\">(<span class=\"type\">int</span> a[],<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(l&gt;=r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> i=l<span class=\"number\">-1</span>,j=r+<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> x=a[((r-l)&gt;&gt;<span class=\"number\">1</span>)+l];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(i&lt;j)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> i++; <span class=\"keyword\">while</span>(a[i]&lt;x);</span><br><span class=\"line\">        <span class=\"keyword\">do</span> j--; <span class=\"keyword\">while</span>(a[j]&gt;x);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(i&lt;j) swap(a[i],a[j]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    qsort(a,l,j);</span><br><span class=\"line\">    qsort(a,j+<span class=\"number\">1</span>,r);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> n;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;n);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">    qsort(a,<span class=\"number\">0</span>,n<span class=\"number\">-1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>;i&lt;n;i++) <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;%d &quot;</span>,a[i]);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//输入</span><br><span class=\"line\">5</span><br><span class=\"line\">5 4 3 2 1</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li><p>可以考虑使用i或j</p>\n</li>\n<li><p>可以考虑使用while(a[i++])</p>\n</li>\n<li><p>快排不稳定，如果要变成稳定的，可以变成&lt;a[i], i&gt;</p>\n</li>\n</ul>"},{"title":"3.7 前向传播、反向传播和计算图","date":"2024-02-07T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 7 前向传播、反向传播和计算图\n- 以带dropout的单层隐藏层mlp为例\n## 7.1 前向传播\n- 按顺序（从输入层到输出层）计算和存储神经网络中每层的结果s。\n    - 1）输入是$\\mathbf{x} \\in \\mathbb{R}^d$，隐藏层不含偏置,得到中间变量：\n    $$\\mathbf{z}=\\mathbf{W}^{(1)}\\mathbf{x}$$\n    - 2）激活：\n    $$\\mathbf{h}=\\phi(\\mathbf{z})$$\n    - 3）输出：\n    $$\\mathbf{o}=\\mathbf{W}^{(2)}\\mathbf{h}$$\n    - 4）损失：\n    $$L=l(\\mathbf{o},y)$$\n    - 5）正则化项（权重衰减）：\n        $$s=\\frac{\\lambda}{2}(||\\mathbf{W}^{(1)}||^2_F+||\\mathbf{W}^{(2)}||^2_F)$$\n        - 其中矩阵的Frobenius范数是将矩阵展平成向量后应用$L_2$范数。\n    - 6）目标函数：\n    $$J=L+s$$\n    \n## 7.2 前向传播计算图\n- 7.1的计算图：\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\7\\1.png)\n![](img/deeplearning/code/pytorch/3_mlp/7/1.png)\n\n\n## 7.3 反向传播\n- 根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。\n- 链式法则：假设有$Y=f(X)$和$Z=g(Y)$，有:\n    $$\\frac{\\partial{Z}}{\\partial{X}}=prod(\\frac{\\partial{Z}}{\\partial{Y}},\\frac{\\partial{Y}}{\\partial{X}})$$\n    - prod表示一定的操作\n- 针对前向传播计算图计算反向梯度：\n    $$\\frac{\\partial J}{\\partial L}=1\\mathrm{~and~}\\frac{\\partial J}{\\partial s}=1$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{o}}=\\text{prod}\\left(\\frac{\\partial J}{\\partial L},\\frac{\\partial L}{\\partial\\mathbf{o}}\\right)=\\frac{\\partial L}{\\partial\\mathbf{o}}\\in\\mathbb{R}^q$$\n    $$\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}=\\lambda\\mathbf{W}^{(1)}\\mathrm{~and~}\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}=\\lambda\\mathbf{W}^{(2)}$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{W}^{(2)}}=\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{W}^{(2)}}\\right)+\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{o}}\\mathbf{h}^\\top+\\lambda\\mathbf{W}^{(2)}$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{h}}=\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{h}}\\right)=\\mathbf{W}^{(2)^\\top}\\frac{\\partial J}{\\partial\\mathbf{o}}$$\n    由于激活函数$\\phi$是按元素计算的，因此计算$\\frac{\\partial J}{\\partial \\mathbf{z}}$需要使用按元素乘法运算符：\n    $$\\frac{\\partial J}{\\partial\\mathbf{z}}=\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{h}},\\frac{\\partial\\mathbf{h}}{\\partial\\mathbf{z}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{h}}\\odot\\phi^{\\prime}\\left(\\mathbf{z}\\right)$$\n    $$\\begin{aligned}\\frac{\\partial J}{\\partial\\mathbf{W}^{(1)}}&=\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{z}},\\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{W}^{(1)}}\\right)+\\text{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{z}}\\mathbf{x}^\\top+\\lambda\\mathbf{W}^{(1)}\\end{aligned}$$\n\n## 7.4 训练神经网络\n- 训练神经网络时，对于前向传播，沿着依赖的方向遍历计算图并计算路径上的所有变量。然后将这些用于反向传播，其中计算顺序与计算图的相反。\n- 一方面，在前向传播期间计算正则项取决于模型参数W(1)和 W(2)的当前值。它们是由优化算法根据最近迭代的反向传播给出的。\n- 另一方面，反向传播期间参数$\\frac{\\partial J}{\\partial W^{(2)}}$的梯度计算，取决于由前向传播给出的隐藏变量h的当前值。\n- 因此，在训练神经网络时，在初始化模型参数后，我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。\n- 反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。\n","source":"_posts/deeplearning/code/pytorch/3_mlp/7_backward.md","raw":"---\ntitle: 3.7 前向传播、反向传播和计算图\ndate: 2024-2-7 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 7 前向传播、反向传播和计算图\n- 以带dropout的单层隐藏层mlp为例\n## 7.1 前向传播\n- 按顺序（从输入层到输出层）计算和存储神经网络中每层的结果s。\n    - 1）输入是$\\mathbf{x} \\in \\mathbb{R}^d$，隐藏层不含偏置,得到中间变量：\n    $$\\mathbf{z}=\\mathbf{W}^{(1)}\\mathbf{x}$$\n    - 2）激活：\n    $$\\mathbf{h}=\\phi(\\mathbf{z})$$\n    - 3）输出：\n    $$\\mathbf{o}=\\mathbf{W}^{(2)}\\mathbf{h}$$\n    - 4）损失：\n    $$L=l(\\mathbf{o},y)$$\n    - 5）正则化项（权重衰减）：\n        $$s=\\frac{\\lambda}{2}(||\\mathbf{W}^{(1)}||^2_F+||\\mathbf{W}^{(2)}||^2_F)$$\n        - 其中矩阵的Frobenius范数是将矩阵展平成向量后应用$L_2$范数。\n    - 6）目标函数：\n    $$J=L+s$$\n    \n## 7.2 前向传播计算图\n- 7.1的计算图：\n![](D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\7\\1.png)\n![](img/deeplearning/code/pytorch/3_mlp/7/1.png)\n\n\n## 7.3 反向传播\n- 根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。\n- 链式法则：假设有$Y=f(X)$和$Z=g(Y)$，有:\n    $$\\frac{\\partial{Z}}{\\partial{X}}=prod(\\frac{\\partial{Z}}{\\partial{Y}},\\frac{\\partial{Y}}{\\partial{X}})$$\n    - prod表示一定的操作\n- 针对前向传播计算图计算反向梯度：\n    $$\\frac{\\partial J}{\\partial L}=1\\mathrm{~and~}\\frac{\\partial J}{\\partial s}=1$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{o}}=\\text{prod}\\left(\\frac{\\partial J}{\\partial L},\\frac{\\partial L}{\\partial\\mathbf{o}}\\right)=\\frac{\\partial L}{\\partial\\mathbf{o}}\\in\\mathbb{R}^q$$\n    $$\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}=\\lambda\\mathbf{W}^{(1)}\\mathrm{~and~}\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}=\\lambda\\mathbf{W}^{(2)}$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{W}^{(2)}}=\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{W}^{(2)}}\\right)+\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{o}}\\mathbf{h}^\\top+\\lambda\\mathbf{W}^{(2)}$$\n    $$\\frac{\\partial J}{\\partial\\mathbf{h}}=\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{h}}\\right)=\\mathbf{W}^{(2)^\\top}\\frac{\\partial J}{\\partial\\mathbf{o}}$$\n    由于激活函数$\\phi$是按元素计算的，因此计算$\\frac{\\partial J}{\\partial \\mathbf{z}}$需要使用按元素乘法运算符：\n    $$\\frac{\\partial J}{\\partial\\mathbf{z}}=\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{h}},\\frac{\\partial\\mathbf{h}}{\\partial\\mathbf{z}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{h}}\\odot\\phi^{\\prime}\\left(\\mathbf{z}\\right)$$\n    $$\\begin{aligned}\\frac{\\partial J}{\\partial\\mathbf{W}^{(1)}}&=\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{z}},\\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{W}^{(1)}}\\right)+\\text{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}\\right)=\\frac{\\partial J}{\\partial\\mathbf{z}}\\mathbf{x}^\\top+\\lambda\\mathbf{W}^{(1)}\\end{aligned}$$\n\n## 7.4 训练神经网络\n- 训练神经网络时，对于前向传播，沿着依赖的方向遍历计算图并计算路径上的所有变量。然后将这些用于反向传播，其中计算顺序与计算图的相反。\n- 一方面，在前向传播期间计算正则项取决于模型参数W(1)和 W(2)的当前值。它们是由优化算法根据最近迭代的反向传播给出的。\n- 另一方面，反向传播期间参数$\\frac{\\partial J}{\\partial W^{(2)}}$的梯度计算，取决于由前向传播给出的隐藏变量h的当前值。\n- 因此，在训练神经网络时，在初始化模型参数后，我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。\n- 反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。\n","slug":"deeplearning/code/pytorch/3_mlp/7_backward","published":1,"updated":"2024-03-18T09:18:45.165Z","_id":"cltwpq3vq000538vwgdld38mn","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"7-前向传播、反向传播和计算图\"><a href=\"#7-前向传播、反向传播和计算图\" class=\"headerlink\" title=\"7 前向传播、反向传播和计算图\"></a>7 前向传播、反向传播和计算图</h1><ul>\n<li>以带dropout的单层隐藏层mlp为例</li>\n</ul>\n<h2 id=\"7-1-前向传播\"><a href=\"#7-1-前向传播\" class=\"headerlink\" title=\"7.1 前向传播\"></a>7.1 前向传播</h2><ul>\n<li>按顺序（从输入层到输出层）计算和存储神经网络中每层的结果s。<ul>\n<li>1）输入是$\\mathbf{x} \\in \\mathbb{R}^d$，隐藏层不含偏置,得到中间变量：<br>  $$\\mathbf{z}&#x3D;\\mathbf{W}^{(1)}\\mathbf{x}$$</li>\n<li>2）激活：<br>  $$\\mathbf{h}&#x3D;\\phi(\\mathbf{z})$$</li>\n<li>3）输出：<br>  $$\\mathbf{o}&#x3D;\\mathbf{W}^{(2)}\\mathbf{h}$$</li>\n<li>4）损失：<br>  $$L&#x3D;l(\\mathbf{o},y)$$</li>\n<li>5）正则化项（权重衰减）：<br>  $$s&#x3D;\\frac{\\lambda}{2}(||\\mathbf{W}^{(1)}||^2_F+||\\mathbf{W}^{(2)}||^2_F)$$<ul>\n<li>其中矩阵的Frobenius范数是将矩阵展平成向量后应用$L_2$范数。</li>\n</ul>\n</li>\n<li>6）目标函数：<br>  $$J&#x3D;L+s$$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"7-2-前向传播计算图\"><a href=\"#7-2-前向传播计算图\" class=\"headerlink\" title=\"7.2 前向传播计算图\"></a>7.2 前向传播计算图</h2><ul>\n<li>7.1的计算图：<br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\7\\1.png\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/7/1.png\"></li>\n</ul>\n<h2 id=\"7-3-反向传播\"><a href=\"#7-3-反向传播\" class=\"headerlink\" title=\"7.3 反向传播\"></a>7.3 反向传播</h2><ul>\n<li>根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。</li>\n<li>链式法则：假设有$Y&#x3D;f(X)$和$Z&#x3D;g(Y)$，有:<br>  $$\\frac{\\partial{Z}}{\\partial{X}}&#x3D;prod(\\frac{\\partial{Z}}{\\partial{Y}},\\frac{\\partial{Y}}{\\partial{X}})$$<ul>\n<li>prod表示一定的操作</li>\n</ul>\n</li>\n<li>针对前向传播计算图计算反向梯度：<br>  $$\\frac{\\partial J}{\\partial L}&#x3D;1\\mathrm{<del>and</del>}\\frac{\\partial J}{\\partial s}&#x3D;1$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{o}}&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial L},\\frac{\\partial L}{\\partial\\mathbf{o}}\\right)&#x3D;\\frac{\\partial L}{\\partial\\mathbf{o}}\\in\\mathbb{R}^q$$<br>  $$\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}&#x3D;\\lambda\\mathbf{W}^{(1)}\\mathrm{<del>and</del>}\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}&#x3D;\\lambda\\mathbf{W}^{(2)}$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{W}^{(2)}}&#x3D;\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{W}^{(2)}}\\right)+\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{o}}\\mathbf{h}^\\top+\\lambda\\mathbf{W}^{(2)}$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{h}}&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{h}}\\right)&#x3D;\\mathbf{W}^{(2)^\\top}\\frac{\\partial J}{\\partial\\mathbf{o}}$$<br>  由于激活函数$\\phi$是按元素计算的，因此计算$\\frac{\\partial J}{\\partial \\mathbf{z}}$需要使用按元素乘法运算符：<br>  $$\\frac{\\partial J}{\\partial\\mathbf{z}}&#x3D;\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{h}},\\frac{\\partial\\mathbf{h}}{\\partial\\mathbf{z}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{h}}\\odot\\phi^{\\prime}\\left(\\mathbf{z}\\right)$$<br>  $$\\begin{aligned}\\frac{\\partial J}{\\partial\\mathbf{W}^{(1)}}&amp;&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{z}},\\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{W}^{(1)}}\\right)+\\text{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{z}}\\mathbf{x}^\\top+\\lambda\\mathbf{W}^{(1)}\\end{aligned}$$</li>\n</ul>\n<h2 id=\"7-4-训练神经网络\"><a href=\"#7-4-训练神经网络\" class=\"headerlink\" title=\"7.4 训练神经网络\"></a>7.4 训练神经网络</h2><ul>\n<li>训练神经网络时，对于前向传播，沿着依赖的方向遍历计算图并计算路径上的所有变量。然后将这些用于反向传播，其中计算顺序与计算图的相反。</li>\n<li>一方面，在前向传播期间计算正则项取决于模型参数W(1)和 W(2)的当前值。它们是由优化算法根据最近迭代的反向传播给出的。</li>\n<li>另一方面，反向传播期间参数$\\frac{\\partial J}{\\partial W^{(2)}}$的梯度计算，取决于由前向传播给出的隐藏变量h的当前值。</li>\n<li>因此，在训练神经网络时，在初始化模型参数后，我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。</li>\n<li>反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"7-前向传播、反向传播和计算图\"><a href=\"#7-前向传播、反向传播和计算图\" class=\"headerlink\" title=\"7 前向传播、反向传播和计算图\"></a>7 前向传播、反向传播和计算图</h1><ul>\n<li>以带dropout的单层隐藏层mlp为例</li>\n</ul>\n<h2 id=\"7-1-前向传播\"><a href=\"#7-1-前向传播\" class=\"headerlink\" title=\"7.1 前向传播\"></a>7.1 前向传播</h2><ul>\n<li>按顺序（从输入层到输出层）计算和存储神经网络中每层的结果s。<ul>\n<li>1）输入是$\\mathbf{x} \\in \\mathbb{R}^d$，隐藏层不含偏置,得到中间变量：<br>  $$\\mathbf{z}&#x3D;\\mathbf{W}^{(1)}\\mathbf{x}$$</li>\n<li>2）激活：<br>  $$\\mathbf{h}&#x3D;\\phi(\\mathbf{z})$$</li>\n<li>3）输出：<br>  $$\\mathbf{o}&#x3D;\\mathbf{W}^{(2)}\\mathbf{h}$$</li>\n<li>4）损失：<br>  $$L&#x3D;l(\\mathbf{o},y)$$</li>\n<li>5）正则化项（权重衰减）：<br>  $$s&#x3D;\\frac{\\lambda}{2}(||\\mathbf{W}^{(1)}||^2_F+||\\mathbf{W}^{(2)}||^2_F)$$<ul>\n<li>其中矩阵的Frobenius范数是将矩阵展平成向量后应用$L_2$范数。</li>\n</ul>\n</li>\n<li>6）目标函数：<br>  $$J&#x3D;L+s$$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"7-2-前向传播计算图\"><a href=\"#7-2-前向传播计算图\" class=\"headerlink\" title=\"7.2 前向传播计算图\"></a>7.2 前向传播计算图</h2><ul>\n<li>7.1的计算图：<br><img src=\"D:\\blog\\themes\\yilia\\source\\img\\deeplearning\\code\\pytorch\\3_mlp\\7\\1.png\"><br><img src=\"/img/deeplearning/code/pytorch/3_mlp/7/1.png\"></li>\n</ul>\n<h2 id=\"7-3-反向传播\"><a href=\"#7-3-反向传播\" class=\"headerlink\" title=\"7.3 反向传播\"></a>7.3 反向传播</h2><ul>\n<li>根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。</li>\n<li>链式法则：假设有$Y&#x3D;f(X)$和$Z&#x3D;g(Y)$，有:<br>  $$\\frac{\\partial{Z}}{\\partial{X}}&#x3D;prod(\\frac{\\partial{Z}}{\\partial{Y}},\\frac{\\partial{Y}}{\\partial{X}})$$<ul>\n<li>prod表示一定的操作</li>\n</ul>\n</li>\n<li>针对前向传播计算图计算反向梯度：<br>  $$\\frac{\\partial J}{\\partial L}&#x3D;1\\mathrm{<del>and</del>}\\frac{\\partial J}{\\partial s}&#x3D;1$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{o}}&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial L},\\frac{\\partial L}{\\partial\\mathbf{o}}\\right)&#x3D;\\frac{\\partial L}{\\partial\\mathbf{o}}\\in\\mathbb{R}^q$$<br>  $$\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}&#x3D;\\lambda\\mathbf{W}^{(1)}\\mathrm{<del>and</del>}\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}&#x3D;\\lambda\\mathbf{W}^{(2)}$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{W}^{(2)}}&#x3D;\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{W}^{(2)}}\\right)+\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(2)}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{o}}\\mathbf{h}^\\top+\\lambda\\mathbf{W}^{(2)}$$<br>  $$\\frac{\\partial J}{\\partial\\mathbf{h}}&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{o}},\\frac{\\partial\\mathbf{o}}{\\partial\\mathbf{h}}\\right)&#x3D;\\mathbf{W}^{(2)^\\top}\\frac{\\partial J}{\\partial\\mathbf{o}}$$<br>  由于激活函数$\\phi$是按元素计算的，因此计算$\\frac{\\partial J}{\\partial \\mathbf{z}}$需要使用按元素乘法运算符：<br>  $$\\frac{\\partial J}{\\partial\\mathbf{z}}&#x3D;\\mathrm{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{h}},\\frac{\\partial\\mathbf{h}}{\\partial\\mathbf{z}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{h}}\\odot\\phi^{\\prime}\\left(\\mathbf{z}\\right)$$<br>  $$\\begin{aligned}\\frac{\\partial J}{\\partial\\mathbf{W}^{(1)}}&amp;&#x3D;\\text{prod}\\left(\\frac{\\partial J}{\\partial\\mathbf{z}},\\frac{\\partial\\mathbf{z}}{\\partial\\mathbf{W}^{(1)}}\\right)+\\text{prod}\\left(\\frac{\\partial J}{\\partial s},\\frac{\\partial s}{\\partial\\mathbf{W}^{(1)}}\\right)&#x3D;\\frac{\\partial J}{\\partial\\mathbf{z}}\\mathbf{x}^\\top+\\lambda\\mathbf{W}^{(1)}\\end{aligned}$$</li>\n</ul>\n<h2 id=\"7-4-训练神经网络\"><a href=\"#7-4-训练神经网络\" class=\"headerlink\" title=\"7.4 训练神经网络\"></a>7.4 训练神经网络</h2><ul>\n<li>训练神经网络时，对于前向传播，沿着依赖的方向遍历计算图并计算路径上的所有变量。然后将这些用于反向传播，其中计算顺序与计算图的相反。</li>\n<li>一方面，在前向传播期间计算正则项取决于模型参数W(1)和 W(2)的当前值。它们是由优化算法根据最近迭代的反向传播给出的。</li>\n<li>另一方面，反向传播期间参数$\\frac{\\partial J}{\\partial W^{(2)}}$的梯度计算，取决于由前向传播给出的隐藏变量h的当前值。</li>\n<li>因此，在训练神经网络时，在初始化模型参数后，我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。</li>\n<li>反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。</li>\n</ul>"},{"title":"1-3 二分","date":"2024-04-17T16:00:00.000Z","comment":false,"toc":true,"_content":"\n#\n<!--more-->\n\n# 3 整数二分\n\n## 3.1思想\n\n- 二分的本质并不是单调性：有单调性一定可以二分，可以二分不一定有单调性。\n\n- 如果可以找到一个性质，将区间分为一边满足，一边不满足，那么二分就可以寻找这个性质的边界。\n\n- 每次分一半，保证答案处在目标区间里。二分一定会有解。\n\n## 3.2 模板\n\n```c++\n//目标在右区间。区间[l, r]被划分成[l, mid], [mid+1, r]\nint bsearch_1(int l, int r){\n    while(l < r){\n        int mid = ((r-l)>>1)+l; //多一个+1\n        if(check(mid)) r=mid;  //check()查看mid是否符合性质\n        else l = mid + 1;\n    }\n    return l;\n}\n\n//目标在左区间。区间[l, r]被划分成[l, mid-1]，[mid, r]\nint bsearch_2(int l, int r){\n    while(l<r){\n        int mid = ((r-l+1)>>1)+l;\n        if (check(mid)) l=mid;\n        else r=mid-1;\n    }\n    return l;\n}\n```\n\n\n\n## 3.3 例题\n\n- 给定一长度为n的升序数组，以及q个查询。对于每次查询，输入一个数k，返回元素k的起始位置和终止位置（从0开始）。不存在则返回-1 -1\n\n```c++\n//测试\n6 3\n1 2 2 3 3 4\n3\n4\n5\n    \n//输出\n3 4\n5 5\n-1 -1\n```\n\n```c++\n#include<iostream>\nusing namespace std;\nint a[100010];\nint n=0,m=0;\n\nint main(){\n        scanf(\"%d%d\",&n,&m);\n        for(int i=0; i<n; i++) scanf(\"%d\",&a[i]);\n        while(m--){\n                int x;\n                scanf(\"%d\", &x);\n\n                int l=0, r=n-1;\n                while(l<r){\n                        int mid = ((r-l)>>1)+l;\n                        if (a[mid] >= x) r=mid;\n                        else l=mid+1;\n                }\n                if (a[l] != x) cout<<\"-1 -1\"<<endl;\n                else{\n                        cout <<l <<' ';\n\n                        int l =0, r=n-1;\n                        while(l<r){\n                                int mid = ((r-l+1)>>1)+l;\n                                if (a[mid] <=x) l=mid;\n                                else r=mid-1;\n                        }\n                        cout<<l<<endl;\n                }\n        }\n        return 0;\n}\n```\n\n# 4 浮点数二分\n\n- 更简单，不用考虑+1问题。\n\n## 4.1 例题\n\n- 计算一个数（>1）的平方根\n\n```c++\n#include<iostream>\nusing namespace std;\n\nint main(){\n        double x=0;\n        cin >>x;\n        double l=0, r=x;\n        while(r-l>1e-8){\n                double mid = ((r-l)/2)+l;\n                if(mid*mid<x) l=mid;\n                else r=mid;\n        }\n        cout<<l<<endl;\n        return 0;\n}\n```\n\n","source":"_posts/algorithm/1_base/3_dichotomy.md","raw":"---\ntitle: 1-3 二分\n\ndate: 2024-4-18\n\ntags: [算法，排序]\n\ncategories: [算法]\n\ncomment: false\n\ntoc: true\n\n\n---\n\n#\n<!--more-->\n\n# 3 整数二分\n\n## 3.1思想\n\n- 二分的本质并不是单调性：有单调性一定可以二分，可以二分不一定有单调性。\n\n- 如果可以找到一个性质，将区间分为一边满足，一边不满足，那么二分就可以寻找这个性质的边界。\n\n- 每次分一半，保证答案处在目标区间里。二分一定会有解。\n\n## 3.2 模板\n\n```c++\n//目标在右区间。区间[l, r]被划分成[l, mid], [mid+1, r]\nint bsearch_1(int l, int r){\n    while(l < r){\n        int mid = ((r-l)>>1)+l; //多一个+1\n        if(check(mid)) r=mid;  //check()查看mid是否符合性质\n        else l = mid + 1;\n    }\n    return l;\n}\n\n//目标在左区间。区间[l, r]被划分成[l, mid-1]，[mid, r]\nint bsearch_2(int l, int r){\n    while(l<r){\n        int mid = ((r-l+1)>>1)+l;\n        if (check(mid)) l=mid;\n        else r=mid-1;\n    }\n    return l;\n}\n```\n\n\n\n## 3.3 例题\n\n- 给定一长度为n的升序数组，以及q个查询。对于每次查询，输入一个数k，返回元素k的起始位置和终止位置（从0开始）。不存在则返回-1 -1\n\n```c++\n//测试\n6 3\n1 2 2 3 3 4\n3\n4\n5\n    \n//输出\n3 4\n5 5\n-1 -1\n```\n\n```c++\n#include<iostream>\nusing namespace std;\nint a[100010];\nint n=0,m=0;\n\nint main(){\n        scanf(\"%d%d\",&n,&m);\n        for(int i=0; i<n; i++) scanf(\"%d\",&a[i]);\n        while(m--){\n                int x;\n                scanf(\"%d\", &x);\n\n                int l=0, r=n-1;\n                while(l<r){\n                        int mid = ((r-l)>>1)+l;\n                        if (a[mid] >= x) r=mid;\n                        else l=mid+1;\n                }\n                if (a[l] != x) cout<<\"-1 -1\"<<endl;\n                else{\n                        cout <<l <<' ';\n\n                        int l =0, r=n-1;\n                        while(l<r){\n                                int mid = ((r-l+1)>>1)+l;\n                                if (a[mid] <=x) l=mid;\n                                else r=mid-1;\n                        }\n                        cout<<l<<endl;\n                }\n        }\n        return 0;\n}\n```\n\n# 4 浮点数二分\n\n- 更简单，不用考虑+1问题。\n\n## 4.1 例题\n\n- 计算一个数（>1）的平方根\n\n```c++\n#include<iostream>\nusing namespace std;\n\nint main(){\n        double x=0;\n        cin >>x;\n        double l=0, r=x;\n        while(r-l>1e-8){\n                double mid = ((r-l)/2)+l;\n                if(mid*mid<x) l=mid;\n                else r=mid;\n        }\n        cout<<l<<endl;\n        return 0;\n}\n```\n\n","slug":"algorithm/1_base/3_dichotomy","published":1,"updated":"2024-04-18T11:20:24.711Z","_id":"cltwpq3vv000e38vwede8hw94","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"3-整数二分\"><a href=\"#3-整数二分\" class=\"headerlink\" title=\"3 整数二分\"></a>3 整数二分</h1><h2 id=\"3-1思想\"><a href=\"#3-1思想\" class=\"headerlink\" title=\"3.1思想\"></a>3.1思想</h2><ul>\n<li><p>二分的本质并不是单调性：有单调性一定可以二分，可以二分不一定有单调性。</p>\n</li>\n<li><p>如果可以找到一个性质，将区间分为一边满足，一边不满足，那么二分就可以寻找这个性质的边界。</p>\n</li>\n<li><p>每次分一半，保证答案处在目标区间里。二分一定会有解。</p>\n</li>\n</ul>\n<h2 id=\"3-2-模板\"><a href=\"#3-2-模板\" class=\"headerlink\" title=\"3.2 模板\"></a>3.2 模板</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//目标在右区间。区间[l, r]被划分成[l, mid], [mid+1, r]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bsearch_1</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(l &lt; r)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> mid = ((r-l)&gt;&gt;<span class=\"number\">1</span>)+l; <span class=\"comment\">//多一个+1</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">check</span>(mid)) r=mid;  <span class=\"comment\">//check()查看mid是否符合性质</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//目标在左区间。区间[l, r]被划分成[l, mid-1]，[mid, r]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bsearch_2</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> mid = ((r-l+<span class=\"number\">1</span>)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"built_in\">check</span>(mid)) l=mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> r=mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"3-3-例题\"><a href=\"#3-3-例题\" class=\"headerlink\" title=\"3.3 例题\"></a>3.3 例题</h2><ul>\n<li>给定一长度为n的升序数组，以及q个查询。对于每次查询，输入一个数k，返回元素k的起始位置和终止位置（从0开始）。不存在则返回-1 -1</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//测试</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">//输出</span></span><br><span class=\"line\"><span class=\"number\">3</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">5</span> <span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">-1</span> <span class=\"number\">-1</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> n=<span class=\"number\">0</span>,m=<span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d%d&quot;</span>,&amp;n,&amp;m);</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>; i&lt;n; i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(m--)&#123;</span><br><span class=\"line\">                <span class=\"type\">int</span> x;</span><br><span class=\"line\">                <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>, &amp;x);</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"type\">int</span> l=<span class=\"number\">0</span>, r=n<span class=\"number\">-1</span>;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">                        <span class=\"type\">int</span> mid = ((r-l)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (a[mid] &gt;= x) r=mid;</span><br><span class=\"line\">                        <span class=\"keyword\">else</span> l=mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (a[l] != x) cout&lt;&lt;<span class=\"string\">&quot;-1 -1&quot;</span>&lt;&lt;endl;</span><br><span class=\"line\">                <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">                        cout &lt;&lt;l &lt;&lt;<span class=\"string\">&#x27; &#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">                        <span class=\"type\">int</span> l =<span class=\"number\">0</span>, r=n<span class=\"number\">-1</span>;</span><br><span class=\"line\">                        <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">                                <span class=\"type\">int</span> mid = ((r-l+<span class=\"number\">1</span>)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">                                <span class=\"keyword\">if</span> (a[mid] &lt;=x) l=mid;</span><br><span class=\"line\">                                <span class=\"keyword\">else</span> r=mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        cout&lt;&lt;l&lt;&lt;endl;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"4-浮点数二分\"><a href=\"#4-浮点数二分\" class=\"headerlink\" title=\"4 浮点数二分\"></a>4 浮点数二分</h1><ul>\n<li>更简单，不用考虑+1问题。</li>\n</ul>\n<h2 id=\"4-1-例题\"><a href=\"#4-1-例题\" class=\"headerlink\" title=\"4.1 例题\"></a>4.1 例题</h2><ul>\n<li>计算一个数（&gt;1）的平方根</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"type\">double</span> x=<span class=\"number\">0</span>;</span><br><span class=\"line\">        cin &gt;&gt;x;</span><br><span class=\"line\">        <span class=\"type\">double</span> l=<span class=\"number\">0</span>, r=x;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(r-l&gt;<span class=\"number\">1e-8</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">double</span> mid = ((r-l)/<span class=\"number\">2</span>)+l;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(mid*mid&lt;x) l=mid;</span><br><span class=\"line\">                <span class=\"keyword\">else</span> r=mid;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cout&lt;&lt;l&lt;&lt;endl;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"3-整数二分\"><a href=\"#3-整数二分\" class=\"headerlink\" title=\"3 整数二分\"></a>3 整数二分</h1><h2 id=\"3-1思想\"><a href=\"#3-1思想\" class=\"headerlink\" title=\"3.1思想\"></a>3.1思想</h2><ul>\n<li><p>二分的本质并不是单调性：有单调性一定可以二分，可以二分不一定有单调性。</p>\n</li>\n<li><p>如果可以找到一个性质，将区间分为一边满足，一边不满足，那么二分就可以寻找这个性质的边界。</p>\n</li>\n<li><p>每次分一半，保证答案处在目标区间里。二分一定会有解。</p>\n</li>\n</ul>\n<h2 id=\"3-2-模板\"><a href=\"#3-2-模板\" class=\"headerlink\" title=\"3.2 模板\"></a>3.2 模板</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//目标在右区间。区间[l, r]被划分成[l, mid], [mid+1, r]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bsearch_1</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(l &lt; r)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> mid = ((r-l)&gt;&gt;<span class=\"number\">1</span>)+l; <span class=\"comment\">//多一个+1</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">check</span>(mid)) r=mid;  <span class=\"comment\">//check()查看mid是否符合性质</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//目标在左区间。区间[l, r]被划分成[l, mid-1]，[mid, r]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bsearch_2</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> mid = ((r-l+<span class=\"number\">1</span>)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"built_in\">check</span>(mid)) l=mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> r=mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"3-3-例题\"><a href=\"#3-3-例题\" class=\"headerlink\" title=\"3.3 例题\"></a>3.3 例题</h2><ul>\n<li>给定一长度为n的升序数组，以及q个查询。对于每次查询，输入一个数k，返回元素k的起始位置和终止位置（从0开始）。不存在则返回-1 -1</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//测试</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">//输出</span></span><br><span class=\"line\"><span class=\"number\">3</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">5</span> <span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">-1</span> <span class=\"number\">-1</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"><span class=\"type\">int</span> a[<span class=\"number\">100010</span>];</span><br><span class=\"line\"><span class=\"type\">int</span> n=<span class=\"number\">0</span>,m=<span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d%d&quot;</span>,&amp;n,&amp;m);</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>; i&lt;n; i++) <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(m--)&#123;</span><br><span class=\"line\">                <span class=\"type\">int</span> x;</span><br><span class=\"line\">                <span class=\"built_in\">scanf</span>(<span class=\"string\">&quot;%d&quot;</span>, &amp;x);</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"type\">int</span> l=<span class=\"number\">0</span>, r=n<span class=\"number\">-1</span>;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">                        <span class=\"type\">int</span> mid = ((r-l)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (a[mid] &gt;= x) r=mid;</span><br><span class=\"line\">                        <span class=\"keyword\">else</span> l=mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (a[l] != x) cout&lt;&lt;<span class=\"string\">&quot;-1 -1&quot;</span>&lt;&lt;endl;</span><br><span class=\"line\">                <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">                        cout &lt;&lt;l &lt;&lt;<span class=\"string\">&#x27; &#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">                        <span class=\"type\">int</span> l =<span class=\"number\">0</span>, r=n<span class=\"number\">-1</span>;</span><br><span class=\"line\">                        <span class=\"keyword\">while</span>(l&lt;r)&#123;</span><br><span class=\"line\">                                <span class=\"type\">int</span> mid = ((r-l+<span class=\"number\">1</span>)&gt;&gt;<span class=\"number\">1</span>)+l;</span><br><span class=\"line\">                                <span class=\"keyword\">if</span> (a[mid] &lt;=x) l=mid;</span><br><span class=\"line\">                                <span class=\"keyword\">else</span> r=mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        cout&lt;&lt;l&lt;&lt;endl;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"4-浮点数二分\"><a href=\"#4-浮点数二分\" class=\"headerlink\" title=\"4 浮点数二分\"></a>4 浮点数二分</h1><ul>\n<li>更简单，不用考虑+1问题。</li>\n</ul>\n<h2 id=\"4-1-例题\"><a href=\"#4-1-例题\" class=\"headerlink\" title=\"4.1 例题\"></a>4.1 例题</h2><ul>\n<li>计算一个数（&gt;1）的平方根</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span><span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"type\">double</span> x=<span class=\"number\">0</span>;</span><br><span class=\"line\">        cin &gt;&gt;x;</span><br><span class=\"line\">        <span class=\"type\">double</span> l=<span class=\"number\">0</span>, r=x;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(r-l&gt;<span class=\"number\">1e-8</span>)&#123;</span><br><span class=\"line\">                <span class=\"type\">double</span> mid = ((r-l)/<span class=\"number\">2</span>)+l;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(mid*mid&lt;x) l=mid;</span><br><span class=\"line\">                <span class=\"keyword\">else</span> r=mid;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cout&lt;&lt;l&lt;&lt;endl;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"3.8 数值稳定性和模型初始化","date":"2024-03-16T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 8 数值稳定性和模型初始化\n- 初始化方案的选择在神经网络学习中起着举足轻重的作用，它对保持数值稳定性至关重要。\n\n## 8.1 梯度消失和梯度爆炸\n- 假设网络有L层，输入X，输出o，每一层$l$由变换$f_l$定义，该变换的参数为权重$\\mathbf{W}^{(l)}$，其隐藏变量是$\\mathbf{h}^{(l)}$。网络定义为：\n    $$\\mathbf{h}^{(l)}= f_l(\\mathbf{h}^{(l-1)})$$\n    - 因此：$\\mathbf{o}=f_L\\circ\\ldots\\circ f_1(\\mathbf{x})$\n    - $\\mathbf{o}$关于任何一组参数$\\mathbf{W}^{(l)}$的梯度：\n        $$\\partial_{\\mathbf{W}^{(l)}}\\mathbf{o}=\\underbrace{\\partial_{\\mathbf{h}^{(L-1)}}\\mathbf{h}^{(L)}}_{\\mathbf{M}^{(L)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}\\cdot\\ldots\\cdot\\underbrace{\\partial_{\\mathbf{h}^{(l)}}\\mathbf{h}^{(l+1)}}_{\\mathbf{M}^{(l+1)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}\\underbrace{\\partial_{\\mathbf{W}^{(l)}}\\mathbf{h}^{(l)}}_{\\mathbf{v}^{(l)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}$$\n    - 该梯度是L − l个矩阵与梯度向量$\\mathbf{v}^{(l)}$的乘积。因此，我们容易受到数值下溢问题的影响. 当将太多的概率乘在一起时，这些问题经常会出现。在处理概率时，一个常见的技巧是切换到对数空间。不幸的是，上面的问题更为严重：最初，矩阵 M(l) 可能具有各种各样的特征值。他们可能很小，也可能很大；他们的乘积可能非常大，也可能非常小。\n    - 不稳定梯度带来的风险不止在于数值表示；也威胁到我们优化算法的稳定性。梯度爆炸（gradient exploding）问题：参数更新过大，破坏了模型的稳定收敛；是梯度消失（gradient vanishing）问题：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。\n### 8.1.1 梯度消失\n- sigmoid函数更符合生物神经元的原理，但可能梯度消失：\n\n    \n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom d2l import torch as d2l\n\nx = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\ny= torch.sigmoid(x)\ny.backward(torch.ones_like(x))\n\n#注意用的是x.grad\nd2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()] , legend=['sigmoid','gradient'], figsize=(4.5, 2.5))\n```\n\n​      ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg)\n\n![svg](img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg)\n    \n\n\n- 当sigmoid函数输入很大或很小时，他的梯度会消失。此外，当反向传播通过许多层时，除非我们在刚刚好的地方，否则整个乘积的梯度可能会消失。当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。\n### 8.1.2 梯度爆炸\n- 生成100个高斯随机矩阵，将他们与某个初始矩阵相乘，矩阵乘积会发生梯度爆炸。当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。\n\n\n```python\nM = torch.normal(0,1, size=(4,4))\nprint('第一个矩阵\\n',M)\nfor i in range(100):\n    M=torch.mm(M, torch.normal(0,1,size=(4,4)))\nprint('乘以100个矩阵后\\n',M)\n```\n\n    第一个矩阵\n     tensor([[ 0.5260, -0.8163, -0.2948,  1.3394],\n            [-0.6026,  0.9170,  0.2718,  1.0166],\n            [ 1.3275, -0.1824,  1.1752,  0.2823],\n            [ 0.8749,  0.4343,  0.0216,  0.8288]])\n    乘以100个矩阵后\n     tensor([[ 1.5284e+25,  3.4216e+24, -2.3112e+23, -1.6804e+25],\n            [ 5.5275e+24,  1.2374e+24, -8.3584e+22, -6.0772e+24],\n            [ 2.6396e+25,  5.9094e+24, -3.9915e+23, -2.9022e+25],\n            [ 1.8637e+25,  4.1723e+24, -2.8182e+23, -2.0490e+25]])\n\n\n### 8.1.3 打破对称性\n- 一个隐藏层中的所有隐藏单元的地位是相同的，具有排列对称性。\n- 如果将隐藏层的所有参数初始化为相同的常量，那么我们可能永远也无法实现网络的表达能力，隐藏层的行为就好像只有一个单元。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。\n## 8.2 参数初始化\n- 解决或减轻上述问题\n### 8.2.1 默认初始化\n- 如果我们不指定初始化方法，框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。\n### 8.2.2 Xavier初始化\n- 假设某层有$n_{in}$个输入：$x_j$，权重为$w_ij$，输出为：$o_i=\\sum_{j=1}^{n_{\\mathrm{in}}}w_{ij}x_j$\n- 假设权重$w_{ij}$服从$N(0,\\sigma ^2)$，输入$x_j$服从$N(0,\\gamma ^2)。（这并不意味着分布必须是高斯的，只是均值和方差需要存在。）\n- 输出$o_i$的均值方差：\n    $$\\begin{aligned}E[o_{i}]& =\\sum_{j=1}^{n_\\mathrm{in}}E[w_{ij}x_j]  \\\\&=\\sum_{j=1}^{n_\\mathrm{in}}E[w_{ij}]E[x_j] \\\\&=0.\\end{aligned}$$\n    $$\\begin{aligned}\\operatorname{Var}[o_i]& =E[o_i^2]-(E[o_i])^2  \\\\&=\\sum_{j=1}^{n_{\\mathrm{in}}}E[w_{ij}^2x_j^2]-0 \\\\&=\\sum_{j=1}^{n_{\\mathrm{in}}}E[w_{ij}^2]E[x_j^2] \\\\&=n_\\text{in}\\sigma^2\\gamma^2.\\end{aligned}$$\n- 保持方差不变的一种方法是设置$n_{in} \\sigma^2=1$。考虑反向传播，使用与前向传播相同的推断，我们可以看到，除非$n_{out} \\sigma^2=1$否则梯度的方差可能会增大，我们不可能同时满足这两个条件，因此提出Xavier初始化：\n    $$\\frac12(n_{\\mathrm{in}}+n_{\\mathrm{out}})\\sigma^2=1 \\rightarrow \\sigma= \\sqrt{\\frac{2}{n_{in}+n_{out}}}$$\n    - 或者改为从$U\\left(-\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}},\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}}\\right)$\n","source":"_posts/deeplearning/code/pytorch/3_mlp/8_init.md","raw":"---\ntitle: 3.8 数值稳定性和模型初始化\ndate: 2024-3-16 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 8 数值稳定性和模型初始化\n- 初始化方案的选择在神经网络学习中起着举足轻重的作用，它对保持数值稳定性至关重要。\n\n## 8.1 梯度消失和梯度爆炸\n- 假设网络有L层，输入X，输出o，每一层$l$由变换$f_l$定义，该变换的参数为权重$\\mathbf{W}^{(l)}$，其隐藏变量是$\\mathbf{h}^{(l)}$。网络定义为：\n    $$\\mathbf{h}^{(l)}= f_l(\\mathbf{h}^{(l-1)})$$\n    - 因此：$\\mathbf{o}=f_L\\circ\\ldots\\circ f_1(\\mathbf{x})$\n    - $\\mathbf{o}$关于任何一组参数$\\mathbf{W}^{(l)}$的梯度：\n        $$\\partial_{\\mathbf{W}^{(l)}}\\mathbf{o}=\\underbrace{\\partial_{\\mathbf{h}^{(L-1)}}\\mathbf{h}^{(L)}}_{\\mathbf{M}^{(L)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}\\cdot\\ldots\\cdot\\underbrace{\\partial_{\\mathbf{h}^{(l)}}\\mathbf{h}^{(l+1)}}_{\\mathbf{M}^{(l+1)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}\\underbrace{\\partial_{\\mathbf{W}^{(l)}}\\mathbf{h}^{(l)}}_{\\mathbf{v}^{(l)}\\overset{\\mathrm{def}}{\\operatorname*{=}}}$$\n    - 该梯度是L − l个矩阵与梯度向量$\\mathbf{v}^{(l)}$的乘积。因此，我们容易受到数值下溢问题的影响. 当将太多的概率乘在一起时，这些问题经常会出现。在处理概率时，一个常见的技巧是切换到对数空间。不幸的是，上面的问题更为严重：最初，矩阵 M(l) 可能具有各种各样的特征值。他们可能很小，也可能很大；他们的乘积可能非常大，也可能非常小。\n    - 不稳定梯度带来的风险不止在于数值表示；也威胁到我们优化算法的稳定性。梯度爆炸（gradient exploding）问题：参数更新过大，破坏了模型的稳定收敛；是梯度消失（gradient vanishing）问题：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。\n### 8.1.1 梯度消失\n- sigmoid函数更符合生物神经元的原理，但可能梯度消失：\n\n    \n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nimport torch\nfrom d2l import torch as d2l\n\nx = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\ny= torch.sigmoid(x)\ny.backward(torch.ones_like(x))\n\n#注意用的是x.grad\nd2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()] , legend=['sigmoid','gradient'], figsize=(4.5, 2.5))\n```\n\n​      ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg)\n\n![svg](img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg)\n    \n\n\n- 当sigmoid函数输入很大或很小时，他的梯度会消失。此外，当反向传播通过许多层时，除非我们在刚刚好的地方，否则整个乘积的梯度可能会消失。当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。\n### 8.1.2 梯度爆炸\n- 生成100个高斯随机矩阵，将他们与某个初始矩阵相乘，矩阵乘积会发生梯度爆炸。当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。\n\n\n```python\nM = torch.normal(0,1, size=(4,4))\nprint('第一个矩阵\\n',M)\nfor i in range(100):\n    M=torch.mm(M, torch.normal(0,1,size=(4,4)))\nprint('乘以100个矩阵后\\n',M)\n```\n\n    第一个矩阵\n     tensor([[ 0.5260, -0.8163, -0.2948,  1.3394],\n            [-0.6026,  0.9170,  0.2718,  1.0166],\n            [ 1.3275, -0.1824,  1.1752,  0.2823],\n            [ 0.8749,  0.4343,  0.0216,  0.8288]])\n    乘以100个矩阵后\n     tensor([[ 1.5284e+25,  3.4216e+24, -2.3112e+23, -1.6804e+25],\n            [ 5.5275e+24,  1.2374e+24, -8.3584e+22, -6.0772e+24],\n            [ 2.6396e+25,  5.9094e+24, -3.9915e+23, -2.9022e+25],\n            [ 1.8637e+25,  4.1723e+24, -2.8182e+23, -2.0490e+25]])\n\n\n### 8.1.3 打破对称性\n- 一个隐藏层中的所有隐藏单元的地位是相同的，具有排列对称性。\n- 如果将隐藏层的所有参数初始化为相同的常量，那么我们可能永远也无法实现网络的表达能力，隐藏层的行为就好像只有一个单元。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。\n## 8.2 参数初始化\n- 解决或减轻上述问题\n### 8.2.1 默认初始化\n- 如果我们不指定初始化方法，框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。\n### 8.2.2 Xavier初始化\n- 假设某层有$n_{in}$个输入：$x_j$，权重为$w_ij$，输出为：$o_i=\\sum_{j=1}^{n_{\\mathrm{in}}}w_{ij}x_j$\n- 假设权重$w_{ij}$服从$N(0,\\sigma ^2)$，输入$x_j$服从$N(0,\\gamma ^2)。（这并不意味着分布必须是高斯的，只是均值和方差需要存在。）\n- 输出$o_i$的均值方差：\n    $$\\begin{aligned}E[o_{i}]& =\\sum_{j=1}^{n_\\mathrm{in}}E[w_{ij}x_j]  \\\\&=\\sum_{j=1}^{n_\\mathrm{in}}E[w_{ij}]E[x_j] \\\\&=0.\\end{aligned}$$\n    $$\\begin{aligned}\\operatorname{Var}[o_i]& =E[o_i^2]-(E[o_i])^2  \\\\&=\\sum_{j=1}^{n_{\\mathrm{in}}}E[w_{ij}^2x_j^2]-0 \\\\&=\\sum_{j=1}^{n_{\\mathrm{in}}}E[w_{ij}^2]E[x_j^2] \\\\&=n_\\text{in}\\sigma^2\\gamma^2.\\end{aligned}$$\n- 保持方差不变的一种方法是设置$n_{in} \\sigma^2=1$。考虑反向传播，使用与前向传播相同的推断，我们可以看到，除非$n_{out} \\sigma^2=1$否则梯度的方差可能会增大，我们不可能同时满足这两个条件，因此提出Xavier初始化：\n    $$\\frac12(n_{\\mathrm{in}}+n_{\\mathrm{out}})\\sigma^2=1 \\rightarrow \\sigma= \\sqrt{\\frac{2}{n_{in}+n_{out}}}$$\n    - 或者改为从$U\\left(-\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}},\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}}\\right)$\n","slug":"deeplearning/code/pytorch/3_mlp/8_init","published":1,"updated":"2024-03-20T11:15:39.508Z","_id":"cltwpq3vw000f38vwccze88c2","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"8-数值稳定性和模型初始化\"><a href=\"#8-数值稳定性和模型初始化\" class=\"headerlink\" title=\"8 数值稳定性和模型初始化\"></a>8 数值稳定性和模型初始化</h1><ul>\n<li>初始化方案的选择在神经网络学习中起着举足轻重的作用，它对保持数值稳定性至关重要。</li>\n</ul>\n<h2 id=\"8-1-梯度消失和梯度爆炸\"><a href=\"#8-1-梯度消失和梯度爆炸\" class=\"headerlink\" title=\"8.1 梯度消失和梯度爆炸\"></a>8.1 梯度消失和梯度爆炸</h2><ul>\n<li>假设网络有L层，输入X，输出o，每一层$l$由变换$f_l$定义，该变换的参数为权重$\\mathbf{W}^{(l)}$，其隐藏变量是$\\mathbf{h}^{(l)}$。网络定义为：<br>  $$\\mathbf{h}^{(l)}&#x3D; f_l(\\mathbf{h}^{(l-1)})$$<ul>\n<li>因此：$\\mathbf{o}&#x3D;f_L\\circ\\ldots\\circ f_1(\\mathbf{x})$</li>\n<li>$\\mathbf{o}$关于任何一组参数$\\mathbf{W}^{(l)}$的梯度：<br>  $$\\partial_{\\mathbf{W}^{(l)}}\\mathbf{o}&#x3D;\\underbrace{\\partial_{\\mathbf{h}^{(L-1)}}\\mathbf{h}^{(L)}}<em>{\\mathbf{M}^{(L)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}\\cdot\\ldots\\cdot\\underbrace{\\partial</em>{\\mathbf{h}^{(l)}}\\mathbf{h}^{(l+1)}}<em>{\\mathbf{M}^{(l+1)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}\\underbrace{\\partial</em>{\\mathbf{W}^{(l)}}\\mathbf{h}^{(l)}}_{\\mathbf{v}^{(l)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}$$</li>\n<li>该梯度是L − l个矩阵与梯度向量$\\mathbf{v}^{(l)}$的乘积。因此，我们容易受到数值下溢问题的影响. 当将太多的概率乘在一起时，这些问题经常会出现。在处理概率时，一个常见的技巧是切换到对数空间。不幸的是，上面的问题更为严重：最初，矩阵 M(l) 可能具有各种各样的特征值。他们可能很小，也可能很大；他们的乘积可能非常大，也可能非常小。</li>\n<li>不稳定梯度带来的风险不止在于数值表示；也威胁到我们优化算法的稳定性。梯度爆炸（gradient exploding）问题：参数更新过大，破坏了模型的稳定收敛；是梯度消失（gradient vanishing）问题：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-1-1-梯度消失\"><a href=\"#8-1-1-梯度消失\" class=\"headerlink\" title=\"8.1.1 梯度消失\"></a>8.1.1 梯度消失</h3><ul>\n<li>sigmoid函数更符合生物神经元的原理，但可能梯度消失：</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(-<span class=\"number\">8.0</span>, <span class=\"number\">8.0</span>, <span class=\"number\">0.1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y= torch.sigmoid(x)</span><br><span class=\"line\">y.backward(torch.ones_like(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#注意用的是x.grad</span></span><br><span class=\"line\">d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()] , legend=[<span class=\"string\">&#x27;sigmoid&#x27;</span>,<span class=\"string\">&#x27;gradient&#x27;</span>], figsize=(<span class=\"number\">4.5</span>, <span class=\"number\">2.5</span>))</span><br></pre></td></tr></table></figure>\n\n<p>​      <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg\" alt=\"svg\"></p>\n<ul>\n<li>当sigmoid函数输入很大或很小时，他的梯度会消失。此外，当反向传播通过许多层时，除非我们在刚刚好的地方，否则整个乘积的梯度可能会消失。当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。</li>\n</ul>\n<h3 id=\"8-1-2-梯度爆炸\"><a href=\"#8-1-2-梯度爆炸\" class=\"headerlink\" title=\"8.1.2 梯度爆炸\"></a>8.1.2 梯度爆炸</h3><ul>\n<li>生成100个高斯随机矩阵，将他们与某个初始矩阵相乘，矩阵乘积会发生梯度爆炸。当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">M = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>, size=(<span class=\"number\">4</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;第一个矩阵\\n&#x27;</span>,M)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">100</span>):</span><br><span class=\"line\">    M=torch.mm(M, torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>,size=(<span class=\"number\">4</span>,<span class=\"number\">4</span>)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;乘以100个矩阵后\\n&#x27;</span>,M)</span><br></pre></td></tr></table></figure>\n\n<pre><code>第一个矩阵\n tensor([[ 0.5260, -0.8163, -0.2948,  1.3394],\n        [-0.6026,  0.9170,  0.2718,  1.0166],\n        [ 1.3275, -0.1824,  1.1752,  0.2823],\n        [ 0.8749,  0.4343,  0.0216,  0.8288]])\n乘以100个矩阵后\n tensor([[ 1.5284e+25,  3.4216e+24, -2.3112e+23, -1.6804e+25],\n        [ 5.5275e+24,  1.2374e+24, -8.3584e+22, -6.0772e+24],\n        [ 2.6396e+25,  5.9094e+24, -3.9915e+23, -2.9022e+25],\n        [ 1.8637e+25,  4.1723e+24, -2.8182e+23, -2.0490e+25]])\n</code></pre>\n<h3 id=\"8-1-3-打破对称性\"><a href=\"#8-1-3-打破对称性\" class=\"headerlink\" title=\"8.1.3 打破对称性\"></a>8.1.3 打破对称性</h3><ul>\n<li>一个隐藏层中的所有隐藏单元的地位是相同的，具有排列对称性。</li>\n<li>如果将隐藏层的所有参数初始化为相同的常量，那么我们可能永远也无法实现网络的表达能力，隐藏层的行为就好像只有一个单元。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。</li>\n</ul>\n<h2 id=\"8-2-参数初始化\"><a href=\"#8-2-参数初始化\" class=\"headerlink\" title=\"8.2 参数初始化\"></a>8.2 参数初始化</h2><ul>\n<li>解决或减轻上述问题</li>\n</ul>\n<h3 id=\"8-2-1-默认初始化\"><a href=\"#8-2-1-默认初始化\" class=\"headerlink\" title=\"8.2.1 默认初始化\"></a>8.2.1 默认初始化</h3><ul>\n<li>如果我们不指定初始化方法，框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。</li>\n</ul>\n<h3 id=\"8-2-2-Xavier初始化\"><a href=\"#8-2-2-Xavier初始化\" class=\"headerlink\" title=\"8.2.2 Xavier初始化\"></a>8.2.2 Xavier初始化</h3><ul>\n<li>假设某层有$n_{in}$个输入：$x_j$，权重为$w_ij$，输出为：$o_i&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}w_{ij}x_j$</li>\n<li>假设权重$w_{ij}$服从$N(0,\\sigma ^2)$，输入$x_j$服从$N(0,\\gamma ^2)。（这并不意味着分布必须是高斯的，只是均值和方差需要存在。）</li>\n<li>输出$o_i$的均值方差：<br>  $$\\begin{aligned}E[o_{i}]&amp; &#x3D;\\sum_{j&#x3D;1}^{n_\\mathrm{in}}E[w_{ij}x_j]  \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_\\mathrm{in}}E[w_{ij}]E[x_j] \\&amp;&#x3D;0.\\end{aligned}$$<br>  $$\\begin{aligned}\\operatorname{Var}[o_i]&amp; &#x3D;E[o_i^2]-(E[o_i])^2  \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}E[w_{ij}^2x_j^2]-0 \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}E[w_{ij}^2]E[x_j^2] \\&amp;&#x3D;n_\\text{in}\\sigma^2\\gamma^2.\\end{aligned}$$</li>\n<li>保持方差不变的一种方法是设置$n_{in} \\sigma^2&#x3D;1$。考虑反向传播，使用与前向传播相同的推断，我们可以看到，除非$n_{out} \\sigma^2&#x3D;1$否则梯度的方差可能会增大，我们不可能同时满足这两个条件，因此提出Xavier初始化：<br>  $$\\frac12(n_{\\mathrm{in}}+n_{\\mathrm{out}})\\sigma^2&#x3D;1 \\rightarrow \\sigma&#x3D; \\sqrt{\\frac{2}{n_{in}+n_{out}}}$$<ul>\n<li>或者改为从$U\\left(-\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}},\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}}\\right)$</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"8-数值稳定性和模型初始化\"><a href=\"#8-数值稳定性和模型初始化\" class=\"headerlink\" title=\"8 数值稳定性和模型初始化\"></a>8 数值稳定性和模型初始化</h1><ul>\n<li>初始化方案的选择在神经网络学习中起着举足轻重的作用，它对保持数值稳定性至关重要。</li>\n</ul>\n<h2 id=\"8-1-梯度消失和梯度爆炸\"><a href=\"#8-1-梯度消失和梯度爆炸\" class=\"headerlink\" title=\"8.1 梯度消失和梯度爆炸\"></a>8.1 梯度消失和梯度爆炸</h2><ul>\n<li>假设网络有L层，输入X，输出o，每一层$l$由变换$f_l$定义，该变换的参数为权重$\\mathbf{W}^{(l)}$，其隐藏变量是$\\mathbf{h}^{(l)}$。网络定义为：<br>  $$\\mathbf{h}^{(l)}&#x3D; f_l(\\mathbf{h}^{(l-1)})$$<ul>\n<li>因此：$\\mathbf{o}&#x3D;f_L\\circ\\ldots\\circ f_1(\\mathbf{x})$</li>\n<li>$\\mathbf{o}$关于任何一组参数$\\mathbf{W}^{(l)}$的梯度：<br>  $$\\partial_{\\mathbf{W}^{(l)}}\\mathbf{o}&#x3D;\\underbrace{\\partial_{\\mathbf{h}^{(L-1)}}\\mathbf{h}^{(L)}}<em>{\\mathbf{M}^{(L)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}\\cdot\\ldots\\cdot\\underbrace{\\partial</em>{\\mathbf{h}^{(l)}}\\mathbf{h}^{(l+1)}}<em>{\\mathbf{M}^{(l+1)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}\\underbrace{\\partial</em>{\\mathbf{W}^{(l)}}\\mathbf{h}^{(l)}}_{\\mathbf{v}^{(l)}\\overset{\\mathrm{def}}{\\operatorname*{&#x3D;}}}$$</li>\n<li>该梯度是L − l个矩阵与梯度向量$\\mathbf{v}^{(l)}$的乘积。因此，我们容易受到数值下溢问题的影响. 当将太多的概率乘在一起时，这些问题经常会出现。在处理概率时，一个常见的技巧是切换到对数空间。不幸的是，上面的问题更为严重：最初，矩阵 M(l) 可能具有各种各样的特征值。他们可能很小，也可能很大；他们的乘积可能非常大，也可能非常小。</li>\n<li>不稳定梯度带来的风险不止在于数值表示；也威胁到我们优化算法的稳定性。梯度爆炸（gradient exploding）问题：参数更新过大，破坏了模型的稳定收敛；是梯度消失（gradient vanishing）问题：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-1-1-梯度消失\"><a href=\"#8-1-1-梯度消失\" class=\"headerlink\" title=\"8.1.1 梯度消失\"></a>8.1.1 梯度消失</h3><ul>\n<li>sigmoid函数更符合生物神经元的原理，但可能梯度消失：</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(-<span class=\"number\">8.0</span>, <span class=\"number\">8.0</span>, <span class=\"number\">0.1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y= torch.sigmoid(x)</span><br><span class=\"line\">y.backward(torch.ones_like(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#注意用的是x.grad</span></span><br><span class=\"line\">d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()] , legend=[<span class=\"string\">&#x27;sigmoid&#x27;</span>,<span class=\"string\">&#x27;gradient&#x27;</span>], figsize=(<span class=\"number\">4.5</span>, <span class=\"number\">2.5</span>))</span><br></pre></td></tr></table></figure>\n\n<p>​      <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/8_init_files/8_init_2_0.svg\" alt=\"svg\"></p>\n<ul>\n<li>当sigmoid函数输入很大或很小时，他的梯度会消失。此外，当反向传播通过许多层时，除非我们在刚刚好的地方，否则整个乘积的梯度可能会消失。当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。</li>\n</ul>\n<h3 id=\"8-1-2-梯度爆炸\"><a href=\"#8-1-2-梯度爆炸\" class=\"headerlink\" title=\"8.1.2 梯度爆炸\"></a>8.1.2 梯度爆炸</h3><ul>\n<li>生成100个高斯随机矩阵，将他们与某个初始矩阵相乘，矩阵乘积会发生梯度爆炸。当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">M = torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>, size=(<span class=\"number\">4</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;第一个矩阵\\n&#x27;</span>,M)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">100</span>):</span><br><span class=\"line\">    M=torch.mm(M, torch.normal(<span class=\"number\">0</span>,<span class=\"number\">1</span>,size=(<span class=\"number\">4</span>,<span class=\"number\">4</span>)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;乘以100个矩阵后\\n&#x27;</span>,M)</span><br></pre></td></tr></table></figure>\n\n<pre><code>第一个矩阵\n tensor([[ 0.5260, -0.8163, -0.2948,  1.3394],\n        [-0.6026,  0.9170,  0.2718,  1.0166],\n        [ 1.3275, -0.1824,  1.1752,  0.2823],\n        [ 0.8749,  0.4343,  0.0216,  0.8288]])\n乘以100个矩阵后\n tensor([[ 1.5284e+25,  3.4216e+24, -2.3112e+23, -1.6804e+25],\n        [ 5.5275e+24,  1.2374e+24, -8.3584e+22, -6.0772e+24],\n        [ 2.6396e+25,  5.9094e+24, -3.9915e+23, -2.9022e+25],\n        [ 1.8637e+25,  4.1723e+24, -2.8182e+23, -2.0490e+25]])\n</code></pre>\n<h3 id=\"8-1-3-打破对称性\"><a href=\"#8-1-3-打破对称性\" class=\"headerlink\" title=\"8.1.3 打破对称性\"></a>8.1.3 打破对称性</h3><ul>\n<li>一个隐藏层中的所有隐藏单元的地位是相同的，具有排列对称性。</li>\n<li>如果将隐藏层的所有参数初始化为相同的常量，那么我们可能永远也无法实现网络的表达能力，隐藏层的行为就好像只有一个单元。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。</li>\n</ul>\n<h2 id=\"8-2-参数初始化\"><a href=\"#8-2-参数初始化\" class=\"headerlink\" title=\"8.2 参数初始化\"></a>8.2 参数初始化</h2><ul>\n<li>解决或减轻上述问题</li>\n</ul>\n<h3 id=\"8-2-1-默认初始化\"><a href=\"#8-2-1-默认初始化\" class=\"headerlink\" title=\"8.2.1 默认初始化\"></a>8.2.1 默认初始化</h3><ul>\n<li>如果我们不指定初始化方法，框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。</li>\n</ul>\n<h3 id=\"8-2-2-Xavier初始化\"><a href=\"#8-2-2-Xavier初始化\" class=\"headerlink\" title=\"8.2.2 Xavier初始化\"></a>8.2.2 Xavier初始化</h3><ul>\n<li>假设某层有$n_{in}$个输入：$x_j$，权重为$w_ij$，输出为：$o_i&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}w_{ij}x_j$</li>\n<li>假设权重$w_{ij}$服从$N(0,\\sigma ^2)$，输入$x_j$服从$N(0,\\gamma ^2)。（这并不意味着分布必须是高斯的，只是均值和方差需要存在。）</li>\n<li>输出$o_i$的均值方差：<br>  $$\\begin{aligned}E[o_{i}]&amp; &#x3D;\\sum_{j&#x3D;1}^{n_\\mathrm{in}}E[w_{ij}x_j]  \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_\\mathrm{in}}E[w_{ij}]E[x_j] \\&amp;&#x3D;0.\\end{aligned}$$<br>  $$\\begin{aligned}\\operatorname{Var}[o_i]&amp; &#x3D;E[o_i^2]-(E[o_i])^2  \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}E[w_{ij}^2x_j^2]-0 \\&amp;&#x3D;\\sum_{j&#x3D;1}^{n_{\\mathrm{in}}}E[w_{ij}^2]E[x_j^2] \\&amp;&#x3D;n_\\text{in}\\sigma^2\\gamma^2.\\end{aligned}$$</li>\n<li>保持方差不变的一种方法是设置$n_{in} \\sigma^2&#x3D;1$。考虑反向传播，使用与前向传播相同的推断，我们可以看到，除非$n_{out} \\sigma^2&#x3D;1$否则梯度的方差可能会增大，我们不可能同时满足这两个条件，因此提出Xavier初始化：<br>  $$\\frac12(n_{\\mathrm{in}}+n_{\\mathrm{out}})\\sigma^2&#x3D;1 \\rightarrow \\sigma&#x3D; \\sqrt{\\frac{2}{n_{in}+n_{out}}}$$<ul>\n<li>或者改为从$U\\left(-\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}},\\sqrt{\\frac6{n_\\mathrm{in}+n_\\mathrm{out}}}\\right)$</li>\n</ul>\n</li>\n</ul>"},{"title":"python中PIL模块的使用","date":"2024-04-01T12:00:00.000Z","toc":true,"_content":"\n#\n\n<!-- more -->\n\n# python中PIL模块的使用\n\n- 读取图像\n\n  ```python\n  from PIL import Image\n  img = Image.open('/')\n  #转成RGB\n  img = Image.open('/').convert('RGB')\n  ```\n\n- 缩放图像\n\n  ```python\n  from PIL import Image\n  img = Image.open('/')\n  img_ = img.resize((512,512) , Image.BICUBIC)\n  ```\n\n- 保存图像\n\n  ```python\n  from PIL import Image\n  img = Image.open()\n  img.save('/')\n  ```\n\n  ","source":"_posts/python/PIL.md","raw":"---\ntitle: python中PIL模块的使用\ndate: 2024-04-1 20:00:00\ntoc: true\ntags: [python]\ncategories: [python]\n\n\n\n---\n\n#\n\n<!-- more -->\n\n# python中PIL模块的使用\n\n- 读取图像\n\n  ```python\n  from PIL import Image\n  img = Image.open('/')\n  #转成RGB\n  img = Image.open('/').convert('RGB')\n  ```\n\n- 缩放图像\n\n  ```python\n  from PIL import Image\n  img = Image.open('/')\n  img_ = img.resize((512,512) , Image.BICUBIC)\n  ```\n\n- 保存图像\n\n  ```python\n  from PIL import Image\n  img = Image.open()\n  img.save('/')\n  ```\n\n  ","slug":"python/PIL","published":1,"updated":"2024-04-01T15:05:55.971Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx760000usvwg4r7hn5m","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"python中PIL模块的使用\"><a href=\"#python中PIL模块的使用\" class=\"headerlink\" title=\"python中PIL模块的使用\"></a>python中PIL模块的使用</h1><ul>\n<li><p>读取图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\">#转成RGB</span></span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>).convert(<span class=\"string\">&#x27;RGB&#x27;</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缩放图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>)</span><br><span class=\"line\">img_ = img.resize((<span class=\"number\">512</span>,<span class=\"number\">512</span>) , Image.BICUBIC)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>()</span><br><span class=\"line\">img.save(<span class=\"string\">&#x27;/&#x27;</span>)</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"python中PIL模块的使用\"><a href=\"#python中PIL模块的使用\" class=\"headerlink\" title=\"python中PIL模块的使用\"></a>python中PIL模块的使用</h1><ul>\n<li><p>读取图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\">#转成RGB</span></span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>).convert(<span class=\"string\">&#x27;RGB&#x27;</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缩放图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/&#x27;</span>)</span><br><span class=\"line\">img_ = img.resize((<span class=\"number\">512</span>,<span class=\"number\">512</span>) , Image.BICUBIC)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存图像</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">img = Image.<span class=\"built_in\">open</span>()</span><br><span class=\"line\">img.save(<span class=\"string\">&#x27;/&#x27;</span>)</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"python中os模块的使用","date":"2024-04-01T12:00:00.000Z","toc":true,"_content":"\n#\n\n<!-- more -->\n\n# python中os模块的使用\n\n- 路径\n\n  - 表示路径：\n\n    `os.path.join()`\n\n  - 输出路径\n\n    `os.listdir()`\n\n  - 创建文件夹\n\n    ```python\n    os.makedirs('/', exits_ok=True)\n    ```\n\n    \n\n- 重命名：\n\n  `os.rename(os.path.join(), os.path.join())`","source":"_posts/python/os.md","raw":"---\ntitle: python中os模块的使用\ndate: 2024-04-1 20:00:00\ntoc: true\ntags: [python]\ncategories: [python]\n\n\n\n---\n\n#\n\n<!-- more -->\n\n# python中os模块的使用\n\n- 路径\n\n  - 表示路径：\n\n    `os.path.join()`\n\n  - 输出路径\n\n    `os.listdir()`\n\n  - 创建文件夹\n\n    ```python\n    os.makedirs('/', exits_ok=True)\n    ```\n\n    \n\n- 重命名：\n\n  `os.rename(os.path.join(), os.path.join())`","slug":"python/os","published":1,"updated":"2024-04-01T14:58:35.646Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx7b0001usvw2gi046cq","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"python中os模块的使用\"><a href=\"#python中os模块的使用\" class=\"headerlink\" title=\"python中os模块的使用\"></a>python中os模块的使用</h1><ul>\n<li><p>路径</p>\n<ul>\n<li><p>表示路径：</p>\n<p><code>os.path.join()</code></p>\n</li>\n<li><p>输出路径</p>\n<p><code>os.listdir()</code></p>\n</li>\n<li><p>创建文件夹</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.makedirs(<span class=\"string\">&#x27;/&#x27;</span>, exits_ok=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p>重命名：</p>\n<p><code>os.rename(os.path.join(), os.path.join())</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"python中os模块的使用\"><a href=\"#python中os模块的使用\" class=\"headerlink\" title=\"python中os模块的使用\"></a>python中os模块的使用</h1><ul>\n<li><p>路径</p>\n<ul>\n<li><p>表示路径：</p>\n<p><code>os.path.join()</code></p>\n</li>\n<li><p>输出路径</p>\n<p><code>os.listdir()</code></p>\n</li>\n<li><p>创建文件夹</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.makedirs(<span class=\"string\">&#x27;/&#x27;</span>, exits_ok=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p>重命名：</p>\n<p><code>os.rename(os.path.join(), os.path.join())</code></p>\n</li>\n</ul>"},{"title":"python中re模块的使用","date":"2024-04-01T12:00:00.000Z","toc":true,"_content":"\n#\n\n<!-- more -->\n\n# python中re模块的使用\n\n- 匹配数字：`match = re.match(r'(\\d+)',string)`\n\n- 输出匹配的第一个：\n\n  `match.group(0)`","source":"_posts/python/re.md","raw":"---\ntitle: python中re模块的使用\ndate: 2024-04-1 20:00:00\ntoc: true\ntags: [python]\ncategories: [python]\n\n\n\n---\n\n#\n\n<!-- more -->\n\n# python中re模块的使用\n\n- 匹配数字：`match = re.match(r'(\\d+)',string)`\n\n- 输出匹配的第一个：\n\n  `match.group(0)`","slug":"python/re","published":1,"updated":"2024-04-01T14:33:07.619Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx7d0003usvwfra8atrh","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h1 id=\"python中re模块的使用\"><a href=\"#python中re模块的使用\" class=\"headerlink\" title=\"python中re模块的使用\"></a>python中re模块的使用</h1><ul>\n<li><p>匹配数字：<code>match = re.match(r&#39;(\\d+)&#39;,string)</code></p>\n</li>\n<li><p>输出匹配的第一个：</p>\n<p><code>match.group(0)</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"python中re模块的使用\"><a href=\"#python中re模块的使用\" class=\"headerlink\" title=\"python中re模块的使用\"></a>python中re模块的使用</h1><ul>\n<li><p>匹配数字：<code>match = re.match(r&#39;(\\d+)&#39;,string)</code></p>\n</li>\n<li><p>输出匹配的第一个：</p>\n<p><code>match.group(0)</code></p>\n</li>\n</ul>"},{"title":"4.1 层和块","date":"2024-04-18T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 1 层和块\n- 单个神经网络：\n    - 一个输入\n    - 标量输出\n    - 一组相关参数，这些参数可以通过学习而优化\n- 层：\n    - 一组输入\n    - 一组输出\n    - 一组可调参数\n- 从编程的角度看，块由类来表示。通常需要定义一个将输入转换成输出的forward函数，并且必须存储任何必须的参数。\n- 定义一个网络：256个单元和ReLU的全连接隐藏层，10个隐藏单元且不带激活函数的全连接输出层\n    - nn.Sequential是一种特殊的module，表示一个块，维护了一个由module组成的有序列表\n    - net(x)相当于net.__call__(x)\n\n\n```python\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nnet= nn.Sequential( #一种特殊的module，表示一个块，维护了一个由module组成的有序列表\n    nn.Linear(20,256),\n    nn.ReLU(), \n    nn.Linear(256,10))\n\nX = torch.rand(2,20)\nprint(net(X))\n```\n\n    tensor([[ 0.0302, -0.1207, -0.0915,  0.0522, -0.3685,  0.0474,  0.0665, -0.0055,\n             -0.1445, -0.1954],\n            [ 0.0275, -0.1345,  0.0009,  0.0987, -0.4689,  0.0405,  0.0012, -0.0243,\n             -0.2954, -0.1414]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.1 自定义块\n- 每个块必须提供的功能：\n    - 数据输入forward函数得到输出\n    - 计算输出关于输入的梯度，通过backward函数\n    - 存储和访问前向传播计算所需要的参数\n    - 初始化模型参数\n\n\n```python\nclass MLP(nn.Module):\n    # 用模型参数声明层。声明两个全连接层\n    def __init__(self):\n        super().__init__() #Module的构造函数进行必要的初始化\n        self.hidden = nn.Linear(20,256) #隐藏层\n        self.out = nn.Linear(256,10) #输出层\n\n    # 前行传播，如何根据输入x返回所需的模型输出\n    def forward(self,X):\n        return self.out(F.relu(self.hidden(X)))\n    \nnet = MLP()\nprint(net(X))\n```\n\n    tensor([[ 0.2163,  0.0644, -0.1128, -0.2947,  0.0708,  0.0907, -0.0680, -0.0381,\n             -0.0843,  0.0921],\n            [ 0.2196,  0.0087,  0.0257, -0.1403, -0.0191,  0.0435, -0.1980,  0.0350,\n              0.0158,  0.0848]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.2 顺序块\n- 构建自己简化的Sequential类需要\n    - 将block逐个追加到列表中\n    - forward函数中，将输入按顺序传递\n\n\n```python\nclass MySequential(nn.Module):\n    def __init__(self, *args) -> None:\n        super().__init__()\n        for idx, module in enumerate(args):\n            # module是Module子类的一个实例\n            # _modules中，_module的类型是OrderedDict\n            #为啥每个Module都有一个_modules属性，为啥不用python列表？\n            # _modules优点：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。\n            self._modules[str(idx)] = module\n    def forward(self, X):\n        for block in self._modules.values():\n            X = block(X)\n        return X\n    \nnet = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))\nprint(net(X))\n```\n\n    tensor([[-0.1585, -0.0420,  0.3813, -0.3592, -0.0889,  0.0362, -0.0543, -0.0557,\n             -0.2022,  0.0183],\n            [-0.0438, -0.1248,  0.5774, -0.3087, -0.0576, -0.0479,  0.0954, -0.2362,\n             -0.2333, -0.1394]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.3 在前向传播函数中执行代码\n- 有时我们希望合并既不是上一层的结果也不是可更新参数的项，成为常数参数。\n\n\n```python\nclass FixedHiddenMLP(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        # 不计算梯度的随机权重参数，因此其在训练期间保持不变\n        self.rand_weight = torch.rand((20,20), requires_grad=False)\n        self.linear = nn.Linear(20,20)\n\n    def forward(self, X):\n        X = self.linear(X)\n        # 使用创建的常量参数以及relu和mm函数\n        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n        # 复用全连接层。相当于两个全连接成共享参数\n        X = self.linear(X)\n        # 控制流：\n        while X.abs().sum() > 1: #l1范数\n            X/=2\n        return X.sum()\nnet = FixedHiddenMLP()\nprint(net(X))\n```\n\n    tensor(-0.2985, grad_fn=<SumBackward0>)\n    \n\n## 1.4 效率\n我们在一个高性能的深度学习库中进行了大量的字典查找、代码执行和许多其他的Python代码。Python的问题全局解释器锁是众所周知的。在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n","source":"_posts/deeplearning/code/pytorch/4_calculate/1_block.md","raw":"---\ntitle: 4.1 层和块\ndate: 2024-4-18 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 1 层和块\n- 单个神经网络：\n    - 一个输入\n    - 标量输出\n    - 一组相关参数，这些参数可以通过学习而优化\n- 层：\n    - 一组输入\n    - 一组输出\n    - 一组可调参数\n- 从编程的角度看，块由类来表示。通常需要定义一个将输入转换成输出的forward函数，并且必须存储任何必须的参数。\n- 定义一个网络：256个单元和ReLU的全连接隐藏层，10个隐藏单元且不带激活函数的全连接输出层\n    - nn.Sequential是一种特殊的module，表示一个块，维护了一个由module组成的有序列表\n    - net(x)相当于net.__call__(x)\n\n\n```python\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nnet= nn.Sequential( #一种特殊的module，表示一个块，维护了一个由module组成的有序列表\n    nn.Linear(20,256),\n    nn.ReLU(), \n    nn.Linear(256,10))\n\nX = torch.rand(2,20)\nprint(net(X))\n```\n\n    tensor([[ 0.0302, -0.1207, -0.0915,  0.0522, -0.3685,  0.0474,  0.0665, -0.0055,\n             -0.1445, -0.1954],\n            [ 0.0275, -0.1345,  0.0009,  0.0987, -0.4689,  0.0405,  0.0012, -0.0243,\n             -0.2954, -0.1414]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.1 自定义块\n- 每个块必须提供的功能：\n    - 数据输入forward函数得到输出\n    - 计算输出关于输入的梯度，通过backward函数\n    - 存储和访问前向传播计算所需要的参数\n    - 初始化模型参数\n\n\n```python\nclass MLP(nn.Module):\n    # 用模型参数声明层。声明两个全连接层\n    def __init__(self):\n        super().__init__() #Module的构造函数进行必要的初始化\n        self.hidden = nn.Linear(20,256) #隐藏层\n        self.out = nn.Linear(256,10) #输出层\n\n    # 前行传播，如何根据输入x返回所需的模型输出\n    def forward(self,X):\n        return self.out(F.relu(self.hidden(X)))\n    \nnet = MLP()\nprint(net(X))\n```\n\n    tensor([[ 0.2163,  0.0644, -0.1128, -0.2947,  0.0708,  0.0907, -0.0680, -0.0381,\n             -0.0843,  0.0921],\n            [ 0.2196,  0.0087,  0.0257, -0.1403, -0.0191,  0.0435, -0.1980,  0.0350,\n              0.0158,  0.0848]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.2 顺序块\n- 构建自己简化的Sequential类需要\n    - 将block逐个追加到列表中\n    - forward函数中，将输入按顺序传递\n\n\n```python\nclass MySequential(nn.Module):\n    def __init__(self, *args) -> None:\n        super().__init__()\n        for idx, module in enumerate(args):\n            # module是Module子类的一个实例\n            # _modules中，_module的类型是OrderedDict\n            #为啥每个Module都有一个_modules属性，为啥不用python列表？\n            # _modules优点：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。\n            self._modules[str(idx)] = module\n    def forward(self, X):\n        for block in self._modules.values():\n            X = block(X)\n        return X\n    \nnet = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))\nprint(net(X))\n```\n\n    tensor([[-0.1585, -0.0420,  0.3813, -0.3592, -0.0889,  0.0362, -0.0543, -0.0557,\n             -0.2022,  0.0183],\n            [-0.0438, -0.1248,  0.5774, -0.3087, -0.0576, -0.0479,  0.0954, -0.2362,\n             -0.2333, -0.1394]], grad_fn=<AddmmBackward0>)\n    \n\n## 1.3 在前向传播函数中执行代码\n- 有时我们希望合并既不是上一层的结果也不是可更新参数的项，成为常数参数。\n\n\n```python\nclass FixedHiddenMLP(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        # 不计算梯度的随机权重参数，因此其在训练期间保持不变\n        self.rand_weight = torch.rand((20,20), requires_grad=False)\n        self.linear = nn.Linear(20,20)\n\n    def forward(self, X):\n        X = self.linear(X)\n        # 使用创建的常量参数以及relu和mm函数\n        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n        # 复用全连接层。相当于两个全连接成共享参数\n        X = self.linear(X)\n        # 控制流：\n        while X.abs().sum() > 1: #l1范数\n            X/=2\n        return X.sum()\nnet = FixedHiddenMLP()\nprint(net(X))\n```\n\n    tensor(-0.2985, grad_fn=<SumBackward0>)\n    \n\n## 1.4 效率\n我们在一个高性能的深度学习库中进行了大量的字典查找、代码执行和许多其他的Python代码。Python的问题全局解释器锁是众所周知的。在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。\n","slug":"deeplearning/code/pytorch/4_calculate/1_block","published":1,"updated":"2024-04-18T14:32:26.169Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx7k000busvwd22mc89k","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"1-层和块\"><a href=\"#1-层和块\" class=\"headerlink\" title=\"1 层和块\"></a>1 层和块</h1><ul>\n<li>单个神经网络：<ul>\n<li>一个输入</li>\n<li>标量输出</li>\n<li>一组相关参数，这些参数可以通过学习而优化</li>\n</ul>\n</li>\n<li>层：<ul>\n<li>一组输入</li>\n<li>一组输出</li>\n<li>一组可调参数</li>\n</ul>\n</li>\n<li>从编程的角度看，块由类来表示。通常需要定义一个将输入转换成输出的forward函数，并且必须存储任何必须的参数。</li>\n<li>定义一个网络：256个单元和ReLU的全连接隐藏层，10个隐藏单元且不带激活函数的全连接输出层<ul>\n<li>nn.Sequential是一种特殊的module，表示一个块，维护了一个由module组成的有序列表</li>\n<li>net(x)相当于net.<strong>call</strong>(x)</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\">net= nn.Sequential( <span class=\"comment\">#一种特殊的module，表示一个块，维护了一个由module组成的有序列表</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(), </span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">2</span>,<span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.0302, -0.1207, -0.0915,  0.0522, -0.3685,  0.0474,  0.0665, -0.0055,\n         -0.1445, -0.1954],\n        [ 0.0275, -0.1345,  0.0009,  0.0987, -0.4689,  0.0405,  0.0012, -0.0243,\n         -0.2954, -0.1414]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-1-自定义块\"><a href=\"#1-1-自定义块\" class=\"headerlink\" title=\"1.1 自定义块\"></a>1.1 自定义块</h2><ul>\n<li>每个块必须提供的功能：<ul>\n<li>数据输入forward函数得到输出</li>\n<li>计算输出关于输入的梯度，通过backward函数</li>\n<li>存储和访问前向传播计算所需要的参数</li>\n<li>初始化模型参数</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"comment\"># 用模型参数声明层。声明两个全连接层</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__() <span class=\"comment\">#Module的构造函数进行必要的初始化</span></span><br><span class=\"line\">        self.hidden = nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">256</span>) <span class=\"comment\">#隐藏层</span></span><br><span class=\"line\">        self.out = nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>) <span class=\"comment\">#输出层</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 前行传播，如何根据输入x返回所需的模型输出</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.out(F.relu(self.hidden(X)))</span><br><span class=\"line\">    </span><br><span class=\"line\">net = MLP()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.2163,  0.0644, -0.1128, -0.2947,  0.0708,  0.0907, -0.0680, -0.0381,\n         -0.0843,  0.0921],\n        [ 0.2196,  0.0087,  0.0257, -0.1403, -0.0191,  0.0435, -0.1980,  0.0350,\n          0.0158,  0.0848]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-2-顺序块\"><a href=\"#1-2-顺序块\" class=\"headerlink\" title=\"1.2 顺序块\"></a>1.2 顺序块</h2><ul>\n<li>构建自己简化的Sequential类需要<ul>\n<li>将block逐个追加到列表中</li>\n<li>forward函数中，将输入按顺序传递</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MySequential</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, *args</span>) -&gt; <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, module <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(args):</span><br><span class=\"line\">            <span class=\"comment\"># module是Module子类的一个实例</span></span><br><span class=\"line\">            <span class=\"comment\"># _modules中，_module的类型是OrderedDict</span></span><br><span class=\"line\">            <span class=\"comment\">#为啥每个Module都有一个_modules属性，为啥不用python列表？</span></span><br><span class=\"line\">            <span class=\"comment\"># _modules优点：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。</span></span><br><span class=\"line\">            self._modules[<span class=\"built_in\">str</span>(idx)] = module</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> block <span class=\"keyword\">in</span> self._modules.values():</span><br><span class=\"line\">            X = block(X)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\">    </span><br><span class=\"line\">net = MySequential(nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>), nn.ReLU(), nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[-0.1585, -0.0420,  0.3813, -0.3592, -0.0889,  0.0362, -0.0543, -0.0557,\n         -0.2022,  0.0183],\n        [-0.0438, -0.1248,  0.5774, -0.3087, -0.0576, -0.0479,  0.0954, -0.2362,\n         -0.2333, -0.1394]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-3-在前向传播函数中执行代码\"><a href=\"#1-3-在前向传播函数中执行代码\" class=\"headerlink\" title=\"1.3 在前向传播函数中执行代码\"></a>1.3 在前向传播函数中执行代码</h2><ul>\n<li>有时我们希望合并既不是上一层的结果也不是可更新参数的项，成为常数参数。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">FixedHiddenMLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>) -&gt; <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 不计算梯度的随机权重参数，因此其在训练期间保持不变</span></span><br><span class=\"line\">        self.rand_weight = torch.rand((<span class=\"number\">20</span>,<span class=\"number\">20</span>), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">20</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># 使用创建的常量参数以及relu和mm函数</span></span><br><span class=\"line\">        X = F.relu(torch.mm(X, self.rand_weight) + <span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 复用全连接层。相当于两个全连接成共享参数</span></span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># 控制流：</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> X.<span class=\"built_in\">abs</span>().<span class=\"built_in\">sum</span>() &gt; <span class=\"number\">1</span>: <span class=\"comment\">#l1范数</span></span><br><span class=\"line\">            X/=<span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> X.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">net = FixedHiddenMLP()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor(-0.2985, grad_fn=&lt;SumBackward0&gt;)\n</code></pre>\n<h2 id=\"1-4-效率\"><a href=\"#1-4-效率\" class=\"headerlink\" title=\"1.4 效率\"></a>1.4 效率</h2><p>我们在一个高性能的深度学习库中进行了大量的字典查找、代码执行和许多其他的Python代码。Python的问题全局解释器锁是众所周知的。在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"1-层和块\"><a href=\"#1-层和块\" class=\"headerlink\" title=\"1 层和块\"></a>1 层和块</h1><ul>\n<li>单个神经网络：<ul>\n<li>一个输入</li>\n<li>标量输出</li>\n<li>一组相关参数，这些参数可以通过学习而优化</li>\n</ul>\n</li>\n<li>层：<ul>\n<li>一组输入</li>\n<li>一组输出</li>\n<li>一组可调参数</li>\n</ul>\n</li>\n<li>从编程的角度看，块由类来表示。通常需要定义一个将输入转换成输出的forward函数，并且必须存储任何必须的参数。</li>\n<li>定义一个网络：256个单元和ReLU的全连接隐藏层，10个隐藏单元且不带激活函数的全连接输出层<ul>\n<li>nn.Sequential是一种特殊的module，表示一个块，维护了一个由module组成的有序列表</li>\n<li>net(x)相当于net.<strong>call</strong>(x)</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\">net= nn.Sequential( <span class=\"comment\">#一种特殊的module，表示一个块，维护了一个由module组成的有序列表</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">256</span>),</span><br><span class=\"line\">    nn.ReLU(), </span><br><span class=\"line\">    nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">2</span>,<span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.0302, -0.1207, -0.0915,  0.0522, -0.3685,  0.0474,  0.0665, -0.0055,\n         -0.1445, -0.1954],\n        [ 0.0275, -0.1345,  0.0009,  0.0987, -0.4689,  0.0405,  0.0012, -0.0243,\n         -0.2954, -0.1414]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-1-自定义块\"><a href=\"#1-1-自定义块\" class=\"headerlink\" title=\"1.1 自定义块\"></a>1.1 自定义块</h2><ul>\n<li>每个块必须提供的功能：<ul>\n<li>数据输入forward函数得到输出</li>\n<li>计算输出关于输入的梯度，通过backward函数</li>\n<li>存储和访问前向传播计算所需要的参数</li>\n<li>初始化模型参数</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"comment\"># 用模型参数声明层。声明两个全连接层</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__() <span class=\"comment\">#Module的构造函数进行必要的初始化</span></span><br><span class=\"line\">        self.hidden = nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">256</span>) <span class=\"comment\">#隐藏层</span></span><br><span class=\"line\">        self.out = nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>) <span class=\"comment\">#输出层</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 前行传播，如何根据输入x返回所需的模型输出</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self,X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.out(F.relu(self.hidden(X)))</span><br><span class=\"line\">    </span><br><span class=\"line\">net = MLP()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[ 0.2163,  0.0644, -0.1128, -0.2947,  0.0708,  0.0907, -0.0680, -0.0381,\n         -0.0843,  0.0921],\n        [ 0.2196,  0.0087,  0.0257, -0.1403, -0.0191,  0.0435, -0.1980,  0.0350,\n          0.0158,  0.0848]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-2-顺序块\"><a href=\"#1-2-顺序块\" class=\"headerlink\" title=\"1.2 顺序块\"></a>1.2 顺序块</h2><ul>\n<li>构建自己简化的Sequential类需要<ul>\n<li>将block逐个追加到列表中</li>\n<li>forward函数中，将输入按顺序传递</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MySequential</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, *args</span>) -&gt; <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, module <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(args):</span><br><span class=\"line\">            <span class=\"comment\"># module是Module子类的一个实例</span></span><br><span class=\"line\">            <span class=\"comment\"># _modules中，_module的类型是OrderedDict</span></span><br><span class=\"line\">            <span class=\"comment\">#为啥每个Module都有一个_modules属性，为啥不用python列表？</span></span><br><span class=\"line\">            <span class=\"comment\"># _modules优点：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。</span></span><br><span class=\"line\">            self._modules[<span class=\"built_in\">str</span>(idx)] = module</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> block <span class=\"keyword\">in</span> self._modules.values():</span><br><span class=\"line\">            X = block(X)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\">    </span><br><span class=\"line\">net = MySequential(nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>), nn.ReLU(), nn.Linear(<span class=\"number\">256</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor([[-0.1585, -0.0420,  0.3813, -0.3592, -0.0889,  0.0362, -0.0543, -0.0557,\n         -0.2022,  0.0183],\n        [-0.0438, -0.1248,  0.5774, -0.3087, -0.0576, -0.0479,  0.0954, -0.2362,\n         -0.2333, -0.1394]], grad_fn=&lt;AddmmBackward0&gt;)\n</code></pre>\n<h2 id=\"1-3-在前向传播函数中执行代码\"><a href=\"#1-3-在前向传播函数中执行代码\" class=\"headerlink\" title=\"1.3 在前向传播函数中执行代码\"></a>1.3 在前向传播函数中执行代码</h2><ul>\n<li>有时我们希望合并既不是上一层的结果也不是可更新参数的项，成为常数参数。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">FixedHiddenMLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>) -&gt; <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 不计算梯度的随机权重参数，因此其在训练期间保持不变</span></span><br><span class=\"line\">        self.rand_weight = torch.rand((<span class=\"number\">20</span>,<span class=\"number\">20</span>), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">20</span>,<span class=\"number\">20</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># 使用创建的常量参数以及relu和mm函数</span></span><br><span class=\"line\">        X = F.relu(torch.mm(X, self.rand_weight) + <span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 复用全连接层。相当于两个全连接成共享参数</span></span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># 控制流：</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> X.<span class=\"built_in\">abs</span>().<span class=\"built_in\">sum</span>() &gt; <span class=\"number\">1</span>: <span class=\"comment\">#l1范数</span></span><br><span class=\"line\">            X/=<span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> X.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">net = FixedHiddenMLP()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))</span><br></pre></td></tr></table></figure>\n\n<pre><code>tensor(-0.2985, grad_fn=&lt;SumBackward0&gt;)\n</code></pre>\n<h2 id=\"1-4-效率\"><a href=\"#1-4-效率\" class=\"headerlink\" title=\"1.4 效率\"></a>1.4 效率</h2><p>我们在一个高性能的深度学习库中进行了大量的字典查找、代码执行和许多其他的Python代码。Python的问题全局解释器锁是众所周知的。在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。</p>"},{"title":"3.10 kaggle:预测房价","date":"2024-03-19T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 10 kaggle:预测房价\n## 10.1 下载和缓存数据集\n\n\n```python\nimport hashlib\nimport os\nimport tarfile\nimport zipfile\nimport requests\n\n#@save\nDATA_HUB = dict() #字典，将数据集名称的字符串映射到数据集相关的二元组上，每个二元组包含数据集的url和校验和密钥\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/' #所有类似的数据集都托管在这个地址上\n\ndef download(name, cache_dir=os.path.join('data')): #@save\n    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名。\"\"\"\n    assert name in DATA_HUB, f\"{name}不存在于{DATA_HUB}\"\n    url, sha1_hash = DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok=True)\n    fname = os.path.join(cache_dir, url.split('/')[-1]) #取出url中最后一个/后面的字符串，作为文件名\n    if os.path.exists(fname):\n        sha1 = hashlib.sha1()\n        with open(fname, 'rb') as f:\n            while True:\n                data = f.read(1048576) # 读取1MB数据\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() == sha1_hash:\n            return fname #命中缓存\n\n    print(f'正在从{url}下载{fname}...')\n    r = requests.get(url, stream=True, verify= True)\n    with open(fname, 'wb') as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder=None): #@save\n    \"\"\"下载并解压zip/tar文件\"\"\"\n    fname = download(name)\n    base_dir = os.path.dirname(fname)\n    data_dir, ext = os.path.splitext(fname)\n    if ext =='.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, '只有zip/tar文件可以被解压缩'\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all(): #@save\n    \"\"\"下载DATA_HUB中的所有文件\"\"\"\n    for name in DATA_HUB:\n        download(name)\n```\n\n## 10.2 访问和读取数据集\n\n\n```python\n\n#读入并处理数据\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nDATA_HUB['kaggle_house_train']=( #@save\n    DATA_URL + 'kaggle_house_pred_train.csv',\n    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\nDATA_HUB['kaggle_house_test'] = (#@save\n    DATA_URL + 'kaggle_house_pred_test.csv',\n    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n\n### 1. 加载数据集\ntrain_data = pd.read_csv(download('kaggle_house_train'))\ntest_data = pd.read_csv(download('kaggle_house_test'))\n#输出维度\nprint(train_data.shape)\nprint(test_data.shape)\n#输出前四个特征、最后两个特征、标签\nprint(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n#去掉id列\nall_features = pd.concat((train_data.iloc[:,1:-1], test_data.iloc[:,1:]))\n```\n\n    正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载data\\kaggle_house_pred_train.csv...\n    正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载data\\kaggle_house_pred_test.csv...\n    (1460, 81)\n    (1459, 80)\n       Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n    0   1          60       RL         65.0       WD        Normal     208500\n    1   2          20       RL         80.0       WD        Normal     181500\n    2   3          60       RL         68.0       WD        Normal     223500\n    3   4          70       RL         60.0       WD       Abnorml     140000\n\n\n## 10.3 数据预处理\n- 缺失值用均值代替\n- 为了将所有特征放到一个共同的尺度上，将特征缩放到均值为0，单位方差：\n$$x \\leftarrow \\frac{x-\\mu} \\sigma$$\n- 标准化数据有两个原因：\n    - 方便优化\n    - 因为我们不知道哪些特征是相关的，所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大\n- 离散值处理：独热编码：如MSZoning列包含值：‘RL’和‘RM’。创建两个新的指标列MSZoning_RL和MSZoning_RM，值为0，1.可以用pandas自动实现\n\n\n```python\n## 2标准化\nnumeric_features = all_features.dtypes[all_features.dtypes != 'object'].index #取出数值特征的索引\nall_features[numeric_features] = all_features[numeric_features].apply(\n    lambda x:(x-x.mean())/ x.std()\n)\n#缺失值设为0\nall_features[numeric_features] = all_features[numeric_features].fillna(0)\n\n## 3离散值处理\n#‘dummy_na=True’将缺失值也当作合法的特征值并为其创建指示特征\nall_features = pd.get_dummies(all_features, dummy_na=True)\nprint(all_features.shape) #特征数量从79 -> 331\n\n## 3转换为张量\nn_train = train_data.shape[0]\ntrain_features = torch.tensor(all_features[:n_train].values, dtype= torch.float32)\ntest_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\ntrain_labels = torch.tensor(\n    train_data.SalePrice.values.reshape(-1,1), dtype=torch.float32\n)\n```\n\n    (2919, 331)\n\n\n## 10.4 训练\n- 先训练一个带有损失平方的线性模型，线性模型可以提供一种健全性检查，以查看数据中是否存在有意义的信息。如果线性模型不能做得比随机猜测更好，那么可能存在数据处理错误。如果一切顺利，线性模型可以作为基线模型（baseline）\n- Adam优化器主要吸引力在于对初始学习率不那么敏感\n\n\n```python\nloss= nn.MSELoss()\nin_features = train_features.shape[1]\ndef get_net():\n    net = nn.Sequential(nn.Linear(in_features,1))\n    return net\n```\n\n- 对于误差，更关心相对误差，例如北京房价预测差了10万与阳新放假预测差了10万是不同的。\n- 可以用价格预测的对数来衡量差异。将$\\sigma for |log y - log \\hat y|$转换为$e^{-\\sigma} \\leq \\frac{\\hat y}{y} \\leq e^{\\sigma}$这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差：\n$$\\sqrt{\\frac1n\\sum_{i=1}^n\\left(\\log y_i-\\log\\hat{y}_i\\right)^2}$$\n\n\n```python\ndef log_rmse(net, features, labels):\n    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))\n    return rmse.item()\n\ndef train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, weight_decay, batch_size):\n    train_ls, test_ls = [], []\n    train_iter = d2l.load_array((train_features,train_labels),batch_size)\n    optimizer = torch.optim.Adam(net.parameters(),\n                                lr =learning_rate,\n                                weight_decay=weight_decay)\n    for epoch in range(num_epochs):\n        for X,y in train_iter:\n                optimizer.zero_grad()\n                l = loss(net(X), y)\n                l.backward()\n                optimizer.step()\n        train_ls.append(log_rmse(net, train_features,train_labels))\n        if test_labels is not None:\n                test_ls.append(log_rmse(net, test_features,test_labels))\n    return train_ls, test_ls\n\n```\n\n## 10.5 K折交叉验证\n- 有助于模型选择和超参数调整。我们首先需要定义一个函数，在K折交叉验证过程中返回第i折的数据。具体地说，它选择第i个切片作为验证数据，其余部分作为训练数据。每次在K − 1个子集上进行训练，并在剩余的一个子集上进行验证。\n\n\n```python\ndef get_k_fold_data(k, i, X, y):\n    assert k > 1\n    fold_size = X.shape[0] // k\n    X_train, y_train = None, None\n    for j in range(k):\n        idx = slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part = X[idx, :], y[idx]\n        if j ==i:\n            X_valid, y_valid = X_part, y_part\n        elif X_train is None:\n            X_train, y_train = X_part, y_part\n        else:\n            X_train = torch.cat([X_train, X_part], 0)\n            y_train = torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid\n```\n\n- 训练K次，并返回训练和验证误差的平均值\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n    train_l_sum, valid_l_sum = 0, 0\n    for i in range(k):\n        data = get_k_fold_data(k, i, X_train, y_train)\n        net = get_net()\n        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n        train_l_sum += train_ls[-1]\n        valid_l_sum += valid_ls[-1]\n        if i == 0:\n            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n                     xlabel='epoch', ylabel='rmse',\n                     legend=['train', 'valid'], yscale='log')\n        print(f'折{i + 1}, 训练log rmse {float(train_ls[-1]):f}, '\n              f'验证log rmse {float(valid_ls[-1]):f}')\n    return train_l_sum / k, valid_l_sum / k\n```\n\n## 10.6 模型选择\n- 使用未调优的超参数\n\n\n```python\nk, num_epochs, lr, weight_decay, batch_size=5, 100, 5, 0, 64\ntrain_l, valid_l= k_fold(k, train_features, train_labels,num_epochs,lr,\n                         weight_decay, batch_size)\nprint(f'{k}-折验证：平均训练log rmse：{float(train_l):f},'\n      f'平均验证log rmse：{float(valid_l):f}')\n```\n\n    折1, 训练log rmse 0.170100, 验证log rmse 0.156652\n    折2, 训练log rmse 0.162041, 验证log rmse 0.188112\n    折3, 训练log rmse 0.163980, 验证log rmse 0.168341\n    折4, 训练log rmse 0.167889, 验证log rmse 0.154215\n    折5, 训练log rmse 0.163577, 验证log rmse 0.183105\n    5-折验证：平均训练log rmse：0.165517,平均验证log rmse：0.170085\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg) \n\n\n![svg](img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg)\n\n​    \n\n\n## 10.7 提交Kaggle预测\n- 使用所有的数据进行训练，将预测保存在csv文件\n\n\n```python\ndef train_and_pred(train_features, test_features, train_labels, test_data,\n                   num_epochs, lr, weight_decay, batch_size):\n    net = get_net()\n    train_ls, _ = train(net, train_features, train_labels, None,None,\n                        num_epochs, lr, weight_decay, batch_size)\n    d2l.plot(np.arange(1, num_epochs+1), [train_ls], xlabel='epoch',\n             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')\n    print(f'训练log rmse:{float(train_ls[-1]):f}')\n    #将网络用于测试集\n    preds = net(test_features).detach().numpy()\n    # 将其重新格式化以导出到kaggle\n    test_data['SalePrice']=pd.Series(preds.reshape(1, -1)[0])\n    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n    submission.to_csv('submission.csv', index=False)\n\ntrain_and_pred(train_features, test_features, train_labels,test_data,\n               num_epochs, lr, weight_decay, batch_size)\n```\n\n    训练log rmse:0.162509\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg)\n\n\n![svg](img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg)\n    \n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price.md","raw":"---\ntitle: 3.10 kaggle:预测房价\ndate: 2024-3-19 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 10 kaggle:预测房价\n## 10.1 下载和缓存数据集\n\n\n```python\nimport hashlib\nimport os\nimport tarfile\nimport zipfile\nimport requests\n\n#@save\nDATA_HUB = dict() #字典，将数据集名称的字符串映射到数据集相关的二元组上，每个二元组包含数据集的url和校验和密钥\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/' #所有类似的数据集都托管在这个地址上\n\ndef download(name, cache_dir=os.path.join('data')): #@save\n    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名。\"\"\"\n    assert name in DATA_HUB, f\"{name}不存在于{DATA_HUB}\"\n    url, sha1_hash = DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok=True)\n    fname = os.path.join(cache_dir, url.split('/')[-1]) #取出url中最后一个/后面的字符串，作为文件名\n    if os.path.exists(fname):\n        sha1 = hashlib.sha1()\n        with open(fname, 'rb') as f:\n            while True:\n                data = f.read(1048576) # 读取1MB数据\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() == sha1_hash:\n            return fname #命中缓存\n\n    print(f'正在从{url}下载{fname}...')\n    r = requests.get(url, stream=True, verify= True)\n    with open(fname, 'wb') as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder=None): #@save\n    \"\"\"下载并解压zip/tar文件\"\"\"\n    fname = download(name)\n    base_dir = os.path.dirname(fname)\n    data_dir, ext = os.path.splitext(fname)\n    if ext =='.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, '只有zip/tar文件可以被解压缩'\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all(): #@save\n    \"\"\"下载DATA_HUB中的所有文件\"\"\"\n    for name in DATA_HUB:\n        download(name)\n```\n\n## 10.2 访问和读取数据集\n\n\n```python\n\n#读入并处理数据\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nDATA_HUB['kaggle_house_train']=( #@save\n    DATA_URL + 'kaggle_house_pred_train.csv',\n    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\nDATA_HUB['kaggle_house_test'] = (#@save\n    DATA_URL + 'kaggle_house_pred_test.csv',\n    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n\n### 1. 加载数据集\ntrain_data = pd.read_csv(download('kaggle_house_train'))\ntest_data = pd.read_csv(download('kaggle_house_test'))\n#输出维度\nprint(train_data.shape)\nprint(test_data.shape)\n#输出前四个特征、最后两个特征、标签\nprint(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n#去掉id列\nall_features = pd.concat((train_data.iloc[:,1:-1], test_data.iloc[:,1:]))\n```\n\n    正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载data\\kaggle_house_pred_train.csv...\n    正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载data\\kaggle_house_pred_test.csv...\n    (1460, 81)\n    (1459, 80)\n       Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n    0   1          60       RL         65.0       WD        Normal     208500\n    1   2          20       RL         80.0       WD        Normal     181500\n    2   3          60       RL         68.0       WD        Normal     223500\n    3   4          70       RL         60.0       WD       Abnorml     140000\n\n\n## 10.3 数据预处理\n- 缺失值用均值代替\n- 为了将所有特征放到一个共同的尺度上，将特征缩放到均值为0，单位方差：\n$$x \\leftarrow \\frac{x-\\mu} \\sigma$$\n- 标准化数据有两个原因：\n    - 方便优化\n    - 因为我们不知道哪些特征是相关的，所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大\n- 离散值处理：独热编码：如MSZoning列包含值：‘RL’和‘RM’。创建两个新的指标列MSZoning_RL和MSZoning_RM，值为0，1.可以用pandas自动实现\n\n\n```python\n## 2标准化\nnumeric_features = all_features.dtypes[all_features.dtypes != 'object'].index #取出数值特征的索引\nall_features[numeric_features] = all_features[numeric_features].apply(\n    lambda x:(x-x.mean())/ x.std()\n)\n#缺失值设为0\nall_features[numeric_features] = all_features[numeric_features].fillna(0)\n\n## 3离散值处理\n#‘dummy_na=True’将缺失值也当作合法的特征值并为其创建指示特征\nall_features = pd.get_dummies(all_features, dummy_na=True)\nprint(all_features.shape) #特征数量从79 -> 331\n\n## 3转换为张量\nn_train = train_data.shape[0]\ntrain_features = torch.tensor(all_features[:n_train].values, dtype= torch.float32)\ntest_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\ntrain_labels = torch.tensor(\n    train_data.SalePrice.values.reshape(-1,1), dtype=torch.float32\n)\n```\n\n    (2919, 331)\n\n\n## 10.4 训练\n- 先训练一个带有损失平方的线性模型，线性模型可以提供一种健全性检查，以查看数据中是否存在有意义的信息。如果线性模型不能做得比随机猜测更好，那么可能存在数据处理错误。如果一切顺利，线性模型可以作为基线模型（baseline）\n- Adam优化器主要吸引力在于对初始学习率不那么敏感\n\n\n```python\nloss= nn.MSELoss()\nin_features = train_features.shape[1]\ndef get_net():\n    net = nn.Sequential(nn.Linear(in_features,1))\n    return net\n```\n\n- 对于误差，更关心相对误差，例如北京房价预测差了10万与阳新放假预测差了10万是不同的。\n- 可以用价格预测的对数来衡量差异。将$\\sigma for |log y - log \\hat y|$转换为$e^{-\\sigma} \\leq \\frac{\\hat y}{y} \\leq e^{\\sigma}$这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差：\n$$\\sqrt{\\frac1n\\sum_{i=1}^n\\left(\\log y_i-\\log\\hat{y}_i\\right)^2}$$\n\n\n```python\ndef log_rmse(net, features, labels):\n    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))\n    return rmse.item()\n\ndef train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, weight_decay, batch_size):\n    train_ls, test_ls = [], []\n    train_iter = d2l.load_array((train_features,train_labels),batch_size)\n    optimizer = torch.optim.Adam(net.parameters(),\n                                lr =learning_rate,\n                                weight_decay=weight_decay)\n    for epoch in range(num_epochs):\n        for X,y in train_iter:\n                optimizer.zero_grad()\n                l = loss(net(X), y)\n                l.backward()\n                optimizer.step()\n        train_ls.append(log_rmse(net, train_features,train_labels))\n        if test_labels is not None:\n                test_ls.append(log_rmse(net, test_features,test_labels))\n    return train_ls, test_ls\n\n```\n\n## 10.5 K折交叉验证\n- 有助于模型选择和超参数调整。我们首先需要定义一个函数，在K折交叉验证过程中返回第i折的数据。具体地说，它选择第i个切片作为验证数据，其余部分作为训练数据。每次在K − 1个子集上进行训练，并在剩余的一个子集上进行验证。\n\n\n```python\ndef get_k_fold_data(k, i, X, y):\n    assert k > 1\n    fold_size = X.shape[0] // k\n    X_train, y_train = None, None\n    for j in range(k):\n        idx = slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part = X[idx, :], y[idx]\n        if j ==i:\n            X_valid, y_valid = X_part, y_part\n        elif X_train is None:\n            X_train, y_train = X_part, y_part\n        else:\n            X_train = torch.cat([X_train, X_part], 0)\n            y_train = torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid\n```\n\n- 训练K次，并返回训练和验证误差的平均值\n\n\n```python\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n    train_l_sum, valid_l_sum = 0, 0\n    for i in range(k):\n        data = get_k_fold_data(k, i, X_train, y_train)\n        net = get_net()\n        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n        train_l_sum += train_ls[-1]\n        valid_l_sum += valid_ls[-1]\n        if i == 0:\n            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n                     xlabel='epoch', ylabel='rmse',\n                     legend=['train', 'valid'], yscale='log')\n        print(f'折{i + 1}, 训练log rmse {float(train_ls[-1]):f}, '\n              f'验证log rmse {float(valid_ls[-1]):f}')\n    return train_l_sum / k, valid_l_sum / k\n```\n\n## 10.6 模型选择\n- 使用未调优的超参数\n\n\n```python\nk, num_epochs, lr, weight_decay, batch_size=5, 100, 5, 0, 64\ntrain_l, valid_l= k_fold(k, train_features, train_labels,num_epochs,lr,\n                         weight_decay, batch_size)\nprint(f'{k}-折验证：平均训练log rmse：{float(train_l):f},'\n      f'平均验证log rmse：{float(valid_l):f}')\n```\n\n    折1, 训练log rmse 0.170100, 验证log rmse 0.156652\n    折2, 训练log rmse 0.162041, 验证log rmse 0.188112\n    折3, 训练log rmse 0.163980, 验证log rmse 0.168341\n    折4, 训练log rmse 0.167889, 验证log rmse 0.154215\n    折5, 训练log rmse 0.163577, 验证log rmse 0.183105\n    5-折验证：平均训练log rmse：0.165517,平均验证log rmse：0.170085\n\n  ![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg) \n\n\n![svg](img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg)\n\n​    \n\n\n## 10.7 提交Kaggle预测\n- 使用所有的数据进行训练，将预测保存在csv文件\n\n\n```python\ndef train_and_pred(train_features, test_features, train_labels, test_data,\n                   num_epochs, lr, weight_decay, batch_size):\n    net = get_net()\n    train_ls, _ = train(net, train_features, train_labels, None,None,\n                        num_epochs, lr, weight_decay, batch_size)\n    d2l.plot(np.arange(1, num_epochs+1), [train_ls], xlabel='epoch',\n             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')\n    print(f'训练log rmse:{float(train_ls[-1]):f}')\n    #将网络用于测试集\n    preds = net(test_features).detach().numpy()\n    # 将其重新格式化以导出到kaggle\n    test_data['SalePrice']=pd.Series(preds.reshape(1, -1)[0])\n    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n    submission.to_csv('submission.csv', index=False)\n\ntrain_and_pred(train_features, test_features, train_labels,test_data,\n               num_epochs, lr, weight_decay, batch_size)\n```\n\n    训练log rmse:0.162509\n\n![svg](D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg)\n\n\n![svg](img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg)\n    \n\n","slug":"deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price","published":1,"updated":"2024-03-20T11:18:04.769Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx7k000dusvw79eogoff","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"10-kaggle-预测房价\"><a href=\"#10-kaggle-预测房价\" class=\"headerlink\" title=\"10 kaggle:预测房价\"></a>10 kaggle:预测房价</h1><h2 id=\"10-1-下载和缓存数据集\"><a href=\"#10-1-下载和缓存数据集\" class=\"headerlink\" title=\"10.1 下载和缓存数据集\"></a>10.1 下载和缓存数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> hashlib</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> tarfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> zipfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\">DATA_HUB = <span class=\"built_in\">dict</span>() <span class=\"comment\">#字典，将数据集名称的字符串映射到数据集相关的二元组上，每个二元组包含数据集的url和校验和密钥</span></span><br><span class=\"line\">DATA_URL = <span class=\"string\">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span> <span class=\"comment\">#所有类似的数据集都托管在这个地址上</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download</span>(<span class=\"params\">name, cache_dir=os.path.join(<span class=\"params\"><span class=\"string\">&#x27;data&#x27;</span></span>)</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> name <span class=\"keyword\">in</span> DATA_HUB, <span class=\"string\">f&quot;<span class=\"subst\">&#123;name&#125;</span>不存在于<span class=\"subst\">&#123;DATA_HUB&#125;</span>&quot;</span></span><br><span class=\"line\">    url, sha1_hash = DATA_HUB[name]</span><br><span class=\"line\">    os.makedirs(cache_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    fname = os.path.join(cache_dir, url.split(<span class=\"string\">&#x27;/&#x27;</span>)[-<span class=\"number\">1</span>]) <span class=\"comment\">#取出url中最后一个/后面的字符串，作为文件名</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(fname):</span><br><span class=\"line\">        sha1 = hashlib.sha1()</span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">                data = f.read(<span class=\"number\">1048576</span>) <span class=\"comment\"># 读取1MB数据</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> data:</span><br><span class=\"line\">                    <span class=\"keyword\">break</span></span><br><span class=\"line\">                sha1.update(data)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sha1.hexdigest() == sha1_hash:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> fname <span class=\"comment\">#命中缓存</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;正在从<span class=\"subst\">&#123;url&#125;</span>下载<span class=\"subst\">&#123;fname&#125;</span>...&#x27;</span>)</span><br><span class=\"line\">    r = requests.get(url, stream=<span class=\"literal\">True</span>, verify= <span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        f.write(r.content)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> fname</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_extract</span>(<span class=\"params\">name, folder=<span class=\"literal\">None</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;</span></span><br><span class=\"line\">    fname = download(name)</span><br><span class=\"line\">    base_dir = os.path.dirname(fname)</span><br><span class=\"line\">    data_dir, ext = os.path.splitext(fname)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ext ==<span class=\"string\">&#x27;.zip&#x27;</span>:</span><br><span class=\"line\">        fp = zipfile.ZipFile(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> ext <span class=\"keyword\">in</span> (<span class=\"string\">&#x27;.tar&#x27;</span>, <span class=\"string\">&#x27;.gz&#x27;</span>):</span><br><span class=\"line\">        fp = tarfile.<span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> <span class=\"literal\">False</span>, <span class=\"string\">&#x27;只有zip/tar文件可以被解压缩&#x27;</span></span><br><span class=\"line\">    fp.extractall(base_dir)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> os.path.join(base_dir, folder) <span class=\"keyword\">if</span> folder <span class=\"keyword\">else</span> data_dir</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_all</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> DATA_HUB:</span><br><span class=\"line\">        download(name)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-2-访问和读取数据集\"><a href=\"#10-2-访问和读取数据集\" class=\"headerlink\" title=\"10.2 访问和读取数据集\"></a>10.2 访问和读取数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读入并处理数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>]=( <span class=\"comment\">#@save</span></span><br><span class=\"line\">    DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_train.csv&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)</span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>] = (<span class=\"comment\">#@save</span></span><br><span class=\"line\">    DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_test.csv&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 1. 加载数据集</span></span><br><span class=\"line\">train_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>))</span><br><span class=\"line\">test_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>))</span><br><span class=\"line\"><span class=\"comment\">#输出维度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(test_data.shape)</span><br><span class=\"line\"><span class=\"comment\">#输出前四个特征、最后两个特征、标签</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.iloc[<span class=\"number\">0</span>:<span class=\"number\">4</span>, [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, -<span class=\"number\">3</span>, -<span class=\"number\">2</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\"><span class=\"comment\">#去掉id列</span></span><br><span class=\"line\">all_features = pd.concat((train_data.iloc[:,<span class=\"number\">1</span>:-<span class=\"number\">1</span>], test_data.iloc[:,<span class=\"number\">1</span>:]))</span><br></pre></td></tr></table></figure>\n\n<pre><code>正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载data\\kaggle_house_pred_train.csv...\n正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载data\\kaggle_house_pred_test.csv...\n(1460, 81)\n(1459, 80)\n   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n0   1          60       RL         65.0       WD        Normal     208500\n1   2          20       RL         80.0       WD        Normal     181500\n2   3          60       RL         68.0       WD        Normal     223500\n3   4          70       RL         60.0       WD       Abnorml     140000\n</code></pre>\n<h2 id=\"10-3-数据预处理\"><a href=\"#10-3-数据预处理\" class=\"headerlink\" title=\"10.3 数据预处理\"></a>10.3 数据预处理</h2><ul>\n<li>缺失值用均值代替</li>\n<li>为了将所有特征放到一个共同的尺度上，将特征缩放到均值为0，单位方差：<br>$$x \\leftarrow \\frac{x-\\mu} \\sigma$$</li>\n<li>标准化数据有两个原因：<ul>\n<li>方便优化</li>\n<li>因为我们不知道哪些特征是相关的，所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大</li>\n</ul>\n</li>\n<li>离散值处理：独热编码：如MSZoning列包含值：‘RL’和‘RM’。创建两个新的指标列MSZoning_RL和MSZoning_RM，值为0，1.可以用pandas自动实现</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 2标准化</span></span><br><span class=\"line\">numeric_features = all_features.dtypes[all_features.dtypes != <span class=\"string\">&#x27;object&#x27;</span>].index <span class=\"comment\">#取出数值特征的索引</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class=\"line\">    <span class=\"keyword\">lambda</span> x:(x-x.mean())/ x.std()</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\">#缺失值设为0</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].fillna(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 3离散值处理</span></span><br><span class=\"line\"><span class=\"comment\">#‘dummy_na=True’将缺失值也当作合法的特征值并为其创建指示特征</span></span><br><span class=\"line\">all_features = pd.get_dummies(all_features, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(all_features.shape) <span class=\"comment\">#特征数量从79 -&gt; 331</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 3转换为张量</span></span><br><span class=\"line\">n_train = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">train_features = torch.tensor(all_features[:n_train].values, dtype= torch.float32)</span><br><span class=\"line\">test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)</span><br><span class=\"line\">train_labels = torch.tensor(</span><br><span class=\"line\">    train_data.SalePrice.values.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>), dtype=torch.float32</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<pre><code>(2919, 331)\n</code></pre>\n<h2 id=\"10-4-训练\"><a href=\"#10-4-训练\" class=\"headerlink\" title=\"10.4 训练\"></a>10.4 训练</h2><ul>\n<li>先训练一个带有损失平方的线性模型，线性模型可以提供一种健全性检查，以查看数据中是否存在有意义的信息。如果线性模型不能做得比随机猜测更好，那么可能存在数据处理错误。如果一切顺利，线性模型可以作为基线模型（baseline）</li>\n<li>Adam优化器主要吸引力在于对初始学习率不那么敏感</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss= nn.MSELoss()</span><br><span class=\"line\">in_features = train_features.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_net</span>():</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(in_features,<span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>对于误差，更关心相对误差，例如北京房价预测差了10万与阳新放假预测差了10万是不同的。</li>\n<li>可以用价格预测的对数来衡量差异。将$\\sigma for |log y - log \\hat y|$转换为$e^{-\\sigma} \\leq \\frac{\\hat y}{y} \\leq e^{\\sigma}$这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差：<br>$$\\sqrt{\\frac1n\\sum_{i&#x3D;1}^n\\left(\\log y_i-\\log\\hat{y}_i\\right)^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_rmse</span>(<span class=\"params\">net, features, labels</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span></span><br><span class=\"line\">    clipped_preds = torch.clamp(net(features), <span class=\"number\">1</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;inf&#x27;</span>))</span><br><span class=\"line\">    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> rmse.item()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_features, train_labels, test_features, test_labels,</span></span><br><span class=\"line\"><span class=\"params\">          num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_ls, test_ls = [], []</span><br><span class=\"line\">    train_iter = d2l.load_array((train_features,train_labels),batch_size)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(),</span><br><span class=\"line\">                                lr =learning_rate,</span><br><span class=\"line\">                                weight_decay=weight_decay)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">                optimizer.zero_grad()</span><br><span class=\"line\">                l = loss(net(X), y)</span><br><span class=\"line\">                l.backward()</span><br><span class=\"line\">                optimizer.step()</span><br><span class=\"line\">        train_ls.append(log_rmse(net, train_features,train_labels))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_labels <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                test_ls.append(log_rmse(net, test_features,test_labels))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_ls, test_ls</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-5-K折交叉验证\"><a href=\"#10-5-K折交叉验证\" class=\"headerlink\" title=\"10.5 K折交叉验证\"></a>10.5 K折交叉验证</h2><ul>\n<li>有助于模型选择和超参数调整。我们首先需要定义一个函数，在K折交叉验证过程中返回第i折的数据。具体地说，它选择第i个切片作为验证数据，其余部分作为训练数据。每次在K − 1个子集上进行训练，并在剩余的一个子集上进行验证。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_k_fold_data</span>(<span class=\"params\">k, i, X, y</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> k &gt; <span class=\"number\">1</span></span><br><span class=\"line\">    fold_size = X.shape[<span class=\"number\">0</span>] // k</span><br><span class=\"line\">    X_train, y_train = <span class=\"literal\">None</span>, <span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        idx = <span class=\"built_in\">slice</span>(j * fold_size, (j + <span class=\"number\">1</span>) * fold_size)</span><br><span class=\"line\">        X_part, y_part = X[idx, :], y[idx]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> j ==i:</span><br><span class=\"line\">            X_valid, y_valid = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> X_train <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            X_train, y_train = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            X_train = torch.cat([X_train, X_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">            y_train = torch.cat([y_train, y_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_train, y_train, X_valid, y_valid</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>训练K次，并返回训练和验证误差的平均值</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">k_fold</span>(<span class=\"params\">k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_l_sum, valid_l_sum = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class=\"line\">        net = get_net()</span><br><span class=\"line\">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)</span><br><span class=\"line\">        train_l_sum += train_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        valid_l_sum += valid_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span><br><span class=\"line\">            d2l.plot(<span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">1</span>, num_epochs + <span class=\"number\">1</span>)), [train_ls, valid_ls],</span><br><span class=\"line\">                     xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, ylabel=<span class=\"string\">&#x27;rmse&#x27;</span>,</span><br><span class=\"line\">                     legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;valid&#x27;</span>], yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;折<span class=\"subst\">&#123;i + <span class=\"number\">1</span>&#125;</span>, 训练log rmse <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>, &#x27;</span></span><br><span class=\"line\">              <span class=\"string\">f&#x27;验证log rmse <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_l_sum / k, valid_l_sum / k</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-6-模型选择\"><a href=\"#10-6-模型选择\" class=\"headerlink\" title=\"10.6 模型选择\"></a>10.6 模型选择</h2><ul>\n<li>使用未调优的超参数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">k, num_epochs, lr, weight_decay, batch_size=<span class=\"number\">5</span>, <span class=\"number\">100</span>, <span class=\"number\">5</span>, <span class=\"number\">0</span>, <span class=\"number\">64</span></span><br><span class=\"line\">train_l, valid_l= k_fold(k, train_features, train_labels,num_epochs,lr,</span><br><span class=\"line\">                         weight_decay, batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;k&#125;</span>-折验证：平均训练log rmse：<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l):f&#125;</span>,&#x27;</span></span><br><span class=\"line\">      <span class=\"string\">f&#x27;平均验证log rmse：<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>折1, 训练log rmse 0.170100, 验证log rmse 0.156652\n折2, 训练log rmse 0.162041, 验证log rmse 0.188112\n折3, 训练log rmse 0.163980, 验证log rmse 0.168341\n折4, 训练log rmse 0.167889, 验证log rmse 0.154215\n折5, 训练log rmse 0.163577, 验证log rmse 0.183105\n5-折验证：平均训练log rmse：0.165517,平均验证log rmse：0.170085\n</code></pre>\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg\" alt=\"svg\"> </p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg\" alt=\"svg\"></p>\n<p>​    </p>\n<h2 id=\"10-7-提交Kaggle预测\"><a href=\"#10-7-提交Kaggle预测\" class=\"headerlink\" title=\"10.7 提交Kaggle预测\"></a>10.7 提交Kaggle预测</h2><ul>\n<li>使用所有的数据进行训练，将预测保存在csv文件</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_and_pred</span>(<span class=\"params\">train_features, test_features, train_labels, test_data,</span></span><br><span class=\"line\"><span class=\"params\">                   num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class=\"line\">    net = get_net()</span><br><span class=\"line\">    train_ls, _ = train(net, train_features, train_labels, <span class=\"literal\">None</span>,<span class=\"literal\">None</span>,</span><br><span class=\"line\">                        num_epochs, lr, weight_decay, batch_size)</span><br><span class=\"line\">    d2l.plot(np.arange(<span class=\"number\">1</span>, num_epochs+<span class=\"number\">1</span>), [train_ls], xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>,</span><br><span class=\"line\">             ylabel=<span class=\"string\">&#x27;log rmse&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;训练log rmse:<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#将网络用于测试集</span></span><br><span class=\"line\">    preds = net(test_features).detach().numpy()</span><br><span class=\"line\">    <span class=\"comment\"># 将其重新格式化以导出到kaggle</span></span><br><span class=\"line\">    test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>]=pd.Series(preds.reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\">    submission = pd.concat([test_data[<span class=\"string\">&#x27;Id&#x27;</span>], test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    submission.to_csv(<span class=\"string\">&#x27;submission.csv&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">train_and_pred(train_features, test_features, train_labels,test_data,</span><br><span class=\"line\">               num_epochs, lr, weight_decay, batch_size)</span><br></pre></td></tr></table></figure>\n\n<pre><code>训练log rmse:0.162509\n</code></pre>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg\" alt=\"svg\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"10-kaggle-预测房价\"><a href=\"#10-kaggle-预测房价\" class=\"headerlink\" title=\"10 kaggle:预测房价\"></a>10 kaggle:预测房价</h1><h2 id=\"10-1-下载和缓存数据集\"><a href=\"#10-1-下载和缓存数据集\" class=\"headerlink\" title=\"10.1 下载和缓存数据集\"></a>10.1 下载和缓存数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> hashlib</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> tarfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> zipfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\">DATA_HUB = <span class=\"built_in\">dict</span>() <span class=\"comment\">#字典，将数据集名称的字符串映射到数据集相关的二元组上，每个二元组包含数据集的url和校验和密钥</span></span><br><span class=\"line\">DATA_URL = <span class=\"string\">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span> <span class=\"comment\">#所有类似的数据集都托管在这个地址上</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download</span>(<span class=\"params\">name, cache_dir=os.path.join(<span class=\"params\"><span class=\"string\">&#x27;data&#x27;</span></span>)</span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名。&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> name <span class=\"keyword\">in</span> DATA_HUB, <span class=\"string\">f&quot;<span class=\"subst\">&#123;name&#125;</span>不存在于<span class=\"subst\">&#123;DATA_HUB&#125;</span>&quot;</span></span><br><span class=\"line\">    url, sha1_hash = DATA_HUB[name]</span><br><span class=\"line\">    os.makedirs(cache_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    fname = os.path.join(cache_dir, url.split(<span class=\"string\">&#x27;/&#x27;</span>)[-<span class=\"number\">1</span>]) <span class=\"comment\">#取出url中最后一个/后面的字符串，作为文件名</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(fname):</span><br><span class=\"line\">        sha1 = hashlib.sha1()</span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">                data = f.read(<span class=\"number\">1048576</span>) <span class=\"comment\"># 读取1MB数据</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> data:</span><br><span class=\"line\">                    <span class=\"keyword\">break</span></span><br><span class=\"line\">                sha1.update(data)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sha1.hexdigest() == sha1_hash:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> fname <span class=\"comment\">#命中缓存</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;正在从<span class=\"subst\">&#123;url&#125;</span>下载<span class=\"subst\">&#123;fname&#125;</span>...&#x27;</span>)</span><br><span class=\"line\">    r = requests.get(url, stream=<span class=\"literal\">True</span>, verify= <span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        f.write(r.content)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> fname</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_extract</span>(<span class=\"params\">name, folder=<span class=\"literal\">None</span></span>): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;</span></span><br><span class=\"line\">    fname = download(name)</span><br><span class=\"line\">    base_dir = os.path.dirname(fname)</span><br><span class=\"line\">    data_dir, ext = os.path.splitext(fname)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ext ==<span class=\"string\">&#x27;.zip&#x27;</span>:</span><br><span class=\"line\">        fp = zipfile.ZipFile(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> ext <span class=\"keyword\">in</span> (<span class=\"string\">&#x27;.tar&#x27;</span>, <span class=\"string\">&#x27;.gz&#x27;</span>):</span><br><span class=\"line\">        fp = tarfile.<span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> <span class=\"literal\">False</span>, <span class=\"string\">&#x27;只有zip/tar文件可以被解压缩&#x27;</span></span><br><span class=\"line\">    fp.extractall(base_dir)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> os.path.join(base_dir, folder) <span class=\"keyword\">if</span> folder <span class=\"keyword\">else</span> data_dir</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_all</span>(): <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> DATA_HUB:</span><br><span class=\"line\">        download(name)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-2-访问和读取数据集\"><a href=\"#10-2-访问和读取数据集\" class=\"headerlink\" title=\"10.2 访问和读取数据集\"></a>10.2 访问和读取数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读入并处理数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>]=( <span class=\"comment\">#@save</span></span><br><span class=\"line\">    DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_train.csv&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)</span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>] = (<span class=\"comment\">#@save</span></span><br><span class=\"line\">    DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_test.csv&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 1. 加载数据集</span></span><br><span class=\"line\">train_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>))</span><br><span class=\"line\">test_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>))</span><br><span class=\"line\"><span class=\"comment\">#输出维度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(test_data.shape)</span><br><span class=\"line\"><span class=\"comment\">#输出前四个特征、最后两个特征、标签</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.iloc[<span class=\"number\">0</span>:<span class=\"number\">4</span>, [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, -<span class=\"number\">3</span>, -<span class=\"number\">2</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\"><span class=\"comment\">#去掉id列</span></span><br><span class=\"line\">all_features = pd.concat((train_data.iloc[:,<span class=\"number\">1</span>:-<span class=\"number\">1</span>], test_data.iloc[:,<span class=\"number\">1</span>:]))</span><br></pre></td></tr></table></figure>\n\n<pre><code>正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载data\\kaggle_house_pred_train.csv...\n正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载data\\kaggle_house_pred_test.csv...\n(1460, 81)\n(1459, 80)\n   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n0   1          60       RL         65.0       WD        Normal     208500\n1   2          20       RL         80.0       WD        Normal     181500\n2   3          60       RL         68.0       WD        Normal     223500\n3   4          70       RL         60.0       WD       Abnorml     140000\n</code></pre>\n<h2 id=\"10-3-数据预处理\"><a href=\"#10-3-数据预处理\" class=\"headerlink\" title=\"10.3 数据预处理\"></a>10.3 数据预处理</h2><ul>\n<li>缺失值用均值代替</li>\n<li>为了将所有特征放到一个共同的尺度上，将特征缩放到均值为0，单位方差：<br>$$x \\leftarrow \\frac{x-\\mu} \\sigma$$</li>\n<li>标准化数据有两个原因：<ul>\n<li>方便优化</li>\n<li>因为我们不知道哪些特征是相关的，所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大</li>\n</ul>\n</li>\n<li>离散值处理：独热编码：如MSZoning列包含值：‘RL’和‘RM’。创建两个新的指标列MSZoning_RL和MSZoning_RM，值为0，1.可以用pandas自动实现</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 2标准化</span></span><br><span class=\"line\">numeric_features = all_features.dtypes[all_features.dtypes != <span class=\"string\">&#x27;object&#x27;</span>].index <span class=\"comment\">#取出数值特征的索引</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class=\"line\">    <span class=\"keyword\">lambda</span> x:(x-x.mean())/ x.std()</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\">#缺失值设为0</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].fillna(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 3离散值处理</span></span><br><span class=\"line\"><span class=\"comment\">#‘dummy_na=True’将缺失值也当作合法的特征值并为其创建指示特征</span></span><br><span class=\"line\">all_features = pd.get_dummies(all_features, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(all_features.shape) <span class=\"comment\">#特征数量从79 -&gt; 331</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 3转换为张量</span></span><br><span class=\"line\">n_train = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">train_features = torch.tensor(all_features[:n_train].values, dtype= torch.float32)</span><br><span class=\"line\">test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)</span><br><span class=\"line\">train_labels = torch.tensor(</span><br><span class=\"line\">    train_data.SalePrice.values.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>), dtype=torch.float32</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<pre><code>(2919, 331)\n</code></pre>\n<h2 id=\"10-4-训练\"><a href=\"#10-4-训练\" class=\"headerlink\" title=\"10.4 训练\"></a>10.4 训练</h2><ul>\n<li>先训练一个带有损失平方的线性模型，线性模型可以提供一种健全性检查，以查看数据中是否存在有意义的信息。如果线性模型不能做得比随机猜测更好，那么可能存在数据处理错误。如果一切顺利，线性模型可以作为基线模型（baseline）</li>\n<li>Adam优化器主要吸引力在于对初始学习率不那么敏感</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss= nn.MSELoss()</span><br><span class=\"line\">in_features = train_features.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_net</span>():</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(in_features,<span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>对于误差，更关心相对误差，例如北京房价预测差了10万与阳新放假预测差了10万是不同的。</li>\n<li>可以用价格预测的对数来衡量差异。将$\\sigma for |log y - log \\hat y|$转换为$e^{-\\sigma} \\leq \\frac{\\hat y}{y} \\leq e^{\\sigma}$这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差：<br>$$\\sqrt{\\frac1n\\sum_{i&#x3D;1}^n\\left(\\log y_i-\\log\\hat{y}_i\\right)^2}$$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_rmse</span>(<span class=\"params\">net, features, labels</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span></span><br><span class=\"line\">    clipped_preds = torch.clamp(net(features), <span class=\"number\">1</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;inf&#x27;</span>))</span><br><span class=\"line\">    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> rmse.item()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_features, train_labels, test_features, test_labels,</span></span><br><span class=\"line\"><span class=\"params\">          num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_ls, test_ls = [], []</span><br><span class=\"line\">    train_iter = d2l.load_array((train_features,train_labels),batch_size)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(),</span><br><span class=\"line\">                                lr =learning_rate,</span><br><span class=\"line\">                                weight_decay=weight_decay)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X,y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">                optimizer.zero_grad()</span><br><span class=\"line\">                l = loss(net(X), y)</span><br><span class=\"line\">                l.backward()</span><br><span class=\"line\">                optimizer.step()</span><br><span class=\"line\">        train_ls.append(log_rmse(net, train_features,train_labels))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_labels <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                test_ls.append(log_rmse(net, test_features,test_labels))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_ls, test_ls</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-5-K折交叉验证\"><a href=\"#10-5-K折交叉验证\" class=\"headerlink\" title=\"10.5 K折交叉验证\"></a>10.5 K折交叉验证</h2><ul>\n<li>有助于模型选择和超参数调整。我们首先需要定义一个函数，在K折交叉验证过程中返回第i折的数据。具体地说，它选择第i个切片作为验证数据，其余部分作为训练数据。每次在K − 1个子集上进行训练，并在剩余的一个子集上进行验证。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_k_fold_data</span>(<span class=\"params\">k, i, X, y</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> k &gt; <span class=\"number\">1</span></span><br><span class=\"line\">    fold_size = X.shape[<span class=\"number\">0</span>] // k</span><br><span class=\"line\">    X_train, y_train = <span class=\"literal\">None</span>, <span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        idx = <span class=\"built_in\">slice</span>(j * fold_size, (j + <span class=\"number\">1</span>) * fold_size)</span><br><span class=\"line\">        X_part, y_part = X[idx, :], y[idx]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> j ==i:</span><br><span class=\"line\">            X_valid, y_valid = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> X_train <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            X_train, y_train = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            X_train = torch.cat([X_train, X_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">            y_train = torch.cat([y_train, y_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_train, y_train, X_valid, y_valid</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>训练K次，并返回训练和验证误差的平均值</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.environ[<span class=\"string\">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class=\"string\">&#x27;True&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">k_fold</span>(<span class=\"params\">k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_l_sum, valid_l_sum = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class=\"line\">        net = get_net()</span><br><span class=\"line\">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)</span><br><span class=\"line\">        train_l_sum += train_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        valid_l_sum += valid_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span><br><span class=\"line\">            d2l.plot(<span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">1</span>, num_epochs + <span class=\"number\">1</span>)), [train_ls, valid_ls],</span><br><span class=\"line\">                     xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, ylabel=<span class=\"string\">&#x27;rmse&#x27;</span>,</span><br><span class=\"line\">                     legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;valid&#x27;</span>], yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;折<span class=\"subst\">&#123;i + <span class=\"number\">1</span>&#125;</span>, 训练log rmse <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>, &#x27;</span></span><br><span class=\"line\">              <span class=\"string\">f&#x27;验证log rmse <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_l_sum / k, valid_l_sum / k</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10-6-模型选择\"><a href=\"#10-6-模型选择\" class=\"headerlink\" title=\"10.6 模型选择\"></a>10.6 模型选择</h2><ul>\n<li>使用未调优的超参数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">k, num_epochs, lr, weight_decay, batch_size=<span class=\"number\">5</span>, <span class=\"number\">100</span>, <span class=\"number\">5</span>, <span class=\"number\">0</span>, <span class=\"number\">64</span></span><br><span class=\"line\">train_l, valid_l= k_fold(k, train_features, train_labels,num_epochs,lr,</span><br><span class=\"line\">                         weight_decay, batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;k&#125;</span>-折验证：平均训练log rmse：<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l):f&#125;</span>,&#x27;</span></span><br><span class=\"line\">      <span class=\"string\">f&#x27;平均验证log rmse：<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>折1, 训练log rmse 0.170100, 验证log rmse 0.156652\n折2, 训练log rmse 0.162041, 验证log rmse 0.188112\n折3, 训练log rmse 0.163980, 验证log rmse 0.168341\n折4, 训练log rmse 0.167889, 验证log rmse 0.154215\n折5, 训练log rmse 0.163577, 验证log rmse 0.183105\n5-折验证：平均训练log rmse：0.165517,平均验证log rmse：0.170085\n</code></pre>\n<p>  <img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg\" alt=\"svg\"> </p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_15_1.svg\" alt=\"svg\"></p>\n<p>​    </p>\n<h2 id=\"10-7-提交Kaggle预测\"><a href=\"#10-7-提交Kaggle预测\" class=\"headerlink\" title=\"10.7 提交Kaggle预测\"></a>10.7 提交Kaggle预测</h2><ul>\n<li>使用所有的数据进行训练，将预测保存在csv文件</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_and_pred</span>(<span class=\"params\">train_features, test_features, train_labels, test_data,</span></span><br><span class=\"line\"><span class=\"params\">                   num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class=\"line\">    net = get_net()</span><br><span class=\"line\">    train_ls, _ = train(net, train_features, train_labels, <span class=\"literal\">None</span>,<span class=\"literal\">None</span>,</span><br><span class=\"line\">                        num_epochs, lr, weight_decay, batch_size)</span><br><span class=\"line\">    d2l.plot(np.arange(<span class=\"number\">1</span>, num_epochs+<span class=\"number\">1</span>), [train_ls], xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>,</span><br><span class=\"line\">             ylabel=<span class=\"string\">&#x27;log rmse&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs], yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;训练log rmse:<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#将网络用于测试集</span></span><br><span class=\"line\">    preds = net(test_features).detach().numpy()</span><br><span class=\"line\">    <span class=\"comment\"># 将其重新格式化以导出到kaggle</span></span><br><span class=\"line\">    test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>]=pd.Series(preds.reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\">    submission = pd.concat([test_data[<span class=\"string\">&#x27;Id&#x27;</span>], test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    submission.to_csv(<span class=\"string\">&#x27;submission.csv&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">train_and_pred(train_features, test_features, train_labels,test_data,</span><br><span class=\"line\">               num_epochs, lr, weight_decay, batch_size)</span><br></pre></td></tr></table></figure>\n\n<pre><code>训练log rmse:0.162509\n</code></pre>\n<p><img src=\"D:/blog/themes/yilia/source/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg\" alt=\"svg\"></p>\n<p><img src=\"/img/deeplearning/code/pytorch/3_mlp/10_kaggle_predict_price_files/10_kaggle_predict_price_17_1.svg\" alt=\"svg\"></p>"},{"title":"3.9 环境和分布偏移","date":"2024-03-17T06:00:00.000Z","comment":true,"toc":true,"_content":"#\n<!--more-->\n# 9 环境和分布偏移\n- （不好懂，建议跳过这一节）\n- 在不同的应用场景模型决策方案会出现漏洞\n## 9.1 分布偏移的类型\n- 考虑一个二元分类问题：区分狗和猫。如果分布可以以任意方式偏移，那么我们的情景允许病态的情况，即输入的分布保持不变：$p_S(x) = p_T (x)$，但标签全部翻转：$p_S(y|x) = 1 − p_T (y|x)$。\n### 9.1.1 协变量偏移\n- 虽然输入的分布可能随时间而改变，但标签函数（即条件分布P(y | x)）没有改变。统计学家称之为协变量偏移（covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。\n- 比如用真的猫狗图像做训练，卡通猫狗做测试。\n### 9.1.2 标签偏移\n- 与协变量偏移相反。假设标签边缘概率P(y)可以改变，但是类别条件分布P(x | y)在不同的领域之间保持不变。当我们认为y导致x时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。\n- 在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使y导致x，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。\n### 9.1.3 概念偏移\n- 当标签的定义发生变化时，就会出现这种问题。\n- 如果我们要建立一个机器翻译系统，P(y | x)的分布可能会因我们的位置不同而得到不同的翻译。这个问题可能很难被发现。所以，我们最好可以利用在时间或空间上逐渐发生偏移的知识。\n## 9.2 分布偏移示例\n### 9.2.1 医学诊断\n- 假设我们想设计一个检测癌症的算法，从健康人和病人那里收集数据，然后训练算法。收集训练数据的分布和在实际中遇到的数据分布可能有很大的不同。用近乎完美的精度来区分健康和患病人群确实很容易。然而，这可能是因为受试者在年龄、激素水平、体力活动、饮食、饮酒以及其他许多与疾病无关的因素上存在差异。这对检测疾病的分类器可能并不适用。这些抽样可能会遇到极端的协变量偏移。此外，这种情况不太可能通过常规方法加以纠正。\n### 9.2.2 自动驾驶汽车\n- 对于一家想利用机器学习来开发自动驾驶汽车的公司，一个关键部件是“路沿检测器”。由于真实的注释数据获取成本很高，他们想出了一个“聪明”的想法：将游戏渲染引擎中的合成数据用作额外的训练数据。这对从渲染引擎中抽取的“测试数据”非常有效，但应用在一辆真正的汽车里真是一场灾难。正如事实证明的那样，路沿被渲染成一种非常简单的纹理。更重要的是，所有的路沿都被渲染成了相同的纹理，路沿检测器很快就学习到了这个“特征”。\n- 当美军第一次试图在森林中探测坦克时，也发生了类似的事情。他们在没有坦克的情况下拍摄了森林的航拍照片，然后把坦克开进森林，拍摄了另一组照片。使用这两组数据训练的分类器似乎工作得很好。不幸的是，分类器仅仅学会了如何区分有阴影的树和没有阴影的树：第一组照片是在清晨拍摄的，而第二组是在中午拍摄的。\n### 9.2.3 非平稳分布\n- 当分布变化缓慢并且模型没有得到充分更新时，就会出现更微妙的情况：非平稳分布（nonstationary distri‐bution）\n    - 训练一个计算广告模型，但却没有经常更新（例如，一个2009年训练的模型不知道一个叫iPad的不知名新设备刚刚上市）；\n    - 建立一个垃圾邮件过滤器，它能很好地检测到所有垃圾邮件。但是，垃圾邮件发送者们变得聪明起来，制造出新的信息，看起来不像我们以前见过的任何垃圾邮件；\n    - 建立一个产品推荐系统，它在整个冬天都有效，但圣诞节过后很久还会继续推荐圣诞帽。\n\n## 9.3 分布偏移纠正\n- 通过一些策略应对分布偏移\n### 9.3.1 经验风险与实际风险\n- 不考虑正则化，训练损失为：$\\operatorname*{minimize}_f\\frac1n\\sum_{i=1}^nl(f(\\mathbf{x}_i),y_i)$，也称经验风险，其中$l$是损失函数。\n- 经验风险是为了近似真实风险：整个训练数据上的平均损失，即从真实分布$p(x,y)$中抽取的所有数据的总体损失的期望值：\n    $$E_{p(\\mathbf{x},y)}[l(f(\\mathbf{x}),y)]=\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x},y)~d\\mathbf{x}dy$$\n    然而，我们通常无法获得总体数据。\n\n### 9.3.2 协变量偏移纠正\n- 假设对于带标签的数据(xi, yi)，我们要评估P(y | x)。然而观测值xi是从某些源分布q(x)中得出的，而不是从目标分布p(x)中得出的。幸运的是，依赖性假设意味着条件分布保持不变，即：p(y | x) = q(y | x)。如果源分布q(x)是“错误的”，我们可以通过在真实风险的计算中，使用以下简单的恒等式来进行纠正：\n$$\\begin{aligned}\\int\\int l(f(\\mathbf{x}),y)p(y\\mid\\mathbf{x})p(\\mathbf{x})d\\mathbf{x}dy&=\\int\\int l(f(\\mathbf{x}),y)q(y\\mid\\mathbf{x})q(\\mathbf{x})\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}d\\mathbf{x}dy\\end{aligned}$$\n- 因此我们需要根据数据来自正确分布与来自错误分布的概率之比，来重新衡量每个数据样本的权重：\n$$\\beta_i\\stackrel{\\mathrm{def}}{=}\\frac{p(\\mathbf{x}_i)}{q(\\mathbf{x}_i)}$$\n- 将权重带入每个数据样本，得到目标函数：加权经验风险最小化\n$$\\min_f\\text{mize }\\frac1n\\sum_{i=1}^n\\beta_il(f(\\mathbf{x}_i),y_i)$$\n- 由于不知道这个比率，我们需要估计它。需要从两个分布中抽取样本：“真实”的分布p，通过访问测试数据获取；训练集q，通过人工合成的很容易获得。我们只需要特征x ∼ p(x)，不需要访问标签y ∼ p(y)。\n- 一种非常有效的方法：对数几率回归，这是用于二元分类的softmax回归的一个特例。我们学习了一个分类器来区分从p(x)抽取的数据和从q(x)抽取的数据。如果无法区分这两个分布，则意味着相关的样本可能来自这两个分布中的任何一个。另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。\n- 假设我们分别从p(x)和q(x) 两个分布中抽取相同数量的样本。现在用z标签表示：从p抽取的数据为1，从q抽取的数据为−1。然后，混合数据集中的概率由下式给出\n$$P(z=1\\mid\\mathbf{x})=\\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})}\\text{ and hence }\\frac{P(z=1\\mid\\mathbf{x})}{P(z=-1\\mid\\mathbf{x})}=\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}$$\n- 因此，如果我们使用对数几率回归方法，其中$P(z=1\\mid\\mathbf{x})=\\frac{1}{1+\\exp(-h(\\mathbf{x}))}$（h是一个参数化函数），则（？？？）\n$$\\beta_i=\\frac{1/(1+\\exp(-h(\\mathbf{x}_i)))}{\\exp(-h(\\mathbf{x}_i))/(1+\\exp(-h(\\mathbf{x}_i)))}=\\exp(h(\\mathbf{x}_i))$$\n- 因此，我们需要解决两个问题：第一个问题是关于区分来自两个分布的数据；第二个问题是关于 (4.9.5) 中的\n加权经验风险的最小化问题。\n- 假设我们有一个训练集{$(x_1,y_1),···，(x_n,y_n)$}和一个未标记的测试集{$u_1,···,u_m$}.假设1 $\\leq$ i $\\leq$ n的$x_i$来自某个源分布，$u_i$来自目标分布。纠正协变量偏移的典型算法：\n    1. 生成一个二元分类训练集：{$(x_1,-1),···,(x_n,-1),(u_1,1),···,(u_m,1)$}\n    2. 用对数几率回归训练二元分类器得到函数h。\n    3. 使用$\\beta_i = exp(h(x_i))$或更好的$\\beta_i = min(exp(h(x_i)),c)$(c为常量)对训练数据进行加权。\n    4. 使用权重$\\beta_i$进行加权经验风险最小化的训练。\n- 上述算法依赖于一个重要的假设：需要目标分布(例如，测试分布)中的每个数据样本在训练时出现的概率非零。如果我们找到p(x) > 0但q(x) = 0的点，那么相应的重要性权重会是无穷大。\n### 9.3.3 标签偏移纠正\n- 假设标签的分布随时间变化：q(y) ̸= p(y)，但类别条件分布保持不变：q(x | y) = p(x | y)。如果源分布q(y)是“错误的”，我们可以根据真实风险的定义进行更正：\n$$\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x}\\mid y)p(y)d\\mathbf{x}dy=\\int\\int l(f(\\mathbf{x}),y)q(\\mathbf{x}\\mid y)q(y)\\frac{p(y)}{q(y)}d\\mathbf{x}dy$$\n- 重要性权重应用于标签似然比率：\n$$\\beta_i\\stackrel{\\mathrm{def}}{=}\\frac{p(y_i)}{q(y_i)}$$\n- 为了估计目标标签分布，我们首先采用性能相当好的现成的分类器（通常基于训练数据进行训练），并使用验证集（也来自训练分布）计算其混淆矩阵。混淆矩阵C是一个k × k矩阵，其中每列对应于标签类别，每行对应于模型的预测类别。每个单元格的值cij是验证集中，真实标签为j，而我们的模型预测为i的样本数量所占的比例。\n- 我们不能直接计算目标数据上的混淆矩阵，因为我们无法看到真实环境下的样本的标签，除非我们再搭建一个复杂的实时标注流程。然而，我们所能做的是将所有模型在测试时的预测取平均数，得到平均模型输出$\\mu(\\hat{\\mathbf{y}})\\in\\mathbb{R}^k$，其中第i个元素$\\mu(\\hat y_i)$是我们模型预测测试集中i的总预测分数。\n- 如果我们的分类器一开始就相当准确，并且目标数据只包含我们以前见过的类别，以及如果标签偏移假设成立（这里最强的假设），我们就可以通过求解一个简单的线性系统来估计测试集的标签分布\n$$\\mathbf{C}p(\\mathbf{y})=\\mu(\\hat{\\mathbf{y}})$$\n- 因为作为一个估计，$\\begin{aligned}\\sum_{j=1}^kc_{ij}p(y_j)=\\mu(\\hat{y}_i)\\end{aligned}$对所有$1\\leq i \\leq k$成立，其中$p(y_i)$是k维标签分布向量p(y)的第$j^{th}$元素。如果我们的分类器一开始就足够精确，那么混淆矩阵$\\mathbf C$将是可逆的，进而我们可以得到一个解$p(y)=\\mathbf C^{-1}\\mu(\\hat y)$因为我们观测源数据上的标签，所以很容易估计分布q(y)。那么对于标签为yi的任何训练样本i，我们可以使用我们估计的p(yi)/q(yi)比率来计算权重$\\beta_i$，并将其代入加权经验风险最小化中。\n### 9.3.4 概念偏移纠正\n- 概念偏移很难用原则性的方式解决。例如，在一个问题突然从“区分猫和狗”偏移为“区分白色和黑色动物”的情况下，除了从零开始收集新标签和训练，别无妙方。幸运的是，在实践中这种极端的偏移是罕见的。相反，通常情况下，概念的变化总是缓慢的。比如下面是一些例子：\n    - 在计算广告中，新产品推出后，旧产品变得不那么受欢迎了。这意味着广告的分布和受欢迎程度是逐渐\n    变化的，任何点击率预测器都需要随之逐渐变化；\n    - 由于环境的磨损，交通摄像头的镜头会逐渐退化，影响摄像头的图像质量；\n    - 新闻内容逐渐变化（即新新闻的出现）。\n- 在这种情况下，我们可以使用与训练网络相同的方法，使其适应数据的变化。换言之，我们使用新数据更新现有的网络权重，而不是从头开始训练。\n## 9.4 学习问题的分类法\n\n### 9.4.1 批量学习\n- 在批量学习（batch learning）中，我们可以访问一组训练特征和标签 {(x1, y1), . . . ,(xn, yn)}，我们使用这些特性和标签训练f(x)。然后，我们部署此模型来对来自同一分布的新数据(x, y)进行评分。例如，我们可以根据猫和狗的大量图片训练猫检测器。一旦我们训练了它，我们就把它作为智能猫门计算视觉系统的一部分，来控制只允许猫进入。然后这个系统会被安装在客户家中，基本再也不会更新。\n\n### 9.4.2 在线学习\n- 除了“批量”地学习，我们还可以单个“在线”学习数据(xi, yi)。更具体地说，我们首先观测到xi，然后我们得出一个估计值f(xi)，只有当我们做到这一点后，我们才观测到yi。然后根据我们的决定，我们会得到奖励或损失。许多实际问题都属于这一类。例如，我们需要预测明天的股票价格，这样我们就可以根据这个预测进行交易。在一天结束时，我们会评估我们的预测是否盈利。换句话说，在在线学习（online learning）中，我们有以下的循环。在这个循环中，给定新的观测结果，我们会不断地改进我们的模型。\n$$\\text{model }f_t\\longrightarrow\\text{data }\\mathbf{x}_t\\longrightarrow\\text{estimate }f_t(\\mathbf{x}_t)\\longrightarrow\\text{observation }y_t\\longrightarrow\\text{loss }l(y_t,f_t(\\mathbf{x}_t))\\longrightarrow\\text{model }f_{t+1}$$\n\n### 9.4.3 老虎机\n- 老虎机（bandits）是上述问题的一个特例。虽然在大多数学习问题中，我们有一个连续参数化的函数f（例如，一个深度网络）。但在一个老虎机问题中，我们只有有限数量的手臂可以拉动。也就是说，我们可以采取的行动是有限的。对于这个更简单的问题，可以获得更强的最优性理论保证，这并不令人惊讶。我们之所以列出它，主要是因为这个问题经常被视为一个单独的学习问题的情景。\n### 9.4.4 控制\n- 在很多情况下，环境会记住我们所做的事。不一定是以一种对抗的方式，但它会记住，而且它的反应将取决于之前发生的事情。例如，咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度。在这种情况下，PID（比例—积分—微分）控制器算法是一个流行的选择。同样，一个用户在新闻网站上的行为将取决于之前向她展示的内容（例如，大多数新闻她只阅读一次）。许多这样的算法形成了一个环境模型，在这个模型中，他们的行为使得他们的决策看起来不那么随机。近年来，控制理论（如PID的变体）也被用于自动调整超参数，以\n获得更好的解构和重建质量，提高生成文本的多样性和生成图像的重建质量。\n### 9.4.5 强化学习\n- 强化学习（reinforcement learning）强调如何基于环境而行动，以取得最大化的预期利益。国际象棋、围棋、西洋双陆棋或星际争霸都是强化学习的应用实例。再比如，为自动驾驶汽车制造一个控制器，或者以其他方式对自动驾驶汽车的驾驶方式做出反应（例如，试图避开某物体，试图造成事故，或者试图与其合作）。\n### 9.4.6 考虑到环境\n- 上述不同情况之间的一个关键区别是：在静止环境中可能一直有效的相同策略，在环境能够改变的情况下可能不会始终有效。例如，一个交易者发现的套利机会很可能在他开始利用它时就消失了。环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型。例如，如果我们知道事情只会缓慢地变化，就可以迫使任何估计也只能缓慢地发生改变。如果我们知道环境可能会瞬间发生变化，但这种变化非常罕见，我们就可以在使用算法时考虑到这一点。当一个数据科学家试图解决的问题会随着时间的推移而发生变化时，这些类\n型的知识至关重要。\n\n","source":"_posts/deeplearning/code/pytorch/3_mlp/9_distribution_shift.md","raw":"---\ntitle: 3.9 环境和分布偏移\ndate: 2024-3-17 14:00:00\ntags: [机器学习,pytorch]\ncategories: [机器学习]\ncomment: true\ntoc: true\n---\n#\n<!--more-->\n# 9 环境和分布偏移\n- （不好懂，建议跳过这一节）\n- 在不同的应用场景模型决策方案会出现漏洞\n## 9.1 分布偏移的类型\n- 考虑一个二元分类问题：区分狗和猫。如果分布可以以任意方式偏移，那么我们的情景允许病态的情况，即输入的分布保持不变：$p_S(x) = p_T (x)$，但标签全部翻转：$p_S(y|x) = 1 − p_T (y|x)$。\n### 9.1.1 协变量偏移\n- 虽然输入的分布可能随时间而改变，但标签函数（即条件分布P(y | x)）没有改变。统计学家称之为协变量偏移（covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。\n- 比如用真的猫狗图像做训练，卡通猫狗做测试。\n### 9.1.2 标签偏移\n- 与协变量偏移相反。假设标签边缘概率P(y)可以改变，但是类别条件分布P(x | y)在不同的领域之间保持不变。当我们认为y导致x时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。\n- 在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使y导致x，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。\n### 9.1.3 概念偏移\n- 当标签的定义发生变化时，就会出现这种问题。\n- 如果我们要建立一个机器翻译系统，P(y | x)的分布可能会因我们的位置不同而得到不同的翻译。这个问题可能很难被发现。所以，我们最好可以利用在时间或空间上逐渐发生偏移的知识。\n## 9.2 分布偏移示例\n### 9.2.1 医学诊断\n- 假设我们想设计一个检测癌症的算法，从健康人和病人那里收集数据，然后训练算法。收集训练数据的分布和在实际中遇到的数据分布可能有很大的不同。用近乎完美的精度来区分健康和患病人群确实很容易。然而，这可能是因为受试者在年龄、激素水平、体力活动、饮食、饮酒以及其他许多与疾病无关的因素上存在差异。这对检测疾病的分类器可能并不适用。这些抽样可能会遇到极端的协变量偏移。此外，这种情况不太可能通过常规方法加以纠正。\n### 9.2.2 自动驾驶汽车\n- 对于一家想利用机器学习来开发自动驾驶汽车的公司，一个关键部件是“路沿检测器”。由于真实的注释数据获取成本很高，他们想出了一个“聪明”的想法：将游戏渲染引擎中的合成数据用作额外的训练数据。这对从渲染引擎中抽取的“测试数据”非常有效，但应用在一辆真正的汽车里真是一场灾难。正如事实证明的那样，路沿被渲染成一种非常简单的纹理。更重要的是，所有的路沿都被渲染成了相同的纹理，路沿检测器很快就学习到了这个“特征”。\n- 当美军第一次试图在森林中探测坦克时，也发生了类似的事情。他们在没有坦克的情况下拍摄了森林的航拍照片，然后把坦克开进森林，拍摄了另一组照片。使用这两组数据训练的分类器似乎工作得很好。不幸的是，分类器仅仅学会了如何区分有阴影的树和没有阴影的树：第一组照片是在清晨拍摄的，而第二组是在中午拍摄的。\n### 9.2.3 非平稳分布\n- 当分布变化缓慢并且模型没有得到充分更新时，就会出现更微妙的情况：非平稳分布（nonstationary distri‐bution）\n    - 训练一个计算广告模型，但却没有经常更新（例如，一个2009年训练的模型不知道一个叫iPad的不知名新设备刚刚上市）；\n    - 建立一个垃圾邮件过滤器，它能很好地检测到所有垃圾邮件。但是，垃圾邮件发送者们变得聪明起来，制造出新的信息，看起来不像我们以前见过的任何垃圾邮件；\n    - 建立一个产品推荐系统，它在整个冬天都有效，但圣诞节过后很久还会继续推荐圣诞帽。\n\n## 9.3 分布偏移纠正\n- 通过一些策略应对分布偏移\n### 9.3.1 经验风险与实际风险\n- 不考虑正则化，训练损失为：$\\operatorname*{minimize}_f\\frac1n\\sum_{i=1}^nl(f(\\mathbf{x}_i),y_i)$，也称经验风险，其中$l$是损失函数。\n- 经验风险是为了近似真实风险：整个训练数据上的平均损失，即从真实分布$p(x,y)$中抽取的所有数据的总体损失的期望值：\n    $$E_{p(\\mathbf{x},y)}[l(f(\\mathbf{x}),y)]=\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x},y)~d\\mathbf{x}dy$$\n    然而，我们通常无法获得总体数据。\n\n### 9.3.2 协变量偏移纠正\n- 假设对于带标签的数据(xi, yi)，我们要评估P(y | x)。然而观测值xi是从某些源分布q(x)中得出的，而不是从目标分布p(x)中得出的。幸运的是，依赖性假设意味着条件分布保持不变，即：p(y | x) = q(y | x)。如果源分布q(x)是“错误的”，我们可以通过在真实风险的计算中，使用以下简单的恒等式来进行纠正：\n$$\\begin{aligned}\\int\\int l(f(\\mathbf{x}),y)p(y\\mid\\mathbf{x})p(\\mathbf{x})d\\mathbf{x}dy&=\\int\\int l(f(\\mathbf{x}),y)q(y\\mid\\mathbf{x})q(\\mathbf{x})\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}d\\mathbf{x}dy\\end{aligned}$$\n- 因此我们需要根据数据来自正确分布与来自错误分布的概率之比，来重新衡量每个数据样本的权重：\n$$\\beta_i\\stackrel{\\mathrm{def}}{=}\\frac{p(\\mathbf{x}_i)}{q(\\mathbf{x}_i)}$$\n- 将权重带入每个数据样本，得到目标函数：加权经验风险最小化\n$$\\min_f\\text{mize }\\frac1n\\sum_{i=1}^n\\beta_il(f(\\mathbf{x}_i),y_i)$$\n- 由于不知道这个比率，我们需要估计它。需要从两个分布中抽取样本：“真实”的分布p，通过访问测试数据获取；训练集q，通过人工合成的很容易获得。我们只需要特征x ∼ p(x)，不需要访问标签y ∼ p(y)。\n- 一种非常有效的方法：对数几率回归，这是用于二元分类的softmax回归的一个特例。我们学习了一个分类器来区分从p(x)抽取的数据和从q(x)抽取的数据。如果无法区分这两个分布，则意味着相关的样本可能来自这两个分布中的任何一个。另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。\n- 假设我们分别从p(x)和q(x) 两个分布中抽取相同数量的样本。现在用z标签表示：从p抽取的数据为1，从q抽取的数据为−1。然后，混合数据集中的概率由下式给出\n$$P(z=1\\mid\\mathbf{x})=\\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})}\\text{ and hence }\\frac{P(z=1\\mid\\mathbf{x})}{P(z=-1\\mid\\mathbf{x})}=\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}$$\n- 因此，如果我们使用对数几率回归方法，其中$P(z=1\\mid\\mathbf{x})=\\frac{1}{1+\\exp(-h(\\mathbf{x}))}$（h是一个参数化函数），则（？？？）\n$$\\beta_i=\\frac{1/(1+\\exp(-h(\\mathbf{x}_i)))}{\\exp(-h(\\mathbf{x}_i))/(1+\\exp(-h(\\mathbf{x}_i)))}=\\exp(h(\\mathbf{x}_i))$$\n- 因此，我们需要解决两个问题：第一个问题是关于区分来自两个分布的数据；第二个问题是关于 (4.9.5) 中的\n加权经验风险的最小化问题。\n- 假设我们有一个训练集{$(x_1,y_1),···，(x_n,y_n)$}和一个未标记的测试集{$u_1,···,u_m$}.假设1 $\\leq$ i $\\leq$ n的$x_i$来自某个源分布，$u_i$来自目标分布。纠正协变量偏移的典型算法：\n    1. 生成一个二元分类训练集：{$(x_1,-1),···,(x_n,-1),(u_1,1),···,(u_m,1)$}\n    2. 用对数几率回归训练二元分类器得到函数h。\n    3. 使用$\\beta_i = exp(h(x_i))$或更好的$\\beta_i = min(exp(h(x_i)),c)$(c为常量)对训练数据进行加权。\n    4. 使用权重$\\beta_i$进行加权经验风险最小化的训练。\n- 上述算法依赖于一个重要的假设：需要目标分布(例如，测试分布)中的每个数据样本在训练时出现的概率非零。如果我们找到p(x) > 0但q(x) = 0的点，那么相应的重要性权重会是无穷大。\n### 9.3.3 标签偏移纠正\n- 假设标签的分布随时间变化：q(y) ̸= p(y)，但类别条件分布保持不变：q(x | y) = p(x | y)。如果源分布q(y)是“错误的”，我们可以根据真实风险的定义进行更正：\n$$\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x}\\mid y)p(y)d\\mathbf{x}dy=\\int\\int l(f(\\mathbf{x}),y)q(\\mathbf{x}\\mid y)q(y)\\frac{p(y)}{q(y)}d\\mathbf{x}dy$$\n- 重要性权重应用于标签似然比率：\n$$\\beta_i\\stackrel{\\mathrm{def}}{=}\\frac{p(y_i)}{q(y_i)}$$\n- 为了估计目标标签分布，我们首先采用性能相当好的现成的分类器（通常基于训练数据进行训练），并使用验证集（也来自训练分布）计算其混淆矩阵。混淆矩阵C是一个k × k矩阵，其中每列对应于标签类别，每行对应于模型的预测类别。每个单元格的值cij是验证集中，真实标签为j，而我们的模型预测为i的样本数量所占的比例。\n- 我们不能直接计算目标数据上的混淆矩阵，因为我们无法看到真实环境下的样本的标签，除非我们再搭建一个复杂的实时标注流程。然而，我们所能做的是将所有模型在测试时的预测取平均数，得到平均模型输出$\\mu(\\hat{\\mathbf{y}})\\in\\mathbb{R}^k$，其中第i个元素$\\mu(\\hat y_i)$是我们模型预测测试集中i的总预测分数。\n- 如果我们的分类器一开始就相当准确，并且目标数据只包含我们以前见过的类别，以及如果标签偏移假设成立（这里最强的假设），我们就可以通过求解一个简单的线性系统来估计测试集的标签分布\n$$\\mathbf{C}p(\\mathbf{y})=\\mu(\\hat{\\mathbf{y}})$$\n- 因为作为一个估计，$\\begin{aligned}\\sum_{j=1}^kc_{ij}p(y_j)=\\mu(\\hat{y}_i)\\end{aligned}$对所有$1\\leq i \\leq k$成立，其中$p(y_i)$是k维标签分布向量p(y)的第$j^{th}$元素。如果我们的分类器一开始就足够精确，那么混淆矩阵$\\mathbf C$将是可逆的，进而我们可以得到一个解$p(y)=\\mathbf C^{-1}\\mu(\\hat y)$因为我们观测源数据上的标签，所以很容易估计分布q(y)。那么对于标签为yi的任何训练样本i，我们可以使用我们估计的p(yi)/q(yi)比率来计算权重$\\beta_i$，并将其代入加权经验风险最小化中。\n### 9.3.4 概念偏移纠正\n- 概念偏移很难用原则性的方式解决。例如，在一个问题突然从“区分猫和狗”偏移为“区分白色和黑色动物”的情况下，除了从零开始收集新标签和训练，别无妙方。幸运的是，在实践中这种极端的偏移是罕见的。相反，通常情况下，概念的变化总是缓慢的。比如下面是一些例子：\n    - 在计算广告中，新产品推出后，旧产品变得不那么受欢迎了。这意味着广告的分布和受欢迎程度是逐渐\n    变化的，任何点击率预测器都需要随之逐渐变化；\n    - 由于环境的磨损，交通摄像头的镜头会逐渐退化，影响摄像头的图像质量；\n    - 新闻内容逐渐变化（即新新闻的出现）。\n- 在这种情况下，我们可以使用与训练网络相同的方法，使其适应数据的变化。换言之，我们使用新数据更新现有的网络权重，而不是从头开始训练。\n## 9.4 学习问题的分类法\n\n### 9.4.1 批量学习\n- 在批量学习（batch learning）中，我们可以访问一组训练特征和标签 {(x1, y1), . . . ,(xn, yn)}，我们使用这些特性和标签训练f(x)。然后，我们部署此模型来对来自同一分布的新数据(x, y)进行评分。例如，我们可以根据猫和狗的大量图片训练猫检测器。一旦我们训练了它，我们就把它作为智能猫门计算视觉系统的一部分，来控制只允许猫进入。然后这个系统会被安装在客户家中，基本再也不会更新。\n\n### 9.4.2 在线学习\n- 除了“批量”地学习，我们还可以单个“在线”学习数据(xi, yi)。更具体地说，我们首先观测到xi，然后我们得出一个估计值f(xi)，只有当我们做到这一点后，我们才观测到yi。然后根据我们的决定，我们会得到奖励或损失。许多实际问题都属于这一类。例如，我们需要预测明天的股票价格，这样我们就可以根据这个预测进行交易。在一天结束时，我们会评估我们的预测是否盈利。换句话说，在在线学习（online learning）中，我们有以下的循环。在这个循环中，给定新的观测结果，我们会不断地改进我们的模型。\n$$\\text{model }f_t\\longrightarrow\\text{data }\\mathbf{x}_t\\longrightarrow\\text{estimate }f_t(\\mathbf{x}_t)\\longrightarrow\\text{observation }y_t\\longrightarrow\\text{loss }l(y_t,f_t(\\mathbf{x}_t))\\longrightarrow\\text{model }f_{t+1}$$\n\n### 9.4.3 老虎机\n- 老虎机（bandits）是上述问题的一个特例。虽然在大多数学习问题中，我们有一个连续参数化的函数f（例如，一个深度网络）。但在一个老虎机问题中，我们只有有限数量的手臂可以拉动。也就是说，我们可以采取的行动是有限的。对于这个更简单的问题，可以获得更强的最优性理论保证，这并不令人惊讶。我们之所以列出它，主要是因为这个问题经常被视为一个单独的学习问题的情景。\n### 9.4.4 控制\n- 在很多情况下，环境会记住我们所做的事。不一定是以一种对抗的方式，但它会记住，而且它的反应将取决于之前发生的事情。例如，咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度。在这种情况下，PID（比例—积分—微分）控制器算法是一个流行的选择。同样，一个用户在新闻网站上的行为将取决于之前向她展示的内容（例如，大多数新闻她只阅读一次）。许多这样的算法形成了一个环境模型，在这个模型中，他们的行为使得他们的决策看起来不那么随机。近年来，控制理论（如PID的变体）也被用于自动调整超参数，以\n获得更好的解构和重建质量，提高生成文本的多样性和生成图像的重建质量。\n### 9.4.5 强化学习\n- 强化学习（reinforcement learning）强调如何基于环境而行动，以取得最大化的预期利益。国际象棋、围棋、西洋双陆棋或星际争霸都是强化学习的应用实例。再比如，为自动驾驶汽车制造一个控制器，或者以其他方式对自动驾驶汽车的驾驶方式做出反应（例如，试图避开某物体，试图造成事故，或者试图与其合作）。\n### 9.4.6 考虑到环境\n- 上述不同情况之间的一个关键区别是：在静止环境中可能一直有效的相同策略，在环境能够改变的情况下可能不会始终有效。例如，一个交易者发现的套利机会很可能在他开始利用它时就消失了。环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型。例如，如果我们知道事情只会缓慢地变化，就可以迫使任何估计也只能缓慢地发生改变。如果我们知道环境可能会瞬间发生变化，但这种变化非常罕见，我们就可以在使用算法时考虑到这一点。当一个数据科学家试图解决的问题会随着时间的推移而发生变化时，这些类\n型的知识至关重要。\n\n","slug":"deeplearning/code/pytorch/3_mlp/9_distribution_shift","published":1,"updated":"2024-03-19T13:24:11.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv5ccx7t000lusvw4b8rg2vk","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n<h1 id=\"9-环境和分布偏移\"><a href=\"#9-环境和分布偏移\" class=\"headerlink\" title=\"9 环境和分布偏移\"></a>9 环境和分布偏移</h1><ul>\n<li>（不好懂，建议跳过这一节）</li>\n<li>在不同的应用场景模型决策方案会出现漏洞</li>\n</ul>\n<h2 id=\"9-1-分布偏移的类型\"><a href=\"#9-1-分布偏移的类型\" class=\"headerlink\" title=\"9.1 分布偏移的类型\"></a>9.1 分布偏移的类型</h2><ul>\n<li>考虑一个二元分类问题：区分狗和猫。如果分布可以以任意方式偏移，那么我们的情景允许病态的情况，即输入的分布保持不变：$p_S(x) &#x3D; p_T (x)$，但标签全部翻转：$p_S(y|x) &#x3D; 1 − p_T (y|x)$。</li>\n</ul>\n<h3 id=\"9-1-1-协变量偏移\"><a href=\"#9-1-1-协变量偏移\" class=\"headerlink\" title=\"9.1.1 协变量偏移\"></a>9.1.1 协变量偏移</h3><ul>\n<li>虽然输入的分布可能随时间而改变，但标签函数（即条件分布P(y | x)）没有改变。统计学家称之为协变量偏移（covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。</li>\n<li>比如用真的猫狗图像做训练，卡通猫狗做测试。</li>\n</ul>\n<h3 id=\"9-1-2-标签偏移\"><a href=\"#9-1-2-标签偏移\" class=\"headerlink\" title=\"9.1.2 标签偏移\"></a>9.1.2 标签偏移</h3><ul>\n<li>与协变量偏移相反。假设标签边缘概率P(y)可以改变，但是类别条件分布P(x | y)在不同的领域之间保持不变。当我们认为y导致x时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。</li>\n<li>在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使y导致x，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。</li>\n</ul>\n<h3 id=\"9-1-3-概念偏移\"><a href=\"#9-1-3-概念偏移\" class=\"headerlink\" title=\"9.1.3 概念偏移\"></a>9.1.3 概念偏移</h3><ul>\n<li>当标签的定义发生变化时，就会出现这种问题。</li>\n<li>如果我们要建立一个机器翻译系统，P(y | x)的分布可能会因我们的位置不同而得到不同的翻译。这个问题可能很难被发现。所以，我们最好可以利用在时间或空间上逐渐发生偏移的知识。</li>\n</ul>\n<h2 id=\"9-2-分布偏移示例\"><a href=\"#9-2-分布偏移示例\" class=\"headerlink\" title=\"9.2 分布偏移示例\"></a>9.2 分布偏移示例</h2><h3 id=\"9-2-1-医学诊断\"><a href=\"#9-2-1-医学诊断\" class=\"headerlink\" title=\"9.2.1 医学诊断\"></a>9.2.1 医学诊断</h3><ul>\n<li>假设我们想设计一个检测癌症的算法，从健康人和病人那里收集数据，然后训练算法。收集训练数据的分布和在实际中遇到的数据分布可能有很大的不同。用近乎完美的精度来区分健康和患病人群确实很容易。然而，这可能是因为受试者在年龄、激素水平、体力活动、饮食、饮酒以及其他许多与疾病无关的因素上存在差异。这对检测疾病的分类器可能并不适用。这些抽样可能会遇到极端的协变量偏移。此外，这种情况不太可能通过常规方法加以纠正。</li>\n</ul>\n<h3 id=\"9-2-2-自动驾驶汽车\"><a href=\"#9-2-2-自动驾驶汽车\" class=\"headerlink\" title=\"9.2.2 自动驾驶汽车\"></a>9.2.2 自动驾驶汽车</h3><ul>\n<li>对于一家想利用机器学习来开发自动驾驶汽车的公司，一个关键部件是“路沿检测器”。由于真实的注释数据获取成本很高，他们想出了一个“聪明”的想法：将游戏渲染引擎中的合成数据用作额外的训练数据。这对从渲染引擎中抽取的“测试数据”非常有效，但应用在一辆真正的汽车里真是一场灾难。正如事实证明的那样，路沿被渲染成一种非常简单的纹理。更重要的是，所有的路沿都被渲染成了相同的纹理，路沿检测器很快就学习到了这个“特征”。</li>\n<li>当美军第一次试图在森林中探测坦克时，也发生了类似的事情。他们在没有坦克的情况下拍摄了森林的航拍照片，然后把坦克开进森林，拍摄了另一组照片。使用这两组数据训练的分类器似乎工作得很好。不幸的是，分类器仅仅学会了如何区分有阴影的树和没有阴影的树：第一组照片是在清晨拍摄的，而第二组是在中午拍摄的。</li>\n</ul>\n<h3 id=\"9-2-3-非平稳分布\"><a href=\"#9-2-3-非平稳分布\" class=\"headerlink\" title=\"9.2.3 非平稳分布\"></a>9.2.3 非平稳分布</h3><ul>\n<li>当分布变化缓慢并且模型没有得到充分更新时，就会出现更微妙的情况：非平稳分布（nonstationary distri‐bution）<ul>\n<li>训练一个计算广告模型，但却没有经常更新（例如，一个2009年训练的模型不知道一个叫iPad的不知名新设备刚刚上市）；</li>\n<li>建立一个垃圾邮件过滤器，它能很好地检测到所有垃圾邮件。但是，垃圾邮件发送者们变得聪明起来，制造出新的信息，看起来不像我们以前见过的任何垃圾邮件；</li>\n<li>建立一个产品推荐系统，它在整个冬天都有效，但圣诞节过后很久还会继续推荐圣诞帽。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"9-3-分布偏移纠正\"><a href=\"#9-3-分布偏移纠正\" class=\"headerlink\" title=\"9.3 分布偏移纠正\"></a>9.3 分布偏移纠正</h2><ul>\n<li>通过一些策略应对分布偏移</li>\n</ul>\n<h3 id=\"9-3-1-经验风险与实际风险\"><a href=\"#9-3-1-经验风险与实际风险\" class=\"headerlink\" title=\"9.3.1 经验风险与实际风险\"></a>9.3.1 经验风险与实际风险</h3><ul>\n<li>不考虑正则化，训练损失为：$\\operatorname*{minimize}<em>f\\frac1n\\sum</em>{i&#x3D;1}^nl(f(\\mathbf{x}_i),y_i)$，也称经验风险，其中$l$是损失函数。</li>\n<li>经验风险是为了近似真实风险：整个训练数据上的平均损失，即从真实分布$p(x,y)$中抽取的所有数据的总体损失的期望值：<br>  $$E_{p(\\mathbf{x},y)}[l(f(\\mathbf{x}),y)]&#x3D;\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x},y)~d\\mathbf{x}dy$$<br>  然而，我们通常无法获得总体数据。</li>\n</ul>\n<h3 id=\"9-3-2-协变量偏移纠正\"><a href=\"#9-3-2-协变量偏移纠正\" class=\"headerlink\" title=\"9.3.2 协变量偏移纠正\"></a>9.3.2 协变量偏移纠正</h3><ul>\n<li>假设对于带标签的数据(xi, yi)，我们要评估P(y | x)。然而观测值xi是从某些源分布q(x)中得出的，而不是从目标分布p(x)中得出的。幸运的是，依赖性假设意味着条件分布保持不变，即：p(y | x) &#x3D; q(y | x)。如果源分布q(x)是“错误的”，我们可以通过在真实风险的计算中，使用以下简单的恒等式来进行纠正：<br>$$\\begin{aligned}\\int\\int l(f(\\mathbf{x}),y)p(y\\mid\\mathbf{x})p(\\mathbf{x})d\\mathbf{x}dy&amp;&#x3D;\\int\\int l(f(\\mathbf{x}),y)q(y\\mid\\mathbf{x})q(\\mathbf{x})\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}d\\mathbf{x}dy\\end{aligned}$$</li>\n<li>因此我们需要根据数据来自正确分布与来自错误分布的概率之比，来重新衡量每个数据样本的权重：<br>$$\\beta_i\\stackrel{\\mathrm{def}}{&#x3D;}\\frac{p(\\mathbf{x}_i)}{q(\\mathbf{x}_i)}$$</li>\n<li>将权重带入每个数据样本，得到目标函数：加权经验风险最小化<br>$$\\min_f\\text{mize }\\frac1n\\sum_{i&#x3D;1}^n\\beta_il(f(\\mathbf{x}_i),y_i)$$</li>\n<li>由于不知道这个比率，我们需要估计它。需要从两个分布中抽取样本：“真实”的分布p，通过访问测试数据获取；训练集q，通过人工合成的很容易获得。我们只需要特征x ∼ p(x)，不需要访问标签y ∼ p(y)。</li>\n<li>一种非常有效的方法：对数几率回归，这是用于二元分类的softmax回归的一个特例。我们学习了一个分类器来区分从p(x)抽取的数据和从q(x)抽取的数据。如果无法区分这两个分布，则意味着相关的样本可能来自这两个分布中的任何一个。另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。</li>\n<li>假设我们分别从p(x)和q(x) 两个分布中抽取相同数量的样本。现在用z标签表示：从p抽取的数据为1，从q抽取的数据为−1。然后，混合数据集中的概率由下式给出<br>$$P(z&#x3D;1\\mid\\mathbf{x})&#x3D;\\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})}\\text{ and hence }\\frac{P(z&#x3D;1\\mid\\mathbf{x})}{P(z&#x3D;-1\\mid\\mathbf{x})}&#x3D;\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}$$</li>\n<li>因此，如果我们使用对数几率回归方法，其中$P(z&#x3D;1\\mid\\mathbf{x})&#x3D;\\frac{1}{1+\\exp(-h(\\mathbf{x}))}$（h是一个参数化函数），则（？？？）<br>$$\\beta_i&#x3D;\\frac{1&#x2F;(1+\\exp(-h(\\mathbf{x}_i)))}{\\exp(-h(\\mathbf{x}_i))&#x2F;(1+\\exp(-h(\\mathbf{x}_i)))}&#x3D;\\exp(h(\\mathbf{x}_i))$$</li>\n<li>因此，我们需要解决两个问题：第一个问题是关于区分来自两个分布的数据；第二个问题是关于 (4.9.5) 中的<br>加权经验风险的最小化问题。</li>\n<li>假设我们有一个训练集{$(x_1,y_1),···，(x_n,y_n)$}和一个未标记的测试集{$u_1,···,u_m$}.假设1 $\\leq$ i $\\leq$ n的$x_i$来自某个源分布，$u_i$来自目标分布。纠正协变量偏移的典型算法：<ol>\n<li>生成一个二元分类训练集：{$(x_1,-1),···,(x_n,-1),(u_1,1),···,(u_m,1)$}</li>\n<li>用对数几率回归训练二元分类器得到函数h。</li>\n<li>使用$\\beta_i &#x3D; exp(h(x_i))$或更好的$\\beta_i &#x3D; min(exp(h(x_i)),c)$(c为常量)对训练数据进行加权。</li>\n<li>使用权重$\\beta_i$进行加权经验风险最小化的训练。</li>\n</ol>\n</li>\n<li>上述算法依赖于一个重要的假设：需要目标分布(例如，测试分布)中的每个数据样本在训练时出现的概率非零。如果我们找到p(x) &gt; 0但q(x) &#x3D; 0的点，那么相应的重要性权重会是无穷大。</li>\n</ul>\n<h3 id=\"9-3-3-标签偏移纠正\"><a href=\"#9-3-3-标签偏移纠正\" class=\"headerlink\" title=\"9.3.3 标签偏移纠正\"></a>9.3.3 标签偏移纠正</h3><ul>\n<li>假设标签的分布随时间变化：q(y) ̸&#x3D; p(y)，但类别条件分布保持不变：q(x | y) &#x3D; p(x | y)。如果源分布q(y)是“错误的”，我们可以根据真实风险的定义进行更正：<br>$$\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x}\\mid y)p(y)d\\mathbf{x}dy&#x3D;\\int\\int l(f(\\mathbf{x}),y)q(\\mathbf{x}\\mid y)q(y)\\frac{p(y)}{q(y)}d\\mathbf{x}dy$$</li>\n<li>重要性权重应用于标签似然比率：<br>$$\\beta_i\\stackrel{\\mathrm{def}}{&#x3D;}\\frac{p(y_i)}{q(y_i)}$$</li>\n<li>为了估计目标标签分布，我们首先采用性能相当好的现成的分类器（通常基于训练数据进行训练），并使用验证集（也来自训练分布）计算其混淆矩阵。混淆矩阵C是一个k × k矩阵，其中每列对应于标签类别，每行对应于模型的预测类别。每个单元格的值cij是验证集中，真实标签为j，而我们的模型预测为i的样本数量所占的比例。</li>\n<li>我们不能直接计算目标数据上的混淆矩阵，因为我们无法看到真实环境下的样本的标签，除非我们再搭建一个复杂的实时标注流程。然而，我们所能做的是将所有模型在测试时的预测取平均数，得到平均模型输出$\\mu(\\hat{\\mathbf{y}})\\in\\mathbb{R}^k$，其中第i个元素$\\mu(\\hat y_i)$是我们模型预测测试集中i的总预测分数。</li>\n<li>如果我们的分类器一开始就相当准确，并且目标数据只包含我们以前见过的类别，以及如果标签偏移假设成立（这里最强的假设），我们就可以通过求解一个简单的线性系统来估计测试集的标签分布<br>$$\\mathbf{C}p(\\mathbf{y})&#x3D;\\mu(\\hat{\\mathbf{y}})$$</li>\n<li>因为作为一个估计，$\\begin{aligned}\\sum_{j&#x3D;1}^kc_{ij}p(y_j)&#x3D;\\mu(\\hat{y}_i)\\end{aligned}$对所有$1\\leq i \\leq k$成立，其中$p(y_i)$是k维标签分布向量p(y)的第$j^{th}$元素。如果我们的分类器一开始就足够精确，那么混淆矩阵$\\mathbf C$将是可逆的，进而我们可以得到一个解$p(y)&#x3D;\\mathbf C^{-1}\\mu(\\hat y)$因为我们观测源数据上的标签，所以很容易估计分布q(y)。那么对于标签为yi的任何训练样本i，我们可以使用我们估计的p(yi)&#x2F;q(yi)比率来计算权重$\\beta_i$，并将其代入加权经验风险最小化中。</li>\n</ul>\n<h3 id=\"9-3-4-概念偏移纠正\"><a href=\"#9-3-4-概念偏移纠正\" class=\"headerlink\" title=\"9.3.4 概念偏移纠正\"></a>9.3.4 概念偏移纠正</h3><ul>\n<li>概念偏移很难用原则性的方式解决。例如，在一个问题突然从“区分猫和狗”偏移为“区分白色和黑色动物”的情况下，除了从零开始收集新标签和训练，别无妙方。幸运的是，在实践中这种极端的偏移是罕见的。相反，通常情况下，概念的变化总是缓慢的。比如下面是一些例子：<ul>\n<li>在计算广告中，新产品推出后，旧产品变得不那么受欢迎了。这意味着广告的分布和受欢迎程度是逐渐<br>  变化的，任何点击率预测器都需要随之逐渐变化；</li>\n<li>由于环境的磨损，交通摄像头的镜头会逐渐退化，影响摄像头的图像质量；</li>\n<li>新闻内容逐渐变化（即新新闻的出现）。</li>\n</ul>\n</li>\n<li>在这种情况下，我们可以使用与训练网络相同的方法，使其适应数据的变化。换言之，我们使用新数据更新现有的网络权重，而不是从头开始训练。</li>\n</ul>\n<h2 id=\"9-4-学习问题的分类法\"><a href=\"#9-4-学习问题的分类法\" class=\"headerlink\" title=\"9.4 学习问题的分类法\"></a>9.4 学习问题的分类法</h2><h3 id=\"9-4-1-批量学习\"><a href=\"#9-4-1-批量学习\" class=\"headerlink\" title=\"9.4.1 批量学习\"></a>9.4.1 批量学习</h3><ul>\n<li>在批量学习（batch learning）中，我们可以访问一组训练特征和标签 {(x1, y1), . . . ,(xn, yn)}，我们使用这些特性和标签训练f(x)。然后，我们部署此模型来对来自同一分布的新数据(x, y)进行评分。例如，我们可以根据猫和狗的大量图片训练猫检测器。一旦我们训练了它，我们就把它作为智能猫门计算视觉系统的一部分，来控制只允许猫进入。然后这个系统会被安装在客户家中，基本再也不会更新。</li>\n</ul>\n<h3 id=\"9-4-2-在线学习\"><a href=\"#9-4-2-在线学习\" class=\"headerlink\" title=\"9.4.2 在线学习\"></a>9.4.2 在线学习</h3><ul>\n<li>除了“批量”地学习，我们还可以单个“在线”学习数据(xi, yi)。更具体地说，我们首先观测到xi，然后我们得出一个估计值f(xi)，只有当我们做到这一点后，我们才观测到yi。然后根据我们的决定，我们会得到奖励或损失。许多实际问题都属于这一类。例如，我们需要预测明天的股票价格，这样我们就可以根据这个预测进行交易。在一天结束时，我们会评估我们的预测是否盈利。换句话说，在在线学习（online learning）中，我们有以下的循环。在这个循环中，给定新的观测结果，我们会不断地改进我们的模型。<br>$$\\text{model }f_t\\longrightarrow\\text{data }\\mathbf{x}_t\\longrightarrow\\text{estimate }f_t(\\mathbf{x}_t)\\longrightarrow\\text{observation }y_t\\longrightarrow\\text{loss }l(y_t,f_t(\\mathbf{x}<em>t))\\longrightarrow\\text{model }f</em>{t+1}$$</li>\n</ul>\n<h3 id=\"9-4-3-老虎机\"><a href=\"#9-4-3-老虎机\" class=\"headerlink\" title=\"9.4.3 老虎机\"></a>9.4.3 老虎机</h3><ul>\n<li>老虎机（bandits）是上述问题的一个特例。虽然在大多数学习问题中，我们有一个连续参数化的函数f（例如，一个深度网络）。但在一个老虎机问题中，我们只有有限数量的手臂可以拉动。也就是说，我们可以采取的行动是有限的。对于这个更简单的问题，可以获得更强的最优性理论保证，这并不令人惊讶。我们之所以列出它，主要是因为这个问题经常被视为一个单独的学习问题的情景。</li>\n</ul>\n<h3 id=\"9-4-4-控制\"><a href=\"#9-4-4-控制\" class=\"headerlink\" title=\"9.4.4 控制\"></a>9.4.4 控制</h3><ul>\n<li>在很多情况下，环境会记住我们所做的事。不一定是以一种对抗的方式，但它会记住，而且它的反应将取决于之前发生的事情。例如，咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度。在这种情况下，PID（比例—积分—微分）控制器算法是一个流行的选择。同样，一个用户在新闻网站上的行为将取决于之前向她展示的内容（例如，大多数新闻她只阅读一次）。许多这样的算法形成了一个环境模型，在这个模型中，他们的行为使得他们的决策看起来不那么随机。近年来，控制理论（如PID的变体）也被用于自动调整超参数，以<br>获得更好的解构和重建质量，提高生成文本的多样性和生成图像的重建质量。</li>\n</ul>\n<h3 id=\"9-4-5-强化学习\"><a href=\"#9-4-5-强化学习\" class=\"headerlink\" title=\"9.4.5 强化学习\"></a>9.4.5 强化学习</h3><ul>\n<li>强化学习（reinforcement learning）强调如何基于环境而行动，以取得最大化的预期利益。国际象棋、围棋、西洋双陆棋或星际争霸都是强化学习的应用实例。再比如，为自动驾驶汽车制造一个控制器，或者以其他方式对自动驾驶汽车的驾驶方式做出反应（例如，试图避开某物体，试图造成事故，或者试图与其合作）。</li>\n</ul>\n<h3 id=\"9-4-6-考虑到环境\"><a href=\"#9-4-6-考虑到环境\" class=\"headerlink\" title=\"9.4.6 考虑到环境\"></a>9.4.6 考虑到环境</h3><ul>\n<li>上述不同情况之间的一个关键区别是：在静止环境中可能一直有效的相同策略，在环境能够改变的情况下可能不会始终有效。例如，一个交易者发现的套利机会很可能在他开始利用它时就消失了。环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型。例如，如果我们知道事情只会缓慢地变化，就可以迫使任何估计也只能缓慢地发生改变。如果我们知道环境可能会瞬间发生变化，但这种变化非常罕见，我们就可以在使用算法时考虑到这一点。当一个数据科学家试图解决的问题会随着时间的推移而发生变化时，这些类<br>型的知识至关重要。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h1 id=\"9-环境和分布偏移\"><a href=\"#9-环境和分布偏移\" class=\"headerlink\" title=\"9 环境和分布偏移\"></a>9 环境和分布偏移</h1><ul>\n<li>（不好懂，建议跳过这一节）</li>\n<li>在不同的应用场景模型决策方案会出现漏洞</li>\n</ul>\n<h2 id=\"9-1-分布偏移的类型\"><a href=\"#9-1-分布偏移的类型\" class=\"headerlink\" title=\"9.1 分布偏移的类型\"></a>9.1 分布偏移的类型</h2><ul>\n<li>考虑一个二元分类问题：区分狗和猫。如果分布可以以任意方式偏移，那么我们的情景允许病态的情况，即输入的分布保持不变：$p_S(x) &#x3D; p_T (x)$，但标签全部翻转：$p_S(y|x) &#x3D; 1 − p_T (y|x)$。</li>\n</ul>\n<h3 id=\"9-1-1-协变量偏移\"><a href=\"#9-1-1-协变量偏移\" class=\"headerlink\" title=\"9.1.1 协变量偏移\"></a>9.1.1 协变量偏移</h3><ul>\n<li>虽然输入的分布可能随时间而改变，但标签函数（即条件分布P(y | x)）没有改变。统计学家称之为协变量偏移（covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。</li>\n<li>比如用真的猫狗图像做训练，卡通猫狗做测试。</li>\n</ul>\n<h3 id=\"9-1-2-标签偏移\"><a href=\"#9-1-2-标签偏移\" class=\"headerlink\" title=\"9.1.2 标签偏移\"></a>9.1.2 标签偏移</h3><ul>\n<li>与协变量偏移相反。假设标签边缘概率P(y)可以改变，但是类别条件分布P(x | y)在不同的领域之间保持不变。当我们认为y导致x时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。</li>\n<li>在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使y导致x，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。</li>\n</ul>\n<h3 id=\"9-1-3-概念偏移\"><a href=\"#9-1-3-概念偏移\" class=\"headerlink\" title=\"9.1.3 概念偏移\"></a>9.1.3 概念偏移</h3><ul>\n<li>当标签的定义发生变化时，就会出现这种问题。</li>\n<li>如果我们要建立一个机器翻译系统，P(y | x)的分布可能会因我们的位置不同而得到不同的翻译。这个问题可能很难被发现。所以，我们最好可以利用在时间或空间上逐渐发生偏移的知识。</li>\n</ul>\n<h2 id=\"9-2-分布偏移示例\"><a href=\"#9-2-分布偏移示例\" class=\"headerlink\" title=\"9.2 分布偏移示例\"></a>9.2 分布偏移示例</h2><h3 id=\"9-2-1-医学诊断\"><a href=\"#9-2-1-医学诊断\" class=\"headerlink\" title=\"9.2.1 医学诊断\"></a>9.2.1 医学诊断</h3><ul>\n<li>假设我们想设计一个检测癌症的算法，从健康人和病人那里收集数据，然后训练算法。收集训练数据的分布和在实际中遇到的数据分布可能有很大的不同。用近乎完美的精度来区分健康和患病人群确实很容易。然而，这可能是因为受试者在年龄、激素水平、体力活动、饮食、饮酒以及其他许多与疾病无关的因素上存在差异。这对检测疾病的分类器可能并不适用。这些抽样可能会遇到极端的协变量偏移。此外，这种情况不太可能通过常规方法加以纠正。</li>\n</ul>\n<h3 id=\"9-2-2-自动驾驶汽车\"><a href=\"#9-2-2-自动驾驶汽车\" class=\"headerlink\" title=\"9.2.2 自动驾驶汽车\"></a>9.2.2 自动驾驶汽车</h3><ul>\n<li>对于一家想利用机器学习来开发自动驾驶汽车的公司，一个关键部件是“路沿检测器”。由于真实的注释数据获取成本很高，他们想出了一个“聪明”的想法：将游戏渲染引擎中的合成数据用作额外的训练数据。这对从渲染引擎中抽取的“测试数据”非常有效，但应用在一辆真正的汽车里真是一场灾难。正如事实证明的那样，路沿被渲染成一种非常简单的纹理。更重要的是，所有的路沿都被渲染成了相同的纹理，路沿检测器很快就学习到了这个“特征”。</li>\n<li>当美军第一次试图在森林中探测坦克时，也发生了类似的事情。他们在没有坦克的情况下拍摄了森林的航拍照片，然后把坦克开进森林，拍摄了另一组照片。使用这两组数据训练的分类器似乎工作得很好。不幸的是，分类器仅仅学会了如何区分有阴影的树和没有阴影的树：第一组照片是在清晨拍摄的，而第二组是在中午拍摄的。</li>\n</ul>\n<h3 id=\"9-2-3-非平稳分布\"><a href=\"#9-2-3-非平稳分布\" class=\"headerlink\" title=\"9.2.3 非平稳分布\"></a>9.2.3 非平稳分布</h3><ul>\n<li>当分布变化缓慢并且模型没有得到充分更新时，就会出现更微妙的情况：非平稳分布（nonstationary distri‐bution）<ul>\n<li>训练一个计算广告模型，但却没有经常更新（例如，一个2009年训练的模型不知道一个叫iPad的不知名新设备刚刚上市）；</li>\n<li>建立一个垃圾邮件过滤器，它能很好地检测到所有垃圾邮件。但是，垃圾邮件发送者们变得聪明起来，制造出新的信息，看起来不像我们以前见过的任何垃圾邮件；</li>\n<li>建立一个产品推荐系统，它在整个冬天都有效，但圣诞节过后很久还会继续推荐圣诞帽。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"9-3-分布偏移纠正\"><a href=\"#9-3-分布偏移纠正\" class=\"headerlink\" title=\"9.3 分布偏移纠正\"></a>9.3 分布偏移纠正</h2><ul>\n<li>通过一些策略应对分布偏移</li>\n</ul>\n<h3 id=\"9-3-1-经验风险与实际风险\"><a href=\"#9-3-1-经验风险与实际风险\" class=\"headerlink\" title=\"9.3.1 经验风险与实际风险\"></a>9.3.1 经验风险与实际风险</h3><ul>\n<li>不考虑正则化，训练损失为：$\\operatorname*{minimize}<em>f\\frac1n\\sum</em>{i&#x3D;1}^nl(f(\\mathbf{x}_i),y_i)$，也称经验风险，其中$l$是损失函数。</li>\n<li>经验风险是为了近似真实风险：整个训练数据上的平均损失，即从真实分布$p(x,y)$中抽取的所有数据的总体损失的期望值：<br>  $$E_{p(\\mathbf{x},y)}[l(f(\\mathbf{x}),y)]&#x3D;\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x},y)~d\\mathbf{x}dy$$<br>  然而，我们通常无法获得总体数据。</li>\n</ul>\n<h3 id=\"9-3-2-协变量偏移纠正\"><a href=\"#9-3-2-协变量偏移纠正\" class=\"headerlink\" title=\"9.3.2 协变量偏移纠正\"></a>9.3.2 协变量偏移纠正</h3><ul>\n<li>假设对于带标签的数据(xi, yi)，我们要评估P(y | x)。然而观测值xi是从某些源分布q(x)中得出的，而不是从目标分布p(x)中得出的。幸运的是，依赖性假设意味着条件分布保持不变，即：p(y | x) &#x3D; q(y | x)。如果源分布q(x)是“错误的”，我们可以通过在真实风险的计算中，使用以下简单的恒等式来进行纠正：<br>$$\\begin{aligned}\\int\\int l(f(\\mathbf{x}),y)p(y\\mid\\mathbf{x})p(\\mathbf{x})d\\mathbf{x}dy&amp;&#x3D;\\int\\int l(f(\\mathbf{x}),y)q(y\\mid\\mathbf{x})q(\\mathbf{x})\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}d\\mathbf{x}dy\\end{aligned}$$</li>\n<li>因此我们需要根据数据来自正确分布与来自错误分布的概率之比，来重新衡量每个数据样本的权重：<br>$$\\beta_i\\stackrel{\\mathrm{def}}{&#x3D;}\\frac{p(\\mathbf{x}_i)}{q(\\mathbf{x}_i)}$$</li>\n<li>将权重带入每个数据样本，得到目标函数：加权经验风险最小化<br>$$\\min_f\\text{mize }\\frac1n\\sum_{i&#x3D;1}^n\\beta_il(f(\\mathbf{x}_i),y_i)$$</li>\n<li>由于不知道这个比率，我们需要估计它。需要从两个分布中抽取样本：“真实”的分布p，通过访问测试数据获取；训练集q，通过人工合成的很容易获得。我们只需要特征x ∼ p(x)，不需要访问标签y ∼ p(y)。</li>\n<li>一种非常有效的方法：对数几率回归，这是用于二元分类的softmax回归的一个特例。我们学习了一个分类器来区分从p(x)抽取的数据和从q(x)抽取的数据。如果无法区分这两个分布，则意味着相关的样本可能来自这两个分布中的任何一个。另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。</li>\n<li>假设我们分别从p(x)和q(x) 两个分布中抽取相同数量的样本。现在用z标签表示：从p抽取的数据为1，从q抽取的数据为−1。然后，混合数据集中的概率由下式给出<br>$$P(z&#x3D;1\\mid\\mathbf{x})&#x3D;\\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})}\\text{ and hence }\\frac{P(z&#x3D;1\\mid\\mathbf{x})}{P(z&#x3D;-1\\mid\\mathbf{x})}&#x3D;\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}$$</li>\n<li>因此，如果我们使用对数几率回归方法，其中$P(z&#x3D;1\\mid\\mathbf{x})&#x3D;\\frac{1}{1+\\exp(-h(\\mathbf{x}))}$（h是一个参数化函数），则（？？？）<br>$$\\beta_i&#x3D;\\frac{1&#x2F;(1+\\exp(-h(\\mathbf{x}_i)))}{\\exp(-h(\\mathbf{x}_i))&#x2F;(1+\\exp(-h(\\mathbf{x}_i)))}&#x3D;\\exp(h(\\mathbf{x}_i))$$</li>\n<li>因此，我们需要解决两个问题：第一个问题是关于区分来自两个分布的数据；第二个问题是关于 (4.9.5) 中的<br>加权经验风险的最小化问题。</li>\n<li>假设我们有一个训练集{$(x_1,y_1),···，(x_n,y_n)$}和一个未标记的测试集{$u_1,···,u_m$}.假设1 $\\leq$ i $\\leq$ n的$x_i$来自某个源分布，$u_i$来自目标分布。纠正协变量偏移的典型算法：<ol>\n<li>生成一个二元分类训练集：{$(x_1,-1),···,(x_n,-1),(u_1,1),···,(u_m,1)$}</li>\n<li>用对数几率回归训练二元分类器得到函数h。</li>\n<li>使用$\\beta_i &#x3D; exp(h(x_i))$或更好的$\\beta_i &#x3D; min(exp(h(x_i)),c)$(c为常量)对训练数据进行加权。</li>\n<li>使用权重$\\beta_i$进行加权经验风险最小化的训练。</li>\n</ol>\n</li>\n<li>上述算法依赖于一个重要的假设：需要目标分布(例如，测试分布)中的每个数据样本在训练时出现的概率非零。如果我们找到p(x) &gt; 0但q(x) &#x3D; 0的点，那么相应的重要性权重会是无穷大。</li>\n</ul>\n<h3 id=\"9-3-3-标签偏移纠正\"><a href=\"#9-3-3-标签偏移纠正\" class=\"headerlink\" title=\"9.3.3 标签偏移纠正\"></a>9.3.3 标签偏移纠正</h3><ul>\n<li>假设标签的分布随时间变化：q(y) ̸&#x3D; p(y)，但类别条件分布保持不变：q(x | y) &#x3D; p(x | y)。如果源分布q(y)是“错误的”，我们可以根据真实风险的定义进行更正：<br>$$\\int\\int l(f(\\mathbf{x}),y)p(\\mathbf{x}\\mid y)p(y)d\\mathbf{x}dy&#x3D;\\int\\int l(f(\\mathbf{x}),y)q(\\mathbf{x}\\mid y)q(y)\\frac{p(y)}{q(y)}d\\mathbf{x}dy$$</li>\n<li>重要性权重应用于标签似然比率：<br>$$\\beta_i\\stackrel{\\mathrm{def}}{&#x3D;}\\frac{p(y_i)}{q(y_i)}$$</li>\n<li>为了估计目标标签分布，我们首先采用性能相当好的现成的分类器（通常基于训练数据进行训练），并使用验证集（也来自训练分布）计算其混淆矩阵。混淆矩阵C是一个k × k矩阵，其中每列对应于标签类别，每行对应于模型的预测类别。每个单元格的值cij是验证集中，真实标签为j，而我们的模型预测为i的样本数量所占的比例。</li>\n<li>我们不能直接计算目标数据上的混淆矩阵，因为我们无法看到真实环境下的样本的标签，除非我们再搭建一个复杂的实时标注流程。然而，我们所能做的是将所有模型在测试时的预测取平均数，得到平均模型输出$\\mu(\\hat{\\mathbf{y}})\\in\\mathbb{R}^k$，其中第i个元素$\\mu(\\hat y_i)$是我们模型预测测试集中i的总预测分数。</li>\n<li>如果我们的分类器一开始就相当准确，并且目标数据只包含我们以前见过的类别，以及如果标签偏移假设成立（这里最强的假设），我们就可以通过求解一个简单的线性系统来估计测试集的标签分布<br>$$\\mathbf{C}p(\\mathbf{y})&#x3D;\\mu(\\hat{\\mathbf{y}})$$</li>\n<li>因为作为一个估计，$\\begin{aligned}\\sum_{j&#x3D;1}^kc_{ij}p(y_j)&#x3D;\\mu(\\hat{y}_i)\\end{aligned}$对所有$1\\leq i \\leq k$成立，其中$p(y_i)$是k维标签分布向量p(y)的第$j^{th}$元素。如果我们的分类器一开始就足够精确，那么混淆矩阵$\\mathbf C$将是可逆的，进而我们可以得到一个解$p(y)&#x3D;\\mathbf C^{-1}\\mu(\\hat y)$因为我们观测源数据上的标签，所以很容易估计分布q(y)。那么对于标签为yi的任何训练样本i，我们可以使用我们估计的p(yi)&#x2F;q(yi)比率来计算权重$\\beta_i$，并将其代入加权经验风险最小化中。</li>\n</ul>\n<h3 id=\"9-3-4-概念偏移纠正\"><a href=\"#9-3-4-概念偏移纠正\" class=\"headerlink\" title=\"9.3.4 概念偏移纠正\"></a>9.3.4 概念偏移纠正</h3><ul>\n<li>概念偏移很难用原则性的方式解决。例如，在一个问题突然从“区分猫和狗”偏移为“区分白色和黑色动物”的情况下，除了从零开始收集新标签和训练，别无妙方。幸运的是，在实践中这种极端的偏移是罕见的。相反，通常情况下，概念的变化总是缓慢的。比如下面是一些例子：<ul>\n<li>在计算广告中，新产品推出后，旧产品变得不那么受欢迎了。这意味着广告的分布和受欢迎程度是逐渐<br>  变化的，任何点击率预测器都需要随之逐渐变化；</li>\n<li>由于环境的磨损，交通摄像头的镜头会逐渐退化，影响摄像头的图像质量；</li>\n<li>新闻内容逐渐变化（即新新闻的出现）。</li>\n</ul>\n</li>\n<li>在这种情况下，我们可以使用与训练网络相同的方法，使其适应数据的变化。换言之，我们使用新数据更新现有的网络权重，而不是从头开始训练。</li>\n</ul>\n<h2 id=\"9-4-学习问题的分类法\"><a href=\"#9-4-学习问题的分类法\" class=\"headerlink\" title=\"9.4 学习问题的分类法\"></a>9.4 学习问题的分类法</h2><h3 id=\"9-4-1-批量学习\"><a href=\"#9-4-1-批量学习\" class=\"headerlink\" title=\"9.4.1 批量学习\"></a>9.4.1 批量学习</h3><ul>\n<li>在批量学习（batch learning）中，我们可以访问一组训练特征和标签 {(x1, y1), . . . ,(xn, yn)}，我们使用这些特性和标签训练f(x)。然后，我们部署此模型来对来自同一分布的新数据(x, y)进行评分。例如，我们可以根据猫和狗的大量图片训练猫检测器。一旦我们训练了它，我们就把它作为智能猫门计算视觉系统的一部分，来控制只允许猫进入。然后这个系统会被安装在客户家中，基本再也不会更新。</li>\n</ul>\n<h3 id=\"9-4-2-在线学习\"><a href=\"#9-4-2-在线学习\" class=\"headerlink\" title=\"9.4.2 在线学习\"></a>9.4.2 在线学习</h3><ul>\n<li>除了“批量”地学习，我们还可以单个“在线”学习数据(xi, yi)。更具体地说，我们首先观测到xi，然后我们得出一个估计值f(xi)，只有当我们做到这一点后，我们才观测到yi。然后根据我们的决定，我们会得到奖励或损失。许多实际问题都属于这一类。例如，我们需要预测明天的股票价格，这样我们就可以根据这个预测进行交易。在一天结束时，我们会评估我们的预测是否盈利。换句话说，在在线学习（online learning）中，我们有以下的循环。在这个循环中，给定新的观测结果，我们会不断地改进我们的模型。<br>$$\\text{model }f_t\\longrightarrow\\text{data }\\mathbf{x}_t\\longrightarrow\\text{estimate }f_t(\\mathbf{x}_t)\\longrightarrow\\text{observation }y_t\\longrightarrow\\text{loss }l(y_t,f_t(\\mathbf{x}<em>t))\\longrightarrow\\text{model }f</em>{t+1}$$</li>\n</ul>\n<h3 id=\"9-4-3-老虎机\"><a href=\"#9-4-3-老虎机\" class=\"headerlink\" title=\"9.4.3 老虎机\"></a>9.4.3 老虎机</h3><ul>\n<li>老虎机（bandits）是上述问题的一个特例。虽然在大多数学习问题中，我们有一个连续参数化的函数f（例如，一个深度网络）。但在一个老虎机问题中，我们只有有限数量的手臂可以拉动。也就是说，我们可以采取的行动是有限的。对于这个更简单的问题，可以获得更强的最优性理论保证，这并不令人惊讶。我们之所以列出它，主要是因为这个问题经常被视为一个单独的学习问题的情景。</li>\n</ul>\n<h3 id=\"9-4-4-控制\"><a href=\"#9-4-4-控制\" class=\"headerlink\" title=\"9.4.4 控制\"></a>9.4.4 控制</h3><ul>\n<li>在很多情况下，环境会记住我们所做的事。不一定是以一种对抗的方式，但它会记住，而且它的反应将取决于之前发生的事情。例如，咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度。在这种情况下，PID（比例—积分—微分）控制器算法是一个流行的选择。同样，一个用户在新闻网站上的行为将取决于之前向她展示的内容（例如，大多数新闻她只阅读一次）。许多这样的算法形成了一个环境模型，在这个模型中，他们的行为使得他们的决策看起来不那么随机。近年来，控制理论（如PID的变体）也被用于自动调整超参数，以<br>获得更好的解构和重建质量，提高生成文本的多样性和生成图像的重建质量。</li>\n</ul>\n<h3 id=\"9-4-5-强化学习\"><a href=\"#9-4-5-强化学习\" class=\"headerlink\" title=\"9.4.5 强化学习\"></a>9.4.5 强化学习</h3><ul>\n<li>强化学习（reinforcement learning）强调如何基于环境而行动，以取得最大化的预期利益。国际象棋、围棋、西洋双陆棋或星际争霸都是强化学习的应用实例。再比如，为自动驾驶汽车制造一个控制器，或者以其他方式对自动驾驶汽车的驾驶方式做出反应（例如，试图避开某物体，试图造成事故，或者试图与其合作）。</li>\n</ul>\n<h3 id=\"9-4-6-考虑到环境\"><a href=\"#9-4-6-考虑到环境\" class=\"headerlink\" title=\"9.4.6 考虑到环境\"></a>9.4.6 考虑到环境</h3><ul>\n<li>上述不同情况之间的一个关键区别是：在静止环境中可能一直有效的相同策略，在环境能够改变的情况下可能不会始终有效。例如，一个交易者发现的套利机会很可能在他开始利用它时就消失了。环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型。例如，如果我们知道事情只会缓慢地变化，就可以迫使任何估计也只能缓慢地发生改变。如果我们知道环境可能会瞬间发生变化，但这种变化非常罕见，我们就可以在使用算法时考虑到这一点。当一个数据科学家试图解决的问题会随着时间的推移而发生变化时，这些类<br>型的知识至关重要。</li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"clt19858600017svwbz9ab1ko","category_id":"clt19858b00047svwderu8ki9","_id":"clt19858g000d7svw8svzau2y"},{"post_id":"clt19858f000c7svwc46oacgf","category_id":"clt19858l000r7svw0i2z7epx","_id":"clt19858o00157svwfo5e97tr"},{"post_id":"clt19858g000f7svwcbxn9bg6","category_id":"clt19858l000r7svw0i2z7epx","_id":"clt19858q001b7svwhqpwee1a"},{"post_id":"clt19858k000n7svwhg56ef2h","category_id":"clt19858r001e7svwc6jz0ggl","_id":"clt19858u001p7svw00p51nvo"},{"post_id":"clt19858o00137svw52io5ukv","category_id":"clt19858y002a7svw8ortfswl","_id":"clt198591002l7svw25rbe9z6"},{"post_id":"clt198590002i7svwbmdj8uh3","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198592002p7svwc1i3arnn"},{"post_id":"clt19858p00177svwayrr2k2h","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198592002t7svwecyg9dvp"},{"post_id":"clt198590002k7svw9qcp94qn","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198593002x7svw0i7n1op0"},{"post_id":"clt198591002n7svw3f22ckr2","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859400307svw0y728wks"},{"post_id":"clt198591002o7svw4y0w7q7b","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859500347svw9unvgx0s"},{"post_id":"clt19858i000h7svw6wjif9gf","category_id":"clt19858l000r7svw0i2z7epx","_id":"clt19859600377svw2uy2gwos"},{"post_id":"clt19858i000h7svw6wjif9gf","category_id":"clt198591002m7svwgr9phivn","_id":"clt198596003b7svweqp0g4iy"},{"post_id":"clt198592002s7svw8mtre56y","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198597003e7svw4dsthw51"},{"post_id":"clt198593002w7svwhs8d44d6","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198598003h7svwgik785g0"},{"post_id":"clt19858p00187svwgmhuc5m6","category_id":"clt19858z002g7svw95zh57rn","_id":"clt198598003j7svw687a10vg"},{"post_id":"clt198594002z7svw8g4v3cm8","category_id":"clt19858b00047svwderu8ki9","_id":"clt198599003o7svw8szr0lzv"},{"post_id":"clt19859500337svw2fvh2hie","category_id":"clt19858b00047svwderu8ki9","_id":"clt19859a003r7svw9ykzht8p"},{"post_id":"clt19858q001c7svw7w4h1ksm","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859b003v7svw6s6b2sj4"},{"post_id":"clt19859500367svwdjqlc04r","category_id":"clt19858b00047svwderu8ki9","_id":"clt19859b003y7svweqoh538q"},{"post_id":"clt198596003a7svwfjbi5qs4","category_id":"clt19858b00047svwderu8ki9","_id":"clt19859c00427svw4tzlgidj"},{"post_id":"clt19858j000j7svwgmhmezqj","category_id":"clt19858l000r7svw0i2z7epx","_id":"clt19859c00447svwggejew59"},{"post_id":"clt19858j000j7svwgmhmezqj","category_id":"clt19859600387svw26ld2ehq","_id":"clt19859d00487svwc3lycjtg"},{"post_id":"clt198597003d7svwe022ejo4","category_id":"clt19858b00047svwderu8ki9","_id":"clt19859e004b7svw67gfcmax"},{"post_id":"clt19858q001d7svw84r93fq2","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859f004g7svw2f7ifbnk"},{"post_id":"clt19858r001g7svw4ucc11df","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859f004j7svwhmuz72ci"},{"post_id":"clt19858s001i7svw6ut0ckf1","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859g004n7svwckf35liq"},{"post_id":"clt19858t001m7svw1i05c27h","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859g004p7svwf2unda3q"},{"post_id":"clt19858t001n7svwhp3g4dq9","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859h004t7svwekw82cbk"},{"post_id":"clt19858u001r7svw18abfw5j","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859i004w7svwc85f8nom"},{"post_id":"clt19858v001t7svw46o68o8s","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859i00517svw9f8e8nsx"},{"post_id":"clt19858v001y7svwc62p6b4u","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859j00537svwhxpt4p2v"},{"post_id":"clt19858w00207svwdai5axd1","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859j00567svw3szvat2k"},{"post_id":"clt19858w00237svw3jg14gqt","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859k005a7svw8yetdbyg"},{"post_id":"clt19858x00267svw4zvzc4ph","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859k005f7svwcq0u5sic"},{"post_id":"clt19858y00287svwgftx5tbp","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859l005j7svwf4uzd6e6"},{"post_id":"clt19858y002c7svwe42s6xfp","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859l005n7svw23ydhih7"},{"post_id":"clt19858z002e7svw34dx4x8j","category_id":"clt19858z002g7svw95zh57rn","_id":"clt19859m005p7svw1my46wrf"},{"post_id":"clt198597003g7svw406y8gbv","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859n005u7svwdr7kf30p"},{"post_id":"clt198598003i7svw6mtscg67","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859n005z7svw43tmhzne"},{"post_id":"clt198599003n7svwe3sfglra","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859o00637svwap2lcr71"},{"post_id":"clt198599003q7svwchg57j21","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859p00677svw45nje8pz"},{"post_id":"clt19859a003u7svwa9j9h6le","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859q006a7svwgbcs6888"},{"post_id":"clt19859b003x7svwd94ndbvi","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859q006d7svwhzrq9up0"},{"post_id":"clt19859c00417svwf55tbtmz","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859r006i7svw3zdrgdy0"},{"post_id":"clt19859c00437svw41olhu0f","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859s006m7svw11p402fd"},{"post_id":"clt19859d00477svwbit3es0h","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859s006p7svw7ydu2pik"},{"post_id":"clt19859e004a7svw07ww6ao9","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859s006u7svwawvkhxln"},{"post_id":"clt19859e004f7svwd2g02hpy","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859t006y7svwe7uxbvjd"},{"post_id":"clt19859f004i7svw9j87ajzi","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859u00737svw08rv87tq"},{"post_id":"clt19859g004m7svw09gyfooa","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859u00767svw1t3rb3e6"},{"post_id":"clt19859g004o7svw06xnefkl","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859v007b7svw0130f0ep"},{"post_id":"clt19859h004s7svwat2y487d","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859v007e7svwd8486ebp"},{"post_id":"clt19859h004v7svwgw1j3zxp","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859v007f7svw27pkgeij"},{"post_id":"clt19859i00507svw17qo18o4","category_id":"clt19859l005m7svwgbh2001y","_id":"clt19859w007j7svw86sn8isj"},{"post_id":"clt1985ac00bh7svw0op4f2nr","category_id":"clt19859l005m7svwgbh2001y","_id":"clt1985ad00bm7svw2w2ye215"},{"post_id":"clt1985ac00bi7svwbxeegipm","category_id":"clt19859l005m7svwgbh2001y","_id":"clt1985ad00bo7svw8zbe6chs"},{"post_id":"clt1985ad00bk7svw8hgr6ppg","category_id":"clt19859l005m7svwgbh2001y","_id":"clt1cimms00025gvwea3z634i"},{"post_id":"clt8fmx0e0000mkvw4n8t3fts","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"clt8fmx0r0004mkvw4jwx3drn"},{"post_id":"clta2pezx0000zovw6hix76mc","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf060006zovw2sjp38vx"},{"post_id":"clta2pf020001zovw9w1nf0iw","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf070009zovwgb4hb0wp"},{"post_id":"clta2pf040003zovw0vqq7bqr","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf08000czovw1v1a2mbs"},{"post_id":"clta2pf050005zovw7hhnb1r6","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf08000ezovw4twqd4dq"},{"post_id":"clta2pf060008zovw0duzbzc8","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf08000gzovw62gx4jtc"},{"post_id":"clta2pf07000bzovwe05igf5i","category_id":"clt19858f000a7svw2vl4djcw","_id":"clta2pf08000hzovw9b7sbrm7"},{"post_id":"cltfntnsz0000ccvw41iu1cn9","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfntnt20006ccvw4d02gdsd"},{"post_id":"cltfntnt00001ccvwb6an9pjh","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfntnt40009ccvwd6sfafw7"},{"post_id":"cltfntnt10003ccvwfyr14vy1","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfntnt5000cccvwfs450e19"},{"post_id":"cltfntnt20005ccvwetgrbrzt","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfntnt5000eccvw9xm46bob"},{"post_id":"cltfntnt30008ccvw3vo48p29","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfntnt6000gccvwchuw4zjq"},{"post_id":"cltfr696y000054vw667819si","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltfr6970000354vw5n443z9l"},{"post_id":"cltmv05yy0001lkvw6f4jcvff","category_id":"clt19858f000a7svw2vl4djcw","_id":"cltmv05za0006lkvw3g950kfq"},{"post_id":"clt19858l000q7svw9jkp1hfm","category_id":"clt19858y002a7svw8ortfswl","_id":"cltmv05zb0009lkvw46mc48cx"},{"post_id":"cltmv05yw0000lkvw5mfe7u66","category_id":"cltmv05yz0002lkvwbjshccfv","_id":"cltmv05zc000alkvw7pvnduet"},{"post_id":"cltmv05z90005lkvwbmmb6maz","category_id":"clt19858y002a7svw8ortfswl","_id":"cltmv05ze000elkvwbdg0amux"},{"post_id":"clt19858m000x7svw6rpk33n9","category_id":"clt19858y002a7svw8ortfswl","_id":"cltmv05zf000flkvwhvnyfchb"},{"post_id":"clt19858m000u7svw5niw3s5n","category_id":"clt19858y002a7svw8ortfswl","_id":"cltmv05zf000glkvwazuz6dmh"},{"post_id":"cltmv05zg000hlkvw3y8h0yn2","category_id":"clt8fmx0h0001mkvw64mfd8ov","_id":"cltmv05zh000llkvw9ck5db5t"},{"post_id":"cltod2agt000050vwd1rrfdto","category_id":"clt19858f000a7svw2vl4djcw","_id":"cltod2ah5000450vw1hin7lib"},{"post_id":"cltmv05zd000dlkvw4nr3cy57","category_id":"cltod2agw000250vwevzac83h","_id":"cltod2ah6000650vwh3vqfbbi"},{"post_id":"cltod2ah7000750vwfj9o5gdr","category_id":"cltod2agw000250vwevzac83h","_id":"cltod2ah8000950vw8o6efxg1"},{"post_id":"cltwpq3va000038vw2mf7bg3v","category_id":"clt19858x00247svw2vuk6md5","_id":"cltwpq3vr000638vw6syo1d8p"},{"post_id":"cltwpq3ve000138vw3rl5awse","category_id":"clt19858y002a7svw8ortfswl","_id":"cltwpq3vr000838vw92v079ir"},{"post_id":"cltwpq3vg000338vw0lct49bb","category_id":"clt19858x00247svw2vuk6md5","_id":"cltwpq3vs000a38vw3i1mhp96"},{"post_id":"cltwpq3vq000538vwgdld38mn","category_id":"clt19859l005m7svwgbh2001y","_id":"cltwpq3vs000c38vw4kzc9gfq"},{"post_id":"cltwpq3vw000f38vwccze88c2","category_id":"clt19859l005m7svwgbh2001y","_id":"cltwpq3vw000i38vw5u9xgjyh"},{"post_id":"clv5ccx760000usvwg4r7hn5m","category_id":"cltmv05yz0002lkvwbjshccfv","_id":"clv5ccx7f0005usvw7jjl1c6m"},{"post_id":"clv5ccx7b0001usvw2gi046cq","category_id":"cltmv05yz0002lkvwbjshccfv","_id":"clv5ccx7g0007usvw350u6z9z"},{"post_id":"clv5ccx7d0003usvwfra8atrh","category_id":"cltmv05yz0002lkvwbjshccfv","_id":"clv5ccx7h0008usvw9lx1feiz"},{"post_id":"cltwpq3vv000e38vwede8hw94","category_id":"clt19858x00247svw2vuk6md5","_id":"clv5ccx7j000ausvw0rkw8y20"},{"post_id":"cltfntnt4000bccvwdcwkc2i5","category_id":"clt19858y002a7svw8ortfswl","_id":"clv5ccx7m000fusvweh8z4peb"},{"post_id":"clv5ccx7k000busvwd22mc89k","category_id":"clt19859l005m7svwgbh2001y","_id":"clv5ccx7n000husvw9udlghr7"},{"post_id":"clv5ccx7k000dusvw79eogoff","category_id":"clt19859l005m7svwgbh2001y","_id":"clv5ccx7o000jusvw1szye464"},{"post_id":"clv5ccx7t000lusvw4b8rg2vk","category_id":"clt19859l005m7svwgbh2001y","_id":"clv5ccx7u000ousvw67s7f8ku"}],"PostTag":[{"post_id":"clt19858600017svwbz9ab1ko","tag_id":"clt19858c00057svw5socdwo1","_id":"clt19858k000m7svwdq0aadbe"},{"post_id":"clt19858600017svwbz9ab1ko","tag_id":"clt19858e00097svwbkj9cnuc","_id":"clt19858l000o7svw0wpu9ryl"},{"post_id":"clt19858600017svwbz9ab1ko","tag_id":"clt19858g000e7svw8ms14ylz","_id":"clt19858m000t7svw2qeq9e75"},{"post_id":"clt19858f000c7svwc46oacgf","tag_id":"clt19858o00127svw5ywrbmid","_id":"clt19858s001h7svw7h6rd27l"},{"post_id":"clt19858f000c7svwc46oacgf","tag_id":"clt19858q00197svw051ve9h0","_id":"clt19858s001j7svwcnik6ud5"},{"post_id":"clt19858g000f7svwcbxn9bg6","tag_id":"clt19858o00127svw5ywrbmid","_id":"clt19858u001s7svwayq74gar"},{"post_id":"clt19858g000f7svwcbxn9bg6","tag_id":"clt19858q00197svw051ve9h0","_id":"clt19858v001u7svw754l3jo9"},{"post_id":"clt19858i000h7svw6wjif9gf","tag_id":"clt19858o00127svw5ywrbmid","_id":"clt19858w001z7svwgxf697gn"},{"post_id":"clt19858j000j7svwgmhmezqj","tag_id":"clt19858o00127svw5ywrbmid","_id":"clt19858x00257svw77aa9yah"},{"post_id":"clt19858k000n7svwhg56ef2h","tag_id":"clt19858w00217svwciiv840w","_id":"clt19858y002b7svweg91bimz"},{"post_id":"clt19858m000u7svw5niw3s5n","tag_id":"clt198590002j7svw8592hmds","_id":"clt198593002v7svw4vw92q36"},{"post_id":"clt19858m000x7svw6rpk33n9","tag_id":"clt198592002q7svw9ftlgwrr","_id":"clt19859400327svw7d881t3q"},{"post_id":"clt19858o00137svw52io5ukv","tag_id":"clt198597003c7svw2skp7e4y","_id":"clt198599003p7svwhl28c7bc"},{"post_id":"clt19858p00177svwayrr2k2h","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859b003w7svwcc373j53"},{"post_id":"clt19858p00187svwgmhuc5m6","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859d00497svw3dc3areq"},{"post_id":"clt19858p00187svwgmhuc5m6","tag_id":"clt19859b00407svw729a22y5","_id":"clt19859e004d7svw550vdm5n"},{"post_id":"clt19858q001c7svw7w4h1ksm","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859f004h7svw0qa9ct2p"},{"post_id":"clt19858q001d7svw84r93fq2","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859h004u7svwdidk0xxo"},{"post_id":"clt19858q001d7svw84r93fq2","tag_id":"clt19859g004l7svw41857ly4","_id":"clt19859i004y7svwapj24a8u"},{"post_id":"clt19858r001g7svw4ucc11df","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859j00587svwdt9oddyu"},{"post_id":"clt19858r001g7svw4ucc11df","tag_id":"clt19859b00407svw729a22y5","_id":"clt19859k005b7svw4bn60ocm"},{"post_id":"clt19858r001g7svw4ucc11df","tag_id":"clt19859g004l7svw41857ly4","_id":"clt19859k005d7svwegsl12ok"},{"post_id":"clt19858s001i7svw6ut0ckf1","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859k005h7svwarxi4nds"},{"post_id":"clt19858s001i7svw6ut0ckf1","tag_id":"clt19859k005c7svwbzua870u","_id":"clt19859l005k7svwh5clc281"},{"post_id":"clt19858t001m7svw1i05c27h","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859m005s7svwd9s8g9tf"},{"post_id":"clt19858t001m7svw1i05c27h","tag_id":"clt19859k005c7svwbzua870u","_id":"clt19859n005v7svwh1j83zzn"},{"post_id":"clt19858t001m7svw1i05c27h","tag_id":"clt19859l005o7svw9shx9peu","_id":"clt19859n005x7svwchhngo6h"},{"post_id":"clt19858t001n7svwhp3g4dq9","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859o00617svwg1qzfdnf"},{"post_id":"clt19858t001n7svwhp3g4dq9","tag_id":"clt19859n005w7svw50cq436l","_id":"clt19859o00647svw4sow6syt"},{"post_id":"clt19858u001r7svw18abfw5j","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859q006e7svw0tvu0pbj"},{"post_id":"clt19858u001r7svw18abfw5j","tag_id":"clt19859k005c7svwbzua870u","_id":"clt19859r006f7svw1fug7g50"},{"post_id":"clt19858u001r7svw18abfw5j","tag_id":"clt19859p00687svwbyh60wax","_id":"clt19859r006j7svwfzukeomr"},{"post_id":"clt19858v001t7svw46o68o8s","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859s006q7svwc9g88qm5"},{"post_id":"clt19858v001t7svw46o68o8s","tag_id":"clt19859r006g7svw4dv2205q","_id":"clt19859s006r7svwdxjagtfd"},{"post_id":"clt19858v001t7svw46o68o8s","tag_id":"clt19859r006k7svwhw8r94ku","_id":"clt19859t006v7svwe8r232yp"},{"post_id":"clt19858v001y7svwc62p6b4u","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859t006z7svwcaoa7oyi"},{"post_id":"clt19858v001y7svwc62p6b4u","tag_id":"clt19859r006g7svw4dv2205q","_id":"clt19859t00707svw689h8qqa"},{"post_id":"clt19858w00207svwdai5axd1","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859u00777svwdaqncsos"},{"post_id":"clt19858w00207svwdai5axd1","tag_id":"clt19859r006g7svw4dv2205q","_id":"clt19859v00787svw2ohd8yyh"},{"post_id":"clt19858w00237svw3jg14gqt","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859w007h7svwctyw9y2e"},{"post_id":"clt19858w00237svw3jg14gqt","tag_id":"clt19859r006g7svw4dv2205q","_id":"clt19859w007i7svwholp2mrd"},{"post_id":"clt19858w00237svw3jg14gqt","tag_id":"clt19859v007c7svwd0eb1wea","_id":"clt19859w007l7svw45wk75ri"},{"post_id":"clt19858x00267svw4zvzc4ph","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859w007n7svw1xsx9gxr"},{"post_id":"clt19858x00267svw4zvzc4ph","tag_id":"clt19859w007k7svwayvz05pt","_id":"clt19859w007o7svwapex9l7f"},{"post_id":"clt19858y00287svwgftx5tbp","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859w007r7svwha7u7tl0"},{"post_id":"clt19858y00287svwgftx5tbp","tag_id":"clt19859w007p7svwb5ru2xxd","_id":"clt19859x007s7svwf6ojb4bh"},{"post_id":"clt19858y002c7svwe42s6xfp","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859x007w7svw3wjhcxgt"},{"post_id":"clt19858y002c7svwe42s6xfp","tag_id":"clt19859w007p7svwb5ru2xxd","_id":"clt19859x007x7svw07r1bbqu"},{"post_id":"clt19858y002c7svwe42s6xfp","tag_id":"clt19859x007u7svwgsl3gds9","_id":"clt19859x007z7svw4etiaoyj"},{"post_id":"clt19858z002e7svw34dx4x8j","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859y00827svwh9e56bwe"},{"post_id":"clt19858z002e7svw34dx4x8j","tag_id":"clt19859w007p7svwb5ru2xxd","_id":"clt19859y00837svwgfbyfufl"},{"post_id":"clt19858z002e7svw34dx4x8j","tag_id":"clt19859x00807svw0d7z36na","_id":"clt19859y00857svwc6c43v7o"},{"post_id":"clt198590002i7svwbmdj8uh3","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859y00867svw5d3xbsbz"},{"post_id":"clt198590002k7svw9qcp94qn","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859y008a7svwatuu9jfu"},{"post_id":"clt198590002k7svw9qcp94qn","tag_id":"clt19859w007p7svwb5ru2xxd","_id":"clt19859y008b7svwh1tn0tem"},{"post_id":"clt198590002k7svw9qcp94qn","tag_id":"clt19859y00887svw230dd67i","_id":"clt19859z008d7svw4mnk2zyj"},{"post_id":"clt198591002n7svw3f22ckr2","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859z008f7svwcmkzd1qc"},{"post_id":"clt198591002n7svw3f22ckr2","tag_id":"clt19859y008c7svwd1zma8f6","_id":"clt19859z008g7svw3z6rezkm"},{"post_id":"clt198591002o7svw4y0w7q7b","tag_id":"clt198598003k7svwbkur4mym","_id":"clt19859z008k7svwdk6i4c5m"},{"post_id":"clt198591002o7svw4y0w7q7b","tag_id":"clt19859y008c7svwd1zma8f6","_id":"clt19859z008l7svwe5fh74ck"},{"post_id":"clt198591002o7svw4y0w7q7b","tag_id":"clt19859z008i7svwdx7de25a","_id":"clt19859z008n7svwhz61c1p0"},{"post_id":"clt198592002s7svw8mtre56y","tag_id":"clt198598003k7svwbkur4mym","_id":"clt1985a0008p7svw34gp57td"},{"post_id":"clt198592002s7svw8mtre56y","tag_id":"clt19859y008c7svwd1zma8f6","_id":"clt1985a0008q7svwg7qd3gsw"},{"post_id":"clt198593002w7svwhs8d44d6","tag_id":"clt198598003k7svwbkur4mym","_id":"clt1985a0008u7svwd4tue050"},{"post_id":"clt198593002w7svwhs8d44d6","tag_id":"clt19859y008c7svwd1zma8f6","_id":"clt1985a0008v7svwaahb5won"},{"post_id":"clt198593002w7svwhs8d44d6","tag_id":"clt1985a0008s7svw9aq8d8mg","_id":"clt1985a0008x7svwh0wdf1eg"},{"post_id":"clt198594002z7svw8g4v3cm8","tag_id":"clt19858c00057svw5socdwo1","_id":"clt1985a1008z7svwfdc64qpa"},{"post_id":"clt198594002z7svw8g4v3cm8","tag_id":"clt1985a0008t7svwa63670f8","_id":"clt1985a100907svw90exbxi1"},{"post_id":"clt198594002z7svw8g4v3cm8","tag_id":"clt1985a0008w7svwgqwv3md7","_id":"clt1985a100927svw0uzz5dw0"},{"post_id":"clt19859500337svw2fvh2hie","tag_id":"clt19858c00057svw5socdwo1","_id":"clt1985a100947svwglra1cb2"},{"post_id":"clt19859500337svw2fvh2hie","tag_id":"clt1985a0008t7svwa63670f8","_id":"clt1985a100957svw34xrf5my"},{"post_id":"clt19859500337svw2fvh2hie","tag_id":"clt1985a0008w7svwgqwv3md7","_id":"clt1985a100977svwakbc1ec1"},{"post_id":"clt19859500367svwdjqlc04r","tag_id":"clt19858c00057svw5socdwo1","_id":"clt1985a200997svwd8b03gq1"},{"post_id":"clt19859500367svwdjqlc04r","tag_id":"clt1985a0008t7svwa63670f8","_id":"clt1985a2009a7svw74k66cjc"},{"post_id":"clt19859500367svwdjqlc04r","tag_id":"clt1985a0008w7svwgqwv3md7","_id":"clt1985a2009c7svw6lzhfnqh"},{"post_id":"clt198596003a7svwfjbi5qs4","tag_id":"clt19858c00057svw5socdwo1","_id":"clt1985a2009e7svw9usmhj1p"},{"post_id":"clt198596003a7svwfjbi5qs4","tag_id":"clt1985a0008t7svwa63670f8","_id":"clt1985a2009f7svw9rsd96zg"},{"post_id":"clt198596003a7svwfjbi5qs4","tag_id":"clt1985a0008w7svwgqwv3md7","_id":"clt1985a2009h7svwe92mdw0h"},{"post_id":"clt198597003d7svwe022ejo4","tag_id":"clt19858c00057svw5socdwo1","_id":"clt1985a2009j7svw433oh68b"},{"post_id":"clt198597003d7svwe022ejo4","tag_id":"clt1985a0008t7svwa63670f8","_id":"clt1985a2009k7svw3gwh4x7z"},{"post_id":"clt198597003d7svwe022ejo4","tag_id":"clt1985a0008w7svwgqwv3md7","_id":"clt1985a3009m7svw3nxy4b9b"},{"post_id":"clt198597003g7svw406y8gbv","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a3009o7svw4tyo6apn"},{"post_id":"clt198597003g7svw406y8gbv","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a3009p7svw8pum972h"},{"post_id":"clt198598003i7svw6mtscg67","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a3009s7svwdidefm5j"},{"post_id":"clt198598003i7svw6mtscg67","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a3009t7svw7v5h9ejp"},{"post_id":"clt198599003n7svwe3sfglra","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a4009w7svwbaq9a5ck"},{"post_id":"clt198599003n7svwe3sfglra","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a4009x7svwc5ktcyj1"},{"post_id":"clt198599003q7svwchg57j21","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a400a07svw4ugj5ejn"},{"post_id":"clt198599003q7svwchg57j21","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a400a17svwfe915mfv"},{"post_id":"clt19859a003u7svwa9j9h6le","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a400a47svw5ucpgll9"},{"post_id":"clt19859a003u7svwa9j9h6le","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a500a57svw3rd0eyq3"},{"post_id":"clt19859b003x7svwd94ndbvi","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a500a87svw8nxl8wgj"},{"post_id":"clt19859b003x7svwd94ndbvi","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a500a97svw11ylg2pm"},{"post_id":"clt19859c00417svwf55tbtmz","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a500ac7svw08m5592b"},{"post_id":"clt19859c00417svwf55tbtmz","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a500ad7svw5otjhxv0"},{"post_id":"clt19859c00437svw41olhu0f","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a600ag7svwajb6afyl"},{"post_id":"clt19859c00437svw41olhu0f","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a600ah7svwehr9h7r4"},{"post_id":"clt19859d00477svwbit3es0h","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a600ak7svwa8xv8osu"},{"post_id":"clt19859d00477svwbit3es0h","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a600al7svw1178hyeo"},{"post_id":"clt19859e004a7svw07ww6ao9","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a700ao7svw7itfav76"},{"post_id":"clt19859e004a7svw07ww6ao9","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a700ap7svw9w382i2a"},{"post_id":"clt19859e004f7svwd2g02hpy","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a700as7svwgxr86c5y"},{"post_id":"clt19859e004f7svwd2g02hpy","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a700at7svwfhw91fs4"},{"post_id":"clt19859f004i7svw9j87ajzi","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a700aw7svwfzvzcczr"},{"post_id":"clt19859f004i7svw9j87ajzi","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a800ax7svw9eeoc1ll"},{"post_id":"clt19859g004m7svw09gyfooa","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a800b07svw6vtsfy5b"},{"post_id":"clt19859g004m7svw09gyfooa","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a800b17svw4ehi8op2"},{"post_id":"clt19859g004o7svw06xnefkl","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a800b47svw1nvxfajp"},{"post_id":"clt19859g004o7svw06xnefkl","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a800b57svw82d44fdk"},{"post_id":"clt19859h004s7svwat2y487d","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a900b87svwfwjx2v3q"},{"post_id":"clt19859h004s7svwat2y487d","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a900b97svw2w4r049h"},{"post_id":"clt19859h004v7svwgw1j3zxp","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a900bc7svw5w3p1dv7"},{"post_id":"clt19859h004v7svwgw1j3zxp","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a900bd7svwcfbpbf0r"},{"post_id":"clt19859i00507svw17qo18o4","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985a900bf7svw495nevul"},{"post_id":"clt19859i00507svw17qo18o4","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985a900bg7svw8ky0ew91"},{"post_id":"clt1985ac00bh7svw0op4f2nr","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985ad00bj7svwd1ck56n8"},{"post_id":"clt1985ac00bh7svw0op4f2nr","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985ad00bl7svwa73e0f29"},{"post_id":"clt1985ac00bi7svwbxeegipm","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1985ad00bn7svwb33g2035"},{"post_id":"clt1985ac00bi7svwbxeegipm","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1985ad00bp7svwhe162p0b"},{"post_id":"clt1985ad00bk7svw8hgr6ppg","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clt1cimmr00005gvw7twwck07"},{"post_id":"clt1985ad00bk7svw8hgr6ppg","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clt1cimmr00015gvw62hc5098"},{"post_id":"clt8fmx0e0000mkvw4n8t3fts","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"clt8fmx0s0006mkvwfp4oau9y"},{"post_id":"clt8fmx0e0000mkvw4n8t3fts","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"clt8fmx0s0007mkvw40m1e7in"},{"post_id":"clt8fmx0e0000mkvw4n8t3fts","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"clt8fmx0s0008mkvwabyqgij0"},{"post_id":"clta2pezx0000zovw6hix76mc","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf040002zovwev87bpw7"},{"post_id":"clta2pf020001zovw9w1nf0iw","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf050004zovw36yx4uxu"},{"post_id":"clta2pf040003zovw0vqq7bqr","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf060007zovw4b6b0525"},{"post_id":"clta2pf050005zovw7hhnb1r6","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf07000azovwdpwf32ye"},{"post_id":"clta2pf060008zovw0duzbzc8","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf08000dzovwac6dg55d"},{"post_id":"clta2pf07000bzovwe05igf5i","tag_id":"clt19858j000i7svweq345fct","_id":"clta2pf08000fzovw8mnoggg4"},{"post_id":"cltfntnsz0000ccvw41iu1cn9","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfntnt10002ccvw4dowbmsx"},{"post_id":"cltfntnsz0000ccvw41iu1cn9","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfntnt20004ccvw3muag8u9"},{"post_id":"cltfntnsz0000ccvw41iu1cn9","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfntnt30007ccvw95v32r9j"},{"post_id":"cltfntnt00001ccvwb6an9pjh","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfntnt4000accvwgp581xzp"},{"post_id":"cltfntnt00001ccvwb6an9pjh","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfntnt5000dccvw229p0xrq"},{"post_id":"cltfntnt00001ccvwb6an9pjh","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfntnt6000fccvw6fushtgs"},{"post_id":"cltfntnt10003ccvwfyr14vy1","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfntnt6000hccvwa0yj653d"},{"post_id":"cltfntnt10003ccvwfyr14vy1","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfntnt6000iccvw7eua3hif"},{"post_id":"cltfntnt10003ccvwfyr14vy1","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfntnt6000jccvwefzneh9m"},{"post_id":"cltfntnt20005ccvwetgrbrzt","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfntnt6000kccvw7phpg8l3"},{"post_id":"cltfntnt20005ccvwetgrbrzt","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfntnt6000lccvwdhzebiqu"},{"post_id":"cltfntnt20005ccvwetgrbrzt","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfntnt6000mccvwg7vkbfv8"},{"post_id":"cltfntnt30008ccvw3vo48p29","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfntnt6000nccvwf2vhhrzz"},{"post_id":"cltfntnt30008ccvw3vo48p29","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfntnt6000occvw3nv03rev"},{"post_id":"cltfntnt30008ccvw3vo48p29","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfntnt6000pccvw7b92b85z"},{"post_id":"cltfr696y000054vw667819si","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltfr6970000154vw4zssdjg8"},{"post_id":"cltfr696y000054vw667819si","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltfr6970000254vw8x35eq9k"},{"post_id":"cltfr696y000054vw667819si","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltfr6970000454vwgl6se09g"},{"post_id":"cltmv05yy0001lkvw6f4jcvff","tag_id":"clt19858j000i7svweq345fct","_id":"cltmv05z90004lkvw5xiw3oy7"},{"post_id":"cltmv05yw0000lkvw5mfe7u66","tag_id":"cltmv05z70003lkvw8d9v4l9n","_id":"cltmv05zb0008lkvw2wca9aaj"},{"post_id":"clt19858l000q7svw9jkp1hfm","tag_id":"cltmv05za0007lkvw2lspgpze","_id":"cltmv05zd000clkvw4fkm4jky"},{"post_id":"cltmv05z90005lkvwbmmb6maz","tag_id":"cltmv05zc000blkvwhb6hcc2w","_id":"cltmv05zg000ilkvw9tp47p3r"},{"post_id":"cltmv05zg000hlkvw3y8h0yn2","tag_id":"clt8fmx0p0002mkvw6cqgd9l0","_id":"cltmv05zh000jlkvw08qogcu6"},{"post_id":"cltmv05zg000hlkvw3y8h0yn2","tag_id":"clt8fmx0r0003mkvw53875qy8","_id":"cltmv05zh000klkvw7yc70dzj"},{"post_id":"cltmv05zg000hlkvw3y8h0yn2","tag_id":"clt8fmx0s0005mkvw2gmiea92","_id":"cltmv05zh000mlkvw4tkqdwys"},{"post_id":"cltod2agt000050vwd1rrfdto","tag_id":"clt19858j000i7svweq345fct","_id":"cltod2agw000150vw0q3hgy2n"},{"post_id":"cltmv05zd000dlkvw4nr3cy57","tag_id":"cltod2ah5000350vw2yw84tok","_id":"cltod2ah6000550vw7apdawa3"},{"post_id":"cltod2ah7000750vwfj9o5gdr","tag_id":"cltod2ah5000350vw2yw84tok","_id":"cltod2ah8000850vwf3e2crhn"},{"post_id":"cltwpq3va000038vw2mf7bg3v","tag_id":"clt198594002y7svwcw3l3vto","_id":"cltwpq3vg000238vwh1kjambq"},{"post_id":"cltwpq3vg000338vw0lct49bb","tag_id":"clt198594002y7svwcw3l3vto","_id":"cltwpq3vr000738vw74jx82o3"},{"post_id":"cltwpq3vq000538vwgdld38mn","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"cltwpq3vs000938vw95smbzqv"},{"post_id":"cltwpq3vq000538vwgdld38mn","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"cltwpq3vs000b38vw2yk46m3l"},{"post_id":"cltwpq3ve000138vw3rl5awse","tag_id":"cltwpq3vh000438vw9eec3i79","_id":"cltwpq3vs000d38vwdaso4tac"},{"post_id":"cltwpq3vw000f38vwccze88c2","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"cltwpq3vw000g38vwbhgtdc1f"},{"post_id":"cltwpq3vw000f38vwccze88c2","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"cltwpq3vw000h38vwayia985e"},{"post_id":"clv5ccx760000usvwg4r7hn5m","tag_id":"cltmv05z70003lkvw8d9v4l9n","_id":"clv5ccx7d0002usvw97ql4ayn"},{"post_id":"clv5ccx7b0001usvw2gi046cq","tag_id":"cltmv05z70003lkvw8d9v4l9n","_id":"clv5ccx7e0004usvwghv43szz"},{"post_id":"clv5ccx7d0003usvwfra8atrh","tag_id":"cltmv05z70003lkvw8d9v4l9n","_id":"clv5ccx7f0006usvw30gl938w"},{"post_id":"cltwpq3vv000e38vwede8hw94","tag_id":"clt198594002y7svwcw3l3vto","_id":"clv5ccx7i0009usvwgm6wczjx"},{"post_id":"cltfntnt4000bccvwdcwkc2i5","tag_id":"clt19859500357svw20efbwjs","_id":"clv5ccx7k000cusvwgtxj8i9r"},{"post_id":"clv5ccx7k000busvwd22mc89k","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clv5ccx7l000eusvw8s7y7dvg"},{"post_id":"clv5ccx7k000busvwd22mc89k","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clv5ccx7m000gusvw7oksdyhj"},{"post_id":"clv5ccx7k000dusvw79eogoff","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clv5ccx7n000iusvwfdk944od"},{"post_id":"clv5ccx7k000dusvw79eogoff","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clv5ccx7p000kusvwavsd2zbi"},{"post_id":"clv5ccx7t000lusvw4b8rg2vk","tag_id":"clt1985a2009i7svw6j5dgwdq","_id":"clv5ccx7u000musvw1oan6tly"},{"post_id":"clv5ccx7t000lusvw4b8rg2vk","tag_id":"clt1985a2009l7svwdivb4xnl","_id":"clv5ccx7u000nusvwdpetcamz"}],"Tag":[{"name":"深度学习","_id":"clt19858c00057svw5socdwo1"},{"name":"DDPM","_id":"clt19858e00097svwbkj9cnuc"},{"name":"生成模型","_id":"clt19858g000e7svw8ms14ylz"},{"name":"Linux","_id":"clt19858j000i7svweq345fct"},{"name":"博客","_id":"clt19858o00127svw5ywrbmid"},{"name":"hexo","_id":"clt19858q00197svw051ve9h0"},{"name":"微信小程序","_id":"clt19858w00217svwciiv840w"},{"name":"其他","_id":"clt19858y00277svwfh7bc81n"},{"name":"pycharm","_id":"clt198590002j7svw8592hmds"},{"name":"vscode","_id":"clt198592002q7svw9ftlgwrr"},{"name":"算法，排序","_id":"clt198594002y7svwcw3l3vto"},{"name":"经验","_id":"clt19859500357svw20efbwjs"},{"name":"kaggle","_id":"clt198597003c7svw2skp7e4y"},{"name":"数据结构","_id":"clt198598003k7svwbkur4mym"},{"name":"栈","_id":"clt19859b00407svw729a22y5"},{"name":"队列","_id":"clt19859g004l7svw41857ly4"},{"name":"线性表","_id":"clt19859k005c7svwbzua870u"},{"name":"单链表","_id":"clt19859l005o7svw9shx9peu"},{"name":"串","_id":"clt19859n005w7svw50cq436l"},{"name":"双链表","_id":"clt19859p00687svwbyh60wax"},{"name":"树","_id":"clt19859r006g7svw4dv2205q"},{"name":"二叉树","_id":"clt19859r006k7svwhw8r94ku"},{"name":"哈夫曼树","_id":"clt19859v007c7svwd0eb1wea"},{"name":"并查集","_id":"clt19859w007k7svwayvz05pt"},{"name":"查找","_id":"clt19859w007p7svwb5ru2xxd"},{"name":"二叉排序树","_id":"clt19859x007u7svwgsl3gds9"},{"name":"平衡二叉树","_id":"clt19859x00807svw0d7z36na"},{"name":"B树","_id":"clt19859y00887svw230dd67i"},{"name":"图","_id":"clt19859y008c7svwd1zma8f6"},{"name":"最短路径","_id":"clt19859z008i7svwdx7de25a"},{"name":"最小生成树","_id":"clt1985a0008s7svw9aq8d8mg"},{"name":"论文","_id":"clt1985a0008t7svwa63670f8"},{"name":"超分","_id":"clt1985a0008w7svwgqwv3md7"},{"name":"机器学习","_id":"clt1985a2009i7svw6j5dgwdq"},{"name":"pytorch","_id":"clt1985a2009l7svwdivb4xnl"},{"name":"生产实习","_id":"clt8fmx0p0002mkvw6cqgd9l0"},{"name":"java","_id":"clt8fmx0r0003mkvw53875qy8"},{"name":"springboot","_id":"clt8fmx0s0005mkvw2gmiea92"},{"name":"python","_id":"cltmv05z70003lkvw8d9v4l9n"},{"name":"Windows","_id":"cltmv05za0007lkvw2lspgpze"},{"name":"键盘","_id":"cltmv05zc000blkvwhb6hcc2w"},{"name":"windows","_id":"cltod2ah5000350vw2yw84tok"},{"name":"鼠标","_id":"cltwpq3vh000438vw9eec3i79"}]}}