{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 6.5 批量规范化\n",
    "date: 2024-4-22 14:00:00\n",
    "tags: [机器学习,pytorch]\n",
    "categories: [机器学习]\n",
    "comment: true\n",
    "toc: true\n",
    "---\n",
    "#\n",
    "<!--more-->\n",
    "# 5 批量规范化\n",
    "- 训练深层神经网络十分困难。批量规范化（batchnormalization）可持续加速深层网络的收敛速度。\n",
    "## 5.1 训练深层网络\n",
    "- 训练神经网络时出现的一些挑战：\n",
    "    - 数据预处理的方式通常会对最终结果产生巨大影响。例如使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一。\n",
    "    - 中间层中的变量（例如，多层感知机中的仿射变换输出）可能具有更广的变化范围\n",
    "    - 更深层的网络很复杂，容易过拟合。这意味着正则化变得更加重要。\n",
    "- 批量规范化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，我们首先规范化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。接下来，我们应用比例系数和比例偏移。正是由于这个基于批量统计的标准化，才有了批量规范化的名称。\n",
    "- 如果使用大小为1的小批量应用批量规范化，我们将无法学到任何东西。这是因为在减去均值之后，每个隐藏单元将为0。所以，只有使用足够大的小批量，批量规范化这种方法才是有效且稳定的。请注意，在应用批量规范化时，批量大小的选择可能比没有批量规范化时更重要。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
