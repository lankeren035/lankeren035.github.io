{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 12.2 微调\n",
    "date: 2024-8-12 12:00:00\n",
    "tags: [机器学习,pytorch]\n",
    "categories: [机器学习]\n",
    "comment: true\n",
    "toc: true\n",
    "---\n",
    "\n",
    "#### \n",
    "\n",
    "<!--more-->\n",
    "\n",
    "# 2 微调\n",
    "\n",
    "\n",
    "## 2.1 步骤\n",
    "\n",
    "- 迁移学习中的常见技巧:微调:\n",
    "\n",
    "    - 在源数据集（例如ImageNet数据集）上预训练神经网络模型，即源模型。\n",
    "\n",
    "    - 创建一个新的神经网络模型，即目标模型。这将复制源模型上的所有模型设计及其参数（输出层除外）。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。\n",
    "\n",
    "    - 向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。\n",
    "\n",
    "    - 在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。\n",
    "\n",
    "![](../../../../../../themes/yilia/source/img/deeplearning/code/pytorch/12_computer_vision/2_finetune/1.png)\n",
    "![](img/deeplearning/code/pytorch/12_computer_vision/2_finetune/1.png)\n",
    "\n",
    "\n",
    "- 当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。\n",
    "\n",
    "## 2.2 热狗识别\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
