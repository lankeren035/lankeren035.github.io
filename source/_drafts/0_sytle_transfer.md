 Domain Adaption 指的是当训练数据和测试数据属于不同的域时，我们通过某种手段利用源域有标签的训练数据训练得到的模型，去预测无标签的测试数据所在的目标域中的数据。 

 Domain Adaption 其中一个套路就是以最小化统计分布差异度量 MMD 的方式，让目标域中的数据和源域中的数据建立起一种映射转换关系。 





 @Naiyan Wang 老师通过公式推导发现，最小化重建结果图和风格图的 Gram 统计量差异其实等价于最小化两个域统计分布之间的基于二阶核函数的 MMD。换言之，风格迁移的过程其实可以看做是让目标风格化结果图的特征表达二阶统计分布去尽可能地逼近风格图的特征表达二阶统计分布。 

 由此可以很自然地想到，既然是衡量统计分布差异，除了有二阶核函数的 MMD 外，其他的 MMD 核函数例如一阶线性核函数、高阶核函数、高斯核函数，也可能达到和 Gram 统计量类似的效果。实验证明也确实如此。这些计算风格特征的方式其实都是在特征表达（feature map）的所有 channel 上进行计算的。 

 除了这些贡献外， @Naiyan Wang 老师还提出了一个新的用 channel-wise 的 BN 统计量去对风格进行建模的方法，即利用 VGG 某些层的特征表达的每一个channel的均值和方差（channel-wise）来表示风格。 



 以往风格化算法在提取特征的时候都是在高层次的 CNN 特征空间（feature space）中完成的，虽然这样做的效果在感知效果上（perceptually）优于利用传统的在像素空间（pixel space）计算的特征，但由于特征空间是对图像的一种抽象表达，会不可避免丢失一些低层次的如边缘等的图形信息这会导致风格化结果图中有一些不是很漂亮的变形等。  



 在训练好的一个风格化网络基础上，只通过在 Instance Norlization 层上做一个仿射变换（他们起了个名字叫 **Conditional Instance Normalization**，简称 **CIN**），就可以得到一个具有完全不同风格的结果。  我们只需要把 CIN 层中仿射变换的很少的参数与每一个风格进行绑定，每个新风格只需要去训练这些参数，其余部分保持不变就 ok 了。  最后实验效果显著。但说实话这个有点类似科学发现的意味，CIN 层 work 的理由现在也没有严格的推导证明。一个大概的解释是 CIN 能够进行一种 style normalization，能够将图像中的风格直接 normalize 成另外一种风格。 