它的应用仍然主要局限于照片级真实感领域，因为现有方法严重依赖现实世界的 3D 数据或多视图 2D 捕获，使得卡通、动漫、游戏和虚拟世界等风格化场景得不到充分服务。

 3D GS 的简单扩展常常因风格纹理对齐不足、语义不连贯以及对抽象美学的适应性有限而失败。虽然最近的工作通过 2D 先验探索 3D GS 风格化（例如，VGG [60] 用于纹理传输 [12,40, 84]，CLIP [54] 用于语义指导 [34]），但它们对简单化特征提取和试错优化的依赖导致了碎片化的风格化、过度平滑的细节以及对象和场景之间的不一致结果。

StyleMe3D 引入了四个关键组件来解决这些风格化挑战，即动态风格评分蒸馏 (DSSD)、同时优化量表 (SOS)、对比风格描述符 (CSD) 和 3D 高斯质量评估 (3DG-QA)。

第一个利用 SD 潜在空间进行 3D GS 风格迁移的作品



- SSD损失：3dgs渲染出图，将图加噪到xt，然后输入给diffusion，预测噪声，拿噪声跟加噪用的噪声算loss，反向优化3dgs，逼迫3dgs出图逼近diffusion分布。 但是diffusion分布缺少3D信息，3d一致性不好
- 