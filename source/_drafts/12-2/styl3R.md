- 当前最先进的 3D 风格化方法通常涉及计算密集型测试时间优化，以将艺术特征转换为预训练的 3D 表示，通常需要密集的姿势输入图像

- 为了解决重建和风格化之间固有的解耦问题，我们引入了一种分支架构，将结构建模和外观着色分开，有效防止风格转换扭曲底层的 3D 场景结构
- 采用身份损失来促进通过新颖的视图合成任务来预训练我们的风格化模型。
- 这一困难源于风格转移和 3D 重建之间的根本不匹配：改变视觉外观以反映所需的风格通常与在重建场景中保持多视图一致性和结构连贯性的需要相冲突。
- 虽然 2D 图像风格迁移 [8,11,19] 已经实现了令人印象深刻的效率和视觉保真度，但天真地将这些技术扩展到 3D 通常会导致视图不一致的风格化。
- 最近的 3D 风格化方法 [7,22,23,51] 提供了改进的外观一致性，但依赖于密集的多视图输入、已知的相机姿势以及耗时的每个场景或每个风格的优化。
- 我们如何从一些未摆出姿势的内容图像和任意风格的图像中实现快速、多视图一致的 3D 风格化，而不需要测试时优化？
- 我们提出了 Styl3R，这是一种前馈网络，可以根据稀疏的、无相机pose的内容图像和任意风格的图像联合重建 3D 场景并对其进行风格化。我们的方法可以灵活地处理 2 到 8 个输入内容图像，无需测试时优化，无需相机监督，也无需针对特定场景或风格进行微调，使其既实用又易于实际使用。